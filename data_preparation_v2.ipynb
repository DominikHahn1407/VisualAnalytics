{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.applications import vgg16, inception_v3, resnet, xception\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(target_size):\n",
    "    x, y = [], []\n",
    "    base_path = \"./data/images/\"\n",
    "\n",
    "    for dir in os.listdir(base_path):\n",
    "        for image in os.listdir(os.path.join(base_path, dir)):\n",
    "            image_path = os.path.join(base_path, dir, image)\n",
    "            image = Image.open(image_path)\n",
    "            rgb_image = image.copy().convert(\"RGB\")\n",
    "            x.append(np.array(rgb_image.resize(target_size), dtype=np.uint8))\n",
    "            y.append(dir)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"./data/metadata.csv\")\n",
    "meta_filter = metadata[[\"Channel\", \"Category\"]]\n",
    "meta_filter = meta_filter.drop_duplicates()\n",
    "meta_dict = meta_filter.set_index(\"Channel\")[\"Category\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: Abroad in Japan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[100])\n",
    "print(f\"class: {y[100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tech,Comedy', 'Entertainment,Comedy', 'Informative', 'Blog', 'Blog,Comedy', 'Food,Entertainment', 'Tech', 'Comedy,Informative', 'Entertainment', 'Food', 'Blog,Science', 'Comedy,Entertainment', 'Comedy', 'News', 'Entertainment,Blog', 'Science', 'Blog,Entertainment', 'VideoGames', 'Tech,Informative', 'Tech,News', 'Automobile', 'Automobile,Comedy'}\n"
     ]
    }
   ],
   "source": [
    "print(set(meta_dict.values()))\n",
    "\n",
    "coarse_dict = {\n",
    "    'automotive': ['Automobile,Comedy', 'Automobile'],\n",
    "    'blog': ['Blog,Comedy', 'Blog,Entertainment', 'Blog', 'Blog,Science'],\n",
    "    'comedy': ['Comedy', 'Comedy,Informative', 'Comedy,Entertainment'],\n",
    "    'entertainment': ['Entertainment,Blog', 'Entertainment,Comedy', 'Entertainment'],\n",
    "    'food': ['Food', 'Food,Entertainment'],\n",
    "    'information': ['Science', 'News', 'Informative'],\n",
    "    'technology': ['VideoGames', 'Tech,Comedy', 'Tech,News', 'Tech,Informative', 'Tech'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fine = [meta_dict[item] for item in y]\n",
    "\n",
    "y_coarse = []\n",
    "for item in y_fine:\n",
    "    for key, value in coarse_dict.items():\n",
    "        if item in value:\n",
    "            y_coarse.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Fine: 2244 ---  Length Coarse: 2244\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length Fine: {len(y_fine)} ---  Length Coarse: {len(y_coarse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(y_fine):\n",
    "    print(f\"Fine: {item} --- Coarse: {y_coarse[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blog': 234, 'entertainment': 164, 'information': 660, 'comedy': 174, 'automotive': 261, 'technology': 513, 'food': 238}\n"
     ]
    }
   ],
   "source": [
    "set_y_coarse = set(y_coarse)\n",
    "count_dict = {}\n",
    "for item in set_y_coarse:\n",
    "    count_dict[item] = y_coarse.count(item)\n",
    "\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/Data/CSV/distribution_v2.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Category\", \"Count\"])\n",
    "    for category, occurence in count_dict.items():\n",
    "        writer.writerow([category, occurence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_coarse)\n",
    "y_one_hot = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "x = np.array(x)\n",
    "n_samples, width, height, n_channels = x.shape\n",
    "\n",
    "x_flat = x.reshape(n_samples, -1)\n",
    "\n",
    "x, y_one_hot = sm.fit_resample(x_flat, y_one_hot)\n",
    "x = x.reshape(-1, width, height, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automotive       660\n",
      "blog             660\n",
      "comedy           660\n",
      "entertainment    660\n",
      "food             660\n",
      "information      660\n",
      "technology       660\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_distribution = pd.DataFrame([le.classes_[np.argmax(line)] for line in y_one_hot])\n",
    "print(value_distribution.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 2956 --- Validation Size: 740 --- Test Size: 924\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_one_hot, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "\n",
    "print(f\"Train Size: {len(y_train)} --- Validation Size: {len(y_val)} --- Test Size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Sequential()\n",
    "custom_model.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=target_size+(3,)))\n",
    "custom_model.add(MaxPooling2D(pool_size=3))\n",
    "custom_model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "custom_model.add(MaxPooling2D(pool_size=3))\n",
    "custom_model.add(Flatten())\n",
    "custom_model.add(Dense(128, activation=\"relu\"))\n",
    "custom_model.add(Dropout(0.3))\n",
    "custom_model.add(Dense(len(le.classes_), activation=\"softmax\"))\n",
    "\n",
    "custom_model.compile(optimizer=Adam(learning_rate=1e-03), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 38s 820ms/step - loss: 1.8529 - accuracy: 0.2897 - val_loss: 1.7439 - val_accuracy: 0.3287 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 36s 797ms/step - loss: 1.6660 - accuracy: 0.3489 - val_loss: 1.6500 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 37s 823ms/step - loss: 1.5450 - accuracy: 0.4095 - val_loss: 1.6042 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 37s 810ms/step - loss: 1.4312 - accuracy: 0.4708 - val_loss: 1.5488 - val_accuracy: 0.4708 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 36s 800ms/step - loss: 1.3883 - accuracy: 0.5014 - val_loss: 1.5142 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 36s 797ms/step - loss: 1.3038 - accuracy: 0.5348 - val_loss: 1.4417 - val_accuracy: 0.4652 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 38s 837ms/step - loss: 1.2667 - accuracy: 0.5411 - val_loss: 1.4149 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 37s 818ms/step - loss: 1.1677 - accuracy: 0.5787 - val_loss: 1.4619 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 36s 787ms/step - loss: 1.0906 - accuracy: 0.5947 - val_loss: 1.4536 - val_accuracy: 0.5042 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 35s 774ms/step - loss: 1.0468 - accuracy: 0.6170 - val_loss: 1.6066 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 35s 767ms/step - loss: 0.9836 - accuracy: 0.6330 - val_loss: 1.4568 - val_accuracy: 0.5181 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 35s 769ms/step - loss: 0.9072 - accuracy: 0.6741 - val_loss: 1.4350 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 35s 772ms/step - loss: 0.8360 - accuracy: 0.7047 - val_loss: 1.4143 - val_accuracy: 0.5237 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 36s 792ms/step - loss: 0.7742 - accuracy: 0.7166 - val_loss: 1.4366 - val_accuracy: 0.5265 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 36s 802ms/step - loss: 0.7543 - accuracy: 0.7298 - val_loss: 1.4623 - val_accuracy: 0.5348 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 36s 807ms/step - loss: 0.7275 - accuracy: 0.7423 - val_loss: 1.4781 - val_accuracy: 0.5320 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 36s 807ms/step - loss: 0.7207 - accuracy: 0.7458 - val_loss: 1.4750 - val_accuracy: 0.5376 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 37s 810ms/step - loss: 0.7458 - accuracy: 0.7284 - val_loss: 1.4335 - val_accuracy: 0.5404 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 36s 809ms/step - loss: 0.7144 - accuracy: 0.7500 - val_loss: 1.4392 - val_accuracy: 0.5404 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 37s 815ms/step - loss: 0.6887 - accuracy: 0.7611 - val_loss: 1.4456 - val_accuracy: 0.5460 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)\n",
    "\n",
    "history = custom_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    ")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 88ms/step\n",
      "Accuracy of 45.66%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x10b8de36fd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAIGCAYAAABJZbv3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAACdWUlEQVR4nOzdd3gUVdvH8e9ueg8JpEEglFBCC53QEQFBEQSRTmgiIl2qIE2kKRCKD01KRBAVUFGRXqT3JoReEmmhJpCQhGTn/YOXlSUBkuyG2V3uz3Pt9bhnZmd/Q5LNnXPOnNEoiqIghBBCCCFeSKt2ACGEEEIISyBFkxBCCCFEJkjRJIQQQgiRCVI0CSGEEEJkghRNQgghhBCZIEWTEEIIIUQmSNEkhBBCCJEJtmoHEJZBp9Nx9epV3Nzc0Gg0ascRQgiRRYqicP/+fQICAtBqc67PJCkpiZSUFKOPY29vj6OjowkSmY4UTSJTrl69SmBgoNoxhBBCGCkmJoZ8+fLlyLGTkpLwdnImEePXzfbz8+PixYtmVThJ0SQyxc3NDYCL/d/H3cFO5TSmo23VQ+0IJqdx8VA7gklp3LzUjmByuvNH1I5gcsqpw2pHMDlt1QZqRzCp+AcJ5K/6pv7zPCekpKSQiEI7XLAn+6MSKSgsvX6dlJQUKZqE5XkyJOfuYIe7g73KaUxH6+aqdgST07jk3AeiGjTu7mpHMDmdq4vaEUxOcTafX2ymYo2fD8ArmWLhiMaooslcJ1xL0SSEEEIIk9KiQWtEcaY107vimmsxJ4QQQggLpTXBIytGjx6NRqMxePj5+em3K4rC6NGjCQgIwMnJiTp16nDixIlsnZcQQgghhEUrWbIk165d0z+OHz+u3zZ58mSmTp3KrFmz2L9/P35+ftSvX5/79+9n6T1keE4IIYQQJqXRgNaIqVMaAAXi4+MN2h0cHHBwcMjwNba2tga9S08oikJERATDhw+nefPmAERGRuLr68uyZcv46KOPMp1LepqEEEIIYVKmGp4LDAzEw8ND/5gwYcJz3/Ps2bMEBARQsGBBWrduzYULFwC4ePEi169fp0GD/66GdHBwoHbt2uzatStL5yU9TUIIIYQwSzExMbg/dQXt83qZqlSpwnfffUfRokW5ceMG48aNo1q1apw4cYLr168D4Ovra/AaX19fLl++nKU8UjQJIYQQwqS0GiOvngNQwN3d3aBoep5GjRrp/7t06dKEhYVRuHBhIiMjqVq1KpB+qQVFUbK8/IIMzwkhhBDCpF711XPPcnFxoXTp0pw9e1Y/z+lJj9MTsbGx6XqfXkaKJiGEEEJYleTkZKKiovD396dgwYL4+fmxYcMG/faUlBS2bdtGtWrVsnRcGZ4TQgghhElpjbx6Lqs9OgMHDqRJkybkz5+f2NhYxo0bR3x8POHh4Wg0Gvr168f48eMJDg4mODiY8ePH4+zsTNu2bbP0PlI0CSGEEMKkjB1iy+pr//33X9q0acOtW7fIkycPVatWZc+ePRQoUACAwYMH8/DhQ3r27Mndu3epUqUK69evz/J9+KRoEkIIIYRFW758+Qu3azQaRo8ezejRo416HymahBBCCGFST25lku3XmzCLKUnRJIQQQgiTetXDc6+KFE1CCCGEMKlXPRH8VTHXXEIIIYQQZkV6moQQQghhUhqM65WROU1CCCGEeC2Y5DYqZkiKJqGKddtPc/TUFW7ceoCdrQ2FAr1o+mYpfHM/XjMjLU3H75tPcuLcdW7fTcDRwY7ihXx4982SeLo5qZw+c0bUbsWdKzfStddq14zWY/q9+kA5YO2MBfw2YSZ1u7Xlgy8Gqx3HKFvnRbIhYi5x12MJKFGUlpNHEVy9itqxsiUp4SG/f7OUo1v2cv9OHPmKFaTl4G4ElQpWO1qmnI26zMY/9hBz8Rpx9x7QvX9LylYqZrDP9Su3+PWHTZyNikZRFPzz5aFrn+Z45fZQKXXW3bt+k18mfMOJrXtISUrGt1B+2k8eRoHSxdWOJp5DiiYLFRQURL9+/ejXr5/aUbLl3OWb1KpUmAIBuUjTPS6QZn2/gxE96+Ngb0vKozRirt+jUa3i5PX1IDHpESvXHmXuD7sZ0v0NteNnypBVc9Hp0vTPr525yIzwgZRvVFvFVKZz6cg/7Ph+JXlDiqodxWgHVqzm58FjaBPxJYWrVmT7gqXMeq8jow5uxiswr9rxsuz7MbO4di6a8HH98Mjjxb4/tzKjxyhGrpyJp6+32vFeKiX5EfkK+BBWuyzzI1ak237zxh2mjokkrE4ob79fGycnB65fvYWdneX8SkuIi+erFh9RLKw8vSKn4uadi5uXr+Ds7qp2NJOw1qvnzDWXahYvXoynp6faMfSel2f//v1079791QcykU/a16BqaAH8fdzJ5+dJ+6YVuBv3kJhr9wBwcrSjd4calC+ZD9/cbhTM50XLRmWJuXaPO3GJ6obPJDdvTzzyeOsfx7fsJk/+AIKrhKodzWhJCYks+uQz2n09EmePrK2oa442zpxP9fBW1OjUBv/iwXzw1Why5Qtg2/wlakfLspSkZI5s2k2zfuEEVyiJT35/3vm4DbkDfPj757Vqx8uUkqFFaPJBXUIrZ9zj8vuPWwkJLcx7besRGORHbt9clCoXjJuHyytOmn3rZ39PLn9fOn49gqDQELwD/SleoyJ5CuRTO5pJPLl6zpiHOZKiyULlyZMHZ2dntWOYTFLyIwCcneyeu8/D5FQ0PC6oLE1qyiP2/baBsPcbG7Xgm7lYPmw8perVpEStqmpHMVpqSgrRh49Tol4tg/YSb9Tiwt4DKqXKPl2aDl2aDjsHw58TO0cHzh8+qVIq09HpFP45cg5fP29mTVjGkB5Tmfz5Qo7uP612tCw5tmEHBcoUZ/7HwxlUvjFfNgpnxw+/qR1LvITVFU1r166lRo0aeHp64u3tzTvvvMP58+cB2Lp1KxqNhnv37un3P3LkCBqNhkuXLrF161Y6d+5MXFycfjXTJ0uu3717l44dO5IrVy6cnZ1p1KgRZ8+e1R/nSY/QH3/8QbFixXB2dub9998nISGByMhIgoKCyJUrF7179yYt7b8hmxcd90V5goKCiIiIAKBNmza0bt3a4N/h0aNH5M6dm0WLFgGgKAqTJ0+mUKFCODk5UbZsWVasSN/trQZFUVi57hiF83sT4JPxfIRHqWn8tvEfKpYOxMnB8oqmoxt28DD+AVVbvKV2FKPt/3Ut0ceiaPZZH7WjmMSD23fQpaXh7pPHoN3dNzfxN26qlCr7HF2cKFimGH/N+4l7sY/Pbe+fW7l0/Axxt+6qHc9o9+MTSE5KYf3vuwgpW5heQ9sSWqkY8yN+5mzUZbXjZdqtmKv8/f0v5CkYSJ/vplGr/Xv8NGoae1b+pXY0k9Ca4GGOzDVXtiUkJDBgwAD279/Ppk2b0Gq1vPfee+h0upe+tlq1akRERODu7s61a9e4du0aAwcOBKBTp04cOHCA1atXs3v3bhRFoXHjxjx69Ej/+sTERGbMmMHy5ctZu3YtW7dupXnz5qxZs4Y1a9awZMkS5s2bZ1CsvOi4L8rztHbt2rF69WoePHigb1u3bh0JCQm0aNECgBEjRrBo0SJmz57NiRMn6N+/P+3bt2fbtm0Z/lskJycTHx9v8MgpP605ytUb8XRqUSnD7WlpOhat2IeiKHzwdmiO5chJu35eQ0itKnj65lY7ilHuXLnOz59Ppss347FzdFA7jkk92wOoKApYaK9gpy/7oQCfNehCn8ot2brsTyo2qoXWxvI/8hVFAaBMhaK80bgKgUF+NHi3OqXKBbN940GV02WeotORv2RRmg3uQWCpYtRs14zqbd7l7yWr1I5mElo0Rj/MkeXMmsukJ0XCEwsWLMDHx4eTJ1/eLW1vb4+HhwcajQY/Pz99+9mzZ1m9ejU7d+6kWrVqACxdupTAwEB+/fVXWrZsCTzu3Zk9ezaFCxcG4P3332fJkiXcuHEDV1dXQkJCqFu3Llu2bKFVq1aZOm5GeZ7VsGFDXFxc+OWXX+jQoQMAy5Yto0mTJri7u5OQkMDUqVPZvHkzYWFhABQqVIgdO3Ywd+5catdOPzF5woQJjBkz5qX/Zsb6ac0Rjp+5Rr9Otcjlnn64MS1Nx4IVe7l9L5HeHWtYZC/T7SvXObXrIN2/Gat2FKNFHzvJ/Vt3mNCwrb5Nl5bGuT2H2LboR2Ze3ofWxkbFhFnn6u2F1saGuBuxBu33Y2/j7mOZRW6eQH8GLPiS5IdJJD1IxCOPF98O/grvAF+1oxnN1c0ZrY0Wv7yGXxu/vLk5fzpGpVRZ5+HjjV9wQYM2vyJBHP5rqzqBRKZYXdF0/vx5Pv/8c/bs2cOtW7f0PUzR0dHZngMUFRWFra0tVar8d/mxt7c3xYoVIyoqSt/m7OysL5gAfH19CQoKwtXV1aAtNjY2S8d9GTs7O1q2bMnSpUvp0KEDCQkJ/PbbbyxbtgyAkydPkpSURP369Q1el5KSQrly5TI85rBhwxgwYID+eXx8PIGBgZnO9DKKovDzX0c5euoqfcNrkTtX+gmcTwqmm7cT6BNeE1dny+zZ2L3iL9y8PSlV1/Ln/xSvWYURWwyHdZf0G4lvkYI06NXZ4gomAFt7e/KXK03U5u2Ue7eRvj1qy3bKvt1AxWTGc3ByxMHJkcT4B0TtOsx7/cLVjmQ0W1sbChQK4Ma12wbtsdfuWNRyA4UqlOHGhWiDttiLMXjnff4fyJbEWm+jYnVFU5MmTQgMDGT+/PkEBASg0+koVaoUKSkp+uLlSfcuYDC89jxP7/9s+9Nd+nZ2hr0gGo0mw7YnhVxmj5sZ7dq1o3bt2sTGxrJhwwYcHR1p1OjxL4An7/fnn3+SN6/h5dMODhkXIg4ODs/dZgo/rTnCgeP/0r11VRwdbIl/kASAo4Md9nY2pOl0fPvzXmKu3aNHmzAURdHv4+xkj62FDDPodDr2rFxL1fcaYmNr+T9ujq4u5C1exKDN3tkJl1we6dotyZu9P2RRt34UKFeGQlUqsH3hUu7GXKFWt/ZqR8uWk7sOoygKvkF5uRl9jV+mLcY3KC9hTeupHS1TkpJSuHn9jv757Zv3iLl0HRdXJ7xye/DmO1VZOGMVwcXzExwSxMmj5zl+6Ax9R3RQMXXW1OvWiq+af8RfsyKp8E49Lh05yY5lv9FuwhC1o5mEtS45YPmf4k+5ffs2UVFRzJ07l5o1awKwY8cO/fY8eR5P9Lx27Rq5cuUCHk8Ef5q9vb3BRG2AkJAQUlNT2bt3r34Y7fbt25w5c4YSJUpkO29mjptRnoxUq1aNwMBAfvzxR/766y9atmyJvb29/n0cHByIjo7OcChODdsPXARgeuR2g/b2TStQNbQA9+Ifcvz0NQAmzt1ssE+f8JoUDTKctGuuTu08yJ2rNwhr2VjtKOIFKr7/Lg/u3OXPidOJvx5LQEgxeq2KxDu/ZV7+/fB+Ar/NXMK9G7dx9nCjXL0w3u3VDhsLWcco+sJVpo/7Xv985fcbAKhSqwwde7xLaKXitO7amPW/7eTnyPX4BHjTrd/7FCmeX63IWRZUNoQe8yby66TZrJmxiNz5/Gk5qi+V32uodjSTkJ4mC5ArVy68vb2ZN28e/v7+REdHM3ToUP32IkWKEBgYyOjRoxk3bhxnz55lypQpBscICgriwYMHbNq0ibJly+Ls7ExwcDBNmzblww8/ZO7cubi5uTF06FDy5s1L06ZNs503M8fNKE9Gw4wajYa2bdsyZ84czpw5w5YtW/Tb3NzcGDhwIP3790en01GjRg3i4+PZtWsXrq6uhIe/+i77WaOav3C7t6fLS/exBCE1K/G/c1vVjpGjBqxaoHYEk6jTPZw63S1/+AqgQsMaVGhYQ+0Y2VY0JIhvlo144T7V6oRSrU7oqwmUQ0rXq07petXVjiGywFyLuWzRarUsX76cgwcPUqpUKfr3789XX32l325nZ8cPP/zAqVOnKFu2LJMmTWLcuHEGx6hWrRo9evSgVatW5MmTh8mTJwOwaNEiKlSowDvvvENY2OPhojVr1qQbfsuqlx33eXky0q5dO06ePEnevHmpXt3wB/GLL75g5MiRTJgwgRIlStCwYUN+//13ChYs+JyjCSGEENnz+Ia92b9yzjyvnQON8ryJNUI8JT4+Hg8PD24PbYO7g73acUxG28E61hp6msbFU+0IJqVxN//bfmSV7qzlXBqfWcpJy1sI9GW01a1rWD3+/gM8S4URFxeHu7t7zrzH//+u+Mo5F06a7PfLPFR0DEq8m6NZs8OqepqEEEIIIXKKVc1pEkIIIYT65Oo5IYQQQohMsNar58w1lxBCCCGEWZGeJiGEEEKYlLH3j5N7zwkhhBDitSDDc0IIIYQQrzHpaRJCCCGESWn+/2HM682RFE1CCCGEMClrHZ6TokkIIYQQJmWtE8HNtZgTQgghhDAr0tMkhBBCCJOS4TkhhBBCiEzQYFzhY56Dc+ZbzAkhhBBCmBXpaRJCCCGEScmSA0IIIYQQmaDVaNBq5Oo5IYQQQojXkvQ0CSGEEMKkZHhOCCGEECITpGgSArDtOwlbd3e1Y5hM6uS+akcwOZu+E9SOIF7G1VPtBCanqfym2hFMTnmUonYEk7K281GDFE1CCCGEMCnpaRJCCCGEyASNRoPGiKvnNGZaNknRJIQQQgiTstaeJllyQAghhBAiE6SnSQghhBAmpcW4Xhlz7dGRokkIIYQQJqXRPH5k+/Wmi2JS5lrMCSGEEEKYFelpEkIIIYRJaf7/f8a83hxJ0SSEEEIIk5Kr54QQQgghXmPS0ySEEEIIk7LWniYpmoQQQghhUlpAa0Tlo1VMFsWkZHhOCCGEECITpKdJCCGEECYlV88JIYQQQmSSeZY9xpGiSQghhBAmZfSK4GZaccmcJiGEEEKITJCeJiGEEEKYlCw5IIQQQgiRCVo0aI0ofYx5bU6S4TkhhBBCiEyQniZhVrbOi2RDxFzirscSUKIoLSePIrh6FbVjZcq67ac5euoKN249wM7WhkKBXjR9sxS+ud0ASEvT8fvmk5w4d53bdxNwdLCjeCEf3n2zJJ5uTiqnz5y10+Zy5I/1XD97ATtHRwpXLkezUQPxCy6kdjSjWfL33rNG1G7FnSs30rXXateM1mP6vfpARrK28wHrPKenyfCceGXq1KlDaGgoERERGW4PCgqiX79+9OvX75XmymkHVqzm58FjaBPxJYWrVmT7gqXMeq8jow5uxiswr9rxXurc5ZvUqlSYAgG5SNM9LpBmfb+DET3r42BvS8qjNGKu36NRreLk9fUgMekRK9ceZe4PuxnS/Q2142fK2Z37qN21HQXKlUaXlsZv46Yxs0VXRu7+EwcXZ7XjZZulf+89a8iqueh0afrn185cZEb4QMo3qq1iquyztvMB6zynp8nVc0LksI0z51M9vBU1OrXBv3gwH3w1mlz5Atg2f4na0TLlk/Y1qBpaAH8fd/L5edK+aQXuxj0k5to9AJwc7ejdoQblS+bDN7cbBfN50bJRWWKu3eNOXKK64TOp94oFhLVtTkCJYPKVKk7HWRO48+9Voo+eUDuaUSz9e+9Zbt6eeOTx1j+Ob9lNnvwBBFcJVTtatljb+YB1npM5mTBhAhqNxqBzQVEURo8eTUBAAE5OTtSpU4cTJ7L22SVFkzALqSkpRB8+Tol6tQzaS7xRiwt7D6iUyjhJyY8AcHaye+4+D5NT0fC4oLJED+PvA+Ds6aFykuyzxu+9p6WmPGLfbxsIe78xGnP98z0LrO18wDrPSWOCR3bt37+fefPmUaZMGYP2yZMnM3XqVGbNmsX+/fvx8/Ojfv363L9/P9PHlqLJTKWmptKrVy88PT3x9vZmxIgRKErGdzCMjo6madOmuLq64u7uzgcffMCNG4Zj5ePGjcPHxwc3Nze6devG0KFDCQ0Nfe77JycnEx8fb/DISQ9u30GXloa7Tx6Ddnff3MTfuJmj750TFEVh5bpjFM7vTYBPxgXFo9Q0ftv4DxVLB+LkYHlFk6IorBgxgcJVK5A3pKjacbLN2r73nnV0ww4exj+gaou31I5iEtZ2PmCd56Qxwf+y48GDB7Rr14758+eTK1cufbuiKERERDB8+HCaN29OqVKliIyMJDExkWXLlmX6+FI0manIyEhsbW3Zu3cvM2bMYNq0aXz77bfp9lMUhWbNmnHnzh22bdvGhg0bOH/+PK1atdLvs3TpUr788ksmTZrEwYMHyZ8/P7Nnz37h+0+YMAEPDw/9IzAw0OTnmJFn/8pSFMV8B7df4Kc1R7l6I55OLSpluD0tTceiFftQFIUP3g59teFMZPngsVw5cYau86eqHcUkrOV771m7fl5DSK0qePrmVjuKSVjb+YB1npOpPPvHe3Jy8gv3/+STT3j77bd58803DdovXrzI9evXadCggb7NwcGB2rVrs2vXrkznkaLJTAUGBjJt2jSKFStGu3bt6N27N9OmTUu338aNGzl27BjLli2jQoUKVKlShSVLlrBt2zb2798PwMyZM+natSudO3emaNGijBw5ktKlS7/w/YcNG0ZcXJz+ERMTkyPn+YSrtxdaGxvibsQatN+PvY27j2V9kPy05gjHz1yjT3hNcrmnnxydlqZjwYq93L6XSK8ONSyyl+nHIV9w/K/N9F8dSa68fmrHMYo1fe896/aV65zadZDqH7ytdhSTsLbzAes8JwCtxvgHPP5d+PQf8BMmTHjuey5fvpyDBw9muM/169cB8PX1NWj39fXVb8vUeWV6T/FKVa1a1eAv37CwMM6ePUtaWprBflFRUQQGBhr0BIWEhODp6UlUVBQAp0+fpnLlygave/b5sxwcHHB3dzd45CRbe3vylytN1ObtBu1RW7ZTqErFHH1vU1EUhZ/WHOHoqav06ViT3Llc0u3zpGC6eTuBXh1q4OrsoELS7FMUheWDx3L4j/X0+y2S3AVeTQ9kTrKG773n2b3iL9y8PSlVt6raUUzC2s4HrPOcwHRzmmJiYgz+gB82bFiG7xcTE0Pfvn1ZunQpjo6Oz8+VQY9yVuaRyZIDFu55X/Bn2zMcejAzb/b+kEXd+lGgXBkKVanA9oVLuRtzhVrd2qsdLVN+WnOEA8f/pXvrqjg62BL/IAkARwc77O1sSNPp+PbnvcRcu0ePNmEoiqLfx9nJHlsb8/8bZvmgMexf8Qc9lv4PB1cX4v5/zo+Tuxv2Ts//oDJ3lv69lxGdTseelWup+l5DbGwt/6Pe2s4HrPOcnjDVOk2Z/aP94MGDxMbGUqFCBX1bWloaf//9N7NmzeL06dPA4x4nf39//T6xsbHpep9exLq+SlZkz5496Z4HBwdjY2Nj0B4SEkJ0dDQxMTH63qaTJ08SFxdHiRIlAChWrBj79u2jQ4cO+tcdOGB+VwVVfP9dHty5y58TpxN/PZaAkGL0WhWJd/58akfLlO0HLgIwPdKwx6J90wpUDS3AvfiHHD99DYCJczcb7NMnvCZFgwwnIpujvxf+AMC0Jh0M2jvOmkBY2+ZqRDIJS//ey8ipnQe5c/UGYS0bqx3FJKztfMA6z0kt9erV4/jx4wZtnTt3pnjx4gwZMoRChQrh5+fHhg0bKFeuHAApKSls27aNSZMmZfp9pGgyUzExMQwYMICPPvqIQ4cOMXPmTKZMmZJuvzfffJMyZcrQrl07IiIiSE1NpWfPntSuXZuKFR8PLfTu3ZsPP/yQihUrUq1aNX788UeOHTtGoULmt4pzne7h1OkernaMbJk16sVFg7eny0v3MXez75xWO0KOseTvvYyE1KzE/85tVTuGyVjb+YB1ntMTxlwB9+T1WeHm5kapUqUM2lxcXPD29ta39+vXj/HjxxMcHExwcDDjx4/H2dmZtm3bZvp9pGgyUx07duThw4dUrlwZGxsbevfuTffu3dPtp9Fo+PXXX+nduze1atVCq9Xy1ltvMXPmTP0+7dq148KFCwwcOJCkpCQ++OADOnXqxL59+17lKQkhhHhNmOOK4IMHD+bhw4f07NmTu3fvUqVKFdavX4+bm1vmcynmOLlF5Lj69evj5+fHkiWZW/E4Pj4eDw8P4q5F5/ik8FcpdXJftSOYnE3f519dYok0DpZ7e5bn0V07r3YE8RqKv/+AXOVqExcXl2Of409+V6zPE4CLNvvzNBN0OhrcvJqjWbNDeppeA4mJicyZM4eGDRtiY2PDDz/8wMaNG9mwYYPa0YQQQlghLcZdnm+ul8VI0fQa0Gg0rFmzhnHjxpGcnEyxYsVYuXJlusW/hBBCCFMw1dVz5kaKpteAk5MTGzduVDuGEEIIYdGkaBJCCCGEaWk0xt182ExvYSRFkxBCCCFMylqH58x1rpUQQgghhFmRniYhhBBCmJS19jRJ0SSEEEIIk9IYOafJqPlQOUiKJiGEEEKYlFbz+GHM682RzGkSQgghhMgE6WkSQgghhElptBo0RnQXGXOz35wkRZMQQgghTMocb9hrCjI8J4QQQgiRCdLTJIQQQgiTstaeJimahBBCCGFS1rrkgAzPCSGEEEJkgvQ0CSGEEMKkZHhOCCGEECITZHhOCCGEEOI1Jj1N4rVm02Ok2hFMLnVoZ7UjmJTdtB/VjmByGkcXtSOYno2d2glMz9ld7QQmpXG4/+reS4bnhBBCCCFeTqvRoDWi8jHmtTlJiiYhhBBCmJS19jTJnCYhhBBCiEyQniYhhBBCmJQGI6+ekxv2CiGEEOJ1oNE+fmT79YrpspiSDM8JIYQQQmSC9DQJIYQQwrSMXNzSXGeCS9EkhBBCCJOSq+eEEEIIIV5j0tMkhBBCCJN63NNkzL3nTBjGhKRoEkIIIYRJyfCcEEIIIcRrTHqahBBCCGFScu85IYQQQohMsNbhOSmahBBCCGFSGiPXaTJqjaccJHOahBBCCCEyQXqahBBCCGFSMjwnhBBCCJEJ1lo0yfCcEEIIIUQmSE+TEEIIIUxKo9Wg0RoxEVwxz64mKZqEWdk6L5INEXOJux5LQImitJw8iuDqVdSOZRJrZyzgtwkzqdutLR98MVjtOC+lrdcMTZnKaHwC4FEKyqUzpP2+FG5eM9zRJy82TdqiKRwCGg3K9X9Ji5wG926rEzybrOl7748p8/hz2nyDNvc8Xkw6vE6lRKZlaT9Lz3N25z42zJhH9JF/iLsey0dL5xD6TgO1Y5mEtQ7PSdFkpTp16sS9e/f49ddf1Y6SaQdWrObnwWNoE/ElhatWZPuCpcx6ryOjDm7GKzCv2vGMcunIP+z4fiV5Q4qqHSXTNIVLoNuxDiXmPGhtsGncCtsew0md9CmkJD/eydsX2z5j0O3dQtranyEpEY1vXkh9pG74LLLG7z3/YoXo+8M3+udaGxsV05iOJf4sPU9yYiJ5S5UgrN37zOvQU+04IhNkTpMwGxtnzqd6eCtqdGqDf/FgPvhqNLnyBbBt/hK1oxklKSGRRZ98RruvR+Ls4aZ2nExLmzcBZf82uP4vXL1M2g+z0XjlQZOvkH4fm8atUaIOo/t9KVy5BLdjUU4ehgfx6gXPBmv83rOxscHDJ7f+4eadS+1IRrPUn6XnKVW/Dk0//5Ry776ldhSTe7IiuDEPcyRFkzALqSkpRB8+Tol6tQzaS7xRiwt7D6iUyjSWDxtPqXo1KVGrqtpRjOPkDICS+ODxc40GTUg5lNhr2Hz0GbZj52HTbxyaUhVVDJl11vq9F3sxhqEVGjEirCnf9vyMm5f/VTuS0azmZ+k18GR4zpiHOZKiKYt0Oh2TJk2iSJEiODg4kD9/fr788ksAjh8/zhtvvIGTkxPe3t50796dBw8e6F/bqVMnmjVrxvjx4/H19cXT05MxY8aQmprKoEGD8PLyIl++fCxcuNDgPa9cuUKrVq3IlSsX3t7eNG3alEuXLum3p6WlMWDAADw9PfH29mbw4MEoiqLf/t133+Ht7U1ycrLBcVu0aEHHjh0zPM/k5GTi4+MNHjnpwe076NLScPfJY9Du7pub+Bs3c/S9c9L+X9cSfSyKZp/1UTuK0WyadkR3IQquxzxucHVH4+iEtl5TlFNHSJ3zJcrx/dh0/hRN4RLqhs0Ca/zeCypXkvCIMfT+fibtJn9GfOxtvm7WlQd376kdLdus6WdJWC4pmrJo2LBhTJo0ic8//5yTJ0+ybNkyfH19SUxM5K233iJXrlzs37+fn3/+mY0bN9KrVy+D12/evJmrV6/y999/M3XqVEaPHs0777xDrly52Lt3Lz169KBHjx7ExDz+xZSYmEjdunVxdXXl77//ZseOHbi6uvLWW2+RkpICwJQpU1i4cCELFixgx44d3Llzh19++UX/ni1btiQtLY3Vq1fr227dusUff/xB586dMzzPCRMm4OHhoX8EBgaa+p8yQ88una8oivn+yfESd65c5+fPJ9Plm/HYOTqoHcco2hZd0ATkJ+27Gf81ah5/fCj/HEC3bQ1cvYxu028oJw+hrVZfpaTZZ03fe6XeqE75t98gb4kilKhZhU++iwBgz89/qhssm6zpZ+l18eQ2KsY8zJFMBM+C+/fvM336dGbNmkV4eDgAhQsXpkaNGsyfP5+HDx/y3Xff4eLiAsCsWbNo0qQJkyZNwtfXFwAvLy9mzJiBVqulWLFiTJ48mcTERD777DPgcVE2ceJEdu7cSevWrVm+fDlarZZvv/1W/020aNEiPD092bp1Kw0aNCAiIoJhw4bRokULAObMmcO6df9dJePk5ETbtm1ZtGgRLVu2BGDp0qXky5ePOnXqZHiuw4YNY8CAAfrn8fHxOVo4uXp7obWxIe5GrEH7/djbuPvkzrH3zUnRx05y/9YdJjRsq2/TpaVxbs8hti36kZmX91nE5Fxt885oS1YgddZoiLvz34aEeJS0VJQbVwz2V25cQVOo+KsNaQRr/N57loOzEwHFixB7MUbtKNliLT9LrxMNRl49Z7IkpiVFUxZERUWRnJxMvXr1MtxWtmxZfcEEUL16dXQ6HadPn9YXTSVLlkSr/a+Dz9fXl1KlSumf29jY4O3tTWzs4w/wgwcPcu7cOdzcDCc9JiUlcf78eeLi4rh27RphYWH6bba2tlSsWNFgiO7DDz+kUqVKXLlyhbx587Jo0SI6der03GrewcEBB4dX9xedrb09+cuVJmrzdsq920jfHrVlO2XftsxLcIvXrMKILSsM2pb0G4lvkYI06NXZIj7ktc07oy1dmdRvxsCdZ4aq0tJQos+j8fE3aNbk8U+/rxmzxu+9Zz1KTuH62UsUqRyqdpRssYafpdeNtd6wV4qmLHBycnruNkVRnvtFfrrdzs4u3baM2nQ6HfB4DlWFChVYunRpuuPmyZMnXdvzlCtXjrJly/Ldd9/RsGFDjh8/zu+//57p178Kb/b+kEXd+lGgXBkKVanA9oVLuRtzhVrd2qsdLVscXV3IW7yIQZu9sxMuuTzStZsjbYuuaCtUJ23BV5D8ENw8Hm9ISoRHj5cU0G35HZuO/dCcj0I5dwJt8VA0JSuQ9s0YFZNnnbV97638IoLSb9bEK68f92/d5a8ZC0h6kEDVlu+oHS1bLP1n6XmSHiRw88Jl/fPbl2OIOXYSl1weFrvUhbWToikLgoODcXJyYtOmTXTr1s1gW0hICJGRkSQkJOh7m3bu3IlWq6Vo0eyvJ1K+fHl+/PFHfHx8cHd3z3Aff39/9uzZQ61aj6/+SU1N5eDBg5QvX95gv27dujFt2jSuXLnCm2+++crmKWVWxfff5cGdu/w5cTrx12MJCClGr1WReOfPp3a015JNjce9LLa9Rhu0py773+OlCADl+H7Sfp6PzZvN4L3OcPMqaYunolw8/YrTGsfavvfuXotlYa8RPLhzD1evXBQsX4rBqxfinc//5S8Wr0z04eNMe+e/IccVnz2+qKhq2xaEz/5KrVimYewVcObZ0SRFU1Y4OjoyZMgQBg8ejL29PdWrV+fmzZucOHGCdu3aMWrUKMLDwxk9ejQ3b96kd+/edOjQQT80lx3t2rXjq6++omnTpowdO5Z8+fIRHR3NqlWrGDRoEPny5aNv375MnDiR4OBgSpQowdSpU7l3716Gxxo4cCDz58/nu+++M+JfIufU6R5One7hasfIMQNWLVA7QqY96t8qU/sp+7aSum9rzoZ5Bazpe6/b/8arHSHHWdLP0vMUrVmV2XEX1I6RI6x1eE6unsuizz//nE8//ZSRI0dSokQJWrVqRWxsLM7Ozqxbt447d+5QqVIl3n//ferVq8esWbOMej9nZ2f+/vtv8ufPT/PmzSlRogRdunTh4cOH+p6nTz/9lI4dO9KpUyfCwsJwc3PjvffeS3csd3d3WrRogaurK82aNTMqlxBCCPG60ShPzxYWVq9+/fqUKFGCGTNmvHznp8THx+Ph4UHctejnDhNaIiXesu6Plhmpo6zrdgx2035UO4LJKXevqx3B9GzsXr6PpXG2ns86gPj4+3gGFiIuLi7HPsef/K64XLUE7rbZn6Afn5pGgT1ROZo1O2R47jVx584d1q9fz+bNm43u/RJCCCFexFqH56Roek2UL1+eu3fvMmnSJIoVK6Z2HCGEEMLiSNH0mnj6titCCCFEjtJqHj+Meb0ZkqJJCCGEEKZl7F13ZXhOCCGEEK8Da53TJEsOCCGEEEJkgvQ0CSGEEMK0ZE6TEEIIIUQmWOmcJhmeE0IIIYTIBCmahBBCCGFSGq3G6EdWzJ49mzJlyuDu7o67uzthYWH89ddf+u2KojB69GgCAgJwcnKiTp06nDhxIsvnJUWTEEIIIUzryfCcMY8syJcvHxMnTuTAgQMcOHCAN954g6ZNm+oLo8mTJzN16lRmzZrF/v378fPzo379+ty/fz9L7yNFkxBCCCHMUnx8vMEjOTk5w/2aNGlC48aNKVq0KEWLFuXLL7/E1dWVPXv2oCgKERERDB8+nObNm1OqVCkiIyNJTExk2bJlWcojRZMQQgghTEqjMXJ47v97mgIDA/Hw8NA/JkyY8NL3TktLY/ny5SQkJBAWFsbFixe5fv06DRo00O/j4OBA7dq12bVrV5bOS66eE0IIIYRpmejquZiYGNzd3fXNDg4Oz33J8ePHCQsLIykpCVdXV3755RdCQkL0hZGvr6/B/r6+vly+fDlLsTJVNM2YMSPTB+zTp0+WAgghhBBCZOTJxO7MKFasGEeOHOHevXusXLmS8PBwtm3bpt/+7CrjiqJkeeXxTBVN06ZNy9TBNBqNFE1CCCHE606LkYtbZv0l9vb2FClSBICKFSuyf/9+pk+fzpAhQwC4fv06/v7++v1jY2PT9T69TKaKposXL2bpoEIIIYR4fZnDvecURSE5OZmCBQvi5+fHhg0bKFeuHAApKSls27aNSZMmZemY2Z7TlJKSwsWLFylcuDC2tjI1SgghhBD/7xXfRuWzzz6jUaNGBAYGcv/+fZYvX87WrVtZu3YtGo2Gfv36MX78eIKDgwkODmb8+PE4OzvTtm3bLL1PlqudxMREevfuTWRkJABnzpyhUKFC9OnTh4CAAIYOHZrVQwqhGl3MabUjmJzdtB/VjmBSumvn1Y5geilJaicwOU0uP7UjmN6962onMK37D9ROkGNu3LhBhw4duHbtGh4eHpQpU4a1a9dSv359AAYPHszDhw/p2bMnd+/epUqVKqxfvx43N7csvU+WRw2HDRvG0aNH2bp1K46Ojvr2N998kx9/tK4PayGEEEJkwyte3HLBggVcunSJ5ORkYmNj2bhxo75gehxHw+jRo7l27RpJSUls27aNUqVKZfm0stzT9Ouvv/Ljjz9StWpVgzHHkJAQzp+3wr8IhRBCCJElGu3jhzGvN0dZjnXz5k18fHzStSckJJhk4pYQQgghhDnKctFUqVIl/vzzT/3zJ4XS/PnzCQsLM10yIYQQQlimVzw896pkeXhuwoQJvPXWW5w8eZLU1FSmT5/OiRMn2L17t8EiUkIIIYR4PT25HYoxrzdHWe5pqlatGjt37iQxMZHChQuzfv16fH192b17NxUqVMiJjEIIIYQQqsvWAkulS5fWLzkghBBCCGHARPeeMzfZKprS0tL45ZdfiIqKQqPRUKJECZo2bSqLXAohhBDilS9u+apkucr5559/aNq0KdevX6dYsWLA4wUu8+TJw+rVqyldurTJQwohhBBCqC3Lc5q6detGyZIl+ffffzl06BCHDh0iJiaGMmXK0L1795zIKIQQQggL8uTec8Y8zFGWe5qOHj3KgQMHyJUrl74tV65cfPnll1SqVMmk4YQQQghhgax0eC7LPU3FihXjxo0b6dpjY2MpUqSISUIJIYQQwpIZu0aTBRdN8fHx+sf48ePp06cPK1as4N9//+Xff/9lxYoV9OvXj0mTJuV0XiGEEEIIVWRqeM7T09NgfFFRFD744AN9m6IoADRp0oS0tLQciCmEEEIIS2HsvCSLntO0ZcuWnM4hhBBCCGthpXOaMlU01a5dO6dzCCGEEEKYtWyvRpmYmEh0dDQpKSkG7WXKlDE6lBBCCCEs12s9PPe0mzdv0rlzZ/76668Mt8ucJiGEEOI1Z6XDc1lecqBfv37cvXuXPXv24OTkxNq1a4mMjCQ4OJjVq1fnREYhhBBCCNVluadp8+bN/Pbbb1SqVAmtVkuBAgWoX78+7u7uTJgwgbfffjsncgohhBDCUljpDXuz3NOUkJCAj48PAF5eXty8eROA0qVLc+jQIdOmE0IIIYTF0Wg1Rj/MUZZ7mooVK8bp06cJCgoiNDSUuXPnEhQUxJw5c/D398+JjGavU6dO3Lt3j19//VXtKBZv67xINkTMJe56LAElitJy8iiCq1dRO1amnD10ko3f/07MqYvE3bpL98kDKVvnv1sLKYrCmvkr2PnrJhLvPyCoZDAfDOpCQOFAFVNnjyV/nZ41onYr7lxJf5eDWu2a0XpMv1cfyEhpqWn8+c0S9v+xhfhbd3HP40VYs/q81aMNWm2W/042S2tnLOC3CTOp260tH3wxWO042Xbv+k1+mfANJ7buISUpGd9C+Wk/eRgFShdXO5p4jiwXTf369ePatWsAjBo1ioYNG7J06VLs7e1ZvHixqfO90OjRo/n11185cuSISY5Xp04dQkNDiYiIyNLrpk+frl/g09xt3bqVunXrcvfuXTw9PdWOY+DAitX8PHgMbSK+pHDVimxfsJRZ73Vk1MHNeAXmVTveS6UkJZMvuABhTeowf8jUdNs3fLeazT/8SYeRH+OT35+1C1cxq/eXjPx5Go4uTiokzh5L/zo9a8iqueh0/13Acu3MRWaED6R8I8tcamX9tz+x/cc1dJzwKQFFCnD5n7MsGT4VRzcX3ujQTO14Rrt05B92fL+SvCFF1Y5ilIS4eL5q8RHFwsrTK3Iqbt65uHn5Cs7urmpHMw0rHZ7LctHUrl07/X+XK1eOS5cucerUKfLnz0/u3LlNGu5VefToEXZ2dtl+vYeHhwnTvL42zpxP9fBW1OjUBoAPvhrNyU3b2DZ/Ce+NHapyupcrWa0cJauVy3CboihsWb6Ghp3eI7Tu4x6ZDqM+Ydhb3dm/bgc1m9d/lVGNYulfp2e5eXsaPF8/dxl58gcQXCVUlTzGung0ijJvVKV07cffZ955/TiwZivR/5xROZnxkhISWfTJZ7T7eiR/RcxXO45R1s/+nlz+vnT8eoS+zTvQikZrtBh59ZzJkpiU0bGcnZ0pX758tgomRVGYPHkyhQoVwsnJibJly7JixQrgcY+IRqNh06ZNVKxYEWdnZ6pVq8bp06cBWLx4MWPGjOHo0aP69SCe9HTFxcXRvXt3fHx8cHd354033uDo0aP69x09ejShoaEsXLiQQoUK4eDgQHh4ONu2bWP69On64126dIm0tDS6du1KwYIFcXJyolixYkyfPt3gPDp16kSzZs30z+vUqUOfPn0YPHgwXl5e+Pn5MXr0aIPXaDQa5s6dyzvvvIOzszMlSpRg9+7dnDt3jjp16uDi4kJYWBjnz583eN3vv/9OhQoVcHR0pFChQowZM4bU1FSD43777be89957ODs7G1zVeOnSJerWrQtArly50Gg0dOrUKctft5yQmpJC9OHjlKhXy6C9xBu1uLD3gEqpTOf21Vjib9+jRNX/1jGzs7ejSPkQLh6znF9m1v51Sk15xL7fNhD2fmOzXSfmZQqXL8npPUe4celfAP49dYHzh05Qslall7zS/C0fNp5S9WpSolZVtaMY7diGHRQoU5z5Hw9nUPnGfNkonB0//KZ2LJN58nvUmIc5ylRP04ABAzJ9wKlT0w9LPM+IESNYtWoVs2fPJjg4mL///pv27duTJ08e/T7Dhw9nypQp5MmThx49etClSxd27txJq1at+Oeff1i7di0bN24EHvf4KIrC22+/jZeXF2vWrMHDw4O5c+dSr149zpw5g5eXFwDnzp3jp59+YuXKldjY2FCgQAHOnj1LqVKlGDt2LAB58uRBp9ORL18+fvrpJ3Lnzs2uXbvo3r07/v7+fPDBB889t8jISAYMGMDevXvZvXs3nTp1onr16tSv/1+PwhdffMHUqVOZOnUqQ4YMoW3bthQqVIhhw4aRP39+unTpQq9evfRrYq1bt4727dszY8YMatasyfnz5+nevTvweKj0iTFjxjB58mS++uorZs6cSbt27bh8+TKBgYGsXLmSFi1acPr0adzd3XFyynhYKDk5meTkZP3z+Pj4TH9ds+PB7Tvo0tJw98lj0O7um5v4jTdz9L1fhfjb9wBw8zLslXT38uDONcs5P2v/Oh3dsIOH8Q+o2uIttaNkW4NuH/DwfgJj3/4QjY0WJU1Hk77hVHq7rtrRjLL/17VEH4ti2NplakcxiVsxV/n7+1+o1601b33SkUtHo/hp1DRs7e2p2qKR2vHEc2SqaDp8+HCmDpaVyjAhIYGpU6eyefNmwsLCAChUqBA7duxg7ty5+mLgyy+/1N/GZejQobz99tskJSXh5OSEq6srtra2+Pn56Y+7efNmjh8/TmxsLA4ODgB8/fXX/Prrr6xYsUJ/3JSUFJYsWWJQoNnb2+Ps7GxwPBsbG8aMGaN/XrBgQXbt2sVPP/30wqKpTJky+kImODiYWbNmsWnTJoOiqXPnzvpjDBkyhLCwMD7//HMaNmwIQN++fencubN+/y+//JKhQ4cSHh6u//f64osvGDx4sEHR1KlTJ9q0eTx0Mn78eGbOnMm+fft466239EWjj4/PC+c0TZgwweC8X5Vnv4cURTHbse3ssJbzs5bzeNaun9cQUqsKnr6WOdUA4OBf29j3x2Y6fzUE/yIF+PfUeVZMmIunjzdVm1nOMPDT7ly5zs+fT6bP8tnYOTqoHcckFJ2OAqWL02xwDwACSxXj6pkL/L1klXUUTVa6uKVqN+w9efIkSUlJBkUEPC5mypX7b17I07dleXJ1XmxsLPnz58/wuAcPHuTBgwd4e3sbtD98+NBgqKtAgQIGBdOLzJkzh2+//ZbLly/z8OFDUlJSCA0NfeFrnr2djL+/P7Gxsc/dx9fXF3i8dMPTbUlJScTHx+Pu7s7BgwfZv38/X375pX6ftLQ0kpKSSExMxNnZOd1xXVxccHNzS/feLzNs2DCDHsb4+HgCA3PuKi9Xby+0NjbE3TDMeT/2Nu4+lvsL7An3/583E3/7Hh65c+nb79+Nx93LcubEWfPX6faV65zadZDu34xVO4pRVn39LQ27fUDFxnUAyFu0IHeuxrJu/o8WWzRFHzvJ/Vt3mNCwrb5Nl5bGuT2H2LboR2Ze3ofWxkbFhFnn4eONX3BBgza/IkEc/murOoFMTSaCm5ZOpwPgzz//JG9ewytuHBwc9AXO0xO0n/x1++S1zzuuv78/W7duTbft6Z4VFxeXTOX86aef6N+/P1OmTCEsLAw3Nze++uor9u7d+8LXPTuxXKPRpMud0bm96Hx1Oh1jxoyhefPm6d7P0dExS+/9Mg4ODvqeulfB1t6e/OVKE7V5O+Xe/e+vrKgt2yn7doNXliOneAf44O7tyam9xwgs9viDMvVRKucOnaRpr7YvebX5sOav0+4Vf+Hm7UmpupY9X+bRw2Q0zywtoNFqUXSWcYVvRorXrMKILSsM2pb0G4lvkYI06NXZ4gomgEIVynDjQrRBW+zFGLzz+j3nFcIcqFY0hYSE4ODgQHR0tH747WnPToDOiL29fbp73ZUvX57r169ja2tLUFBQljJldLzt27dTrVo1evbsmaVsOaF8+fKcPn2aIkWKZPsY9vb2gHneI/DN3h+yqFs/CpQrQ6EqFdi+cCl3Y65Qq1t7taNlSlJiEjf/va5/fvtqLDFnLuHi7oqXX27qtm7MusW/kifQH5/8fqxb9Cv2jg5UalhDxdRZZ+lfp4zodDr2rFxL1fcaYmOr2seiSZSuW4W1c5eTyz8PAUUKEBN1ns2RvxDW3HKLWkdXF/IWN/zcs3d2wiWXR7p2S1GvWyu+av4Rf82KpMI79bh05CQ7lv1GuwlD1I5mGtLTZFpubm4MHDiQ/v37o9PpqFGjBvHx8ezatQtXV1cKFCjw0mMEBQVx8eJFjhw5Qr58+XBzc+PNN98kLCyMZs2aMWnSJIoVK8bVq1dZs2YNzZo1o2LFii883t69e7l06RKurq54eXlRpEgRvvvuO9atW0fBggVZsmQJ+/fvp2DBgs89Tk4ZOXIk77zzDoGBgbRs2RKtVsuxY8c4fvw448aNy9QxChQogEaj4Y8//qBx48b6uWHmoOL77/Lgzl3+nDid+OuxBIQUo9eqSLzz51M7WqZER51n+sf/De2sjPgOgCpv16bjqJ7U7/guj5JT+HHyAhLvJxBUsgi9Zn5mUWs0geV/nTJyaudB7ly9QVjLxmpHMdoHw3vy+4zv+HHsN9y/cw8PH29qfNCIxh+3e/mLxSsTVDaEHvMm8uuk2ayZsYjc+fxpOaovld9rqHY0EzGyaEKKpnS++OILfHx8mDBhAhcuXMDT05Py5cvz2WefZWo4qUWLFqxatYq6dety7949Fi1aRKdOnVizZg3Dhw+nS5cu3Lx5Ez8/P2rVqqWfN/Q8AwcOJDw8nJCQEB4+fMjFixfp0aMHR44coVWrVmg0Gtq0aUPPnj31V7S9Sg0bNuSPP/5g7NixTJ48GTs7O4oXL063bt0yfYy8efMyZswYhg4dSufOnenYseMrX5T0Rep0D6dO93C1Y2RL0Qol+Wbfj8/drtFoeLt7S97u3vIVpsoZlvx1ykhIzUr879xWtWOYhKOLMy2H9aDlsB5qR8lRA1YtUDuC0UrXq07petXVjiGyQKNYylLWQlXx8fF4eHgQdy0ad3d3teOYTNqJXWpHMDmbktXUjmBSumvqDIfnqJQktROYnCaXFc7FSUlUO4FJxd9/gGepMOLi4nLsc/zJ74rbH7+Nu0P2F42OT36E9+w/czRrdmRrccslS5ZQvXp1AgICuHz5MgARERH89pv1LMwlhBBCiGx6MqfJmIcZynLRNHv2bAYMGEDjxo25d++efkKxp6dnlu/ZJoQQQghhKbJcNM2cOZP58+czfPhwbJ66zLNixYocP37cpOGEEEIIYYGstKcpyxPBL168aLD45BMODg4kJCSYJJQQQgghLJiVLjmQ5Z6mggULcuTIkXTtf/31FyEhIabIJIQQQghLptUa/zBDWe5pGjRoEJ988glJSUkoisK+ffv44YcfmDBhAt9++21OZBRCCCGEUF2Wi6bOnTuTmprK4MGDSUxMpG3btuTNm5fp06fTunXrnMgohBBCCEtipcNz2Vrc8sMPP+TDDz/k1q1b6HQ6fHx8TJ1LCCGEEJZKiqb0cue27LuaCyGEEEJkVpaLpoIFC6J5QQV44cIFowIJIYQQwsJJT9Nj/fr1M3j+6NEjDh8+zNq1axk0aJCpcgkhhBDCUhl7BZy1XD3Xt2/fDNu/+eYbDhw4YHQgIYQQQghzZLJSrlGjRqxcudJUhxNCCCGEpZIVwV9sxYoVeHl5mepwQgghhLBUGoyc02SyJCaV5aKpXLlyBhPBFUXh+vXr3Lx5k//9738mDSeEEEIIYS6yXDQ1a9bM4LlWqyVPnjzUqVOH4sWLmyqXEEIIISyVXD0HqampBAUF0bBhQ/z8/HIqkxBCCCEsmEarRWPEFXDGvDYnZSmVra0tH3/8McnJyTmVRwghhBAWz9hJ4ObZ05TlUq5KlSocPnw4J7IIIYQQQpitLM9p6tmzJ59++in//vsvFSpUwMXFxWB7mTJlTBZOmB8lNRUl9ZHaMUxGWyRU7QgmpyQnqh3BpLT+hdWOYHIPu7yrdgSTc5y1RO0IpufgrXYC01LsX917ve5zmrp06UJERAStWrUCoE+fPvptGo0GRVHQaDSkpaWZPqUQQgghLMfrXjRFRkYyceJELl68mJN5hBBCCCHMUqaLJkVRAChQoECOhRFCCCGEFZB7z2GwqKUQQgghRIZe9+E5gKJFi760cLpz545RgYQQQgghzFGWiqYxY8bg4eGRU1mEEEIIYQ2kpwlat26Nj49PTmURQgghhDWw0qIp0zOtZD6TEEIIIV5nWb56TgghhBDihaz06rlMp9LpdDI0J4QQQoiXM+a+c9kY2pswYQKVKlXCzc0NHx8fmjVrxunTpw32URSF0aNHExAQgJOTE3Xq1OHEiRNZeh/zLOWEEEIIYblecdG0bds2PvnkE/bs2cOGDRtITU2lQYMGJCQk6PeZPHkyU6dOZdasWezfvx8/Pz/q16/P/fv3M/0+Wb73nBBCCCGEOVm7dq3B80WLFuHj48PBgwepVasWiqIQERHB8OHDad68OfD4Tie+vr4sW7aMjz76KFPvIz1NQgghhDCtJ3OajHkA8fHxBo/k5ORMvX1cXBwAXl5eAFy8eJHr16/ToEED/T4ODg7Url2bXbt2Zf60Mr2nEEIIIURmaDByeO7xYQIDA/Hw8NA/JkyY8NK3VhSFAQMGUKNGDUqVKgXA9evXAfD19TXY19fXV78tM2R4TgghhBBmKSYmBnd3d/1zBweHl76mV69eHDt2jB07dqTb9uzySYqiZGlJJSmahBBCCGFaJlrc0t3d3aBoepnevXuzevVq/v77b/Lly6dv9/PzAx73OPn7++vbY2Nj0/U+vYgMzwkhhBDCtF7x1XOKotCrVy9WrVrF5s2bKViwoMH2ggUL4ufnx4YNG/RtKSkpbNu2jWrVqmX6faSnSQghhBAW7ZNPPmHZsmX89ttvuLm56ecpeXh44OTkhEajoV+/fowfP57g4GCCg4MZP348zs7OtG3bNtPvI0WTEEIIIUxLY+SK4JqsvXb27NkA1KlTx6B90aJFdOrUCYDBgwfz8OFDevbsyd27d6lSpQrr16/Hzc0t0+8jRZMQQgghTOsV37A3M7d602g0jB49mtGjR2czlMxpEkIIIYTIFOlpMjOKovDRRx+xYsUK7t69y+HDhwkNDTX5+9SpU4fQ0FAiIiJMfuzsOrtzHxtmzCP6yD/EXY/lo6VzCH2nwctfaKbWTpvLkT/Wc/3sBewcHSlcuRzNRg3EL7iQ2tGyzRrP6Ymt8yLZEDGXuOuxBJQoSsvJowiuXkXtWC9l2/h9bCqEofHPCykp6M6d4tGKSJTrV/7bycERu/fDsSlXBVzdUG7FkrrxD9K2/qVe8CzYtmg52xf/yO3oqwD4Fy9C4097UOrNmionyz5r/lkCXnlP06siPU1mZu3atSxevJg//viDa9eu6Rfmeh0kJyaSt1QJWn01Wu0oJnF25z5qd23H4HU/0XfVItJS05jZoivJCYlqR8s2azwngAMrVvPz4DE0Gtyb4bv+oki1ysx6ryN3Yq68/MUq0xYrRermP0keN4jkKSPBxgb7AWPA/r/1bOxad0Vbqjwp86eSPPwTUjesxq5dd7Sh5l8UAuQK8KPZiP4M3fgjQzf+SLEalZnTsTdXT51TO1q2WevPkp5Ga/zDDElPk5k5f/48/v7+WboE0lqUql+HUvXrqB3DZHqvWGDwvOOsCQwuGkb00RMEV6ukUirjWOM5AWycOZ/q4a2o0akNAB98NZqTm7axbf4S3hs7VOV0L5YybbTh84XTcZr+PdqgIujOPL6Du7ZwcdJ2bUZ3+h8A0ratw7Z2Q7QFi6A7svdVR86yMg3rGDxvOrwvfy/+kYsHjhJQvIg6oYxkrT9LelrN44cxrzdD5lnKvaY6depE7969iY6ORqPREBQURHJyMn369MHHxwdHR0dq1KjB/v37DV63bds2KleujIODA/7+/gwdOpTU1FT99oSEBDp27Iirqyv+/v5MmTLlVZ+aAB7GP76TtrOnh8pJTMcazik1JYXow8cpUa+WQXuJN2pxYe8BlVJln8bJBQAl4b87t+vOnsQmtDJ4Pr4Pl7Z4aTR+Aej+OaRKRmPo0tLY/8saUhIfUqhSqNpxTMYafpZeB9LTZEamT59O4cKFmTdvHvv378fGxobBgwezcuVKIiMjKVCgAJMnT6Zhw4acO3cOLy8vrly5QuPGjenUqRPfffcdp06d4sMPP8TR0VF/hcCgQYPYsmULv/zyC35+fnz22WccPHjwhXOlkpOTDW6MGB8fn8Nnb90URWHFiAkUrlqBvCFF1Y5jEtZyTg9u30GXloa7Tx6Ddnff3MRvvKlSquyza9WFtDMnUK5E69seLZuPXadeOE1djJKaCorCo8Uz0Z2NUjFp1lw5eYavGrXjUXIKDi7OfLR4Ov7FCqsdyySs5WfJgLFDbDI8J17Gw8MDNzc3bGxs8PPzIyEhgdmzZ7N48WIaNWoEwPz589mwYQMLFixg0KBB/O9//yMwMJBZs2ah0WgoXrw4V69eZciQIYwcOZLExEQWLFjAd999R/369QGIjIw0WF4+IxMmTGDMmDE5fs6vi+WDx3LlxBkGrlmmdhSTsbZzyuieVOY6GfV57Np/hCYwiOQJhkOKtm++g7ZwUZKnf4Fy+ybaoiWx69ADJe4uupNHVUqbNb5FCvLZlpU8jI/n8O8biOw9nAG/LbaKwsnafpYAmQguXr3z58/z6NEjqlevrm+zs7OjcuXKREU9/gsxKiqKsLAwgw/86tWr8+DBA/7991/Onz9PSkoKYWFh+u1eXl4UK1bshe89bNgw4uLi9I+YmBgTn93r48chX3D8r830Xx1Jrrx+ascxCWs6J1dvL7Q2NsTdiDVovx97G3ef3Cqlyjq7tt3RhlYmZfIIuHv7qQ322LbowKPlC9Ed3Y/y7yXSNv9J2r4d2DZ8T73AWWRrb4dPofwUCC1Fs8/7k7dkMTbP+17tWEazpp+l14EUTWbsyWJdL7orc0Z3aH76dZlZ8CsjDg4O+hslZvWGieIxRVFYPngsh/9YT7/fIsldIFDtSEazxnOytbcnf7nSRG3ebtAetWU7hapUVClV1ti1+wibCmGkTB6BcuuG4UYbGzS2dqDoDNt1OrP9az5TFIXU5BS1U2SbNf4sGdBqjX+YIfNMJQAoUqQI9vb27NixQ9/26NEjDhw4QIkSJQAICQlh165dBsXRrl27cHNzI2/evBQpUgQ7Ozv27Nmj33737l3OnDnz6k4kk5IeJBBz7CQxx04CcPtyDDHHTlrEZd8ZWT5oDPt+Wk2XeVNwcHUh7sZN4m7cJOVhktrRss0azwngzd4fsnPxcnZGLufaqbP8NHg0d2OuUKtbe7WjvZRd+x7YhNUmZe7XKEkPwd3z8cPO/vEOSQ9JO3Ucu5ad0RYrhSa3LzbV38CmWl3SDu150aHNxq/jIji7+yC3o69w5eQZfvtyOmd27qfy+2+rHS3brPVnSe8V37D3VZE5TWbMxcWFjz/+mEGDBuHl5UX+/PmZPHkyiYmJdO3aFYCePXsSERFB79696dWrF6dPn2bUqFEMGDAArVaLq6srXbt2ZdCgQXh7e+Pr68vw4cPRmmEVH334ONPe+e/GiSs++xKAqm1bED77K7ViZdvfC38AYFqTDgbtHWdNIKxtczUiGc0azwmg4vvv8uDOXf6cOJ3467EEhBSj16pIvPO/eO6fObB9ozEADkMnGLSnLIggbefmx/895yvs3u+IffdPwcUV5fZNUld9bzGLW96/eZvFnwwj/sZNHN3dyBtSlN4/zqFEHctdmsVaf5asnRRNZm7ixInodDo6dOjA/fv3qVixIuvWrSNXrlwA5M2blzVr1jBo0CDKli2Ll5cXXbt2ZcSIEfpjfPXVVzx48IB3330XNzc3Pv30U+Li4tQ6pecqWrMqs+MuqB3DZGbfOa12BJOzxnN6ok73cOp0D1c7RpY97PLuy3eKv8ejhTN4lPNxckSH6V+oHcHkrPlnCbDaq+c0SnYnvYjXSnx8PB4eHtyLuYC7e+bvCG320iz118jrQ+PgrHYEk8tUoWNhHGctUTuC6dnYqZ3ApOLj7+MZVIy4uLgcm6f65HfFnW+G4u7kmP3jPEzC65OJOZo1O8yzlBNCCCGEMDMyPCeEEEII0zL2CjgznHcLUjQJIYQQwtSsdHFLKZqEEEIIYVpWOhHcPFMJIYQQQpgZ6WkSQgghhGlpNKCV4TkhhBBCiBeT4TkhhBBCiNeX9DQJIYQQwrTk6jkhhBBCiEyQ4TkhhBBCiNeX9DQJIYQQwrS0Rl49Z8xrc5AUTUIIIYQwLSud0yTDc0IIIYQQmSA9TUIIIYQwLSudCC5FkxBCCCFMS+Y0CSGEEEJkgkZjZE+TeRZN5tn/JYQQQghhZqSnSQghhBCmZaVXz0nRJLIm7gboEtROYTIpn/dVO4LJ2Y38Su0IppUnv9oJTM7+06FqRzC5Ef5l1I5gciNalFU7gkklPUp9dW9mpRPBzTOVEEIIIYSZkZ4mIYQQQpiWXD0nhBBCCJEJMjwnhBBCCPH6kp4mIYQQQpiWXD0nhBBCCJEJWu3jhzGvN0PmmUoIIYQQwsxIT5MQQgghTMzI4TlkeE4IIYQQrwMrvXpOiiYhhBBCmJaVTgQ3z1JOCCGEEMLMSE+TEEIIIUzLSq+ek6JJCCGEEKYlw3NCCCGEEK8v6WkSQgghhGlpNEZePWeePU1SNAkhhBDCtGR4TgghhBDi9SU9TUIIIYQwLVncUgghhBAiE7Saxw9jXm+GzLOUE0IIIYQwM9LTJMzGves3+WXCN5zYuoeUpGR8C+Wn/eRhFChdXO1omWLTsDna0Kpo/PLCoxR050+R9usSlBtX9fs4zF6V4WtTV0WStuG3VxU120bUbsWdKzfStddq14zWY/q9+kAmcHbnPjbMmEf0kX+Iux7LR0vnEPpOA7VjZcnZQyfZ+P3vxJy6SNytu3SfPJCydSrptyuKwpr5K9j56yYS7z8gqGQwHwzqQkDhQBVTZ06tAT1pOGoIO/+3gDXDxgLgkic3b40ZSpE3auHo4c6lXXv5Y9Aobl+4pG7YF7Bt/D42FcLQ+OeFlBR0507xaEUkyvUr/+3k4Ijd++HYlKsCrm4ot2JJ3fgHaVv/Ui94dsnwnHmrU6cOoaGhREREZGr/U6dO0alTJ44cOULx4sU5cuRIjuYzldGjR/Prr79aTN7MSoiL56sWH1EsrDy9Iqfi5p2Lm5ev4Ozuqna0TNMGlyRt218ol8+B1gabpm2x6z2KlLF9ICUZgOQhXQxfU7I8tu17knZ4jxqRs2zIqrnodGn659fOXGRG+EDKN6qtYirjJCcmkrdUCcLavc+8Dj3VjpMtKUnJ5AsuQFiTOswfMjXd9g3frWbzD3/SYeTH+OT3Z+3CVczq/SUjf56Go4uTCokzJ2/5MlTq1JZrx08atLdfNp+0R4/4vm03kuMfUL1XNzr/tpTpVd7kUeJDldK+mLZYKVI3/4nu4lmwscGueQfsB4whecQn+s8Hu9Zd0RYvQ8r8qSi3YtGWKodd+x4o9+6gO7JX5TPIIiu9es5qiqZVq1ZhZ2eX6f1HjRqFi4sLp0+fxtXVPH8xazQafvnlF5o1a6ZvGzhwIL1791YvVA5ZP/t7cvn70vHrEfo270B/FRNl3aNZXxg8T/1uFg5fLUaTvzDKuf//0I+/Z7CPtkwllDP/wK30vTfmyM3b0+D5+rnLyJM/gOAqoarkMYVS9etQqn4dtWMYpWS1cpSsVi7DbYqisGX5Ghp2eo/QulUA6DDqE4a91Z3963ZQs3n9Vxk10+xdnPlg/nR+7TOEOgP/+8zzLlyQ/JXLM73Km8SeOgvA6gEj+Oz8Icq+35QD3y1XK/ILpUwbbfh84XScpn+PNqgIujMnANAWLk7ars3oTv8DQNq2ddjWboi2YBELLJqss6fJPFNlg5eXF25ubpne//z589SoUYMCBQrg7e2drfdMSUnJ1uuM4erqmu285uzYhh0UKFOc+R8PZ1D5xnzZKJwdP5j/cNULOTk//v/EBxlvd/NAW7oCabs2vbpMJpSa8oh9v20g7P3GaMz0r0IBt6/GEn/7HiWqltG32dnbUaR8CBePnVEx2Ys1+foLTq/bzPmtOw3abR3sAUhNTta3KTodaSmPKFC14ivNaAyNkwsASsJ9fZvu7ElsQiuDpxcA2uKl0fgFoPvnkCoZRXpWUzTVqVOHfv36ARAUFMT48ePp0qULbm5u5M+fn3nz5un31Wg0HDx4kLFjx6LRaBg9ejQAx48f54033sDJyQlvb2+6d+/Ogwf//cLr1KkTzZo1Y8KECQQEBFC0aFEuXbqERqPhp59+ombNmjg5OVGpUiXOnDnD/v37qVixIq6urrz11lvcvHlTf6z9+/dTv359cufOjYeHB7Vr1+bQof9+MIKCggB477330Gg0+uejR48mNDRUv59Op2Ps2LHky5cPBwcHQkNDWbt2rX77k3yrVq2ibt26ODs7U7ZsWXbv3m2if3nTuBVzlb+//4U8BQPp8900arV/j59GTWPPSgscy/9/tu93RnfuJMrV6Ay321StC0kP0VnI0Nyzjm7YwcP4B1Rt8ZbaUcQLxN++B4Cbl4dBu7uXh36buSndogl5Q0uzfszkdNtunjnP3csxNBg1BEdPd2zs7KjV/2Pc/Hxw8/NRIW322LXqQtqZEyhX/vt8eLRsPrqrMThNXYzjvFXY9x/NoyVz0J2NUjFp9mg0GqMf5shqiqZnTZkyhYoVK3L48GF69uzJxx9/zKlTpwC4du0aJUuW5NNPP+XatWsMHDiQxMRE3nrrLXLlysX+/fv5+eef2bhxI7169TI47qZNm4iKimLDhg388ccf+vZRo0YxYsQIDh06hK2tLW3atGHw4MFMnz6d7du3c/78eUaOHKnf//79+4SHh7N9+3b27NlDcHAwjRs35v79x3917N+/H4BFixZx7do1/fNnTZ8+nSlTpvD1119z7NgxGjZsyLvvvsvZs2cN9hs+fDgDBw7kyJEjFC1alDZt2pCamvrcf7/k5GTi4+MNHjlJ0enIX7IozQb3ILBUMWq2a0b1Nu/y95KMJ06bO9vWH6LNW4BHC6Y9dx9ttTfQ7dsOqY9eYTLT2fXzGkJqVcHTN7faUUQmPPtLSFEUs5w34pHXn3cmjuKnD/sa9CY9oUtNZVnHHuQuXJDPLx9n1PVTFKxRldPrt6BL06mQOOvs2n+EJjCIlLlfG7TbvvkO2sJFSZ7+BcljB/Dox4XYdeiBNqSsSkmN8GR4zpiHGbKaOU3Paty4MT17Pp7UOWTIEKZNm8bWrVspXrw4fn5+2Nra4urqip+fHwDz58/n4cOHfPfdd7i4PO42nTVrFk2aNGHSpEn4+voC4OLiwrfffou9/eMu4kuXLgGP5xo1bNgQgL59+9KmTRs2bdpE9erVAejatSuLFy/W53vjjTcM8s6dO5dcuXKxbds23nnnHfLkyQOAp6enPmNGvv76a4YMGULr1q0BmDRpElu2bCEiIoJvvvlGv9/AgQN5++23ARgzZgwlS5bk3LlzFC+e8ZVpEyZMYMyYMS/6JzYpDx9v/IILGrT5FQni8F9bX1kGU7H9oBva0pVImToC7t3OcB9NkRJo/fKR8m36SbuW4PaV65zadZDu34xVO4p4Cff/n4cWf/seHrlz6dvv343H/ZneJ3MQEFoaV5889Nz23x+lNra2BFWvQtXu4YzKE8zVI/8wq2ZjHNzdsLGzI/H2HXps+pUrh4+rmDxz7Np2RxtamZSJn8Hdpz4f7OyxbdGBlFkT0B07AEDav5fQ5i+IbcP3SDl5VKXE4mnmWcqZQJky/43fazQa/Pz8iI2Nfe7+UVFRlC1bVl8wAVSvXh2dTsfp06f1baVLl9YXTM97vycFVunSpQ3ann7/2NhYevToQdGiRfHw8MDDw4MHDx4QHZ3xUE5G4uPjuXr1qr4wezp3VJRhd+7T+fz9/fUZnmfYsGHExcXpHzExMZnOlR2FKpThxgXDc4+9GIN33ucXjObItlU3tOWq8ChiFNx+/r+vTbV66C6fQ7ly6dWFM6HdK/7CzduTUnWrqh1FvIR3gA/u3p6c2ntM35b6KJVzh05SsExRFZNl7Py2nUyvWp9ZNRrpH/8eOsrRn35lVo1GKLr/epOS4++TePsO3oWCyFuuDFFr1quY/OXs2n2ETYUwUiaPQHn24g8bGzS2dqA801um05llj+BLSU+TZXn2SjqNRoNO9/yuW0VRnjuG+nT700XV897vyf7Ptj39/p06deLmzZtERERQoEABHBwcCAsLy9bk8oy63Z9tyyjfi/49HBwccHBwyHKW7KrXrRVfNf+Iv2ZFUuGdelw6cpIdy36j3YQhryyDsWxbd0dbqSaP5kxASX4I7p6PNzxMhEdPfV0dndCWr0bqysVqxDSaTqdjz8q1VH2vITa2lv8RkvQggZsXLuuf374cQ8yxk7jk8sArMK+KyTIvKTGJm/9e1z+/fTWWmDOXcHF3xcsvN3VbN2bd4l/JE+iPT34/1i36FXtHByo1rKFi6oylPEggNspwgnpKQiKJd+7q20s1a0zCrTvc+/cKfiHFeXviKE7+uZ5zm7erETlT7Nr3wKZqLVJmfImSlMHnQ9JD0k4dx65lZx6lpKDcvom2WElsqtXl0fKFqmbPFo2RK4KbaaFo+Z94JhISEkJkZCQJCQn6wmjnzp1otVqKFjX9X2Pbt2/nf//7H40bNwYgJiaGW7duGexjZ2dHWlpaRi8HwN3dnYCAAHbs2EGtWrX07bt27aJy5comz5yTgsqG0GPeRH6dNJs1MxaRO58/LUf1pfJ7DdWOlmk2tR9PiLYfMM6g/VHkTHR7tuifayvWAI0G3f4drzSfqZzaeZA7V28Q1rKx2lFMIvrwcaa901b/fMVnXwJQtW0Lwmd/pVasLImOOs/0j/8bKl0Z8R0AVd6uTcdRPanf8V0eJafw4+QFJN5PIKhkEXrN/Mys12h6ETdfHxp9+TmuPrm5fz2WI8tXsWXyDLVjvZDtG49/XhyGTjBoT1kQQdrOzY//e85X2L3fEfvun4KLK8rtm6Su+t4yF7d8xf7++2+++uorDh48yLVr19It16MoCmPGjGHevHncvXuXKlWq8M0331CyZMksvY8UTf+vXbt2jBo1ivDwcEaPHs3Nmzfp3bs3HTp00A+3mVKRIkVYsmQJFStWJD4+nkGDBuHkZPgBFhQUpJ8X5eDgQK5cudIdZ9CgQYwaNYrChQsTGhrKokWLOHLkCEuXLjV55pxWul51Ster/vIdzVTyx80ztZ9uxwZSdmzI4TQ5J6RmJf53bqvaMUymaM2qzI67oHYMoxStUJJv9v343O0ajYa3u7fk7e4tX2Eq01nwTmuD57vnLmb33MXqhMmmh13efflO8fd4tHAGlnlpyDNe8TpNCQkJlC1bls6dO9OiRYt02ydPnszUqVNZvHgxRYsWZdy4cdSvX5/Tp09nabki8xw0VIGzszPr1q3jzp07VKpUiffff5969eoxa9asHHm/hQsXcvfuXcqVK0eHDh3o06cPPj6Gl8tOmTKFDRs2EBgYSLlyGS9c16dPHz799FM+/fRTSpcuzdq1a1m9ejXBwcE5klsIIYR4qScrghvzgHRXcSdncEUlQKNGjRg3bhzNm6f/41VRFCIiIhg+fDjNmzenVKlSREZGkpiYyLJly7J2WoqiKFn/1xCvm/j4eDw8PLj3z27c3cxzBfXsSPm8r9oRTM5upGUMKWWWJk9+tSOYnO50xkuIWLKR1dqoHcHkRrSwwEv9XyD+USp+q3YRFxeHu7t7zrzH//+uuLtlBe6uztk/zoNEctV9P137qFGj9GsrPs+zd9O4cOEChQsX5tChQwYdEE2bNsXT05PIyMhM55LhOSGEEEKYlkZj5PDc456mmJgYgwIvOxcoXb/++CKJZ6fa+Pr6cvny5Yxe8lxSNAkhhBDCtEx0w153d3eT9Ypl5krzl5E5TUIIIYQwLTNap+nJAtFPepyeiI2NzfKFXlI0CSGEEMJqFSxYED8/PzZs+O+q5ZSUFLZt20a1atWydCwZnhNCCCGEaWmNXNwyi6998OAB586d0z+/ePEiR44cwcvLi/z589OvXz/Gjx9PcHAwwcHBjB8/HmdnZ9q2bfuCo6YnRZMQQgghTOsVr9N04MAB6tatq38+YMAAAMLDw1m8eDGDBw/m4cOH9OzZU7+45fr167O0RhNI0SSEEEIIC1enTh1etIKSRqNh9OjRL12u4GWkaBJCCCGEaZno6jlzI0WTEEIIIUzrFQ/PvSrmmUoIIYQQwsxIT5MQQgghTEuG54QQQgghMkGG54QQQgghXl/S0ySEEEII09JqHz+Meb0ZkqJJCCGEECal0WiyfDPcZ19vjqRoEkIIIYRpaTRGzmkyz6LJPPu/hBBCCCHMjPQ0CSGEEMK0ZMkBIYQQQojMMHLJATMdCJOiSWSNhy+4Z+2u0ObMtnpVtSOYnMbRRe0IppX2SO0EpvcoSe0EJjd22yK1I5jcJ9U7qh3BpFJ4/g1tReZI0SSEEEII05LhOSGEEEKITLDSdZrMM5UQQgghhJmRniYhhBBCmJYMzwkhhBBCZILcsFcIIYQQ4vUlPU1CCCGEMC0ZnhNCCCGEyAzN/z+Meb35kaJJCCGEEKZlpT1NMqdJCCGEECITpKdJCCGEEKZlpT1NUjQJIYQQwsSsc06TDM8JIYQQQmSC9DQJIYQQwrRkeE4IIYQQIhOsc3ROhueEEEIIITJDepqEEEIIYWLW2dUkRZMQQgghTMtK5zTJ8JwQQgghRCZIT5MQQgghTEuDkT1NJktiUlI0CbNxduc+NsyYR/SRf4i7HstHS+cQ+k4DtWNl2tkzV9i4/hAx0TeJi0ug+8eNKRtaWL89KSmF337ZxbEjF0hISMLL2506b5SlVu3SKqbOmj+mzOPPafMN2tzzeDHp8DqVEhlv7bS5HPljPdfPXsDO0ZHClcvRbNRA/IILqR0t084eOcXGZX8Rc+oScbfv0X1CH8rWqqDffmTrAXb8toXo05dIiHvA0EVjCSxaQMXEL2Zt5wPwzmcDeGf4AIO2uBuxDClUHoDQdxtRs2s7CoSWwTW3F+PCGvDvsZNqRDUR65zTJMNzmXTp0iU0Gg1HjhyxivcxR8mJieQtVYJWX41WO0q2pKQ8Il++3HzQulaG21f+vJ2TJ6IJ79KAz0e35416ofy8fBtHj1x4xUmN41+sEBMP/aV/jNi4XO1IRjm7cx+1u7Zj8Lqf6LtqEWmpacxs0ZXkhES1o2VaysNk8hUJ5IMBHTLcnpyUTKHSwTTt0fIVJ8seazufJ66cPMXgQuX0jy8qv6nf5uDizPndB/hl5AQVE5rQkzlNxjzMkNX2NNWpU4fQ0FAiIiLUjiIyqVT9OpSqX0ftGNlWslQQJUsFPXf7xQvXqRpWnKLF8gFQo1Ypdmz/h+jLsZQNtZxeDRsbGzx8cqsdw2R6r1hg8LzjrAkMLhpG9NETBFerpFKqrCkZVpaSYWWfu73KW9UBuH3t5quKZBRrO58ndKlpxN/IOPPeH1YC4J0/36uMJLJIepqEeEUKFwng2NGL3Lv7AEVROHP6X2Jv3KNEyfxqR8uS2IsxDK3QiBFhTfm252fcvPyv2pFM6mH8fQCcPT1UTiKsjU/hgkw8d4BxJ3bRdfE35A6yrJ/9rNGY4GF+rLJo6tSpE9u2bWP69OloNBo0Gg2XLl3i5MmTNG7cGFdXV3x9fenQoQO3bt3Sv06n0zFp0iSKFCmCg4MD+fPn58svvzQ49oULF6hbty7Ozs6ULVuW3bt367ctXrwYT09P1q1bR4kSJXB1deWtt97i2rVrBu8xduxY8uXLh4ODA6Ghoaxdu/aF57Nt2zYqV66Mg4MD/v7+DB06lNTUVP32+/fv065dO1xcXPD392fatGnUqVOHfv36ATB27FhKl04/b6ZChQqMHDkyw/dMTk4mPj7e4CGM07JVLfz9vRg+dBF9ev6Pb2b8Rqu2dShSJEDtaJkWVK4k4RFj6P39TNpN/oz42Nt83awrD+7eUzuaSSiKwooREyhctQJ5Q4qqHUdYkYsHDrP4w37MaNqe73sNxsPXh0Gbf8XFy1PtaDnDSofnrLJomj59OmFhYXz44Ydcu3aNa9euYWdnR+3atQkNDeXAgQOsXbuWGzdu8MEHH+hfN2zYMCZNmsTnn3/OyZMnWbZsGb6+vgbHHj58OAMHDuTIkSMULVqUNm3aGBQwiYmJfP311yxZsoS///6b6OhoBg4caJBtypQpfP311xw7doyGDRvy7rvvcvbs2QzP5cqVKzRu3JhKlSpx9OhRZs+ezYIFCxg3bpx+nwEDBrBz505Wr17Nhg0b2L59O4cOHdJv79KlCydPnmT//v36tmPHjnH48GE6deqU4ftOmDABDw8P/SMwMDBz//jiubZuPsrFi9fp0fMdhg5vxXvv1+DHZVs5FRWtdrRMK/VGdcq//QZ5SxShRM0qfPJdBAB7fv5T3WAmsnzwWK6cOEPX+VPVjiKszIn1Wzj82xqunjjFqS07mNWiIwBV21nWvKzXnVXOafLw8MDe3h5nZ2f8/PwAGDlyJOXLl2f8+PH6/RYuXEhgYCBnzpzB39+f6dOnM2vWLMLDwwEoXLgwNWrUMDj2wIEDefvttwEYM2YMJUuW5Ny5cxQvXhyAR48eMWfOHAoXfnzVVK9evRg7dqz+9V9//TVDhgyhdevWAEyaNIktW7YQERHBN998k+5c/ve//xEYGMisWbPQaDQUL16cq1evMmTIEEaOHElCQgKRkZEsW7aMevXqAbBo0SICAv7rvciXLx8NGzZk0aJFVKpUSb9P7dq1KVQo47k0w4YNY8CA/670iI+Pl8LJCCkpqaz+dTfdP25MqdIFAcibLzdXYm6xcf1hipewzG56B2cnAooXIfZijNpRjPbjkC84/tdmBvz5Pbny+qkdR1i5lMSHXD1xCp/CBdWOkjNkcUvLdvDgQbZs2YKrq6v+8aTQOX/+PFFRUSQnJ+sLj+cpU6aM/r/9/f0BiI2N1bc5OzvrC6Yn+zzZHh8fz9WrV6levbrBMatXr05UVFSG7xcVFUVYWBiap76BqlevzoMHD/j333+5cOECjx49onLlyvrtHh4eFCtWzOA4H374IT/88ANJSUk8evSIpUuX0qVLl+eep4ODA+7u7gYPkX1paTrS0nQGX0cAjVaDoigqpTLeo+QUrp+9hIePt9pRsk1RFJYPHsvhP9bT77dIcheQPw5EzrO1t8evWDBx12NfvrNFss45TVbZ05QRnU5HkyZNmDRpUrpt/v7+XLiQucu+7ezs9P/95BegTqfLcPuTfZ79pfjsL05FUdK1vWjbk+M9fezn7fNEkyZNcHBw4JdffsHBwYHk5GRatGiR8UmqJOlBAjcvXNY/v305hphjJ3HJ5YFXYF4Vk2VOUlIKN2/G6Z/fvhVPTMxNXFwc8fJyI7hoXn5ZuRM7O1u8vN04e+Yq+/aconnLmiqmzpqVX0RQ+s2aeOX14/6tu/w1YwFJDxKo2vIdtaNl2/JBY9i/4g96LP0fDq4uxP3/1U1O7m7YOzmqnC5zkhKTuPnvDf3z21dvEnPmMi7urnj5eZMQ/4A7128Td+seALHR1wFw9/bAw9tThcQvZm3nA9Bi/AiOrdnInZgruOXJTeMhfXB0c2XP0p8BcM7liVdgAJ7+j3s5fYMf//Edf+Pmc6+4E6+e1RZN9vb2pKWl6Z+XL1+elStXEhQUhK1t+tMODg7GycmJTZs20a1btxzJ5O7uTkBAADt27KBWrf/W8tm1a5dBT9HTQkJCWLlypUHxtGvXLtzc3MibNy+enp7Y2dmxb98+/fBZfHw8Z8+epXbt2vrj2NraEh4ezqJFi3BwcKB169Y4OzvnyHlmV/Th40x7p63++YrPHk/Cr9q2BeGzv1IrVqZFX45l+tRf9M9X/rwDgCphxenYqT6duzVk9S+7WbxwPYkJSXh5udGkaRg1a5VSK3KW3b0Wy8JeI3hw5x6uXrkoWL4Ug1cvxDufv9rRsu3vhT8AMK2J4ZpAHWdNIKxtczUiZVn0qYtM7z1R/3zlzMfnVKVRDTqO+JBj2w/z/fhv9dsXjvofAI27NOPtru+92rCZYG3nA+AZ4E/XxbNw9fbiwa07XNh3iMl13+VOzBUAyr5dn/C50/T7f/jdbAD++HIqf4y3vDl2Ty7CMub15shqi6agoCD27t3LpUuXcHV15ZNPPmH+/Pm0adOGQYMGkTt3bs6dO8fy5cuZP38+jo6ODBkyhMGDB2Nvb0/16tW5efMmJ06coGvXribLNWjQIEaNGkXhwoUJDQ1l0aJFHDlyhKVLl2a4f8+ePYmIiKB379706tWL06dPM2rUKAYMGIBWq8XNzY3w8HAGDRqEl5cXPj4+jBo1Cq1Wm+6brlu3bpQoUQKAnTt3muycTKVozarMjrOshR6fVrRYPr6Z2/u52z08XOjQ6c3nbrcE3f43/uU7WZjZd06rHcFoRcuX4Judkc/dHvZ2TcLetpweTWs7H4AFnT554fbd3//M7u9/fkVpXgErndNktUXTwIEDCQ8PJyQkhIcPH3Lx4kV27tzJkCFDaNiwIcnJyRQoUIC33noLrfbx1K7PP/8cW1tbRo4cydWrV/H396dHjx4mzdWnTx/i4+P59NNPiY2NJSQkhNWrVxMcHJzh/nnz5mXNmjUMGjSIsmXL4uXlRdeuXRkxYoR+n6lTp9KjRw/eeecd3N3dGTx4MDExMTg6Gg4tBAcHU61aNW7fvk2VKlVMel5CCCGEtdMoljwLVWQoISGBvHnzMmXKFINeMkVRKF68OB999JHBlXGZER8fj4eHB/diLuDu7mbqyKrRLZ/28p0sjPbtjmpHMC1n67sIQRe1R+0IIhM+qW5dP0spKCwigbi4uBy7uOfJ74q4i1G4u2X/d0X8/ft4FCyRo1mzw2p7ml4nhw8f5tSpU1SuXJm4uDj9EgdNmzbV7xMbG8uSJUu4cuUKnTt3ViuqEEKI14KxC1TK8JzIQV9//TWnT5/G3t6eChUqsH37dnLn/u/+YL6+vuTOnZt58+aRK1cuFZMKIYSwejKnSZircuXKcfDgwRfuI6OwQgghhHGkaBJCCCGEiRm7QKX0NAkhhBDidWClw3OvzW1UhBBCCCGMIT1NQgghhDAt6xydk6JJCCGEEKZmnVWTDM8JIYQQQmSC9DQJIYQQwrSsdCK4FE1CCCGEMC0rLZpkeE4IIYQQIhOkp0kIIYQQJmadE8GlaBJCCCGEaWkwcnjOZElMSoomIYQQQpiWzGkSQgghhDBf//vf/yhYsCCOjo5UqFCB7du3m/T4UjQJIYQQwsQ0JnhkzY8//ki/fv0YPnw4hw8fpmbNmjRq1Ijo6GgTnM9jUjQJIYQQwrSeDM8Z88iiqVOn0rVrV7p160aJEiWIiIggMDCQ2bNnm+y0ZE6TyBRFUQCIv39f5SSmpXuYrHYEk9Pef6B2BNNKNc+5DcbQJSSqHUFkQgqK2hFM6sn5PPk8z0nG/q548vr4+HiDdgcHBxwcHNLtn5KSwsGDBxk6dKhBe4MGDdi1a5dRWZ4mRZPIlPv//w2cP6SsyknEy01RO4AQwozdv38fDw+PHDm2vb09fn5+BBYtafSxXF1dCQwMNGgbNWoUo0ePTrfvrVu3SEtLw9fX16Dd19eX69evG53lCSmaRKYEBAQQExODm5sbmhy+qiE+Pp7AwEBiYmJwd3fP0fd6FaztfEDOyVLIOZm/V3k+iqJw//59AgICcuw9HB0duXjxIikpKUYfS1GUdL9vMupletqz+2d0DGNI0SQyRavVki9fvlf6nu7u7lbxofiEtZ0PyDlZCjkn8/eqzienepie5ujoiKOjY46/z9Ny586NjY1Nul6l2NjYdL1PxpCJ4EIIIYSwaPb29lSoUIENGzYYtG/YsIFq1aqZ7H2kp0kIIYQQFm/AgAF06NCBihUrEhYWxrx584iOjqZHjx4mew8pmoTZcXBwYNSoUS8du7YU1nY+IOdkKeSczJ+1nY+aWrVqxe3btxk7dizXrl2jVKlSrFmzhgIFCpjsPTTKq7j2UAghhBDCwsmcJiGEEEKITJCiSQghhBAiE6RoEkIIIYTIBCmahBBCCCEyQYomIYQQQohMkKJJCPHa6tKli/6+ik9LSEigS5cuKiQSr4PRo0dz+fJltWOIbJAlB4TZ2L59O3PnzuX8+fOsWLGCvHnzsmTJEgoWLEiNGjXUjvfa69SpE126dKFWrVpqRzEZGxsbrl27ho+Pj0H7rVu38PPzIzU1VaVkmTdgwIBM7zt16tQcTCIyq0KFChw9epTatWvTtWtXmjdv/spvOyKyRxa3FGZh5cqVdOjQgXbt2nH48GGSk5OBx3fjHj9+PGvWrFE5YdaVK1cuwxtFajQaHB0dKVKkCJ06daJu3boqpMu6+/fv06BBAwIDA+ncuTPh4eHkzZtX7VjZEh8fj6Io+huYPv0LKy0tjTVr1qQrpMzV4cOHDZ4fPHiQtLQ0ihUrBsCZM2ewsbGhQoUKasQzGZ1Ox7lz54iNjUWn0xlss7RC/uDBgxw7doxFixbRv39/PvnkE1q3bk2XLl2oVKmS2vHEiyhCmIHQ0FAlMjJSURRFcXV1Vc6fP68oiqIcPnxY8fX1VTNatg0dOlTx8PBQatSooQwYMEDp37+/UrNmTcXDw0Pp27evUr9+fUWr1Sq//vqr2lEz7datW0pERIQSGhqq2NraKm+99Zby888/KykpKWpHyxKNRqNotdrnPmxsbJRx48apHTPLpkyZojRp0kS5c+eOvu3OnTtK06ZNla+//lrFZMbZvXu3UrBgQUWr1SoajcbgodVq1Y5nlEePHimrVq1SmjRpotjZ2SmlSpVSIiIilHv37qkdTWRAhueEWXB2dubkyZMEBQXh5ubG0aNHKVSoEBcuXCAkJISkpCS1I2bZhx9+SP78+fn8888N2seNG8fly5eZP38+o0aN4s8//+TAgQMqpcy+w4cPs3DhQr799ltcXV1p3749PXv2JDg4WO1oL7Vt2zYUReGNN95g5cqVeHl56bfZ29tToEABAgICVEyYPXnz5mX9+vWULFnSoP2ff/6hQYMGXL16VaVkxgkNDaVo0aKMGTMGf3//dD24Hh4eKiUzXkpKCr/88gsLFy5k8+bNVKtWjRs3bnD16lXmz59Pq1at1I4onqZy0SaEoiiKUqhQIWXDhg2Kohj2NEVGRiolSpRQM1q2ubu7K2fPnk3XfvbsWcXd3V1RFEWJiopSXF1dX3U0o129elWZOHGiUrRoUcXFxUXp2LGjUr9+fcXW1laZOnWq2vEy7dKlS0paWpraMUzG1dVV2bRpU7r2TZs2WeT32RPOzs4Z/ixZsgMHDiiffPKJ4uXlpfj7+ytDhgwxOMevv/5a8fHxUTGhyIjMaRJm4aOPPqJv374sXLgQjUbD1atX2b17NwMHDmTkyJFqx8sWR0dHdu3aRZEiRQzad+3apZ9Do9PpLOZGnY8ePWL16tUsWrSI9evXU6ZMGfr370+7du1wc3MDYPny5Xz88cf0799f5bSZU6BAAe7du8e+ffsynCvTsWNHlZJlz3vvvUfnzp2ZMmUKVatWBWDPnj0MGjSI5s2bq5wu+6pUqcK5c+fS/SxZqjJlyhAVFUWDBg1YsGABTZo0wcbGxmCfjh07MmjQIJUSiueRokmYhcGDBxMXF0fdunVJSkqiVq1aODg4MHDgQHr16qV2vGzp3bs3PXr04ODBg1SqVAmNRsO+ffv49ttv+eyzzwBYt24d5cqVUzlp5vj7+6PT6WjTpg379u0jNDQ03T4NGzbE09PzlWfLrt9//5127dqRkJCAm5ubwbCPRqOxuKJpzpw5DBw4kPbt2/Po0SMAbG1t6dq1K1999ZXK6bKvd+/efPrpp1y/fp3SpUtjZ2dnsL1MmTIqJcueli1b0qVLlxdeSJEnT550RbxQn8xpEmYlMTGRkydPotPpCAkJwdXVVe1IRlm6dCmzZs3i9OnTABQrVozevXvTtm1bAB4+fKi/ms7cLVmyhJYtW1pE1swqWrQojRs3Zvz48Tg7O6sdx2QSEhI4f/48iqJQpEgRXFxc1I5kFK02/ZKCGo0GRVHQaDSkpaWpkEq8jqRoEmYhMjKS999/3+I/3IVlcXFx4fjx4xQqVEjtKCb377//otFoLHZZiKe9bCHIAgUKvKIkpvG8tbWeXo6kadOmBhcoCPMgRZMwC3ny5CExMZEmTZrQvn173nrrLWxtrWP0+ODBg0RFRaHRaAgJCbGY4TggS/NgVq1alYNJckbz5s1p3bo1H3zwgdpRTEKn0zFu3DimTJnCgwcPAHBzc+PTTz9l+PDhGfbYiFevbt26HDp0SL+elqIonD17FhsbG4oXL87p06fRaDTs2LGDkJAQteOKp1jHbyVh8a5du8batWv54YcfaN26NU5OTrRs2ZL27dtTrVo1teNlS2xsLK1bt2br1q14enqiKIp+3tby5cvJkyeP2hFf6ulLuRVF4ZdffsHDw4OKFSsCjwvCe/fuWewk47fffptBgwZx8uTJDOfKvPvuuyoly57hw4ezYMECJk6cSPXq1VEUhZ07dzJ69GiSkpL48ssv1Y6YbefPnyciIkL/B0iJEiXo27cvhQsXVjtalj3pRVq0aBHu7u7A4wVXu3btSo0aNfjwww9p27Yt/fv3Z926dSqnFU+TniZhdhITE/nll19YtmwZGzduJF++fJw/f17tWFnWqlUrzp8/z5IlSyhRogQAJ0+eJDw8nCJFivDDDz+onDBrhgwZwp07d5gzZ47+Sp+0tDR69uyJu7u7RU40flHPiyXOlQkICGDOnDnpir3ffvuNnj17cuXKFZWSGWfdunW8++67hIaG6ovBXbt2cfToUX7//Xfq16+vdsQsyZs3Lxs2bEjXi3TixAkaNGjAlStXOHToEA0aNODWrVsqpRQZUmGZAyFe6ubNm8rMmTOVkiVLWuyKv+7u7sq+ffvSte/du1fx8PB49YGMlDt3buXUqVPp2k+dOqV4eXmpkEg8y8HBQTl9+nS69lOnTimOjo4qJDKN0NBQZciQIenahwwZopQrV06FRMZxcXFRtmzZkq59y5Yt+vW0zp8/r7i5ub3iZOJlZIBbmI3ExESWLl1K48aNCQgIYNq0aTRr1ox//vlH7WjZotPp0g33ANjZ2VnkpcSpqalERUWla4+KirLI83mWJa46/6yyZcsya9asdO2zZs2ibNmyKiQyjaioKLp27ZquvUuXLpw8eVKFRMZp2rQpXbp04ZdffuHff//lypUr/PLLL3Tt2pVmzZoBsG/fPooWLapuUJGOzGkSZqFNmzb8/vvvODs707JlS7Zu3Wqxc5meeOONN+jbty8//PCD/pYcV65coX///tSrV0/ldFnXuXNnunTpwrlz5wwWTpw4cSKdO3dWOV32pKWlMX78eObMmcONGzc4c+YMhQoV4vPPPycoKCjDX9TmbPLkybz99tts3LiRsLAwNBoNu3btIiYmxiJvev1Enjx5OHLkSLpb9Bw5csRibqz8tLlz59K/f39at25Namoq8Hg9rfDwcKZNmwZA8eLF+fbbb9WMKTKidleXEIqiKG3atFH++OMP5dGjR2pHMZno6GilXLlyip2dnVKoUCGlcOHCip2dnVK+fHklJiZG7XhZlpaWpkyaNEkJCAjQ3yw1ICBAmTRpkpKamqp2vGwZM2aMUqhQIeX7779XnJyc9Lfv+fHHH5WqVauqnC57rly5onz22WdK8+bNlffee08ZPny4cuXKFbVjGWXMmDGKp6enMnHiROXvv/9Wtm/frkyYMEHx9PRUvvjiC7XjZdv9+/eVo0ePKkeOHFHu37+vdhyRCTIRXIgctmHDBk6dOoWiKISEhPDmm2+qHclo8fHxAPorfyxVkSJFmDt3LvXq1TO4UfSpU6cICwvj7t27akcUPL5yMyIigilTpuhvOhwQEMCgQYPo06dPuhv4WhJrWk/rdSBFk1DNjBkz6N69O46OjsyYMeOF+/bp0+cVpRIvkpqaytatWzl//jxt27bFzc2Nq1ev4u7ubpGrtzs5OXHq1CkKFChgUDSdPHmSypUr69c6siT37t1jwYIFBmuDdenSxWD5CEt2//59AP39Di2RrKdluaRoEqopWLAgBw4cwNvbm4IFCz53P41Gw4ULF15hsux7WfH3NEsrBC9fvsxbb71FdHQ0ycnJ+vk//fr1IykpiTlz5qgdMcsqVqxIv379aN++vUHRNGbMGDZu3Mj27dvVjpglBw4coGHDhjg5OVG5cmUUReHAgQM8fPiQ9evXU758ebUjCmDYsGEsWLCAMWPGpFtP68MPP7To9bSsnRRNQpjQi4q/p1lSIfhEs2bNcHNzY8GCBXh7e+sLjG3bttGtWzfOnj2rdsQs+/333+nQoQPDhg1j7NixjBkzhtOnT/Pdd9/xxx9/WNz6PzVr1qRIkSLMnz9fv6J+amoq3bp148KFC/z9998qJ8y88uXLs2nTJnLlykW5cuVeOAR36NChV5jMeNa6ntbrQK6eE2Zh7NixDBw4MN1NUx8+fMhXX33FyJEjVUqWNRcvXsyw/cnfJpY892LHjh3s3LkTe3t7g/YCBQpY7Id8kyZN+PHHHxk/fjwajYaRI0dSvnx5i1wwER73ND1dMMHjq7IGDx6sX8XdUjRt2hQHBwf9f1vyz86z7ty5Q/HixdO1Fy9enDt37qiQSGSW9DQJs2BjY8O1a9fSXT58+/ZtfHx8LG5l5icWLFjAtGnT9L0wwcHB9OvXj27duqmcLOu8vLz098J6eihrx44dtGjRghs3bqgd8bXn6+vLkiVLaNCggUH7unXr6Nixo3yNzESVKlWoUqVKuuH83r17s3//fvbs2aNSMvEy0tMkzIKiKBn+JXn06FGLvdP3559/zrRp0+jduzdhYWEA7N69m/79+3Pp0iXGjRuncsKsqV+/PhEREcybNw943Gv24MEDRo0aRePGjVVOZ7wHDx6kW6TT0q4ObNWqFV27duXrr7+mWrVq+pu+Dho0iDZt2qgdL9sKFSrE/v378fb2Nmi/d+8e5cuXt7ihbmtdT+t1ID1NQlW5cuVCo9EQFxeHu7u7QeGUlpbGgwcP6NGjB998842KKbMnd+7czJw5M90vqx9++IHevXtb3D2lrl69St26dbGxseHs2bNUrFiRs2fPkjt3bv7++2+LXGTw4sWL9OrVi61btxqsCP6kiLeEHs5jx45RqlQptFotKSkpDBo0iDlz5ugXTbSzs+Pjjz9m4sSJ+uEuS6PVarl+/Xq677EbN24QGBhISkqKSsmy7+rVq3zzzTcGy5H07NlTvxCuME9SNAlVRUZGoigKXbp0ISIiwuCyaHt7e4KCgvS9NJYmV65c7Nu3L90qxmfOnKFy5crcu3dPnWBGePjwIT/88AOHDh1Cp9NRvnx52rVrh5OTk9rRsuXJqvN9+/bF19c3XW9n7dq11YiVJU8PbT/pkXFycuLcuXPA47Wonp0raClWr14NPL4IITIy0uDzIS0tjU2bNrFhwwZOnz6tVkTxmpGiSZiFbdu2Ua1atQzv1WapevfujZ2dHVOnTjVoHzhwIA8fPrTI3jNr4+rqysGDBylWrJjaUbLN29ubNWvWUKVKFbRaLTdu3CBPnjxqxzKJJ+sVaTQanv1VZWdnR1BQEFOmTOGdd95RI16WHDt2LNP7lilTJgeTCGPInCZhFmrXrk1aWhorV640WJTv3XffxcbGRu14mTZgwAD9f2s0Gr799lvWr19vcK+2mJgYOnbsqFZEo1y5coWdO3cSGxubbv6Ppa07BVCpUiViYmIsumhq0aIFtWvXxt/fH41GQ8WKFZ/7M2Npc3+efI8VLFiQ/fv3kzt3bpUTZV9oaGiGxd+zLGVY+HUlPU3CLJw7d47GjRtz5coVihUrhqIonDlzhsDAQP78808KFy6sdsRMqVu3bqb202g0bN68OYfTmNaiRYvo0aMH9vb2eHt7GwxlWeK6UwDnz5+nR48etG/fnlKlSqXr6bSUv/jXrl3LuXPn6NOnD2PHjn3uatl9+/Z9xcnEE5cvX870vgUKFMjBJMIYUjQJs9C4cWMURWHp0qX6q+Vu375N+/bt0Wq1/PnnnyonFIGBgfTo0YNhw4ZZzW0e9uzZQ9u2bbl06ZK+7UlvgCX+xd+5c2dmzJhh0bcYeZ6EhAS2bdtGdHR0uonfltjLKSyTFE3CLLi4uLBnzx5Kly5t0H706FGqV69ukfcAszbe3t7s27fPYnr9MiMkJIQSJUowePDgDCeCy1/85uHw4cM0btyYxMREEhIS8PLy4tatWzg7O+Pj42OxvZwRERH66QglSpSgb9++VvXzZY2s489FYfEcHBz0N+J82oMHD9KtQC3U0bVrV37++We1Y5jU5cuXmTRpElWqVCEoKIgCBQoYPIR56N+/P02aNOHOnTs4OTmxZ88eLl++TIUKFfj666/Vjpdl69atIyQkhH379lGmTBlKlSrF3r17KVmyJBs2bFA7nngB6WkSZqFjx44cOnSIBQsWULlyZQD27t3Lhx9+SIUKFVi8eLG6AQVpaWm88847PHz4kNKlS6eb//PsVYKWoEmTJnTq1IkWLVqoHUW8gKenJ3v37qVYsWJ4enqye/duSpQowd69ewkPD+fUqVNqR8yScuXK0bBhQyZOnGjQPnToUNavX29x99J7ncjVc8IszJgxg/DwcMLCwvS/jFNTU3n33XeZPn26yukEwPjx41m3bp3+SrNnJ4JboiZNmtC/f3+OHz+eYSH47A1VhTrs7Oz032O+vr5ER0dTokQJPDw8iI6OVjld1kVFRfHTTz+la3+yXp0wX1I0CbPg6enJb7/9xtmzZw1WyC1SpIja0cT/mzp1KgsXLqRTp05qRzGZHj16AI9vGP0sS5wIbq3KlSvHgQMHKFq0KHXr1mXkyJHcunWLJUuWpJsHaQny5MnDkSNH0i18e+TIEYtcWf91IkWTMCvBwcHpPkiEeXBwcKB69epqxzCpZ9eaEuZp/Pjx+jmPX3zxBeHh4Xz88ccUKVKERYsWqZwu6z788EO6d+/OhQsXDO4ROGnSJD799FO144kXkDlNwiwoisKKFSvYsmVLhgsnrlq1SqVk4okJEyZw7dq1dHdmF0JkjaIoREREMGXKFK5evQpAQEAAgwYNok+fPhY73P06kKJJmIU+ffowb9486tatm+Gl35b416S1ee+999i8eTPe3t6ULFky3fwfSy1sN23axKZNmzIs1hcuXKhSKvG6eNKDZo1ra1kjGZ4TZuH7779n1apVNG7cWO0o4jk8PT1p3ry52jFMasyYMYwdO5aKFSvqb0MizM/t27cZOXLkc3ui79y5o1Iy40mxZFmkaBJmwcPDg0KFCqkdQ7yANfb2zZkzh8WLF9OhQwe1o4gXaN++PefPn6dr164Z9kRbmhs3bjBw4EB9D+ezAz5yAYL5kuE5YRYiIyNZu3YtCxcuxMnJSe044gVu3rzJ6dOn0Wg0FC1alDx58qgdKduscZVza+Tm5saOHTsoW7as2lFMolGjRkRHR9OrV68MezibNm2qUjLxMtLTJMxCy5Yt+eGHH/Dx8SEoKCjdfBlZ7E19CQkJ9O7dm++++04/PGJjY0PHjh2ZOXMmzs7OKifMum7durFs2TI+//xztaOIFyhevDgPHz5UO4bJ7Nixg+3btxMaGqp2FJFFUjQJs9CpUycOHjxI+/btraL73RoNGDCAbdu28fvvv+uXHtixYwd9+vTh008/Zfbs2SonzLqkpCTmzZvHxo0bKVOmjFWscm6N/ve//zF06FBGjhxJqVKl0n2d3N3dVUqWPYGBgemG5IRlkOE5YRZcXFxYt24dNWrUUDuKeI7cuXOzYsUK6tSpY9C+ZcsWPvjgA27evKlOMCPUrVv3uds0Gg2bN29+hWnE85w9e5Y2bdpw+PBhg3ZFUSxyEdL169czZcoU5s6dS1BQkNpxRBZIT5MwC4GBgRb31+LrJjExEV9f33TtPj4+JCYmqpDIeFu2bFE7gsiEdu3aYW9vz7Jly6yiJ7pVq1YkJiZSuHBhnJ2d0/WcWfLVgNZOepqEWfjzzz+ZOXMmc+bMkb+8zFS9evXw9vbmu+++w9HREYCHDx8SHh7OnTt32Lhxo8oJhbVydnbm8OHD+vseWrrIyMgXbg8PD39FSURWSdEkzEKuXLlITEwkNTVV/vIyU8ePH6dRo0YkJSVRtmxZNBoNR44cwcHBgfXr11OyZEm1I2ZK8+bNWbx4Me7u7i9dd8pSF+y0NrVq1WLkyJG8+eabakcRrzkZnhNmQe7sbf5Kly7N2bNn+f777/U3VW7dujXt2rWzqGUiPDw89MM7Hh4eKqcRmdG7d2/69u3LoEGDKF26dLo/qsqUKaNSsuzT6XScO3cuw8U6a9WqpVIq8TLS0ySEyJQJEybg6+tLly5dDNoXLlzIzZs3GTJkiErJhLXTarXp2jQajcVOBN+zZw9t27bl8uXL6a6is8TzeZ1I0STMRlpaGr/++itRUVFoNBpCQkJ49913sbGxUTuaAIKCgli2bBnVqlUzaN+7dy+tW7fm4sWLKiUT1u7y5csv3F6gwP+1d/dBUZ1nG8Cvw4fsCiJCANHiwoqgJAwfseomRo2aMRqrjBnFYqtGMCW2YgsUdBSUICbEjySYiRKSCqZmLNEkHYmNSRCdSgqVbyMrCSKurTIakRIWUJY97x+UfV0X7SLEs7DXb8YZ9zmHwyUyy815nuc+ikeUZGCEhITA398fqampvTa35B1Qy8WiiSxCXV0dFixYgH//+98ICAiAKIr47rvv4O3tjc8//5wdmy2ATCaDWq2Gr6+v0Xh9fT0CAwPR0dEhUbL+OXLkCPLy8qDRaHDnzh2jY2yqKr3Ozk4EBAQgPz8fgYGBUscZEI6OjqiqqoKfn5/UUaiPTO95EkkgNjYW48ePx5UrV1BeXo6KigpoNBr4+voiNjZW6niE7rYQRUVFJuNFRUUYM2aMBIn6LzMzEy+99BI8PDxQUVGBKVOmwM3NDfX19Zg/f77U8QiAvb09bt++PejbDNxt6tSpqKurkzoGPQQuBCeLcPr0aRQXF8PV1dUw5ubmhtdff93QfZqkFR0djd///vfo7OzE7NmzAQAFBQVITExEfHy8xOkezrvvvov33nsPv/zlL5Gbm4vExEQolUqkpKRwx6YFWb9+PTIyMvD+++/Dzm5w/tiqrq42/H39+vWIj49HY2PjkFnYbi0G53cfDTkODg748ccfTcZbW1sxbNgwCRLRvRITE9HU1IR169YZprFkMhmSkpKwadMmidM9HI1GY1ijJZfLDd+Dv/71rzFt2jS88847Usaj/yopKUFBQQG+/PJLBAUFwdHR0ej4YGgNERISYli83uPuTRWDeWG7NWHRRBZh4cKFePnll/HBBx9gypQpALrfKGNiYrBo0SKJ0xHQ/aaekZGB5ORkqNVqyOVyTJgwAQ4ODlJHe2ijR4/GzZs3oVAooFAoUFxcjODgYFy6dInPBrMgLi4uePHFF6WO0S/cKDE0cCE4WYTm5masWrUKx44dM9yq1ul0WLRoEQ4cOAAXFxdpA9KQFB0dDW9vb2zduhX79+9HXFwcnn76aZSWlmLJkiX44IMPpI5IRBaERRNZlLq6OqjVaoiiiMDAQO4uoZ+UXq+HXq83rJPJy8vDmTNn4Ofnh5iYGE4NW5gbN26gtrYWgiDA398f7u7uUkd6KOx5NnixaCKL8OqrryIhIQHDhw83Gm9vb8fOnTuRkpIiUTIayjQaDby9vU12ZomiiCtXrmDcuHESJaO7abVarF+/HgcPHjR0z7a1tcXKlSuxd+9ek/cNS8eeZ4MXWw6QRUhNTUVra6vJeFtbG1JTUyVIRNbA19cXN27cMBlvamoy6UdF0omLi8Pp06dx7NgxNDc3o7m5GX/9619x+vTpQblzs7GxEV5eXibj7u7uuHbtmgSJyFxcCE4WoWfXyL2qqqqM2hAQDaT7fd+1trZCJpNJkIh6c/ToURw5cgSzZs0yjC1YsAByuRzLli3Dvn37pAv3EHp6nt1bmA/mnmfWgkUTSWrUqFEQBMGwRuHuH2BdXV1obW1FTEyMhAlpKIqLiwPQvSMwOTnZaHqnq6sLJSUlCAkJkSgd3autrQ2enp4m4x4eHmhra5MgUf8MxZ5n1oJrmkhSubm5EEURa9aswVtvvWX0zKVhw4bBx8cHKpVKwoQ0FD377LMAupuqqlQqowXfPd93CQkJmDBhglQR6S5z5syBm5sbDh48aLgD2N7ejlWrVqGpqQlff/21xAn7RhRFbNy4EZmZmSY9z7h+07KxaCKLcPr0aTz11FMmnXGJfkqrV6/G3r17MWLECKmj0AOcO3cO8+fPR0dHB4KDgyEIAiorKyGTyXDixAk8/vjjUkd8KK2trUOm55m1YNFEFkGj0TzwOHcx0UDT6XSQyWSorKzEE088IXUc+h/a29vx5z//GRcuXDC0JFmxYgXkcrnU0R5aXV0dLl68iBkzZkAul993jR1ZDq5pIovg4+PzwDcLPlaABpqdnR0UCgW/tyxUWFgYCgoKMGrUKENLkrVr10oda0DcvHkTy5YtQ2FhIQRBwPfffw+lUono6Gi4uLhg9+7dUkek+2DLAbIIFRUVKC8vN/wpKSnB/v374e/vj48//ljqeDREbdmyBZs2beLDeS2QWq2GVqsFcP+WJIPVH/7wB9jb20Oj0RhtQoiIiMAXX3whYTL6Xzg9Rxbt888/x86dO3Hq1Cmpo9AQFBoairq6OnR2dkKhUJg8CLa8vFyiZKRSqeDk5ITp06cjNTUVCQkJcHJy6vXcwbZ4evTo0Thx4gSCg4MxYsQIVFVVQalU4tKlSwgKChpSBeJQw+k5smj+/v44e/as1DFoiAoPD5c6At1HTk4Otm7divz8fAiCgL/97W+Gx93cTRCEQVc0abXaXruY//DDD1wMbuF4p4ksQktLi9FrURRx7do1bNu2DRcuXEBlZaU0wYhIcjY2NmhsbISHh4fUUQbECy+8gLCwMKSlpWHEiBGorq6GQqHA8uXLodfrceTIEakj0n3wThNZBBcXl16f/+Xt7Y3Dhw9LlIqsQXNzM44cOYKLFy/ij3/8I1xdXVFeXg5PT0+MHTtW6ngEGJ43N1Ts3LkTs2bNQmlpKe7cuYPExEScP38eTU1NKCoqkjoePQCLJrIIhYWFRq9tbGzg7u4OPz+/Xm/JEw2E6upqzJ07FyNHjkRDQwPWrl0LV1dXfPrpp7h8+TIOHjwodUT6r++++w6nTp3C9evXTYqowTY95+TkhMrKSmRlZcHW1hZarRZLlizBb3/7W3R2dkodjx6A03NkUWpqaqDRaAxdcnssWrRIokQ0lM2dOxdhYWF44403jBbkfvPNN4iMjERDQ4PUEQlAdnY2XnnlFTz22GMYPXq00V1pQRAG3YJ9W1tbXLt2zWS68ebNm/Dw8GAbDAvGX+HJItTX12PJkiWorq6GIAjoqeV73hz5JkI/hbNnzyIrK8tkfOzYsWhsbJQgEfVm+/btSE9PR1JSktRRBsT97lXwQdGWj0UTWYQNGzbAx8cHX331FZRKJUpKStDU1IT4+Hjs2rVL6ng0RMlkMpNNCABQW1sLd3d3CRJRb27duoWlS5dKHaPf7n5QdEpKCh8UPQixaCKL8I9//AMnT56Eu7s7bGxsYGtri+nTp+O1115DbGwsKioqpI5IQ9DixYvx6quvIi8vD0D3DzONRoONGzfixRdflDgd9Vi6dCm+/PJLxMTESB2lX3rex0RRxLlz50weFB0cHIyEhASp4pEZWDSRRejq6jI0rnvsscdw9epVBAQEQKFQoLa2VuJ0NFTt2rULCxYsgIeHB9rb2zFz5kw0NjZCpVIhPT1d6nj0X35+fkhOTkZxcTGCgoJMHuwdGxsrUbK+6dnw8tJLL+Htt9+Gs7OzxImor7gQnCzCM888g/j4eISHhyMyMhK3bt3Cli1b8N5776GsrAzffvut1BFpCDt58iTKy8uh1+sRFhaGuXPnSh2J7uLr63vfY4IgoL6+/hGmIWvGookswokTJwzbbuvr67Fw4UJcuHABbm5u+Mtf/oLZs2dLHZGGoIMHDyIiIsKkC/OdO3dw+PBhrFy5UqJkRGSJWDSRxWpqasKoUaNMml4SDRRu/bZccXFxSEtLg6Ojo2EBdW8EQcDu3bsfYTKyZlzTRBbL1dVV6gg0xImi2GtR/q9//QsjR46UIBH1qKioMDR6fNBGEP5SRY8S7zQRkdUJDQ2FIAioqqrC448/btR1vqurC5cuXcLzzz9v2FVHRATwThMRWaHw8HAAQGVlJebNm2fYuQl0b/328fFhywEiMsE7TURktXJzcxEREcEuzERkFhZNRGT17ty50+uDYMeNGydRIiKyRJyeIyKr9f3332PNmjX45ptvjMZ7Fohz9xwR3Y1FExFZrdWrV8POzg75+fnw8vLiTiwieiBOzxGR1XJ0dERZWRkmTpwodRQiGgRspA5ARCSVwMBA/PDDD1LHIKJBgkUTEVmtjIwMJCYm4tSpU7h58yZaWlqM/hAR3Y3Tc0RktWxs/v/3xrvXM3EhOBH1hgvBichqFRYWSh2BiAYRTs8RkdWaOXMmbGxskJ2djY0bN8LPzw8zZ86ERqOBra2t1PGIyMKwaCIiq3X06FHMmzcPcrkcFRUVuH37NgDgxx9/xI4dOyROR0SWhkUTEVmt7du3Y//+/cjOzoa9vb1h/KmnnkJ5ebmEyYjIErFoIiKrVVtbixkzZpiMOzs7o7m5+dEHIiKLxqKJiKyWl5cX6urqTMbPnDkDpVIpQSIismQsmojIav3mN7/Bhg0bUFJSAkEQcPXqVRw6dAgJCQlYt26d1PGIyMKwTxMRWbXNmzfjzTffREdHBwDAwcEBCQkJSEtLkzgZEVkaFk1EZPXa2tpQU1MDvV6PwMBAODk5SR2JiCwQiyYiIiIiM3BNExEREZEZWDQRERERmYFFExEREZEZWDQRERERmYFFExENGtu2bUNISIjh9erVqxEeHv7IczQ0NEAQBFRWVt73HB8fH7z11ltmXzMnJwcuLi79ziYIAj777LN+X4eITLFoIqJ+Wb16NQRBgCAIsLe3h1KpREJCArRa7U/+ud9++23k5OSYda45hQ4R0YPYSR2AiAa/559/HgcOHEBnZyf+/ve/Izo6GlqtFvv27TM5t7Oz0+jhuP0xcuTIAbkOEZE5eKeJiPrNwcEBo0ePhre3NyIjI7FixQrDFFHPlNqf/vQnKJVKODg4QBRF/Oc//8HLL78MDw8PODs7Y/bs2aiqqjK67uuvvw5PT0+MGDECUVFRhq7dPe6dntPr9cjIyICfnx8cHBwwbtw4pKenAwB8fX0BAKGhoRAEAbNmzTJ83IEDBzBp0iTIZDJMnDgR7777rtHn+ec//4nQ0FDIZDJMnjwZFRUVff4a7dmzB0FBQXB0dIS3tzfWrVuH1tZWk/M+++wz+Pv7QyaT4bnnnsOVK1eMjh87dgxPPvkkZDIZlEolUlNTodPp+pyHiPqORRMRDTi5XI7Ozk7D67q6OuTl5eHo0aOG6bEXXngBjY2NOH78OMrKyhAWFoY5c+agqakJAJCXl4etW7ciPT0dpaWl8PLyMilm7rVp0yZkZGQgOTkZNTU1+Oijj+Dp6Qmgu/ABgK+//hrXrl3DJ598AgDIzs7G5s2bkZ6eDrVajR07diA5ORm5ubkAAK1Wi4ULFyIgIABlZWXYtm0bEhIS+vw1sbGxQWZmJr799lvk5ubi5MmTSExMNDqnra0N6enpyM3NRVFREVpaWrB8+XLD8RMnTuBXv/oVYmNjUVNTg6ysLOTk5BgKQyL6iYlERP2watUqcfHixYbXJSUlopubm7hs2TJRFEVx69ator29vXj9+nXDOQUFBaKzs7PY0dFhdK3x48eLWVlZoiiKokqlEmNiYoyOT506VQwODu71c7e0tIgODg5idnZ2rzkvXbokAhArKiqMxr29vcWPPvrIaCwtLU1UqVSiKIpiVlaW6OrqKmq1WsPxffv29XqtuykUCvHNN9+87/G8vDzRzc3N8PrAgQMiALG4uNgwplarRQBiSUmJKIqi+Mwzz4g7duwwus6HH34oenl5GV4DED/99NP7fl4ienhc00RE/Zafnw8nJyfodDp0dnZi8eLF2Lt3r+G4QqGAu7u74XVZWRlaW1vh5uZmdJ329nZcvHgRAKBWqxETE2N0XKVSobCwsNcMarUat2/fxpw5c8zOfePGDVy5cgVRUVFYu3atYVyn0xnWS6nVagQHB2P48OFGOfqqsLAQO3bsQE1NDVpaWqDT6dDR0QGtVgtHR0cAgJ2dHSZPnmz4mIkTJ8LFxQVqtRpTpkxBWVkZzp49a3RnqaurCx0dHWhrazPKSEQDj0UTEfXbs88+i3379sHe3h5jxowxWejdUxT00Ov18PLywqlTp0yu9bDb7uVyeZ8/Rq/XA+ieops6darRMVtbWwCAOACP57x8+TIWLFiAmJgYpKWlwdXVFWfOnEFUVJTRNCbQ3TLgXj1jer0eqampWLJkick5Mpms3zmJ6MFYNBFRvzk6OsLPz8/s88PCwtDY2Ag7Ozv4+Pj0es6kSZNQXFyMlStXGsaKi4vve80JEyZALpejoKAA0dHRJseHDRsGoPvOTA9PT0+MHTsW9fX1WLFiRa/XDQwMxIcffoj29nZDYfagHL0pLS2FTqfD7t27YWPTvZQ0Ly/P5DydTofS0lJMmTIFAFBbW4vm5mZMnDgRQPfXrba2tk9fayIaOCyaiOiRmzt3LlQqFcLDw5GRkYGAgABcvXoVx48fR3h4OCZPnowNGzZg1apVmDx5MqZPn45Dhw7h/PnzUCqVvV5TJpMhKSkJiYmJGDZsGJ5++mncuHED58+fR1RUFDw8PCCXy/HFF1/gZz/7GWQyGUaOHIlt27YhNjYWzs7OmD9/Pm7fvo3S0lLcunULcXFxiIyMxObNmxEVFYUtW7agoaEBu3bt6tO/d/z48dDpdNi7dy9+8YtfoKioCPv37zc5z97eHuvXr0dmZibs7e3xu9/9DtOmTTMUUSkpKVi4cCG8vb2xdOlS2NjYoLq6GufOncP27dv7/h9BRH3C3XNE9MgJgoDjx49jxowZWLNmDfz9/bF8+XI0NDQYdrtFREQgJSUFSUlJePLJJ3H58mW88sorD7xucnIy4uPjkZKSgkmTJiEiIgLXr18H0L1eKDMzE1lZWRgzZgwWL14MAIiOjsb777+PnJwcBAUFYebMmcjJyTG0KHBycsKxY8dQU1OD0NBQbN68GRkZGX3694aEhGDPnj3IyMjAE088gUOHDuG1114zOW/48OFISkpCZGQkVCoV5HI5Dh8+bDg+b9485Ofn46uvvsLPf/5zTJs2DXv27IFCoehTHiJ6OII4EBP2REREREMc7zQRERERmYFFExEREZEZWDQRERERmYFFExEREZEZWDQRERERmYFFExEREZEZWDQRERERmYFFExEREZEZWDQRERERmYFFExEREZEZWDQRERERmeH/AJpnqv2ejKt1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = custom_model.predict(x_test)\n",
    "predictions = np.argmax(pred, axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), predictions)\n",
    "acc = accuracy_score(np.argmax(y_test, axis=1), predictions)\n",
    "print(f\"Accuracy of {round(acc*100, 2)}%\")\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 14s 75ms/step - loss: 2.9764 - accuracy: 0.3822 - val_loss: 0.5117 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4497 - accuracy: 0.5548 - val_loss: 0.3329 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2855 - accuracy: 0.6929 - val_loss: 0.5779 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1936 - accuracy: 0.7904 - val_loss: 0.3452 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1562 - accuracy: 0.8452 - val_loss: 0.3059 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1292 - accuracy: 0.8751 - val_loss: 0.3904 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0964 - accuracy: 0.9066 - val_loss: 0.4488 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0931 - accuracy: 0.9168 - val_loss: 0.3671 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0684 - accuracy: 0.9406 - val_loss: 0.3464 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0518 - accuracy: 0.9437 - val_loss: 0.4366 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0472 - accuracy: 0.9548 - val_loss: 0.4153 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0386 - accuracy: 0.9574 - val_loss: 0.4749 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0338 - accuracy: 0.9584 - val_loss: 0.4938 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0292 - accuracy: 0.9619 - val_loss: 0.5644 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0253 - accuracy: 0.9624 - val_loss: 0.5750 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.3173 - accuracy: 0.6846\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.685 total time=  58.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 68ms/step - loss: 2.5878 - accuracy: 0.3968 - val_loss: 0.8198 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.5344 - accuracy: 0.6758 - val_loss: 0.5224 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2640 - accuracy: 0.8341 - val_loss: 0.7305 - val_accuracy: 0.6122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1724 - accuracy: 0.8909 - val_loss: 0.7195 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0947 - accuracy: 0.9523 - val_loss: 0.6648 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0578 - accuracy: 0.9645 - val_loss: 0.6690 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0375 - accuracy: 0.9822 - val_loss: 0.7263 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.5599 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0032 - accuracy: 0.9975 - val_loss: 0.5605 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5819 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9743e-04 - accuracy: 0.9995 - val_loss: 0.5970 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9742e-04 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 0.6129 - accuracy: 0.5797\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.580 total time=  37.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 51ms/step - loss: 2.4298 - accuracy: 0.4307 - val_loss: 0.4848 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3835 - accuracy: 0.7291 - val_loss: 0.4648 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1875 - accuracy: 0.8600 - val_loss: 0.4000 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1199 - accuracy: 0.9148 - val_loss: 0.4442 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0841 - accuracy: 0.9533 - val_loss: 0.5349 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0569 - accuracy: 0.9650 - val_loss: 1.1006 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0540 - accuracy: 0.9746 - val_loss: 0.5860 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 0.7849 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.5579 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5792 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.5895 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.6020 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9985 - val_loss: 0.6410 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4566 - accuracy: 0.6843\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.684 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5774 - accuracy: 0.4853 - val_loss: 0.8557 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.3192 - accuracy: 0.8569 - val_loss: 0.4782 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0661 - accuracy: 0.9731 - val_loss: 0.5059 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.4417 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.4717 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9257e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4680e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9456e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9123e-04 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8807e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8503e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8165e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4332 - accuracy: 0.7657\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.766 total time=  40.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.7488 - accuracy: 0.4774 - val_loss: 0.6613 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3319 - accuracy: 0.8645 - val_loss: 0.5478 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.6365 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.5732 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5848 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5907 - val_accuracy: 0.7946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.5827 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4148e-04 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8363e-04 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5845e-04 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4107e-04 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5893 - accuracy: 0.7086\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.709 total time=  34.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.3638 - accuracy: 0.4957 - val_loss: 0.7382 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.4009 - accuracy: 0.8331 - val_loss: 0.5341 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1071 - accuracy: 0.9645 - val_loss: 0.5587 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0381 - accuracy: 0.9919 - val_loss: 0.5700 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0263 - accuracy: 0.9964 - val_loss: 0.5299 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0216 - accuracy: 0.9970 - val_loss: 0.5215 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.5423 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.5172 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4355e-04 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0898e-04 - accuracy: 0.9995 - val_loss: 0.5631 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3308e-04 - accuracy: 0.9995 - val_loss: 0.5319 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.2463e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4485e-04 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7284e-04 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4756e-04 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3672e-04 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2948e-04 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5845 - accuracy: 0.7411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.741 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.9415 - accuracy: 0.3832 - val_loss: 0.8438 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3802 - accuracy: 0.6518 - val_loss: 0.5365 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2643 - accuracy: 0.7660 - val_loss: 0.4064 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1598 - accuracy: 0.8528 - val_loss: 0.3616 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1097 - accuracy: 0.8964 - val_loss: 0.4235 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0721 - accuracy: 0.9381 - val_loss: 0.4723 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0562 - accuracy: 0.9624 - val_loss: 0.5237 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0438 - accuracy: 0.9701 - val_loss: 0.5103 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0280 - accuracy: 0.9812 - val_loss: 0.7329 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0126 - accuracy: 0.9883 - val_loss: 0.6460 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9944 - val_loss: 0.6566 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0029 - accuracy: 0.9944 - val_loss: 0.6780 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9954 - val_loss: 0.6878 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9964 - val_loss: 0.7060 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3995 - accuracy: 0.6237\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.624 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.8079 - accuracy: 0.3952 - val_loss: 0.6025 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4035 - accuracy: 0.6809 - val_loss: 0.4255 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2387 - accuracy: 0.8072 - val_loss: 0.4166 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1540 - accuracy: 0.8772 - val_loss: 0.4104 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0949 - accuracy: 0.9239 - val_loss: 0.4349 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0664 - accuracy: 0.9513 - val_loss: 0.4677 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0446 - accuracy: 0.9660 - val_loss: 0.6124 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0333 - accuracy: 0.9782 - val_loss: 0.6451 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0326 - accuracy: 0.9787 - val_loss: 0.5815 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0177 - accuracy: 0.9904 - val_loss: 0.5602 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0082 - accuracy: 0.9939 - val_loss: 0.5778 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0044 - accuracy: 0.9959 - val_loss: 0.6100 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 0.9970 - val_loss: 0.6239 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9970 - val_loss: 0.6656 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4273 - accuracy: 0.6721\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.672 total time=  41.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.7573 - accuracy: 0.3501 - val_loss: 0.5035 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3959 - accuracy: 0.5419 - val_loss: 0.3769 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2952 - accuracy: 0.6626 - val_loss: 0.4178 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2100 - accuracy: 0.7468 - val_loss: 0.3081 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1539 - accuracy: 0.8138 - val_loss: 0.2893 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1283 - accuracy: 0.8483 - val_loss: 0.3319 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1145 - accuracy: 0.8706 - val_loss: 0.3506 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0957 - accuracy: 0.8894 - val_loss: 0.3416 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0700 - accuracy: 0.9173 - val_loss: 0.4329 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0686 - accuracy: 0.9259 - val_loss: 0.3522 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0408 - accuracy: 0.9472 - val_loss: 0.3713 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0362 - accuracy: 0.9482 - val_loss: 0.4076 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0335 - accuracy: 0.9508 - val_loss: 0.4447 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0305 - accuracy: 0.9523 - val_loss: 0.5422 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0274 - accuracy: 0.9579 - val_loss: 0.5382 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3035 - accuracy: 0.6457\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.646 total time=  44.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.8071 - accuracy: 0.3467 - val_loss: 0.3542 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3467 - accuracy: 0.5528 - val_loss: 0.3123 - val_accuracy: 0.5865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2313 - accuracy: 0.7091 - val_loss: 0.2647 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1595 - accuracy: 0.7924 - val_loss: 0.2646 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1112 - accuracy: 0.8584 - val_loss: 0.2856 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0880 - accuracy: 0.8853 - val_loss: 0.2881 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0736 - accuracy: 0.9051 - val_loss: 0.3107 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0664 - accuracy: 0.9162 - val_loss: 0.3162 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0588 - accuracy: 0.9264 - val_loss: 0.3092 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0544 - accuracy: 0.9355 - val_loss: 0.3249 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0451 - accuracy: 0.9360 - val_loss: 0.3179 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0407 - accuracy: 0.9386 - val_loss: 0.3142 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0387 - accuracy: 0.9381 - val_loss: 0.3172 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0372 - accuracy: 0.9396 - val_loss: 0.3282 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2502 - accuracy: 0.6765\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.676 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0989 - accuracy: 0.3780 - val_loss: 0.3581 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2954 - accuracy: 0.6129 - val_loss: 0.3045 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1693 - accuracy: 0.7905 - val_loss: 0.3208 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0947 - accuracy: 0.8889 - val_loss: 0.3730 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0519 - accuracy: 0.9442 - val_loss: 0.3629 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9619 - val_loss: 0.3680 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9782 - val_loss: 0.3883 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0124 - accuracy: 0.9853 - val_loss: 0.3839 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9888 - val_loss: 0.3868 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0071 - accuracy: 0.9893 - val_loss: 0.3902 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0064 - accuracy: 0.9899 - val_loss: 0.3911 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0059 - accuracy: 0.9899 - val_loss: 0.3929 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3208 - accuracy: 0.5431\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.543 total time=  35.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4157 - accuracy: 0.4668 - val_loss: 0.5074 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1836 - accuracy: 0.8909 - val_loss: 0.3936 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0496 - accuracy: 0.9751 - val_loss: 0.4007 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0226 - accuracy: 0.9954 - val_loss: 0.4099 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.4481 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.9179e-04 - accuracy: 0.9995 - val_loss: 0.4003 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8791e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7264e-04 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6259e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5398e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4602e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4446 - accuracy: 0.7025\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.703 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 4.3191 - accuracy: 0.4284 - val_loss: 0.8100 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.6271 - accuracy: 0.7919 - val_loss: 0.8744 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3110 - accuracy: 0.9015 - val_loss: 0.8591 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1692 - accuracy: 0.9523 - val_loss: 0.8375 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1318 - accuracy: 0.9624 - val_loss: 1.9288 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1187 - accuracy: 0.9731 - val_loss: 1.0603 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0259 - accuracy: 0.9959 - val_loss: 0.9591 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.9719 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6421e-04 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9837e-04 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5081e-06 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.8971 - accuracy: 0.6450\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.645 total time=  33.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.4745 - accuracy: 0.4049 - val_loss: 1.3793 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.8121 - accuracy: 0.7113 - val_loss: 1.0284 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4534 - accuracy: 0.8366 - val_loss: 0.9269 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2035 - accuracy: 0.9234 - val_loss: 0.8512 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1744 - accuracy: 0.9417 - val_loss: 0.8444 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1133 - accuracy: 0.9711 - val_loss: 0.8286 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0791 - accuracy: 0.9822 - val_loss: 0.8968 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0620 - accuracy: 0.9843 - val_loss: 0.9936 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0553 - accuracy: 0.9909 - val_loss: 1.9342 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0629 - accuracy: 0.9858 - val_loss: 1.0482 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0319 - accuracy: 0.9949 - val_loss: 0.9946 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.9324 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.7618e-04 - accuracy: 0.9995 - val_loss: 0.9467 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.4473e-05 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2460e-06 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.1850e-06 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.8442 - accuracy: 0.7360\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.736 total time=  47.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.2237 - accuracy: 0.4373 - val_loss: 1.5213 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.6576 - accuracy: 0.7681 - val_loss: 1.1140 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2741 - accuracy: 0.9066 - val_loss: 1.2661 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1181 - accuracy: 0.9635 - val_loss: 1.0295 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1013 - accuracy: 0.9650 - val_loss: 0.9808 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0817 - accuracy: 0.9762 - val_loss: 0.8042 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0712 - accuracy: 0.9817 - val_loss: 0.9494 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 1.4364 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 1.6223 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9934 - val_loss: 1.3025 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 1.2481 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 1.0257 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.0534 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 1.0193 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.3936e-07 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4704e-07 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.9133 - accuracy: 0.7218\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.722 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3314 - accuracy: 0.5036 - val_loss: 0.8731 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3286 - accuracy: 0.9066 - val_loss: 0.7664 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0929 - accuracy: 0.9746 - val_loss: 0.8198 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 0.7577 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0155 - accuracy: 0.9990 - val_loss: 0.8244 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.8822 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.8568 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.8463 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8407 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7661e-05 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.2706e-05 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9895e-05 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7626 - accuracy: 0.7556\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.756 total time=  40.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.1270 - accuracy: 0.5099 - val_loss: 0.7594 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.3132 - accuracy: 0.9097 - val_loss: 0.8286 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0789 - accuracy: 0.9792 - val_loss: 0.7503 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0330 - accuracy: 0.9954 - val_loss: 0.7169 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.8355 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7224e-04 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.0825e-05 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.0329e-05 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9692e-05 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9033e-05 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8325e-05 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7672e-05 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7601 - accuracy: 0.7503\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.750 total time=  40.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 47ms/step - loss: 1.6035 - accuracy: 0.4683 - val_loss: 0.5344 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2926 - accuracy: 0.8767 - val_loss: 0.4614 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0916 - accuracy: 0.9685 - val_loss: 0.5033 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.4455 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.5226 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.4847 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4888 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4822 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4050e-04 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3560e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3190e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2865e-04 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2555e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4869 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.742 total time=  40.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.3014 - accuracy: 0.4147 - val_loss: 0.5475 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3627 - accuracy: 0.7574 - val_loss: 0.5873 - val_accuracy: 0.6135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2082 - accuracy: 0.8619 - val_loss: 0.4879 - val_accuracy: 0.6378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1010 - accuracy: 0.9340 - val_loss: 0.4811 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0707 - accuracy: 0.9533 - val_loss: 0.5820 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0526 - accuracy: 0.9721 - val_loss: 0.5019 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.7488 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.8146 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.8538 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 0.7247 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7704e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.4745e-05 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7776e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4692 - accuracy: 0.7343\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.734 total time=  41.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.6217 - accuracy: 0.4216 - val_loss: 0.4631 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4084 - accuracy: 0.6535 - val_loss: 0.4124 - val_accuracy: 0.5486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2396 - accuracy: 0.7768 - val_loss: 0.3099 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1770 - accuracy: 0.8610 - val_loss: 0.5126 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1098 - accuracy: 0.9132 - val_loss: 0.4009 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0824 - accuracy: 0.9366 - val_loss: 0.3433 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0632 - accuracy: 0.9548 - val_loss: 0.4994 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0520 - accuracy: 0.9660 - val_loss: 0.5899 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0314 - accuracy: 0.9807 - val_loss: 0.5142 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0146 - accuracy: 0.9883 - val_loss: 0.5041 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9909 - val_loss: 0.5304 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9909 - val_loss: 0.5762 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0045 - accuracy: 0.9929 - val_loss: 0.6177 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3568 - accuracy: 0.6721\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.672 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.1392 - accuracy: 0.4282 - val_loss: 0.5408 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4031 - accuracy: 0.7159 - val_loss: 0.4347 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2579 - accuracy: 0.8234 - val_loss: 0.4055 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1501 - accuracy: 0.8970 - val_loss: 0.6148 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0992 - accuracy: 0.9417 - val_loss: 0.6491 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0927 - accuracy: 0.9493 - val_loss: 0.6719 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0528 - accuracy: 0.9726 - val_loss: 0.6957 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.9950 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0258 - accuracy: 0.9878 - val_loss: 0.6253 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0058 - accuracy: 0.9954 - val_loss: 0.6423 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.6530 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.6665 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.7002 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4837 - accuracy: 0.6335\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.634 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.7938 - accuracy: 0.5254 - val_loss: 0.7419 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1817 - accuracy: 0.9218 - val_loss: 0.6011 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.6295 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.6399 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.5780 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6051 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9833e-04 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0328e-04 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.5242e-05 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3100e-05 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4850e-05 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.8841e-05 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.4032e-05 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.0384e-05 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.0002e-05 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9650e-05 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9235e-05 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.8869e-05 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5308 - accuracy: 0.7647\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.765 total time=  51.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 47ms/step - loss: 1.5541 - accuracy: 0.5028 - val_loss: 0.5422 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2079 - accuracy: 0.8914 - val_loss: 0.4999 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 0.4394 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.4424 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.4732 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.9329e-04 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7995e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8401e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7941e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7519e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7102e-04 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6666e-04 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5123 - accuracy: 0.7046\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.705 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.6050 - accuracy: 0.5373 - val_loss: 0.6132 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2344 - accuracy: 0.8955 - val_loss: 0.5443 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0655 - accuracy: 0.9706 - val_loss: 0.5879 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.5479 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.5383 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5445 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4451e-04 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2720e-04 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.2024e-04 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5095e-04 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.5027e-05 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.3483e-05 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7922e-05 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4725e-05 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4371e-05 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4035e-05 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3696e-05 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3348e-05 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.6309 - accuracy: 0.7543\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.754 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5912 - accuracy: 0.3716 - val_loss: 0.3416 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1771 - accuracy: 0.7761 - val_loss: 0.2943 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0677 - accuracy: 0.9305 - val_loss: 0.3486 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0243 - accuracy: 0.9817 - val_loss: 0.3904 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9959 - val_loss: 0.3921 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.3889 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.4744 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9460e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7860e-05 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0998e-06 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6614e-06 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1512e-07 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2962 - accuracy: 0.6217\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.622 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6312 - accuracy: 0.3927 - val_loss: 0.3693 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1929 - accuracy: 0.7504 - val_loss: 0.3237 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0846 - accuracy: 0.9137 - val_loss: 0.2868 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0352 - accuracy: 0.9716 - val_loss: 0.3480 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0178 - accuracy: 0.9883 - val_loss: 0.4371 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0091 - accuracy: 0.9954 - val_loss: 0.4133 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.4967 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.4637 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8650e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.1763e-05 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1903e-06 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4425e-06 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7591e-07 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2843 - accuracy: 0.6650\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.665 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5323 - accuracy: 0.3516 - val_loss: 0.3557 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2047 - accuracy: 0.7250 - val_loss: 0.3548 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0985 - accuracy: 0.8858 - val_loss: 0.3073 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0431 - accuracy: 0.9523 - val_loss: 0.2941 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0219 - accuracy: 0.9802 - val_loss: 0.3187 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0142 - accuracy: 0.9883 - val_loss: 0.3957 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0079 - accuracy: 0.9954 - val_loss: 0.4646 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0048 - accuracy: 0.9964 - val_loss: 0.4364 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.5391 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.5527e-04 - accuracy: 0.9990 - val_loss: 0.4774 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.3637e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.6820e-05 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6298e-05 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5391e-05 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3488 - accuracy: 0.6548\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.655 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.5326 - accuracy: 0.3579 - val_loss: 0.3255 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1938 - accuracy: 0.7371 - val_loss: 0.2784 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0889 - accuracy: 0.9036 - val_loss: 0.2742 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0373 - accuracy: 0.9716 - val_loss: 0.2855 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0161 - accuracy: 0.9914 - val_loss: 0.3221 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.3278 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3497 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9578e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5323e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.1728e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8457e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.5358e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2559 - accuracy: 0.6613\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.661 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6012 - accuracy: 0.3450 - val_loss: 0.3221 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2006 - accuracy: 0.7250 - val_loss: 0.2623 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0991 - accuracy: 0.8914 - val_loss: 0.2438 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0416 - accuracy: 0.9630 - val_loss: 0.2638 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0177 - accuracy: 0.9899 - val_loss: 0.2965 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.2974 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3313 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1973e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5494e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.0671e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.6517e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2612 - accuracy: 0.6579\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.658 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5693 - accuracy: 0.3577 - val_loss: 0.3279 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1987 - accuracy: 0.7265 - val_loss: 0.2862 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0857 - accuracy: 0.9016 - val_loss: 0.2682 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0380 - accuracy: 0.9685 - val_loss: 0.2898 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.3238 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.3327 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.3499 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3848 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3717 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3702 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3709 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2842 - accuracy: 0.6335\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.634 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6683 - accuracy: 0.3096 - val_loss: 0.3866 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2645 - accuracy: 0.6056 - val_loss: 0.3254 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1474 - accuracy: 0.8117 - val_loss: 0.3328 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0665 - accuracy: 0.9239 - val_loss: 0.3339 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0435 - accuracy: 0.9523 - val_loss: 0.4170 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0279 - accuracy: 0.9736 - val_loss: 0.4397 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0139 - accuracy: 0.9893 - val_loss: 0.5214 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0055 - accuracy: 0.9954 - val_loss: 0.4590 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 0.4802 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.4898 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 0.5144 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 6.8460e-04 - accuracy: 0.9990 - val_loss: 0.5466 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3116 - accuracy: 0.5801\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.580 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 54ms/step - loss: 0.7332 - accuracy: 0.3364 - val_loss: 0.4104 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2372 - accuracy: 0.6733 - val_loss: 0.2966 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1224 - accuracy: 0.8468 - val_loss: 0.3099 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0558 - accuracy: 0.9457 - val_loss: 0.4156 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0265 - accuracy: 0.9807 - val_loss: 0.3638 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0161 - accuracy: 0.9873 - val_loss: 0.3963 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0069 - accuracy: 0.9954 - val_loss: 0.4815 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4366 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5532e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.3832e-05 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7706e-06 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.9172e-06 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3276 - accuracy: 0.5635\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.563 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6519 - accuracy: 0.3374 - val_loss: 0.3776 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2560 - accuracy: 0.6464 - val_loss: 0.3319 - val_accuracy: 0.5365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1473 - accuracy: 0.8270 - val_loss: 0.3130 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0778 - accuracy: 0.9183 - val_loss: 0.3757 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0510 - accuracy: 0.9503 - val_loss: 0.4451 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0287 - accuracy: 0.9751 - val_loss: 0.3980 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0158 - accuracy: 0.9904 - val_loss: 0.5616 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0125 - accuracy: 0.9924 - val_loss: 0.4255 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 0.4103 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.4271 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6002e-04 - accuracy: 0.9990 - val_loss: 0.4594 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.9836e-04 - accuracy: 0.9995 - val_loss: 0.4930 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.3894e-04 - accuracy: 0.9995 - val_loss: 0.5223 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3413 - accuracy: 0.5939\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.594 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6824 - accuracy: 0.3142 - val_loss: 0.3622 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2508 - accuracy: 0.6162 - val_loss: 0.3189 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1335 - accuracy: 0.8294 - val_loss: 0.2935 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0656 - accuracy: 0.9315 - val_loss: 0.3124 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9614 - val_loss: 0.3335 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0200 - accuracy: 0.9802 - val_loss: 0.3666 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0117 - accuracy: 0.9909 - val_loss: 0.3913 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9929 - val_loss: 0.3927 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.3891 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.3923 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3960 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3990 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4013 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2982 - accuracy: 0.6187\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.619 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7074 - accuracy: 0.3394 - val_loss: 0.3600 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2362 - accuracy: 0.6479 - val_loss: 0.3371 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1338 - accuracy: 0.8229 - val_loss: 0.2947 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0680 - accuracy: 0.9305 - val_loss: 0.3090 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0355 - accuracy: 0.9630 - val_loss: 0.3045 - val_accuracy: 0.6243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0198 - accuracy: 0.9817 - val_loss: 0.3188 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0115 - accuracy: 0.9909 - val_loss: 0.3315 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0085 - accuracy: 0.9934 - val_loss: 0.3531 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0051 - accuracy: 0.9970 - val_loss: 0.3542 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.3554 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.3564 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3570 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.3585 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3122 - accuracy: 0.5949\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.595 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6408 - accuracy: 0.3222 - val_loss: 0.3530 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2556 - accuracy: 0.6251 - val_loss: 0.3054 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1550 - accuracy: 0.7854 - val_loss: 0.2876 - val_accuracy: 0.6189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0869 - accuracy: 0.8914 - val_loss: 0.3059 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0440 - accuracy: 0.9482 - val_loss: 0.3046 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0312 - accuracy: 0.9655 - val_loss: 0.3114 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9777 - val_loss: 0.3105 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0171 - accuracy: 0.9827 - val_loss: 0.3488 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0130 - accuracy: 0.9868 - val_loss: 0.3368 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0096 - accuracy: 0.9883 - val_loss: 0.3376 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9893 - val_loss: 0.3396 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0076 - accuracy: 0.9904 - val_loss: 0.3416 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0071 - accuracy: 0.9909 - val_loss: 0.3414 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3327 - accuracy: 0.5411\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.541 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 54ms/step - loss: 0.7084 - accuracy: 0.3518 - val_loss: 0.3114 - val_accuracy: 0.5257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2052 - accuracy: 0.7152 - val_loss: 0.2650 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0905 - accuracy: 0.9122 - val_loss: 0.3544 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0390 - accuracy: 0.9695 - val_loss: 0.3904 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0182 - accuracy: 0.9893 - val_loss: 0.4623 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0102 - accuracy: 0.9934 - val_loss: 0.3642 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.4338 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.3821 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.3333e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.8591e-05 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.6077e-05 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 7.8291e-06 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2647 - accuracy: 0.6471\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.647 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7172 - accuracy: 0.4069 - val_loss: 0.3548 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1656 - accuracy: 0.8001 - val_loss: 0.2760 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0630 - accuracy: 0.9452 - val_loss: 0.2662 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0245 - accuracy: 0.9812 - val_loss: 0.4628 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0126 - accuracy: 0.9939 - val_loss: 0.4842 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.3809 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0167 - accuracy: 0.9934 - val_loss: 0.3935 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.5614 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4357 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6396e-05 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7819e-06 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5248e-07 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5985e-07 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2886 - accuracy: 0.6751\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.675 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7241 - accuracy: 0.3643 - val_loss: 0.3518 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2127 - accuracy: 0.7199 - val_loss: 0.2976 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1018 - accuracy: 0.8869 - val_loss: 0.3001 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0519 - accuracy: 0.9493 - val_loss: 0.3106 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0224 - accuracy: 0.9848 - val_loss: 0.3262 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0162 - accuracy: 0.9878 - val_loss: 0.4273 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.4012 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.3807 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3939 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6560e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4205e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6750e-05 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3226 - accuracy: 0.5766\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.577 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.7412 - accuracy: 0.3797 - val_loss: 0.3559 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1505 - accuracy: 0.8381 - val_loss: 0.3079 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0501 - accuracy: 0.9655 - val_loss: 0.3078 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.3152 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.3337 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3457 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.7027 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3029 - accuracy: 0.6785\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.678 total time=  37.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6376 - accuracy: 0.3998 - val_loss: 0.3138 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1378 - accuracy: 0.8554 - val_loss: 0.2639 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0430 - accuracy: 0.9736 - val_loss: 0.2681 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.2784 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.3009 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3072 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9439e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.6574e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.3943e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1420e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8878e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2817 - accuracy: 0.6386\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.639 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 52ms/step - loss: 0.6818 - accuracy: 0.3475 - val_loss: 0.3599 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1839 - accuracy: 0.7712 - val_loss: 0.2959 - val_accuracy: 0.6068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0776 - accuracy: 0.9325 - val_loss: 0.2925 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0289 - accuracy: 0.9822 - val_loss: 0.3168 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.3353 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0078 - accuracy: 0.9959 - val_loss: 0.3492 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3907 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0278e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4522e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0453e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.6833e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2871 - accuracy: 0.6660\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.666 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9095 - accuracy: 0.3518 - val_loss: 0.4124 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2188 - accuracy: 0.7447 - val_loss: 0.3505 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0983 - accuracy: 0.9046 - val_loss: 0.4379 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0435 - accuracy: 0.9716 - val_loss: 0.3952 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0193 - accuracy: 0.9883 - val_loss: 0.5144 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9893 - val_loss: 0.5076 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.5113 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.4887 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2058e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1825e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7225e-06 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0365e-07 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3290 - accuracy: 0.6308\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.631 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0583 - accuracy: 0.3607 - val_loss: 0.4124 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2048 - accuracy: 0.7768 - val_loss: 0.3421 - val_accuracy: 0.6135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0800 - accuracy: 0.9330 - val_loss: 0.3723 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9741 - val_loss: 0.4555 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0238 - accuracy: 0.9858 - val_loss: 0.4508 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0183 - accuracy: 0.9904 - val_loss: 0.5046 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 0.5442 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.1153e-05 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.2601e-06 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7223e-07 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5719e-07 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3738 - accuracy: 0.5716\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.572 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9266 - accuracy: 0.3861 - val_loss: 0.4015 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1950 - accuracy: 0.7859 - val_loss: 0.4266 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0761 - accuracy: 0.9274 - val_loss: 0.3961 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0367 - accuracy: 0.9741 - val_loss: 0.5998 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0184 - accuracy: 0.9878 - val_loss: 0.4880 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.4889 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.6072 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.6484 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 0.6029 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6197e-05 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7855e-06 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7762e-07 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4809e-07 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4173 - accuracy: 0.6467\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.647 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.9842 - accuracy: 0.3777 - val_loss: 0.4202 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1508 - accuracy: 0.8447 - val_loss: 0.3642 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0395 - accuracy: 0.9802 - val_loss: 0.3573 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.3834 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.8015e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3814e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.2348e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.0889e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.9404e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7929e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3289 - accuracy: 0.6592\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.659 total time=  37.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 52ms/step - loss: 0.9614 - accuracy: 0.3978 - val_loss: 0.3904 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1534 - accuracy: 0.8407 - val_loss: 0.3514 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0419 - accuracy: 0.9721 - val_loss: 0.3591 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.3666 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.3856 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3872 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.4226 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7197e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0095e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4223e-04 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9907e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3637 - accuracy: 0.5909\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.591 total time=  34.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.8920 - accuracy: 0.4145 - val_loss: 0.3927 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1513 - accuracy: 0.8214 - val_loss: 0.3408 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0506 - accuracy: 0.9599 - val_loss: 0.3463 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0191 - accuracy: 0.9914 - val_loss: 0.3543 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.3613 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.3841 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4011 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.6730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.6743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9120e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.4355e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0646e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3728 - accuracy: 0.5716\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.572 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.3606 - accuracy: 0.3964 - val_loss: 0.7621 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4326 - accuracy: 0.6355 - val_loss: 0.4979 - val_accuracy: 0.5162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2675 - accuracy: 0.7624 - val_loss: 0.5832 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1858 - accuracy: 0.8508 - val_loss: 0.4869 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1214 - accuracy: 0.8832 - val_loss: 0.5020 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0681 - accuracy: 0.9365 - val_loss: 0.4249 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0566 - accuracy: 0.9574 - val_loss: 0.4387 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0439 - accuracy: 0.9685 - val_loss: 0.5492 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0226 - accuracy: 0.9838 - val_loss: 0.7640 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0233 - accuracy: 0.9853 - val_loss: 0.5360 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0232 - accuracy: 0.9822 - val_loss: 0.5354 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0130 - accuracy: 0.9929 - val_loss: 0.5256 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0079 - accuracy: 0.9934 - val_loss: 0.5246 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0056 - accuracy: 0.9944 - val_loss: 0.5460 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0045 - accuracy: 0.9949 - val_loss: 0.5361 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0040 - accuracy: 0.9949 - val_loss: 0.5559 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4636 - accuracy: 0.6744\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.674 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.0109 - accuracy: 0.4064 - val_loss: 0.9763 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4996 - accuracy: 0.6073 - val_loss: 0.4529 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2810 - accuracy: 0.7311 - val_loss: 0.3326 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1909 - accuracy: 0.8311 - val_loss: 0.3696 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1445 - accuracy: 0.8762 - val_loss: 0.5561 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0874 - accuracy: 0.9254 - val_loss: 0.4749 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0678 - accuracy: 0.9437 - val_loss: 0.5432 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0597 - accuracy: 0.9564 - val_loss: 0.4547 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0207 - accuracy: 0.9812 - val_loss: 0.4658 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0100 - accuracy: 0.9888 - val_loss: 0.4910 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0065 - accuracy: 0.9934 - val_loss: 0.5232 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9959 - val_loss: 0.5298 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0032 - accuracy: 0.9970 - val_loss: 0.5592 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3592 - accuracy: 0.6122\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.612 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.5093 - accuracy: 0.4059 - val_loss: 0.7780 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.5607 - accuracy: 0.7818 - val_loss: 0.6152 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2558 - accuracy: 0.9011 - val_loss: 0.7826 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1633 - accuracy: 0.9432 - val_loss: 0.7398 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1035 - accuracy: 0.9650 - val_loss: 1.1284 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1038 - accuracy: 0.9726 - val_loss: 1.1328 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0471 - accuracy: 0.9873 - val_loss: 1.1764 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.8881 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.8498 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7698e-05 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.7191e-06 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.6676 - accuracy: 0.7056\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.706 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 1.4504 - accuracy: 0.4645 - val_loss: 0.6451 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4010 - accuracy: 0.8076 - val_loss: 0.5035 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0933 - accuracy: 0.9609 - val_loss: 0.5679 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 0.5312 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.4796 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4614 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7283e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.8892e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.0893e-04 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3969e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9231e-04 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6126e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5755e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5407e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5080e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4716e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4471 - accuracy: 0.7404\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.740 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4482 - accuracy: 0.4434 - val_loss: 0.6995 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3714 - accuracy: 0.8174 - val_loss: 0.6022 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1285 - accuracy: 0.9366 - val_loss: 0.5659 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.5742 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.5279 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.6238 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.5949 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.5207 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5765 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5779 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5614 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6031 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4801e-04 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8969e-04 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7559e-04 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6716e-04 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5578 - accuracy: 0.7178\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.718 total time=  51.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.3481 - accuracy: 0.4505 - val_loss: 0.5155 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2743 - accuracy: 0.8143 - val_loss: 0.4301 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1158 - accuracy: 0.9422 - val_loss: 0.4237 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 0.4210 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.4455 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0091 - accuracy: 0.9959 - val_loss: 0.4337 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.4384 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4518 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.2821e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.2173e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.0237e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8490e-04 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6827e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4745 - accuracy: 0.7076\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.708 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5052 - accuracy: 0.3122 - val_loss: 0.4494 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4185 - accuracy: 0.4249 - val_loss: 0.4501 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3595 - accuracy: 0.5335 - val_loss: 0.3524 - val_accuracy: 0.5473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2525 - accuracy: 0.6675 - val_loss: 0.3468 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2028 - accuracy: 0.7421 - val_loss: 0.3482 - val_accuracy: 0.5554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1616 - accuracy: 0.7995 - val_loss: 0.2875 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1327 - accuracy: 0.8325 - val_loss: 0.4784 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1074 - accuracy: 0.8761 - val_loss: 0.3416 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0870 - accuracy: 0.8853 - val_loss: 0.3706 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0860 - accuracy: 0.9005 - val_loss: 0.4029 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0682 - accuracy: 0.9198 - val_loss: 0.6047 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0645 - accuracy: 0.9234 - val_loss: 0.3692 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0467 - accuracy: 0.9355 - val_loss: 0.3909 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0413 - accuracy: 0.9376 - val_loss: 0.4571 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0352 - accuracy: 0.9365 - val_loss: 0.4879 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0306 - accuracy: 0.9426 - val_loss: 0.5505 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2763 - accuracy: 0.6663\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.666 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.9465 - accuracy: 0.3430 - val_loss: 0.4564 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3568 - accuracy: 0.5074 - val_loss: 0.3572 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2782 - accuracy: 0.6454 - val_loss: 0.2717 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2073 - accuracy: 0.7336 - val_loss: 0.3609 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1656 - accuracy: 0.7986 - val_loss: 0.3851 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1260 - accuracy: 0.8473 - val_loss: 0.3436 - val_accuracy: 0.6378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1063 - accuracy: 0.8727 - val_loss: 0.3055 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0881 - accuracy: 0.8990 - val_loss: 0.3155 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0574 - accuracy: 0.9214 - val_loss: 0.3610 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0454 - accuracy: 0.9300 - val_loss: 0.4199 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0391 - accuracy: 0.9351 - val_loss: 0.4047 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0325 - accuracy: 0.9452 - val_loss: 0.4344 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0304 - accuracy: 0.9482 - val_loss: 0.4481 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3132 - accuracy: 0.5909\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.591 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.1287 - accuracy: 0.3866 - val_loss: 0.5558 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3793 - accuracy: 0.6601 - val_loss: 0.3378 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2138 - accuracy: 0.7910 - val_loss: 0.3458 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1474 - accuracy: 0.8625 - val_loss: 0.3531 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0901 - accuracy: 0.9209 - val_loss: 0.4949 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0638 - accuracy: 0.9447 - val_loss: 0.5572 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0444 - accuracy: 0.9609 - val_loss: 0.4555 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0224 - accuracy: 0.9782 - val_loss: 0.4478 - val_accuracy: 0.7189 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0143 - accuracy: 0.9822 - val_loss: 0.4630 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0095 - accuracy: 0.9863 - val_loss: 0.4779 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9883 - val_loss: 0.5347 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0051 - accuracy: 0.9909 - val_loss: 0.5701 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3359 - accuracy: 0.5645\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.564 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.0020 - accuracy: 0.3995 - val_loss: 0.3197 - val_accuracy: 0.5473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2606 - accuracy: 0.7259 - val_loss: 0.3558 - val_accuracy: 0.5905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1323 - accuracy: 0.8802 - val_loss: 0.3092 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0552 - accuracy: 0.9645 - val_loss: 0.2853 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0250 - accuracy: 0.9878 - val_loss: 0.3223 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0116 - accuracy: 0.9939 - val_loss: 0.3164 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0101 - accuracy: 0.9939 - val_loss: 0.3272 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.3621 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.3431 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.3342 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.3373 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.3418 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3443 - val_accuracy: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3448 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3124 - accuracy: 0.7099\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.710 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9641 - accuracy: 0.3856 - val_loss: 0.4213 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3060 - accuracy: 0.6890 - val_loss: 0.3506 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1588 - accuracy: 0.8493 - val_loss: 0.3356 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0587 - accuracy: 0.9472 - val_loss: 0.3197 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0347 - accuracy: 0.9685 - val_loss: 0.3346 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0177 - accuracy: 0.9893 - val_loss: 0.3523 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 0.3532 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.3454 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3653 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.3632 - val_accuracy: 0.7216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7673e-04 - accuracy: 0.9990 - val_loss: 0.3621 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0093e-04 - accuracy: 0.9990 - val_loss: 0.3617 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4074e-04 - accuracy: 0.9995 - val_loss: 0.3616 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9194e-04 - accuracy: 0.9995 - val_loss: 0.3621 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3329 - accuracy: 0.7005\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.701 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4795 - accuracy: 0.3912 - val_loss: 0.3625 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2608 - accuracy: 0.6717 - val_loss: 0.3114 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1492 - accuracy: 0.8031 - val_loss: 0.3307 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1003 - accuracy: 0.8874 - val_loss: 0.3462 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0662 - accuracy: 0.9274 - val_loss: 0.3240 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0444 - accuracy: 0.9589 - val_loss: 0.4600 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0346 - accuracy: 0.9721 - val_loss: 0.3497 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0205 - accuracy: 0.9792 - val_loss: 0.3672 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0169 - accuracy: 0.9822 - val_loss: 0.3796 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0147 - accuracy: 0.9843 - val_loss: 0.3869 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0132 - accuracy: 0.9853 - val_loss: 0.3895 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9858 - val_loss: 0.3969 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2910 - accuracy: 0.6020\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.602 total time=  34.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 5.2696 - accuracy: 0.4294 - val_loss: 1.3597 - val_accuracy: 0.5554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.6548 - accuracy: 0.7650 - val_loss: 2.7674 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3201 - accuracy: 0.8782 - val_loss: 1.0405 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1591 - accuracy: 0.9411 - val_loss: 0.7267 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1205 - accuracy: 0.9650 - val_loss: 0.9011 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0740 - accuracy: 0.9858 - val_loss: 1.4502 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0723 - accuracy: 0.9807 - val_loss: 1.0621 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 1.3614 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0500 - accuracy: 0.9888 - val_loss: 1.1804 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.0501 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.2255e-04 - accuracy: 1.0000 - val_loss: 1.0354 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6372e-07 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.8444e-07 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7176 - accuracy: 0.7546\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.755 total time=  41.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 3.3374 - accuracy: 0.4191 - val_loss: 0.8681 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.5299 - accuracy: 0.7565 - val_loss: 1.2700 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2641 - accuracy: 0.8818 - val_loss: 0.5009 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.6778 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0796 - accuracy: 0.9741 - val_loss: 0.5546 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0514 - accuracy: 0.9822 - val_loss: 0.7771 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 0.7361 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.6786 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.4906e-05 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1384e-06 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2814e-06 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5976e-07 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.6275 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.689 total time=  38.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 6.1707 - accuracy: 0.4125 - val_loss: 1.9703 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0031 - accuracy: 0.7965 - val_loss: 1.3268 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4322 - accuracy: 0.9092 - val_loss: 1.9202 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2761 - accuracy: 0.9482 - val_loss: 1.4354 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1750 - accuracy: 0.9625 - val_loss: 1.3822 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0952 - accuracy: 0.9792 - val_loss: 1.8461 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1373 - accuracy: 0.9756 - val_loss: 1.3084 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0630 - accuracy: 0.9878 - val_loss: 2.2918 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0580 - accuracy: 0.9904 - val_loss: 2.0443 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0571 - accuracy: 0.9924 - val_loss: 1.5984 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9954 - val_loss: 1.6251 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0555 - accuracy: 0.9939 - val_loss: 2.1397 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0156 - accuracy: 0.9985 - val_loss: 1.7015 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.8141e-04 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9331e-07 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6318e-08 - accuracy: 1.0000 - val_loss: 1.7184 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.2388e-09 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.4827 - accuracy: 0.7381\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.738 total time=  49.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.0718 - accuracy: 0.5122 - val_loss: 1.0350 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3937 - accuracy: 0.8954 - val_loss: 0.9327 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1491 - accuracy: 0.9604 - val_loss: 0.9364 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0434 - accuracy: 0.9924 - val_loss: 0.9049 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 0.9572 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 0.8963 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.9095 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.9360 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.0391e-04 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7267e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8490e-05 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6405e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6230e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6035e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5851e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5657e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7747 - accuracy: 0.7809\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.781 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.0733 - accuracy: 0.4769 - val_loss: 0.5660 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2889 - accuracy: 0.8640 - val_loss: 0.5230 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0677 - accuracy: 0.9726 - val_loss: 0.5576 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.4345 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.5094 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.2793e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6701e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7543e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4469e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2753e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2422e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2080e-04 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4978 - accuracy: 0.7553\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.755 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.9529 - accuracy: 0.4911 - val_loss: 0.6724 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2955 - accuracy: 0.8904 - val_loss: 0.6454 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 0.7928 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0415 - accuracy: 0.9914 - val_loss: 0.7201 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.6753 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.6703 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.1029e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5715e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4520e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3630e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2909e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7208 - accuracy: 0.7107\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.711 total time=  35.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.9259 - accuracy: 0.4259 - val_loss: 0.7399 - val_accuracy: 0.5689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4302 - accuracy: 0.7670 - val_loss: 0.4609 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2391 - accuracy: 0.8746 - val_loss: 0.6332 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1357 - accuracy: 0.9355 - val_loss: 0.6232 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0801 - accuracy: 0.9655 - val_loss: 0.5527 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0660 - accuracy: 0.9751 - val_loss: 0.6990 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0346 - accuracy: 0.9873 - val_loss: 0.7668 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.6653 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6784 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4144e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2592e-06 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.9260e-06 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4602 - accuracy: 0.7160\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.716 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.7922 - accuracy: 0.4485 - val_loss: 1.1641 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4928 - accuracy: 0.7489 - val_loss: 0.7773 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2524 - accuracy: 0.8681 - val_loss: 0.6769 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1721 - accuracy: 0.9295 - val_loss: 0.6905 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1114 - accuracy: 0.9599 - val_loss: 0.8537 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0692 - accuracy: 0.9736 - val_loss: 0.8196 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0740 - accuracy: 0.9777 - val_loss: 1.0786 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.9423 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.7771 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3622e-04 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.8313e-06 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 8.4814e-07 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.6363e-07 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.7061 - accuracy: 0.6690\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.669 total time=  39.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.5986 - accuracy: 0.4536 - val_loss: 0.6191 - val_accuracy: 0.5716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3882 - accuracy: 0.7834 - val_loss: 0.4836 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2042 - accuracy: 0.8884 - val_loss: 0.6293 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1367 - accuracy: 0.9406 - val_loss: 0.7444 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0495 - accuracy: 0.9787 - val_loss: 0.5008 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0727 - accuracy: 0.9751 - val_loss: 0.7291 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0298 - accuracy: 0.9873 - val_loss: 0.7552 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 0.7028 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.7079 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3254e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1207e-06 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3141e-06 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.4762 - accuracy: 0.6995\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.699 total time=  36.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.8483 - accuracy: 0.5173 - val_loss: 0.7233 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2712 - accuracy: 0.8761 - val_loss: 0.7202 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0863 - accuracy: 0.9766 - val_loss: 0.6360 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.6663 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.6484 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5897 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.6294 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.7286 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.7185 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.6483 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8083e-05 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4221e-05 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.7651e-05 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.2951e-05 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5701 - accuracy: 0.7647\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.765 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.2567 - accuracy: 0.5008 - val_loss: 0.4984 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2645 - accuracy: 0.8782 - val_loss: 0.4442 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0946 - accuracy: 0.9645 - val_loss: 0.5158 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0263 - accuracy: 0.9888 - val_loss: 0.4422 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.5142 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.8179e-04 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2621e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0482e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0318e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0133e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9641e-05 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7853e-05 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4937 - accuracy: 0.7289\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.729 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 2.2978 - accuracy: 0.4850 - val_loss: 0.6831 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2528 - accuracy: 0.8894 - val_loss: 0.5879 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0497 - accuracy: 0.9797 - val_loss: 0.4508 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.4815 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.6129 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.4576 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.7820e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9241e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5055e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4743e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4387e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4047e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3715e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4852 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.723 total time=  38.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5715 - accuracy: 0.3416 - val_loss: 0.3406 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2164 - accuracy: 0.7036 - val_loss: 0.3078 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1061 - accuracy: 0.8670 - val_loss: 0.2983 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0451 - accuracy: 0.9528 - val_loss: 0.3521 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9802 - val_loss: 0.4066 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0134 - accuracy: 0.9904 - val_loss: 0.4026 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0117 - accuracy: 0.9929 - val_loss: 0.5813 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0056 - accuracy: 0.9949 - val_loss: 0.5339 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5831e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5986e-04 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.4072e-05 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5593e-05 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.8073e-06 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3123 - accuracy: 0.6481\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.648 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5020 - accuracy: 0.3785 - val_loss: 0.3572 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1814 - accuracy: 0.7646 - val_loss: 0.2625 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0734 - accuracy: 0.9259 - val_loss: 0.2806 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0287 - accuracy: 0.9746 - val_loss: 0.3341 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9924 - val_loss: 0.3081 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.4174 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4277 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.4231 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.3666e-04 - accuracy: 0.9995 - val_loss: 0.4380 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.9262e-04 - accuracy: 0.9995 - val_loss: 0.4731 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7709e-04 - accuracy: 0.9995 - val_loss: 0.4912 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.1970e-05 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2723 - accuracy: 0.6071\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.607 total time=  35.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5543 - accuracy: 0.3841 - val_loss: 0.3443 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1953 - accuracy: 0.7311 - val_loss: 0.3201 - val_accuracy: 0.5932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0888 - accuracy: 0.9066 - val_loss: 0.2803 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0386 - accuracy: 0.9655 - val_loss: 0.3434 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0186 - accuracy: 0.9904 - val_loss: 0.3554 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0082 - accuracy: 0.9949 - val_loss: 0.3788 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7459e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6992e-05 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0976e-06 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1618e-06 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.4539e-07 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3126 - accuracy: 0.6619\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.662 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.5433 - accuracy: 0.3431 - val_loss: 0.3198 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2088 - accuracy: 0.7137 - val_loss: 0.2829 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0980 - accuracy: 0.8883 - val_loss: 0.2694 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0356 - accuracy: 0.9706 - val_loss: 0.2932 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0162 - accuracy: 0.9893 - val_loss: 0.3126 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9964 - val_loss: 0.3159 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 0.3438 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0149e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.3173e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9054e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2453 - accuracy: 0.6724\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.672 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6134 - accuracy: 0.3480 - val_loss: 0.3341 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2120 - accuracy: 0.7022 - val_loss: 0.2774 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0986 - accuracy: 0.8792 - val_loss: 0.2627 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0449 - accuracy: 0.9589 - val_loss: 0.2755 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0227 - accuracy: 0.9807 - val_loss: 0.3017 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0106 - accuracy: 0.9934 - val_loss: 0.3261 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0051 - accuracy: 0.9970 - val_loss: 0.3537 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.3520 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3556 - val_accuracy: 0.6959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3586 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3626 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3659 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3687 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2867 - accuracy: 0.6162\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.616 total time=  37.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.5622 - accuracy: 0.3252 - val_loss: 0.3415 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2283 - accuracy: 0.6692 - val_loss: 0.2988 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1184 - accuracy: 0.8508 - val_loss: 0.2862 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0590 - accuracy: 0.9366 - val_loss: 0.3004 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0331 - accuracy: 0.9645 - val_loss: 0.3171 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9822 - val_loss: 0.3351 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0112 - accuracy: 0.9899 - val_loss: 0.3324 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9944 - val_loss: 0.3577 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0035 - accuracy: 0.9964 - val_loss: 0.3551 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0029 - accuracy: 0.9975 - val_loss: 0.3564 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.3594 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 0.3628 - val_accuracy: 0.6743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.3655 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2854 - accuracy: 0.6162\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.616 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7218 - accuracy: 0.3360 - val_loss: 0.3723 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2635 - accuracy: 0.6096 - val_loss: 0.4361 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1498 - accuracy: 0.8086 - val_loss: 0.3229 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0864 - accuracy: 0.9096 - val_loss: 0.3640 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0431 - accuracy: 0.9533 - val_loss: 0.4237 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0268 - accuracy: 0.9782 - val_loss: 0.4148 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0170 - accuracy: 0.9898 - val_loss: 0.4596 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0090 - accuracy: 0.9949 - val_loss: 0.6020 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.5333 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 0.5516 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9626e-04 - accuracy: 0.9995 - val_loss: 0.5738 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4043e-04 - accuracy: 0.9995 - val_loss: 0.5973 - val_accuracy: 0.7216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4721e-04 - accuracy: 0.9995 - val_loss: 0.6225 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3035 - accuracy: 0.6176\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.618 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6755 - accuracy: 0.3328 - val_loss: 0.3456 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2453 - accuracy: 0.6474 - val_loss: 0.3297 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1388 - accuracy: 0.8255 - val_loss: 0.3449 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0728 - accuracy: 0.9224 - val_loss: 0.3301 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0445 - accuracy: 0.9513 - val_loss: 0.3763 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0235 - accuracy: 0.9792 - val_loss: 0.4173 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0151 - accuracy: 0.9904 - val_loss: 0.5874 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0053 - accuracy: 0.9959 - val_loss: 0.4672 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.4654 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.3905e-04 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7263e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.7544e-05 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.3649 - accuracy: 0.5371\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.537 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 50ms/step - loss: 0.6872 - accuracy: 0.3272 - val_loss: 0.3755 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2647 - accuracy: 0.6129 - val_loss: 0.3153 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1511 - accuracy: 0.8011 - val_loss: 0.3113 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0930 - accuracy: 0.8767 - val_loss: 0.3388 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0570 - accuracy: 0.9376 - val_loss: 0.3787 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9650 - val_loss: 0.3354 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0226 - accuracy: 0.9782 - val_loss: 0.3699 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0158 - accuracy: 0.9863 - val_loss: 0.5126 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0070 - accuracy: 0.9949 - val_loss: 0.4355 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0031 - accuracy: 0.9970 - val_loss: 0.4483 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0016 - accuracy: 0.9985 - val_loss: 0.4626 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8941e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.0701e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3575 - accuracy: 0.5858\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.586 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6603 - accuracy: 0.3396 - val_loss: 0.3633 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2301 - accuracy: 0.6665 - val_loss: 0.3199 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1157 - accuracy: 0.8543 - val_loss: 0.3076 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0556 - accuracy: 0.9411 - val_loss: 0.3300 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0281 - accuracy: 0.9756 - val_loss: 0.3324 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0149 - accuracy: 0.9883 - val_loss: 0.3508 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9924 - val_loss: 0.3774 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0062 - accuracy: 0.9964 - val_loss: 0.3895 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0035 - accuracy: 0.9970 - val_loss: 0.3866 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 0.3867 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.3880 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 0.3891 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.3906 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2883 - accuracy: 0.6095\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.610 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8326 - accuracy: 0.2988 - val_loss: 0.3757 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2678 - accuracy: 0.5860 - val_loss: 0.3288 - val_accuracy: 0.5351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1579 - accuracy: 0.7747 - val_loss: 0.2888 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0891 - accuracy: 0.8909 - val_loss: 0.2993 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0490 - accuracy: 0.9482 - val_loss: 0.3354 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0297 - accuracy: 0.9736 - val_loss: 0.3399 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0203 - accuracy: 0.9812 - val_loss: 0.4165 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0146 - accuracy: 0.9858 - val_loss: 0.3774 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0088 - accuracy: 0.9899 - val_loss: 0.3690 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0065 - accuracy: 0.9924 - val_loss: 0.3744 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0055 - accuracy: 0.9929 - val_loss: 0.3785 - val_accuracy: 0.6811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9959 - val_loss: 0.3830 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0045 - accuracy: 0.9959 - val_loss: 0.3871 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3018 - accuracy: 0.5716\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.572 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6971 - accuracy: 0.3577 - val_loss: 0.3450 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2395 - accuracy: 0.6560 - val_loss: 0.2931 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1448 - accuracy: 0.8092 - val_loss: 0.2801 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0877 - accuracy: 0.8940 - val_loss: 0.2855 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0514 - accuracy: 0.9406 - val_loss: 0.2842 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0315 - accuracy: 0.9701 - val_loss: 0.3170 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0204 - accuracy: 0.9807 - val_loss: 0.3484 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0179 - accuracy: 0.9843 - val_loss: 0.3524 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0102 - accuracy: 0.9888 - val_loss: 0.3499 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0072 - accuracy: 0.9909 - val_loss: 0.3505 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0060 - accuracy: 0.9939 - val_loss: 0.3509 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0054 - accuracy: 0.9939 - val_loss: 0.3529 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0050 - accuracy: 0.9939 - val_loss: 0.3548 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3220 - accuracy: 0.5685\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.569 total time=  38.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8463 - accuracy: 0.3655 - val_loss: 0.3523 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1827 - accuracy: 0.7711 - val_loss: 0.3037 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0646 - accuracy: 0.9508 - val_loss: 0.3019 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0257 - accuracy: 0.9832 - val_loss: 0.4387 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.3530 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0091 - accuracy: 0.9954 - val_loss: 0.4559 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5810 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.5094 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.5583e-05 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.2274e-06 - accuracy: 1.0000 - val_loss: 0.5215 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.0094e-06 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9313e-07 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0552e-07 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2810 - accuracy: 0.7008\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.701 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7062 - accuracy: 0.3998 - val_loss: 0.3413 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1773 - accuracy: 0.7834 - val_loss: 0.2626 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0623 - accuracy: 0.9452 - val_loss: 0.2408 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0198 - accuracy: 0.9853 - val_loss: 0.2995 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.3093 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.5592 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 0.5590 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.4252 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1974e-05 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6037e-06 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3828e-06 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.5648e-07 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.2947e-07 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2627 - accuracy: 0.7066\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.707 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 0.9309 - accuracy: 0.4064 - val_loss: 0.4022 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1779 - accuracy: 0.7839 - val_loss: 0.2437 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0675 - accuracy: 0.9386 - val_loss: 0.2961 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0220 - accuracy: 0.9893 - val_loss: 0.6430 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0112 - accuracy: 0.9929 - val_loss: 0.3566 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.4359 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9949 - val_loss: 0.3785 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3730 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.8676e-04 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2099e-05 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.0231e-06 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.2861e-07 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2760 - accuracy: 0.6660\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.666 total time=  36.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6579 - accuracy: 0.3711 - val_loss: 0.3311 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1672 - accuracy: 0.8010 - val_loss: 0.2876 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0597 - accuracy: 0.9487 - val_loss: 0.2825 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0209 - accuracy: 0.9909 - val_loss: 0.3147 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.3241 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.3351 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3553 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3637 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1926e-04 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.8026e-04 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.5402e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.2897e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2667 - accuracy: 0.6856\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.686 total time=  37.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6831 - accuracy: 0.4099 - val_loss: 0.3419 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1557 - accuracy: 0.8280 - val_loss: 0.2974 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0529 - accuracy: 0.9614 - val_loss: 0.2758 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0171 - accuracy: 0.9914 - val_loss: 0.3082 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.3149 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3554 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8692e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4147e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.1356e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.8964e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6781e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3097 - accuracy: 0.6589\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.659 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6805 - accuracy: 0.4064 - val_loss: 0.3333 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1500 - accuracy: 0.8316 - val_loss: 0.2780 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0556 - accuracy: 0.9543 - val_loss: 0.2776 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.2937 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.3214 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.2912e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1635e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.9590e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.7573e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.5556e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.3540e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2899 - accuracy: 0.6457\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.646 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.1942 - accuracy: 0.3523 - val_loss: 0.4282 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2303 - accuracy: 0.7193 - val_loss: 0.3779 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1094 - accuracy: 0.8868 - val_loss: 0.4237 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0529 - accuracy: 0.9599 - val_loss: 0.3822 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0252 - accuracy: 0.9853 - val_loss: 0.4717 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0178 - accuracy: 0.9904 - val_loss: 0.5580 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.6507 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5423 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.5419 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.5539e-04 - accuracy: 0.9995 - val_loss: 0.5513 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6203e-06 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.3704e-06 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3653 - accuracy: 0.6288\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.629 total time=  35.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9808 - accuracy: 0.3932 - val_loss: 0.3836 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1997 - accuracy: 0.7686 - val_loss: 0.3541 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0912 - accuracy: 0.9198 - val_loss: 0.3562 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0348 - accuracy: 0.9741 - val_loss: 0.4409 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0247 - accuracy: 0.9853 - val_loss: 0.4386 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.4843 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.6060 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.5964 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0565e-05 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7831e-06 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1172e-06 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.4314e-07 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4024 - accuracy: 0.5736\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.574 total time=  36.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0467 - accuracy: 0.4003 - val_loss: 0.4117 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1999 - accuracy: 0.7712 - val_loss: 0.3248 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0877 - accuracy: 0.9239 - val_loss: 0.3579 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0338 - accuracy: 0.9746 - val_loss: 0.3801 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0230 - accuracy: 0.9893 - val_loss: 0.4023 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0115 - accuracy: 0.9944 - val_loss: 0.4668 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.5247 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.4761 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1479e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.2305e-06 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7094e-06 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5382e-07 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3863 - accuracy: 0.5807\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.581 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9260 - accuracy: 0.3518 - val_loss: 0.3706 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1992 - accuracy: 0.7492 - val_loss: 0.3224 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0840 - accuracy: 0.9086 - val_loss: 0.3055 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0370 - accuracy: 0.9695 - val_loss: 0.3253 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0141 - accuracy: 0.9919 - val_loss: 0.3508 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.3718 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.3798 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 0.4023 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7388e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2864 - accuracy: 0.6511\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.651 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9524 - accuracy: 0.3957 - val_loss: 0.3834 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1569 - accuracy: 0.8295 - val_loss: 0.3418 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0487 - accuracy: 0.9609 - val_loss: 0.3385 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.3412 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.3576 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3745 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3806 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3913 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.8060e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2830e-04 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9296e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.5950e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.2733e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3652 - accuracy: 0.6335\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.634 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.0417 - accuracy: 0.4013 - val_loss: 0.3817 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1423 - accuracy: 0.8529 - val_loss: 0.3524 - val_accuracy: 0.6054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0394 - accuracy: 0.9812 - val_loss: 0.3277 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.3306 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.3455 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3589 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3783 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.6892 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.8281e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.6892 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0089e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4268e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.9518e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3655 - accuracy: 0.6223\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.622 total time=  38.1s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 1.4987 - accuracy: 0.5355 - val_loss: 0.4688 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.2065 - accuracy: 0.8877 - val_loss: 0.3825 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0579 - accuracy: 0.9723 - val_loss: 0.3778 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.3509 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.3572 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.3397 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 9.0943e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 4.5722e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.7973 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.9219e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.4178e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.0750e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.8446e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.8206e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7703e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7427e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_vgg16_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inceptionv3_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 69ms/step - loss: 13.4405 - accuracy: 0.1624 - val_loss: 4.3928 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.2021 - accuracy: 0.1675 - val_loss: 0.6559 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7281 - accuracy: 0.1487 - val_loss: 0.6029 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5770 - accuracy: 0.1604 - val_loss: 0.5366 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5143 - accuracy: 0.1563 - val_loss: 0.4739 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4479 - accuracy: 0.1477 - val_loss: 0.4268 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4176 - accuracy: 0.1452 - val_loss: 0.4111 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4108 - accuracy: 0.1421 - val_loss: 0.4101 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1467 - val_loss: 0.4099 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4099 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4103 - accuracy: 0.1264 - val_loss: 0.4099 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1447 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1386 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1406 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1365 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1431 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1492 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1467 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 44ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  59.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 20.4652 - accuracy: 0.1938 - val_loss: 2.4708 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 4.3980 - accuracy: 0.1984 - val_loss: 3.4735 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9946 - accuracy: 0.1395 - val_loss: 0.6460 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6677 - accuracy: 0.1314 - val_loss: 0.5969 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5655 - accuracy: 0.1416 - val_loss: 0.5285 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4918 - accuracy: 0.1497 - val_loss: 0.4567 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4348 - accuracy: 0.1497 - val_loss: 0.4186 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4132 - accuracy: 0.1492 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1456 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1466 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1385 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1426 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1284 - val_loss: 0.4106 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1416 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 44ms/step - loss: 0.4104 - accuracy: 0.1401\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.140 total time=  55.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 19.5038 - accuracy: 0.1664 - val_loss: 4.0070 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.1712 - accuracy: 0.1654 - val_loss: 0.6649 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6726 - accuracy: 0.1451 - val_loss: 0.6337 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6039 - accuracy: 0.1471 - val_loss: 0.5636 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5185 - accuracy: 0.1471 - val_loss: 0.4732 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4434 - accuracy: 0.1471 - val_loss: 0.4200 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4135 - accuracy: 0.1471 - val_loss: 0.4102 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4104 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1461 - val_loss: 0.4103 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1390 - val_loss: 0.4103 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1471 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1446 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4105 - accuracy: 0.1340\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.134 total time=  49.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 8.0318 - accuracy: 0.1954 - val_loss: 2.7327 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.8625 - accuracy: 0.2868 - val_loss: 1.8162 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0907 - accuracy: 0.4223 - val_loss: 1.3089 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8423 - accuracy: 0.4888 - val_loss: 1.1846 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6800 - accuracy: 0.5503 - val_loss: 1.4124 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5356 - accuracy: 0.6208 - val_loss: 1.2080 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4805 - accuracy: 0.6665 - val_loss: 1.0854 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3161 - accuracy: 0.7543 - val_loss: 1.4796 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3171 - accuracy: 0.7599 - val_loss: 1.1061 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2853 - accuracy: 0.7959 - val_loss: 1.1647 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1612 - accuracy: 0.8853 - val_loss: 1.0114 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1525 - accuracy: 0.8964 - val_loss: 1.1048 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1715 - accuracy: 0.8939 - val_loss: 1.2443 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1207 - accuracy: 0.9360 - val_loss: 1.2413 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1102 - accuracy: 0.9371 - val_loss: 1.1009 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0759 - accuracy: 0.9624 - val_loss: 1.2887 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0260 - accuracy: 0.9964 - val_loss: 1.1295 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 41ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 1.1929 - accuracy: 0.4148\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.415 total time=  55.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 6.1779 - accuracy: 0.1913 - val_loss: 3.1543 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6468 - accuracy: 0.3567 - val_loss: 1.7231 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9017 - accuracy: 0.5297 - val_loss: 1.6806 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8330 - accuracy: 0.5652 - val_loss: 1.5950 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7710 - accuracy: 0.6043 - val_loss: 1.6409 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4171 - accuracy: 0.7610 - val_loss: 1.6627 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3463 - accuracy: 0.7930 - val_loss: 1.4302 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3503 - accuracy: 0.7889 - val_loss: 2.2420 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3960 - accuracy: 0.8067 - val_loss: 1.7107 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2421 - accuracy: 0.8564 - val_loss: 1.4666 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1263 - accuracy: 0.9168 - val_loss: 1.4198 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0727 - accuracy: 0.9569 - val_loss: 1.4433 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0441 - accuracy: 0.9807 - val_loss: 1.6087 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 1.3474 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0272 - accuracy: 0.9878 - val_loss: 1.3985 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0753 - accuracy: 0.9635 - val_loss: 1.4312 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 1.4543 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 1.4178 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.3909 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3826 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.4699 - accuracy: 0.4223\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.422 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 6.4899 - accuracy: 0.1887 - val_loss: 2.1131 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2944 - accuracy: 0.3156 - val_loss: 1.9956 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9007 - accuracy: 0.3907 - val_loss: 0.9838 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6458 - accuracy: 0.4105 - val_loss: 0.8878 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4493 - accuracy: 0.5145 - val_loss: 0.7985 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3478 - accuracy: 0.5764 - val_loss: 0.6874 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2887 - accuracy: 0.6337 - val_loss: 0.6239 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2353 - accuracy: 0.7047 - val_loss: 0.6672 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3051 - accuracy: 0.6474 - val_loss: 0.7668 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2462 - accuracy: 0.7169 - val_loss: 0.7796 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2046 - accuracy: 0.7549 - val_loss: 0.6782 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1534 - accuracy: 0.8321 - val_loss: 0.8472 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0877 - accuracy: 0.9274 - val_loss: 0.7080 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0669 - accuracy: 0.9635 - val_loss: 0.7065 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0605 - accuracy: 0.9716 - val_loss: 0.6958 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0575 - accuracy: 0.9751 - val_loss: 0.6962 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0528 - accuracy: 0.9787 - val_loss: 0.7090 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.6601 - accuracy: 0.2924\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.292 total time=  48.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 17.2006 - accuracy: 0.1619 - val_loss: 0.6906 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6873 - accuracy: 0.1431 - val_loss: 0.6250 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5903 - accuracy: 0.1426 - val_loss: 0.5375 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4835 - accuracy: 0.1426 - val_loss: 0.4345 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4183 - accuracy: 0.1401 - val_loss: 0.4101 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1467 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1391 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1431 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1386 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4104 - accuracy: 0.1345 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1360 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1320 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1437 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4143 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 18.1355 - accuracy: 0.1730 - val_loss: 5.1224 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 5.1707 - accuracy: 0.1852 - val_loss: 3.3311 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.3922 - accuracy: 0.1426 - val_loss: 2.4838 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.6304 - accuracy: 0.1568 - val_loss: 0.6164 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6461 - accuracy: 0.1624 - val_loss: 0.6621 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6285 - accuracy: 0.1421 - val_loss: 0.6109 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5725 - accuracy: 0.1497 - val_loss: 0.5257 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4940 - accuracy: 0.1537 - val_loss: 0.4422 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4229 - accuracy: 0.1426 - val_loss: 0.4115 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1431 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1431 - val_loss: 0.4109 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1451 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1350 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4109 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4108 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time=  57.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 18.0637 - accuracy: 0.1634 - val_loss: 11.2144 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.7477 - accuracy: 0.1786 - val_loss: 0.5790 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6320 - accuracy: 0.1497 - val_loss: 0.5761 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5612 - accuracy: 0.1512 - val_loss: 0.5479 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5078 - accuracy: 0.1441 - val_loss: 0.4663 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4389 - accuracy: 0.1497 - val_loss: 0.4878 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4140 - accuracy: 0.1441 - val_loss: 0.4107 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4134 - accuracy: 0.1476 - val_loss: 0.4103 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4096 - accuracy: 0.1613 - val_loss: 0.4138 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4092 - accuracy: 0.1466 - val_loss: 0.4127 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4080 - accuracy: 0.1532 - val_loss: 0.4124 - val_accuracy: 0.1162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1421 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1400 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4101 - accuracy: 0.1320\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.132 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 8.5435 - accuracy: 0.2086 - val_loss: 3.2417 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.6487 - accuracy: 0.3721 - val_loss: 3.1320 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6252 - accuracy: 0.4883 - val_loss: 2.3336 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.0266 - accuracy: 0.5670 - val_loss: 2.3361 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7729 - accuracy: 0.6162 - val_loss: 1.8028 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3880 - accuracy: 0.7599 - val_loss: 1.3428 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3594 - accuracy: 0.7604 - val_loss: 1.5205 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2553 - accuracy: 0.8330 - val_loss: 1.6697 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4109 - accuracy: 0.7706 - val_loss: 1.5858 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1811 - accuracy: 0.8756 - val_loss: 1.3134 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1761 - accuracy: 0.8822 - val_loss: 1.4410 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0559 - accuracy: 0.9690 - val_loss: 1.2448 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 1.2978 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 1.2977 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 1.3111 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 1.3147 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3400 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.3312 - accuracy: 0.4544\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.454 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.2204 - accuracy: 0.1892 - val_loss: 1.4952 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8755 - accuracy: 0.2907 - val_loss: 0.8835 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5160 - accuracy: 0.3491 - val_loss: 0.5294 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3646 - accuracy: 0.4181 - val_loss: 0.4664 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3071 - accuracy: 0.5195 - val_loss: 0.4934 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3003 - accuracy: 0.5485 - val_loss: 0.5820 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3642 - accuracy: 0.4871 - val_loss: 0.5531 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2819 - accuracy: 0.5718 - val_loss: 0.6201 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2756 - accuracy: 0.6058 - val_loss: 0.6459 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1795 - accuracy: 0.7514 - val_loss: 0.4755 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1446 - accuracy: 0.8163 - val_loss: 0.4766 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1344 - accuracy: 0.8290 - val_loss: 0.4834 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1267 - accuracy: 0.8427 - val_loss: 0.4770 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1176 - accuracy: 0.8686 - val_loss: 0.4874 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4819 - accuracy: 0.2843\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.284 total time=  40.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.3585 - accuracy: 0.1806 - val_loss: 1.6892 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9827 - accuracy: 0.2613 - val_loss: 0.8504 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5355 - accuracy: 0.2983 - val_loss: 0.6422 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4648 - accuracy: 0.3242 - val_loss: 0.6646 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3819 - accuracy: 0.4176 - val_loss: 0.6376 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4406 - accuracy: 0.4084 - val_loss: 0.6270 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3447 - accuracy: 0.4850 - val_loss: 0.5790 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3291 - accuracy: 0.5079 - val_loss: 0.6083 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2762 - accuracy: 0.6073 - val_loss: 0.5527 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2567 - accuracy: 0.6347 - val_loss: 0.5733 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2208 - accuracy: 0.6768 - val_loss: 0.6811 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2359 - accuracy: 0.6601 - val_loss: 0.7329 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2485 - accuracy: 0.6626 - val_loss: 0.6588 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2079 - accuracy: 0.7067 - val_loss: 0.7085 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1526 - accuracy: 0.7864 - val_loss: 0.6012 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1140 - accuracy: 0.8473 - val_loss: 0.5855 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1038 - accuracy: 0.8671 - val_loss: 0.5946 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0976 - accuracy: 0.8777 - val_loss: 0.5876 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0930 - accuracy: 0.8848 - val_loss: 0.6112 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5926 - accuracy: 0.2934\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.293 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 30.7861 - accuracy: 0.2112 - val_loss: 13.8598 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 11.0466 - accuracy: 0.2340 - val_loss: 5.6718 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 6.1758 - accuracy: 0.2482 - val_loss: 1.8357 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 2.3377 - accuracy: 0.2543 - val_loss: 0.5765 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5629 - accuracy: 0.1817 - val_loss: 0.5925 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5066 - accuracy: 0.1482 - val_loss: 0.4960 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5089 - accuracy: 0.1462 - val_loss: 0.4739 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5077 - accuracy: 0.1584 - val_loss: 0.4938 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5397 - accuracy: 0.1543 - val_loss: 0.4824 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4704 - accuracy: 0.1538 - val_loss: 0.4708 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4448 - accuracy: 0.1421 - val_loss: 0.4312 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4185 - accuracy: 0.1381 - val_loss: 0.4160 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4113 - accuracy: 0.1376 - val_loss: 0.4132 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1411 - val_loss: 0.4126 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4125 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4125 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1396 - val_loss: 0.4124 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1457 - val_loss: 0.4123 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1416 - val_loss: 0.4122 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4123 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4107 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  57.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 31.2202 - accuracy: 0.1740 - val_loss: 12.2986 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 10.4508 - accuracy: 0.2308 - val_loss: 11.9248 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 8.3630 - accuracy: 0.2613 - val_loss: 5.8098 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 6.3318 - accuracy: 0.3049 - val_loss: 4.4131 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.2906 - accuracy: 0.3196 - val_loss: 5.7183 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.7690 - accuracy: 0.3623 - val_loss: 6.7894 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.4460 - accuracy: 0.3658 - val_loss: 4.3003 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.4537 - accuracy: 0.3856 - val_loss: 2.5938 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1016 - accuracy: 0.4110 - val_loss: 5.2158 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6631 - accuracy: 0.4465 - val_loss: 4.0617 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.4654 - accuracy: 0.4510 - val_loss: 1.3656 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2883 - accuracy: 0.4764 - val_loss: 1.9308 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0294 - accuracy: 0.5129 - val_loss: 1.3982 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9023 - accuracy: 0.5195 - val_loss: 1.0076 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8589 - accuracy: 0.5495 - val_loss: 1.7973 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7057 - accuracy: 0.5576 - val_loss: 0.8613 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5900 - accuracy: 0.6119 - val_loss: 1.6281 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6547 - accuracy: 0.5931 - val_loss: 1.3095 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5001 - accuracy: 0.6535 - val_loss: 1.4283 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4435 - accuracy: 0.6728 - val_loss: 0.8880 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.9228 - accuracy: 0.3563\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.356 total time=  58.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 30.4674 - accuracy: 0.1720 - val_loss: 26.5838 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 10.2923 - accuracy: 0.2106 - val_loss: 6.5623 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 6.0979 - accuracy: 0.2278 - val_loss: 5.5681 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.5613 - accuracy: 0.2511 - val_loss: 2.0403 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.5771 - accuracy: 0.3054 - val_loss: 3.5864 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0792 - accuracy: 0.3217 - val_loss: 4.2278 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.2619 - accuracy: 0.3623 - val_loss: 3.4552 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.0649 - accuracy: 0.3998 - val_loss: 2.8720 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7848 - accuracy: 0.3937 - val_loss: 2.4238 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4810 - accuracy: 0.6728 - val_loss: 0.9813 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2278 - accuracy: 0.7930 - val_loss: 0.8364 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1791 - accuracy: 0.8295 - val_loss: 0.8073 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1432 - accuracy: 0.8650 - val_loss: 0.8568 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1244 - accuracy: 0.8798 - val_loss: 0.8652 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1055 - accuracy: 0.9016 - val_loss: 0.8129 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0913 - accuracy: 0.9183 - val_loss: 0.7648 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0801 - accuracy: 0.9310 - val_loss: 0.7853 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0707 - accuracy: 0.9452 - val_loss: 0.7823 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.0617 - accuracy: 0.9493 - val_loss: 0.7585 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0559 - accuracy: 0.9645 - val_loss: 0.7916 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.7968 - accuracy: 0.4000\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.400 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 16.6654 - accuracy: 0.1929 - val_loss: 3.9843 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.7062 - accuracy: 0.3934 - val_loss: 3.5728 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.7050 - accuracy: 0.5244 - val_loss: 4.2983 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.1576 - accuracy: 0.5335 - val_loss: 3.8836 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8155 - accuracy: 0.7437 - val_loss: 2.5991 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5692 - accuracy: 0.8112 - val_loss: 2.5305 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5095 - accuracy: 0.8340 - val_loss: 2.7368 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4044 - accuracy: 0.8777 - val_loss: 2.3522 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1695 - accuracy: 0.9416 - val_loss: 2.3285 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1595 - accuracy: 0.9497 - val_loss: 2.4558 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1543 - accuracy: 0.9569 - val_loss: 3.4131 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6640 - accuracy: 0.8350 - val_loss: 3.2159 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7185 - accuracy: 0.8132 - val_loss: 3.5690 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5677 - accuracy: 0.8533 - val_loss: 2.9516 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0922 - accuracy: 0.9741 - val_loss: 2.6093 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 2.5674 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 2.5637 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 2.5239 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 2.5247 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.4610 - accuracy: 0.4026\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.403 total time=  53.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 11.6500 - accuracy: 0.1979 - val_loss: 4.3321 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.2655 - accuracy: 0.4044 - val_loss: 3.0118 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 2.1560 - accuracy: 0.5292 - val_loss: 4.4610 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 2.4748 - accuracy: 0.5525 - val_loss: 5.9594 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7280 - accuracy: 0.6596 - val_loss: 3.1238 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.3245 - accuracy: 0.7296 - val_loss: 3.4050 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.8535 - accuracy: 0.8001 - val_loss: 3.5152 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3234 - accuracy: 0.9269 - val_loss: 2.7372 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1352 - accuracy: 0.9614 - val_loss: 2.5978 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0885 - accuracy: 0.9675 - val_loss: 2.5921 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0618 - accuracy: 0.9777 - val_loss: 2.5229 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0472 - accuracy: 0.9812 - val_loss: 2.4924 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0362 - accuracy: 0.9848 - val_loss: 2.4990 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0272 - accuracy: 0.9883 - val_loss: 2.4671 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0212 - accuracy: 0.9914 - val_loss: 2.5201 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 2.4469 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 2.4558 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 2.4493 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 2.4581 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 2.4653 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.7020 - accuracy: 0.4264\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.426 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 10.0294 - accuracy: 0.2116 - val_loss: 6.9680 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.5110 - accuracy: 0.3714 - val_loss: 5.8629 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.4403 - accuracy: 0.4409 - val_loss: 3.8353 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1795 - accuracy: 0.5840 - val_loss: 3.5316 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3239 - accuracy: 0.6961 - val_loss: 3.5271 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.2088 - accuracy: 0.7286 - val_loss: 3.5994 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0796 - accuracy: 0.7742 - val_loss: 3.4610 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.3118 - accuracy: 0.7423 - val_loss: 4.7077 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.1253 - accuracy: 0.8102 - val_loss: 4.2193 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7211 - accuracy: 0.8579 - val_loss: 4.1829 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4735 - accuracy: 0.9107 - val_loss: 3.1868 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2296 - accuracy: 0.9604 - val_loss: 3.4285 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2006 - accuracy: 0.9670 - val_loss: 3.3673 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5463 - accuracy: 0.9046 - val_loss: 3.7890 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2697 - accuracy: 0.9452 - val_loss: 4.0500 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1828 - accuracy: 0.9721 - val_loss: 4.2907 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0679 - accuracy: 0.9919 - val_loss: 3.2480 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 3.2193 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 3.2035 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 3.2096 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 3.3003 - accuracy: 0.4193\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.419 total time=  56.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 30.4345 - accuracy: 0.1959 - val_loss: 6.1782 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 7.2147 - accuracy: 0.2249 - val_loss: 3.0590 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.3483 - accuracy: 0.2076 - val_loss: 2.8989 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.8972 - accuracy: 0.1665 - val_loss: 0.4857 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5457 - accuracy: 0.1487 - val_loss: 0.5136 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5427 - accuracy: 0.1472 - val_loss: 0.5250 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5194 - accuracy: 0.1543 - val_loss: 0.5016 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4591 - accuracy: 0.1553 - val_loss: 0.4276 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4198 - accuracy: 0.1437 - val_loss: 0.4120 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4098 - accuracy: 0.1538 - val_loss: 0.4176 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4107 - accuracy: 0.1518 - val_loss: 0.4101 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4097 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1411 - val_loss: 0.4102 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4110 - accuracy: 0.1477 - val_loss: 0.4164 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4096 - accuracy: 0.1431 - val_loss: 0.4232 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4110 - accuracy: 0.1518 - val_loss: 0.4104 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4082 - accuracy: 0.1574 - val_loss: 0.4104 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4072 - accuracy: 0.1482 - val_loss: 0.4111 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4069 - accuracy: 0.1462 - val_loss: 0.4106 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4069 - accuracy: 0.1538 - val_loss: 0.4125 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4116 - accuracy: 0.1237\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.124 total time=  58.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 24.5403 - accuracy: 0.1568 - val_loss: 7.0129 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 6.9206 - accuracy: 0.2308 - val_loss: 8.3917 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.3963 - accuracy: 0.2359 - val_loss: 3.0724 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 2.5176 - accuracy: 0.2121 - val_loss: 0.7292 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5900 - accuracy: 0.1892 - val_loss: 0.6390 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5917 - accuracy: 0.1390 - val_loss: 0.5805 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5289 - accuracy: 0.1558 - val_loss: 0.4754 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4683 - accuracy: 0.1502 - val_loss: 0.4324 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4177 - accuracy: 0.1284 - val_loss: 0.4106 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4105 - accuracy: 0.1218 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1527 - val_loss: 0.4110 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1329 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1527 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1360 - val_loss: 0.4109 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4108 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1441 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1497 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4104 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 25.0345 - accuracy: 0.1740 - val_loss: 5.5797 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 7.5724 - accuracy: 0.2166 - val_loss: 3.6286 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 4.2008 - accuracy: 0.2197 - val_loss: 7.7200 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 1.3321 - accuracy: 0.1892 - val_loss: 0.5043 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5739 - accuracy: 0.1517 - val_loss: 0.7772 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6004 - accuracy: 0.1461 - val_loss: 0.5788 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5296 - accuracy: 0.1654 - val_loss: 0.4911 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4642 - accuracy: 0.1568 - val_loss: 0.4322 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4160 - accuracy: 0.1527 - val_loss: 0.4112 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4087 - accuracy: 0.1426 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4085 - accuracy: 0.1512 - val_loss: 0.4104 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4117 - accuracy: 0.1517 - val_loss: 0.4090 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4082 - accuracy: 0.1426 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4097 - accuracy: 0.1512 - val_loss: 0.4096 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4076 - accuracy: 0.1512 - val_loss: 0.4092 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4083 - accuracy: 0.1608 - val_loss: 0.4099 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4077 - accuracy: 0.1390 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1537 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1537 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1466 - val_loss: 0.4093 - val_accuracy: 0.1216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4089 - accuracy: 0.1381\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.138 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 12.2358 - accuracy: 0.2299 - val_loss: 5.4877 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.4010 - accuracy: 0.4020 - val_loss: 2.1043 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2666 - accuracy: 0.5345 - val_loss: 2.0751 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8301 - accuracy: 0.6325 - val_loss: 1.7621 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5784 - accuracy: 0.7254 - val_loss: 1.6545 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3857 - accuracy: 0.8096 - val_loss: 2.0687 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4020 - accuracy: 0.8041 - val_loss: 1.5695 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5114 - accuracy: 0.7569 - val_loss: 1.8777 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3080 - accuracy: 0.8396 - val_loss: 1.6459 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1448 - accuracy: 0.9264 - val_loss: 1.5532 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1188 - accuracy: 0.9421 - val_loss: 1.5551 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0648 - accuracy: 0.9675 - val_loss: 1.6197 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0365 - accuracy: 0.9827 - val_loss: 1.6094 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1355 - accuracy: 0.9421 - val_loss: 1.7719 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1312 - accuracy: 0.9325 - val_loss: 1.5490 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1186 - accuracy: 0.9457 - val_loss: 1.8421 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0928 - accuracy: 0.9569 - val_loss: 1.5104 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0848 - accuracy: 0.9614 - val_loss: 1.4996 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1588 - accuracy: 0.9325 - val_loss: 2.2203 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1428 - accuracy: 0.9360 - val_loss: 2.1321 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2241 - accuracy: 0.3854\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.385 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.3284 - accuracy: 0.2349 - val_loss: 4.3724 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.7743 - accuracy: 0.4343 - val_loss: 3.0289 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.7343 - accuracy: 0.5591 - val_loss: 3.2921 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2536 - accuracy: 0.6403 - val_loss: 2.7427 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.1536 - accuracy: 0.6895 - val_loss: 2.9811 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6841 - accuracy: 0.7905 - val_loss: 2.6905 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3889 - accuracy: 0.8620 - val_loss: 2.3675 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3112 - accuracy: 0.8894 - val_loss: 2.4264 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4303 - accuracy: 0.8772 - val_loss: 2.7984 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3363 - accuracy: 0.8940 - val_loss: 2.7226 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2430 - accuracy: 0.9214 - val_loss: 2.4335 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2092 - accuracy: 0.9330 - val_loss: 2.3827 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0263 - accuracy: 0.9949 - val_loss: 2.2394 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.2027 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2027 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2070 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1972 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2002 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1883 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1910 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.4811 - accuracy: 0.4376\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.438 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 13.7093 - accuracy: 0.2131 - val_loss: 7.2144 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.8249 - accuracy: 0.4485 - val_loss: 4.6031 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0839 - accuracy: 0.5246 - val_loss: 4.2715 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7288 - accuracy: 0.6758 - val_loss: 4.8056 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3928 - accuracy: 0.7144 - val_loss: 3.8549 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.1380 - accuracy: 0.7514 - val_loss: 4.1073 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4656 - accuracy: 0.8767 - val_loss: 3.1292 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3282 - accuracy: 0.9148 - val_loss: 3.2868 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4790 - accuracy: 0.8879 - val_loss: 4.1514 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3238 - accuracy: 0.9214 - val_loss: 3.7164 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2728 - accuracy: 0.9295 - val_loss: 3.8945 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1603 - accuracy: 0.9584 - val_loss: 3.2092 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0237 - accuracy: 0.9975 - val_loss: 3.0276 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 2.9231 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.9222 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 7.8452e-04 - accuracy: 1.0000 - val_loss: 2.9129 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.9023e-04 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.0658e-04 - accuracy: 1.0000 - val_loss: 2.9084 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 4.4961e-04 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.9858 - accuracy: 0.3929\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.393 total time=  56.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 2.6704 - accuracy: 0.1690 - val_loss: 0.8985 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6783 - accuracy: 0.1832 - val_loss: 0.5390 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5027 - accuracy: 0.2117 - val_loss: 0.5573 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4388 - accuracy: 0.2299 - val_loss: 0.4277 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4208 - accuracy: 0.2670 - val_loss: 0.4124 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3966 - accuracy: 0.3168 - val_loss: 0.4335 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3760 - accuracy: 0.3365 - val_loss: 0.4255 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3678 - accuracy: 0.3736 - val_loss: 0.4187 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3469 - accuracy: 0.3934 - val_loss: 0.4034 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3333 - accuracy: 0.4147 - val_loss: 0.4272 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3137 - accuracy: 0.4543 - val_loss: 0.4873 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3060 - accuracy: 0.4538 - val_loss: 0.4340 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2901 - accuracy: 0.5015 - val_loss: 0.5475 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2823 - accuracy: 0.5142 - val_loss: 0.5638 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2224 - accuracy: 0.6046 - val_loss: 0.4699 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2110 - accuracy: 0.6305 - val_loss: 0.4988 - val_accuracy: 0.3568 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2032 - accuracy: 0.6482 - val_loss: 0.5098 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1980 - accuracy: 0.6599 - val_loss: 0.5141 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1936 - accuracy: 0.6660 - val_loss: 0.5322 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 0.4039 - accuracy: 0.2901\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.290 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.1196 - accuracy: 0.1659 - val_loss: 0.5038 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4928 - accuracy: 0.1989 - val_loss: 0.6972 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4690 - accuracy: 0.1877 - val_loss: 0.4295 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4369 - accuracy: 0.2298 - val_loss: 0.4379 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4204 - accuracy: 0.2334 - val_loss: 0.4670 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4152 - accuracy: 0.2603 - val_loss: 0.4224 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3972 - accuracy: 0.2775 - val_loss: 0.4231 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3894 - accuracy: 0.2958 - val_loss: 0.4214 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3862 - accuracy: 0.3130 - val_loss: 0.4253 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3744 - accuracy: 0.3354 - val_loss: 0.4905 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3674 - accuracy: 0.3663 - val_loss: 0.4140 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3548 - accuracy: 0.3749 - val_loss: 0.4186 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3523 - accuracy: 0.3831 - val_loss: 0.4658 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3463 - accuracy: 0.3998 - val_loss: 0.5148 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3337 - accuracy: 0.4313 - val_loss: 0.4805 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3325 - accuracy: 0.4287 - val_loss: 0.5031 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2868 - accuracy: 0.5053 - val_loss: 0.4444 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2650 - accuracy: 0.5566 - val_loss: 0.4523 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2579 - accuracy: 0.5718 - val_loss: 0.4690 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2513 - accuracy: 0.5870 - val_loss: 0.4638 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4634 - accuracy: 0.3127\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.313 total time=  56.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.1629 - accuracy: 0.1629 - val_loss: 0.5895 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4748 - accuracy: 0.1903 - val_loss: 0.4627 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4596 - accuracy: 0.2050 - val_loss: 0.4249 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4312 - accuracy: 0.2095 - val_loss: 0.4600 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4261 - accuracy: 0.2182 - val_loss: 0.4169 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4126 - accuracy: 0.2354 - val_loss: 0.4253 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4042 - accuracy: 0.2603 - val_loss: 0.4286 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3929 - accuracy: 0.2659 - val_loss: 0.4091 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3837 - accuracy: 0.2988 - val_loss: 0.4215 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3737 - accuracy: 0.3135 - val_loss: 0.4496 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.3676 - accuracy: 0.3384 - val_loss: 0.4383 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3602 - accuracy: 0.3496 - val_loss: 0.4508 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3490 - accuracy: 0.3648 - val_loss: 0.4698 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2920 - accuracy: 0.4663 - val_loss: 0.4391 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2801 - accuracy: 0.4815 - val_loss: 0.4477 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2734 - accuracy: 0.4926 - val_loss: 0.4393 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2668 - accuracy: 0.5094 - val_loss: 0.4791 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2617 - accuracy: 0.5256 - val_loss: 0.4689 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4160 - accuracy: 0.2193\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.219 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 1.0140 - accuracy: 0.1827 - val_loss: 0.4695 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4115 - accuracy: 0.2929 - val_loss: 0.4114 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3619 - accuracy: 0.4020 - val_loss: 0.4213 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3333 - accuracy: 0.4604 - val_loss: 0.4205 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2986 - accuracy: 0.5599 - val_loss: 0.3996 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2614 - accuracy: 0.6426 - val_loss: 0.4076 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2296 - accuracy: 0.6904 - val_loss: 0.4326 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2035 - accuracy: 0.7365 - val_loss: 0.4270 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1785 - accuracy: 0.7822 - val_loss: 0.4530 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1305 - accuracy: 0.8701 - val_loss: 0.4764 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0927 - accuracy: 0.9299 - val_loss: 0.4533 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0844 - accuracy: 0.9396 - val_loss: 0.4572 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0802 - accuracy: 0.9442 - val_loss: 0.4689 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0772 - accuracy: 0.9487 - val_loss: 0.4656 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0735 - accuracy: 0.9497 - val_loss: 0.4700 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4017 - accuracy: 0.3519\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.352 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.2885 - accuracy: 0.2035 - val_loss: 0.5341 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4220 - accuracy: 0.3338 - val_loss: 0.4814 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3503 - accuracy: 0.4531 - val_loss: 0.4128 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2943 - accuracy: 0.5647 - val_loss: 0.4183 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2591 - accuracy: 0.6251 - val_loss: 0.4179 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2332 - accuracy: 0.6859 - val_loss: 0.4760 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1950 - accuracy: 0.7742 - val_loss: 0.4572 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1549 - accuracy: 0.8331 - val_loss: 0.4807 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1124 - accuracy: 0.9173 - val_loss: 0.4592 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1018 - accuracy: 0.9422 - val_loss: 0.4641 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0962 - accuracy: 0.9488 - val_loss: 0.4636 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0924 - accuracy: 0.9533 - val_loss: 0.4667 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0880 - accuracy: 0.9579 - val_loss: 0.4759 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4150 - accuracy: 0.3381\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.338 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.1259 - accuracy: 0.1913 - val_loss: 0.4892 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4097 - accuracy: 0.3298 - val_loss: 0.4529 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3590 - accuracy: 0.4115 - val_loss: 0.4238 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3242 - accuracy: 0.4855 - val_loss: 0.4402 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2793 - accuracy: 0.5723 - val_loss: 0.4691 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2549 - accuracy: 0.6220 - val_loss: 0.4284 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2241 - accuracy: 0.6941 - val_loss: 0.4866 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2441 - accuracy: 0.6550 - val_loss: 0.5099 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1466 - accuracy: 0.8250 - val_loss: 0.4635 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1298 - accuracy: 0.8554 - val_loss: 0.4725 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1216 - accuracy: 0.8706 - val_loss: 0.4775 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1135 - accuracy: 0.8808 - val_loss: 0.4833 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1049 - accuracy: 0.8935 - val_loss: 0.4859 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4224 - accuracy: 0.2802\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.280 total time=  38.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.1951 - accuracy: 0.1599 - val_loss: 0.6536 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5321 - accuracy: 0.1518 - val_loss: 0.4725 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4880 - accuracy: 0.1599 - val_loss: 0.6116 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4811 - accuracy: 0.1772 - val_loss: 0.4287 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4709 - accuracy: 0.1817 - val_loss: 0.4443 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4573 - accuracy: 0.1924 - val_loss: 0.4891 - val_accuracy: 0.1270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4546 - accuracy: 0.1858 - val_loss: 0.5313 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.1909 - val_loss: 0.4904 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4435 - accuracy: 0.2041 - val_loss: 0.4947 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3831 - accuracy: 0.2640 - val_loss: 0.4197 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3724 - accuracy: 0.2782 - val_loss: 0.4243 - val_accuracy: 0.2135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3692 - accuracy: 0.2777 - val_loss: 0.4253 - val_accuracy: 0.1946 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3654 - accuracy: 0.2883 - val_loss: 0.4222 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3642 - accuracy: 0.3036 - val_loss: 0.4295 - val_accuracy: 0.2095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3612 - accuracy: 0.3066 - val_loss: 0.4315 - val_accuracy: 0.1959 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3571 - accuracy: 0.2959 - val_loss: 0.4289 - val_accuracy: 0.2149 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3554 - accuracy: 0.2995 - val_loss: 0.4284 - val_accuracy: 0.2216 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3550 - accuracy: 0.3015 - val_loss: 0.4298 - val_accuracy: 0.2230 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3545 - accuracy: 0.3086 - val_loss: 0.4302 - val_accuracy: 0.2284 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3542 - accuracy: 0.3239 - val_loss: 0.4309 - val_accuracy: 0.2203 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4188 - accuracy: 0.2160\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.216 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.2111 - accuracy: 0.1547 - val_loss: 0.6114 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5047 - accuracy: 0.1547 - val_loss: 0.4466 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4880 - accuracy: 0.1593 - val_loss: 0.4332 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4782 - accuracy: 0.1487 - val_loss: 0.4686 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4795 - accuracy: 0.1339 - val_loss: 0.4927 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4710 - accuracy: 0.1426 - val_loss: 0.4504 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4656 - accuracy: 0.1598 - val_loss: 0.5159 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4562 - accuracy: 0.1558 - val_loss: 0.4294 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.1745 - val_loss: 0.4415 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4477 - accuracy: 0.1821 - val_loss: 0.4306 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4434 - accuracy: 0.1847 - val_loss: 0.5109 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4387 - accuracy: 0.1857 - val_loss: 0.4904 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4311 - accuracy: 0.2014 - val_loss: 0.4302 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3898 - accuracy: 0.2197 - val_loss: 0.4328 - val_accuracy: 0.1635 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3852 - accuracy: 0.2232 - val_loss: 0.4309 - val_accuracy: 0.1595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3835 - accuracy: 0.2293 - val_loss: 0.4393 - val_accuracy: 0.1905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3812 - accuracy: 0.2278 - val_loss: 0.4429 - val_accuracy: 0.1865 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3795 - accuracy: 0.2329 - val_loss: 0.4331 - val_accuracy: 0.1932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4271 - accuracy: 0.1574\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.157 total time=  51.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.7337 - accuracy: 0.1481 - val_loss: 0.9824 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5376 - accuracy: 0.1451 - val_loss: 0.4836 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4857 - accuracy: 0.1588 - val_loss: 0.4853 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4762 - accuracy: 0.1948 - val_loss: 0.5045 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4586 - accuracy: 0.1781 - val_loss: 0.4650 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4590 - accuracy: 0.1852 - val_loss: 0.5240 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4527 - accuracy: 0.2045 - val_loss: 0.4536 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4453 - accuracy: 0.2045 - val_loss: 0.4175 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.2009 - val_loss: 0.5371 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4429 - accuracy: 0.2146 - val_loss: 0.5815 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4256 - accuracy: 0.2095 - val_loss: 0.4301 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3988 - accuracy: 0.2146 - val_loss: 0.4631 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3893 - accuracy: 0.2415 - val_loss: 0.4385 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3578 - accuracy: 0.2806 - val_loss: 0.4349 - val_accuracy: 0.2216 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3497 - accuracy: 0.2867 - val_loss: 0.4362 - val_accuracy: 0.2284 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3453 - accuracy: 0.3034 - val_loss: 0.4250 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3421 - accuracy: 0.3303 - val_loss: 0.4322 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3389 - accuracy: 0.3379 - val_loss: 0.4422 - val_accuracy: 0.2257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4115 - accuracy: 0.1919\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.192 total time=  51.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 1.4903 - accuracy: 0.1863 - val_loss: 0.4587 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4300 - accuracy: 0.2142 - val_loss: 0.4272 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3987 - accuracy: 0.2711 - val_loss: 0.4170 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3835 - accuracy: 0.3102 - val_loss: 0.4332 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3707 - accuracy: 0.3264 - val_loss: 0.4254 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3453 - accuracy: 0.3807 - val_loss: 0.4057 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3418 - accuracy: 0.4168 - val_loss: 0.4612 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3318 - accuracy: 0.4228 - val_loss: 0.4266 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3085 - accuracy: 0.4731 - val_loss: 0.4341 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2856 - accuracy: 0.5183 - val_loss: 0.4992 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2858 - accuracy: 0.5264 - val_loss: 0.4514 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2360 - accuracy: 0.6178 - val_loss: 0.4472 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2212 - accuracy: 0.6345 - val_loss: 0.4466 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2110 - accuracy: 0.6584 - val_loss: 0.4480 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2041 - accuracy: 0.6655 - val_loss: 0.4567 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1993 - accuracy: 0.6772 - val_loss: 0.4639 - val_accuracy: 0.3446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4089 - accuracy: 0.2475\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.247 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.1481 - accuracy: 0.1953 - val_loss: 0.4981 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4405 - accuracy: 0.2547 - val_loss: 0.4646 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4029 - accuracy: 0.2927 - val_loss: 0.4259 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3623 - accuracy: 0.3846 - val_loss: 0.4358 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 41ms/step - loss: 0.3371 - accuracy: 0.4262 - val_loss: 0.4254 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3098 - accuracy: 0.4845 - val_loss: 0.4879 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2917 - accuracy: 0.5211 - val_loss: 0.4711 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2609 - accuracy: 0.5835 - val_loss: 0.4530 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2415 - accuracy: 0.6129 - val_loss: 0.4667 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2158 - accuracy: 0.6667 - val_loss: 0.4768 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1560 - accuracy: 0.7742 - val_loss: 0.4965 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1380 - accuracy: 0.8087 - val_loss: 0.4989 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1294 - accuracy: 0.8224 - val_loss: 0.5037 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1245 - accuracy: 0.8366 - val_loss: 0.5159 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1181 - accuracy: 0.8463 - val_loss: 0.5170 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4551 - accuracy: 0.2640\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.264 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.7126 - accuracy: 0.1974 - val_loss: 0.6269 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4824 - accuracy: 0.2846 - val_loss: 0.4737 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3804 - accuracy: 0.3628 - val_loss: 0.4448 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3474 - accuracy: 0.4221 - val_loss: 0.4317 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3066 - accuracy: 0.5043 - val_loss: 0.4322 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2844 - accuracy: 0.5566 - val_loss: 0.4409 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2554 - accuracy: 0.6154 - val_loss: 0.4796 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2684 - accuracy: 0.5911 - val_loss: 0.4622 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2072 - accuracy: 0.7149 - val_loss: 0.5072 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1504 - accuracy: 0.8153 - val_loss: 0.4590 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1252 - accuracy: 0.8584 - val_loss: 0.4744 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1158 - accuracy: 0.8747 - val_loss: 0.4709 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1069 - accuracy: 0.8909 - val_loss: 0.4802 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1006 - accuracy: 0.9021 - val_loss: 0.4860 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 0.4286 - accuracy: 0.2832\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.283 total time=  41.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 3.9280 - accuracy: 0.1782 - val_loss: 1.4685 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.8309 - accuracy: 0.2188 - val_loss: 0.5589 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4804 - accuracy: 0.1802 - val_loss: 0.4924 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4456 - accuracy: 0.2020 - val_loss: 0.4204 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4251 - accuracy: 0.2467 - val_loss: 0.4222 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4060 - accuracy: 0.2680 - val_loss: 0.4138 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3908 - accuracy: 0.3142 - val_loss: 0.4406 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3710 - accuracy: 0.3371 - val_loss: 0.4330 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3567 - accuracy: 0.3761 - val_loss: 0.4235 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3406 - accuracy: 0.4086 - val_loss: 0.4197 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3265 - accuracy: 0.4284 - val_loss: 0.4848 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2673 - accuracy: 0.5335 - val_loss: 0.4205 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2472 - accuracy: 0.5675 - val_loss: 0.4268 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2387 - accuracy: 0.5817 - val_loss: 0.4356 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.2319 - accuracy: 0.5990 - val_loss: 0.4423 - val_accuracy: 0.3243 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2246 - accuracy: 0.6183 - val_loss: 0.4487 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4224 - accuracy: 0.2201\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.220 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.9701 - accuracy: 0.1725 - val_loss: 0.8546 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6217 - accuracy: 0.2314 - val_loss: 0.5064 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5098 - accuracy: 0.2237 - val_loss: 0.4891 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4621 - accuracy: 0.2740 - val_loss: 0.5335 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4135 - accuracy: 0.2998 - val_loss: 0.4256 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3870 - accuracy: 0.3196 - val_loss: 0.4489 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3576 - accuracy: 0.3688 - val_loss: 0.4085 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3513 - accuracy: 0.3927 - val_loss: 0.4325 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3200 - accuracy: 0.4394 - val_loss: 0.4970 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3197 - accuracy: 0.4729 - val_loss: 0.5139 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3051 - accuracy: 0.4815 - val_loss: 0.4513 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2794 - accuracy: 0.5312 - val_loss: 1.2311 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2409 - accuracy: 0.6281 - val_loss: 0.4807 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1937 - accuracy: 0.6844 - val_loss: 0.4860 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1823 - accuracy: 0.7108 - val_loss: 0.4982 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1737 - accuracy: 0.7296 - val_loss: 0.5003 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1655 - accuracy: 0.7489 - val_loss: 0.5206 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.3987 - accuracy: 0.2863\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.286 total time=  49.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.7458 - accuracy: 0.1796 - val_loss: 0.8637 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.0811 - accuracy: 0.2085 - val_loss: 0.7104 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5582 - accuracy: 0.2491 - val_loss: 0.4991 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4380 - accuracy: 0.2709 - val_loss: 0.5064 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4147 - accuracy: 0.3090 - val_loss: 0.4700 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3857 - accuracy: 0.3486 - val_loss: 0.4397 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3693 - accuracy: 0.3917 - val_loss: 0.4944 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3401 - accuracy: 0.4708 - val_loss: 0.4381 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3221 - accuracy: 0.4967 - val_loss: 0.4372 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3073 - accuracy: 0.5622 - val_loss: 0.4115 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2716 - accuracy: 0.5921 - val_loss: 0.5737 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2602 - accuracy: 0.6159 - val_loss: 0.5038 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2336 - accuracy: 0.6651 - val_loss: 0.6874 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2227 - accuracy: 0.6880 - val_loss: 0.5120 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1993 - accuracy: 0.7144 - val_loss: 0.6192 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1168 - accuracy: 0.8453 - val_loss: 0.5236 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0956 - accuracy: 0.8782 - val_loss: 0.5820 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0861 - accuracy: 0.8950 - val_loss: 0.5984 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0774 - accuracy: 0.9056 - val_loss: 0.6510 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0707 - accuracy: 0.9117 - val_loss: 0.6853 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4212 - accuracy: 0.3381\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.338 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 2.4319 - accuracy: 0.2056 - val_loss: 1.0353 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7487 - accuracy: 0.3619 - val_loss: 0.8081 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4357 - accuracy: 0.5259 - val_loss: 0.7042 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3272 - accuracy: 0.6122 - val_loss: 0.5968 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2151 - accuracy: 0.7614 - val_loss: 0.5793 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1755 - accuracy: 0.8086 - val_loss: 0.5518 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1688 - accuracy: 0.8462 - val_loss: 0.5766 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1172 - accuracy: 0.8980 - val_loss: 0.6030 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0986 - accuracy: 0.9294 - val_loss: 0.5855 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0712 - accuracy: 0.9614 - val_loss: 0.6103 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.6559 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0278 - accuracy: 0.9964 - val_loss: 0.6138 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0245 - accuracy: 0.9980 - val_loss: 0.6144 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.6190 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.6217 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0216 - accuracy: 0.9975 - val_loss: 0.6232 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5677 - accuracy: 0.4026\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.403 total time=  45.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.9937 - accuracy: 0.2121 - val_loss: 0.7701 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5573 - accuracy: 0.3450 - val_loss: 0.6676 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4668 - accuracy: 0.4307 - val_loss: 0.5561 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3154 - accuracy: 0.5622 - val_loss: 0.4642 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2581 - accuracy: 0.6667 - val_loss: 0.4866 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2221 - accuracy: 0.7286 - val_loss: 0.4635 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1606 - accuracy: 0.8270 - val_loss: 0.4843 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1321 - accuracy: 0.8864 - val_loss: 0.5248 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1412 - accuracy: 0.8549 - val_loss: 0.5524 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1038 - accuracy: 0.9219 - val_loss: 0.5318 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0845 - accuracy: 0.9396 - val_loss: 0.6419 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0495 - accuracy: 0.9858 - val_loss: 0.5507 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0382 - accuracy: 0.9964 - val_loss: 0.5491 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0356 - accuracy: 0.9970 - val_loss: 0.5512 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0335 - accuracy: 0.9975 - val_loss: 0.5491 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0321 - accuracy: 0.9975 - val_loss: 0.5520 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4723 - accuracy: 0.3726\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.373 total time=  45.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.0999 - accuracy: 0.1984 - val_loss: 0.8615 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5090 - accuracy: 0.4033 - val_loss: 0.5852 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3506 - accuracy: 0.5424 - val_loss: 0.5493 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2814 - accuracy: 0.6494 - val_loss: 0.6210 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2127 - accuracy: 0.7605 - val_loss: 0.4826 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1412 - accuracy: 0.8600 - val_loss: 0.5455 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1217 - accuracy: 0.8985 - val_loss: 0.5584 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1037 - accuracy: 0.9158 - val_loss: 0.5270 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0880 - accuracy: 0.9427 - val_loss: 0.5933 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0600 - accuracy: 0.9721 - val_loss: 0.6323 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0335 - accuracy: 0.9959 - val_loss: 0.5729 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0274 - accuracy: 0.9995 - val_loss: 0.5718 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0257 - accuracy: 0.9995 - val_loss: 0.5729 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0246 - accuracy: 0.9995 - val_loss: 0.5736 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0236 - accuracy: 0.9995 - val_loss: 0.5750 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4798 - accuracy: 0.4000\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.400 total time=  43.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.8577 - accuracy: 0.1756 - val_loss: 0.9007 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6585 - accuracy: 0.1843 - val_loss: 0.5314 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5040 - accuracy: 0.1650 - val_loss: 0.5313 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4853 - accuracy: 0.2056 - val_loss: 0.4989 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4529 - accuracy: 0.2193 - val_loss: 0.5968 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4490 - accuracy: 0.2335 - val_loss: 0.5076 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4366 - accuracy: 0.2690 - val_loss: 0.4376 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4251 - accuracy: 0.2685 - val_loss: 0.4229 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4172 - accuracy: 0.2904 - val_loss: 0.4246 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4047 - accuracy: 0.3117 - val_loss: 0.4134 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3832 - accuracy: 0.3320 - val_loss: 0.5239 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3828 - accuracy: 0.3497 - val_loss: 0.5352 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3593 - accuracy: 0.3574 - val_loss: 0.5318 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3587 - accuracy: 0.3614 - val_loss: 0.4251 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3688 - accuracy: 0.3685 - val_loss: 0.7066 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3276 - accuracy: 0.4041 - val_loss: 0.4259 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2953 - accuracy: 0.4208 - val_loss: 0.4206 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2890 - accuracy: 0.4330 - val_loss: 0.4393 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2839 - accuracy: 0.4421 - val_loss: 0.4473 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2793 - accuracy: 0.4472 - val_loss: 0.4876 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4333 - accuracy: 0.2627\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.263 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 5.3714 - accuracy: 0.1613 - val_loss: 0.4402 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5520 - accuracy: 0.1613 - val_loss: 0.5429 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5128 - accuracy: 0.1847 - val_loss: 0.5380 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5055 - accuracy: 0.1781 - val_loss: 1.2150 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4796 - accuracy: 0.2121 - val_loss: 0.5072 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4528 - accuracy: 0.2232 - val_loss: 0.5344 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3856 - accuracy: 0.2511 - val_loss: 0.4250 - val_accuracy: 0.1784 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3713 - accuracy: 0.2735 - val_loss: 0.4320 - val_accuracy: 0.2027 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3660 - accuracy: 0.2709 - val_loss: 0.4364 - val_accuracy: 0.2189 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3617 - accuracy: 0.2750 - val_loss: 0.4319 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3562 - accuracy: 0.3019 - val_loss: 0.4335 - val_accuracy: 0.2176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3528 - accuracy: 0.3135 - val_loss: 0.4255 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3468 - accuracy: 0.3369 - val_loss: 0.4262 - val_accuracy: 0.2486 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3447 - accuracy: 0.3394 - val_loss: 0.4266 - val_accuracy: 0.2635 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3439 - accuracy: 0.3420 - val_loss: 0.4273 - val_accuracy: 0.2622 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3432 - accuracy: 0.3404 - val_loss: 0.4262 - val_accuracy: 0.2568 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3428 - accuracy: 0.3415 - val_loss: 0.4262 - val_accuracy: 0.2662 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4174 - accuracy: 0.1787\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.179 total time=  49.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.8968 - accuracy: 0.1771 - val_loss: 0.5418 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5486 - accuracy: 0.1984 - val_loss: 0.5334 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5023 - accuracy: 0.1568 - val_loss: 0.4642 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4962 - accuracy: 0.1776 - val_loss: 0.5748 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4620 - accuracy: 0.2024 - val_loss: 0.5289 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4623 - accuracy: 0.2055 - val_loss: 0.5706 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4453 - accuracy: 0.2354 - val_loss: 0.5131 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4362 - accuracy: 0.2405 - val_loss: 0.5055 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3750 - accuracy: 0.2887 - val_loss: 0.4330 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3586 - accuracy: 0.2943 - val_loss: 0.4433 - val_accuracy: 0.2270 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3534 - accuracy: 0.3176 - val_loss: 0.4336 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3487 - accuracy: 0.3267 - val_loss: 0.4388 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3443 - accuracy: 0.3262 - val_loss: 0.4391 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3408 - accuracy: 0.3338 - val_loss: 0.4506 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3335 - accuracy: 0.3546 - val_loss: 0.4448 - val_accuracy: 0.2432 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3323 - accuracy: 0.3567 - val_loss: 0.4440 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3317 - accuracy: 0.3577 - val_loss: 0.4450 - val_accuracy: 0.2405 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3311 - accuracy: 0.3602 - val_loss: 0.4454 - val_accuracy: 0.2432 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3307 - accuracy: 0.3607 - val_loss: 0.4466 - val_accuracy: 0.2446 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4024 - accuracy: 0.2447\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.245 total time=  54.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 2.8772 - accuracy: 0.2056 - val_loss: 0.9414 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6387 - accuracy: 0.3391 - val_loss: 0.5934 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3889 - accuracy: 0.4751 - val_loss: 0.6089 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3054 - accuracy: 0.5635 - val_loss: 0.5078 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2367 - accuracy: 0.6812 - val_loss: 0.4922 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1925 - accuracy: 0.7604 - val_loss: 0.5079 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1559 - accuracy: 0.8269 - val_loss: 0.5501 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1507 - accuracy: 0.8198 - val_loss: 0.5601 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1055 - accuracy: 0.9071 - val_loss: 0.5506 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0778 - accuracy: 0.9442 - val_loss: 0.5958 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0380 - accuracy: 0.9914 - val_loss: 0.5693 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 0.5699 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 0.5747 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0275 - accuracy: 0.9985 - val_loss: 0.5775 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: 0.5789 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5094 - accuracy: 0.3661\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.366 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.1773 - accuracy: 0.1994 - val_loss: 0.8431 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5209 - accuracy: 0.3734 - val_loss: 0.5924 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3520 - accuracy: 0.5003 - val_loss: 0.4886 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2763 - accuracy: 0.6210 - val_loss: 0.5076 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2099 - accuracy: 0.7316 - val_loss: 0.5144 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1780 - accuracy: 0.7950 - val_loss: 0.4914 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1327 - accuracy: 0.8737 - val_loss: 0.5258 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1027 - accuracy: 0.9295 - val_loss: 0.5549 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.5201 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0488 - accuracy: 0.9904 - val_loss: 0.5195 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0454 - accuracy: 0.9924 - val_loss: 0.5221 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0427 - accuracy: 0.9924 - val_loss: 0.5263 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 0.5318 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4986 - accuracy: 0.3421\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.342 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.7165 - accuracy: 0.1958 - val_loss: 0.8787 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5628 - accuracy: 0.3562 - val_loss: 0.5690 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3743 - accuracy: 0.4866 - val_loss: 0.5357 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3157 - accuracy: 0.5576 - val_loss: 0.5546 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2558 - accuracy: 0.6631 - val_loss: 0.5554 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2093 - accuracy: 0.7347 - val_loss: 0.5392 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1767 - accuracy: 0.7910 - val_loss: 0.6057 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1455 - accuracy: 0.8316 - val_loss: 0.6258 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0902 - accuracy: 0.9188 - val_loss: 0.5625 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0699 - accuracy: 0.9513 - val_loss: 0.5601 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0627 - accuracy: 0.9625 - val_loss: 0.5690 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0584 - accuracy: 0.9650 - val_loss: 0.5726 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0547 - accuracy: 0.9706 - val_loss: 0.5737 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5175 - accuracy: 0.3005\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.301 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 14.1344 - accuracy: 0.1513 - val_loss: 0.6804 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6840 - accuracy: 0.1447 - val_loss: 0.6326 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6032 - accuracy: 0.1426 - val_loss: 0.5656 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5237 - accuracy: 0.1396 - val_loss: 0.4809 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4515 - accuracy: 0.1355 - val_loss: 0.4267 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4173 - accuracy: 0.1320 - val_loss: 0.4110 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4107 - accuracy: 0.1396 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1376 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1472 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1381 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 17.6608 - accuracy: 0.1847 - val_loss: 6.3937 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.5635 - accuracy: 0.2146 - val_loss: 0.8941 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7695 - accuracy: 0.1720 - val_loss: 0.4677 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5167 - accuracy: 0.1431 - val_loss: 0.5113 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5418 - accuracy: 0.1360 - val_loss: 0.6475 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5145 - accuracy: 0.1502 - val_loss: 0.5027 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5243 - accuracy: 0.1370 - val_loss: 0.5209 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4855 - accuracy: 0.1390 - val_loss: 0.4625 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4541 - accuracy: 0.1360 - val_loss: 0.4358 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4236 - accuracy: 0.1390 - val_loss: 0.4140 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4115 - accuracy: 0.1395 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1385 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1476 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1375 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1446 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1497 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4107 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.130 total time=  56.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 26.5498 - accuracy: 0.1725 - val_loss: 9.1073 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.3760 - accuracy: 0.2045 - val_loss: 0.6584 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7078 - accuracy: 0.1720 - val_loss: 0.8546 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5582 - accuracy: 0.1451 - val_loss: 0.5800 - val_accuracy: 0.1176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5037 - accuracy: 0.1471 - val_loss: 0.5169 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4963 - accuracy: 0.1492 - val_loss: 0.4626 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4853 - accuracy: 0.1547 - val_loss: 0.4876 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4600 - accuracy: 0.1395 - val_loss: 0.4367 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4245 - accuracy: 0.1461 - val_loss: 0.4145 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4121 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1324 - val_loss: 0.4103 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1481 - val_loss: 0.4107 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1436 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1405 - val_loss: 0.4105 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1481 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1436 - val_loss: 0.4105 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4102 - accuracy: 0.1350\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.135 total time=  57.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.4711 - accuracy: 0.2096 - val_loss: 2.6263 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.0647 - accuracy: 0.3782 - val_loss: 2.0029 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.2941 - accuracy: 0.4858 - val_loss: 2.2000 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.4866 - accuracy: 0.5325 - val_loss: 2.8848 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.1879 - accuracy: 0.5909 - val_loss: 1.7949 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5755 - accuracy: 0.7645 - val_loss: 1.9863 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5734 - accuracy: 0.7827 - val_loss: 2.3952 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5781 - accuracy: 0.7665 - val_loss: 2.0184 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4544 - accuracy: 0.8183 - val_loss: 1.6366 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3143 - accuracy: 0.8741 - val_loss: 2.2507 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2733 - accuracy: 0.8843 - val_loss: 1.9133 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1793 - accuracy: 0.9218 - val_loss: 1.7090 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1047 - accuracy: 0.9609 - val_loss: 1.8798 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0857 - accuracy: 0.9685 - val_loss: 1.9334 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 1.5805 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 1.5532 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 1.5454 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.5486 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.5554 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 1.5547 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.6208 - accuracy: 0.4473\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.447 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 5.8951 - accuracy: 0.2090 - val_loss: 4.0348 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1768 - accuracy: 0.4145 - val_loss: 2.2799 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.2512 - accuracy: 0.5464 - val_loss: 3.2353 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2005 - accuracy: 0.5977 - val_loss: 2.1657 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7237 - accuracy: 0.7270 - val_loss: 3.0457 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5161 - accuracy: 0.8113 - val_loss: 2.0310 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3898 - accuracy: 0.8478 - val_loss: 1.9063 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4274 - accuracy: 0.8488 - val_loss: 1.9925 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2568 - accuracy: 0.9127 - val_loss: 1.9869 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2973 - accuracy: 0.8945 - val_loss: 2.1538 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1915 - accuracy: 0.9315 - val_loss: 1.8483 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1987 - accuracy: 0.9376 - val_loss: 2.3076 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1269 - accuracy: 0.9584 - val_loss: 2.1480 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2380 - accuracy: 0.9163 - val_loss: 2.3143 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2346 - accuracy: 0.9188 - val_loss: 2.5175 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1718 - accuracy: 0.9462 - val_loss: 2.3219 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 2.0419 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.0383 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2049 - accuracy: 0.4416\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.442 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 6.4073 - accuracy: 0.2207 - val_loss: 3.7078 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.5295 - accuracy: 0.4049 - val_loss: 2.7996 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.5783 - accuracy: 0.5408 - val_loss: 2.6127 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.0889 - accuracy: 0.6114 - val_loss: 2.7970 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8555 - accuracy: 0.6895 - val_loss: 2.4616 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5955 - accuracy: 0.7854 - val_loss: 2.0916 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.8246 - accuracy: 0.7154 - val_loss: 3.1124 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6579 - accuracy: 0.7752 - val_loss: 2.1522 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2603 - accuracy: 0.8955 - val_loss: 2.0813 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2126 - accuracy: 0.9178 - val_loss: 2.1243 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1797 - accuracy: 0.9269 - val_loss: 2.1336 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0897 - accuracy: 0.9680 - val_loss: 2.0460 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0820 - accuracy: 0.9741 - val_loss: 2.3433 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0524 - accuracy: 0.9792 - val_loss: 1.9967 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1188 - accuracy: 0.9650 - val_loss: 2.2020 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 2.6162 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1344 - accuracy: 0.9472 - val_loss: 2.3427 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3801 - accuracy: 0.8752 - val_loss: 2.4197 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2938 - accuracy: 0.8803 - val_loss: 2.7132 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0586 - accuracy: 0.9797 - val_loss: 2.2390 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2352 - accuracy: 0.4132\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.413 total time=  56.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 20.4146 - accuracy: 0.1629 - val_loss: 3.3733 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1695 - accuracy: 0.1614 - val_loss: 0.6373 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6318 - accuracy: 0.1340 - val_loss: 0.5839 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5382 - accuracy: 0.1386 - val_loss: 0.4838 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4451 - accuracy: 0.1386 - val_loss: 0.4181 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4120 - accuracy: 0.1416 - val_loss: 0.4103 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1371 - val_loss: 0.4104 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1426 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1442 - val_loss: 0.4101 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1335 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1462 - val_loss: 0.4101 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1396 - val_loss: 0.4103 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1416 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 14.6735 - accuracy: 0.1715 - val_loss: 9.6263 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.8509 - accuracy: 0.2192 - val_loss: 2.8573 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5161 - accuracy: 0.1761 - val_loss: 0.4712 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6009 - accuracy: 0.1339 - val_loss: 0.6237 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5775 - accuracy: 0.1456 - val_loss: 0.5386 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4891 - accuracy: 0.1456 - val_loss: 0.4486 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4286 - accuracy: 0.1441 - val_loss: 0.4132 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4112 - accuracy: 0.1421 - val_loss: 0.4102 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1309 - val_loss: 0.4104 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1395 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1380 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4103 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4103 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1401\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.140 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 12.4767 - accuracy: 0.1537 - val_loss: 2.9720 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.3031 - accuracy: 0.1456 - val_loss: 0.6320 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5985 - accuracy: 0.1380 - val_loss: 0.5566 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5858 - accuracy: 0.1390 - val_loss: 0.5407 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4913 - accuracy: 0.1431 - val_loss: 0.4439 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4224 - accuracy: 0.1431 - val_loss: 0.4115 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4106 - accuracy: 0.1400 - val_loss: 0.4108 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1324 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1390 - val_loss: 0.4110 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1537 - val_loss: 0.4108 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1466 - val_loss: 0.4110 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4114 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4113 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4112 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4112 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4115 - accuracy: 0.1492\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.149 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 6.9470 - accuracy: 0.2071 - val_loss: 2.1093 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7392 - accuracy: 0.3807 - val_loss: 2.3112 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0062 - accuracy: 0.5005 - val_loss: 1.2460 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6873 - accuracy: 0.6203 - val_loss: 1.3416 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7168 - accuracy: 0.6000 - val_loss: 1.2632 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3680 - accuracy: 0.7497 - val_loss: 1.4993 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2373 - accuracy: 0.8335 - val_loss: 1.2510 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1928 - accuracy: 0.8675 - val_loss: 1.2763 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0686 - accuracy: 0.9594 - val_loss: 0.9830 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0311 - accuracy: 0.9868 - val_loss: 0.9688 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.9758 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.9693 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0184 - accuracy: 0.9970 - val_loss: 0.9558 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.9615 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.9620 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.9592 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0133 - accuracy: 0.9985 - val_loss: 0.9561 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.9540 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 0.9580 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0108 - accuracy: 0.9995 - val_loss: 0.9519 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.9813 - accuracy: 0.4412\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.441 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 7.0944 - accuracy: 0.2273 - val_loss: 2.8369 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1457 - accuracy: 0.3617 - val_loss: 2.3653 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.1052 - accuracy: 0.4795 - val_loss: 1.5621 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6671 - accuracy: 0.5936 - val_loss: 1.6285 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5400 - accuracy: 0.6484 - val_loss: 1.0753 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2523 - accuracy: 0.7783 - val_loss: 1.1284 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2193 - accuracy: 0.8260 - val_loss: 0.9986 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1334 - accuracy: 0.8884 - val_loss: 0.9531 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0779 - accuracy: 0.9396 - val_loss: 1.2052 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0896 - accuracy: 0.9310 - val_loss: 0.9600 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0432 - accuracy: 0.9731 - val_loss: 0.9011 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0698 - accuracy: 0.9518 - val_loss: 1.0592 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1694 - accuracy: 0.8874 - val_loss: 1.6110 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2405 - accuracy: 0.8610 - val_loss: 0.9722 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0919 - accuracy: 0.9361 - val_loss: 1.2713 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0762 - accuracy: 0.9508 - val_loss: 1.3841 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0237 - accuracy: 0.9853 - val_loss: 1.0787 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0647 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 1.2331 - accuracy: 0.4091\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.409 total time=  55.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.8776 - accuracy: 0.2268 - val_loss: 3.6499 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.3147 - accuracy: 0.3998 - val_loss: 2.6920 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7194 - accuracy: 0.4795 - val_loss: 1.7484 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6448 - accuracy: 0.6631 - val_loss: 1.5250 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4144 - accuracy: 0.7641 - val_loss: 1.6353 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3099 - accuracy: 0.8280 - val_loss: 1.6674 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2505 - accuracy: 0.8782 - val_loss: 1.3317 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1857 - accuracy: 0.8970 - val_loss: 1.1878 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0969 - accuracy: 0.9508 - val_loss: 1.3762 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0920 - accuracy: 0.9508 - val_loss: 1.3273 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0534 - accuracy: 0.9782 - val_loss: 1.2723 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0647 - accuracy: 0.9691 - val_loss: 1.5113 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2069 - accuracy: 0.9117 - val_loss: 1.5179 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0350 - accuracy: 0.9919 - val_loss: 1.3934 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 1.3690 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 1.3386 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.2431 - accuracy: 0.3888\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.389 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 28.6497 - accuracy: 0.1741 - val_loss: 3.9325 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.5478 - accuracy: 0.2218 - val_loss: 5.5574 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 4.4783 - accuracy: 0.2457 - val_loss: 6.5111 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.1439 - accuracy: 0.2797 - val_loss: 6.5920 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.8019 - accuracy: 0.2959 - val_loss: 1.5073 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.2321 - accuracy: 0.3259 - val_loss: 2.0167 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7697 - accuracy: 0.3477 - val_loss: 4.2191 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6896 - accuracy: 0.3624 - val_loss: 2.0757 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5481 - accuracy: 0.4020 - val_loss: 1.5219 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.4874 - accuracy: 0.3868 - val_loss: 1.7909 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3721 - accuracy: 0.6665 - val_loss: 0.7458 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2345 - accuracy: 0.7487 - val_loss: 0.6787 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1897 - accuracy: 0.7954 - val_loss: 0.6613 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1638 - accuracy: 0.8264 - val_loss: 0.6726 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1450 - accuracy: 0.8386 - val_loss: 0.6598 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1306 - accuracy: 0.8680 - val_loss: 0.6347 - val_accuracy: 0.4041 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1183 - accuracy: 0.8883 - val_loss: 0.6401 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1100 - accuracy: 0.9010 - val_loss: 0.6251 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.0992 - accuracy: 0.9132 - val_loss: 0.6141 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0909 - accuracy: 0.9355 - val_loss: 0.6425 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.6781 - accuracy: 0.4097\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.410 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 35.7216 - accuracy: 0.1832 - val_loss: 14.4561 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 11.3851 - accuracy: 0.2111 - val_loss: 6.8734 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.7881 - accuracy: 0.1842 - val_loss: 0.6502 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6409 - accuracy: 0.1400 - val_loss: 0.5687 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5388 - accuracy: 0.1786 - val_loss: 0.5370 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4866 - accuracy: 0.1872 - val_loss: 0.5714 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4527 - accuracy: 0.1700 - val_loss: 0.4364 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4231 - accuracy: 0.1624 - val_loss: 0.4150 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4140 - accuracy: 0.1451 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4099 - accuracy: 0.1481 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1451 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4101 - accuracy: 0.1487 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4099 - accuracy: 0.1446 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4099 - accuracy: 0.1360 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4109 - accuracy: 0.1512 - val_loss: 0.4114 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4095 - accuracy: 0.1380 - val_loss: 0.4110 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4098 - accuracy: 0.1421 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4092 - accuracy: 0.1476 - val_loss: 0.4151 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1416 - val_loss: 0.4118 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4092 - accuracy: 0.1537 - val_loss: 0.4121 - val_accuracy: 0.1392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4105 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.130 total time=  57.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 22.5405 - accuracy: 0.1689 - val_loss: 4.3728 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 5.2667 - accuracy: 0.2004 - val_loss: 2.6919 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.0955 - accuracy: 0.2060 - val_loss: 1.4863 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.2252 - accuracy: 0.2324 - val_loss: 1.2586 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.5158 - accuracy: 0.2050 - val_loss: 3.4198 - val_accuracy: 0.1162 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.4037 - accuracy: 0.1613 - val_loss: 1.4896 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9776 - accuracy: 0.1547 - val_loss: 0.5914 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9468 - accuracy: 0.1497 - val_loss: 0.6058 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9536 - accuracy: 0.1624 - val_loss: 0.8986 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8021 - accuracy: 0.1786 - val_loss: 0.7125 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7671 - accuracy: 0.1750 - val_loss: 0.5274 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5120 - accuracy: 0.1481 - val_loss: 0.5662 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4813 - accuracy: 0.1421 - val_loss: 0.4652 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4743 - accuracy: 0.1461 - val_loss: 0.4607 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4703 - accuracy: 0.1466 - val_loss: 0.5466 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4761 - accuracy: 0.1471 - val_loss: 0.4415 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4648 - accuracy: 0.1629 - val_loss: 0.5059 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4694 - accuracy: 0.1588 - val_loss: 0.4994 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4662 - accuracy: 0.1532 - val_loss: 0.4322 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4599 - accuracy: 0.1563 - val_loss: 0.5179 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5189 - accuracy: 0.1360\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.136 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 13.3921 - accuracy: 0.2091 - val_loss: 3.8212 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.5938 - accuracy: 0.4518 - val_loss: 4.0626 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.8530 - accuracy: 0.4457 - val_loss: 3.4562 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.6709 - accuracy: 0.6157 - val_loss: 3.1669 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0882 - accuracy: 0.6959 - val_loss: 3.1295 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7389 - accuracy: 0.7604 - val_loss: 2.8714 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7391 - accuracy: 0.7853 - val_loss: 3.0086 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6944 - accuracy: 0.7772 - val_loss: 2.6694 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3605 - accuracy: 0.8746 - val_loss: 2.6085 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2890 - accuracy: 0.9056 - val_loss: 2.8112 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2821 - accuracy: 0.9112 - val_loss: 2.5204 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1143 - accuracy: 0.9629 - val_loss: 2.3348 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2595 - accuracy: 0.9244 - val_loss: 2.8809 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3916 - accuracy: 0.8741 - val_loss: 2.7922 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2886 - accuracy: 0.9142 - val_loss: 3.5466 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1571 - accuracy: 0.9518 - val_loss: 3.1073 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1526 - accuracy: 0.9635 - val_loss: 3.3289 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0401 - accuracy: 0.9929 - val_loss: 2.7143 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 2.7090 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6770 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.8127 - accuracy: 0.4331\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.433 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 11.1005 - accuracy: 0.2263 - val_loss: 4.4037 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.2608 - accuracy: 0.4181 - val_loss: 4.3649 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 3.8105 - accuracy: 0.4526 - val_loss: 6.9307 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.8090 - accuracy: 0.5190 - val_loss: 3.7095 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3096 - accuracy: 0.6905 - val_loss: 3.1750 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9252 - accuracy: 0.7377 - val_loss: 2.6868 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5803 - accuracy: 0.8498 - val_loss: 2.6464 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4091 - accuracy: 0.8762 - val_loss: 2.5871 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2832 - accuracy: 0.9163 - val_loss: 2.1209 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3907 - accuracy: 0.8950 - val_loss: 2.5424 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2321 - accuracy: 0.9335 - val_loss: 2.6708 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1915 - accuracy: 0.9594 - val_loss: 2.7108 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1931 - accuracy: 0.9462 - val_loss: 2.9814 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3708 - accuracy: 0.9097 - val_loss: 3.1440 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0723 - accuracy: 0.9833 - val_loss: 2.4138 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0205 - accuracy: 0.9975 - val_loss: 2.3688 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 2.2893 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.2962 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 2.2944 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.3646 - accuracy: 0.4081\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.408 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.8119 - accuracy: 0.2171 - val_loss: 6.6470 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.3960 - accuracy: 0.4536 - val_loss: 6.3389 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0603 - accuracy: 0.5317 - val_loss: 4.3978 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1081 - accuracy: 0.6332 - val_loss: 4.2131 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.3735 - accuracy: 0.7484 - val_loss: 5.0716 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.4001 - accuracy: 0.7666 - val_loss: 6.3311 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.8692 - accuracy: 0.8189 - val_loss: 5.3510 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6745 - accuracy: 0.8747 - val_loss: 4.4537 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6443 - accuracy: 0.8879 - val_loss: 4.0825 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5080 - accuracy: 0.9082 - val_loss: 4.7022 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4266 - accuracy: 0.9229 - val_loss: 4.3093 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3270 - accuracy: 0.9462 - val_loss: 4.4176 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5744 - accuracy: 0.8970 - val_loss: 4.5273 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2866 - accuracy: 0.9599 - val_loss: 4.6089 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0481 - accuracy: 0.9959 - val_loss: 4.1266 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 4.0471 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 4.0446 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 4.0687 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 6.5808e-04 - accuracy: 1.0000 - val_loss: 4.0776 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 4.2369e-04 - accuracy: 1.0000 - val_loss: 4.0651 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 4.1662 - accuracy: 0.3980\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.398 total time=  55.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 24.8186 - accuracy: 0.1629 - val_loss: 14.9081 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.4055 - accuracy: 0.1832 - val_loss: 1.1733 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6822 - accuracy: 0.1650 - val_loss: 0.5587 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5674 - accuracy: 0.1411 - val_loss: 0.6357 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5670 - accuracy: 0.1350 - val_loss: 0.5133 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4898 - accuracy: 0.1442 - val_loss: 0.4533 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4282 - accuracy: 0.1355 - val_loss: 0.4123 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4108 - accuracy: 0.1289 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1442 - val_loss: 0.4102 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1376 - val_loss: 0.4103 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1355 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1452 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1457 - val_loss: 0.4102 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1391 - val_loss: 0.4102 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1442 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1467 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  58.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 27.2532 - accuracy: 0.1903 - val_loss: 10.2750 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 8.8633 - accuracy: 0.2314 - val_loss: 4.1140 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.4198 - accuracy: 0.2420 - val_loss: 3.1748 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.2296 - accuracy: 0.2293 - val_loss: 1.3218 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.6952 - accuracy: 0.2040 - val_loss: 1.8543 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.7162 - accuracy: 0.2024 - val_loss: 0.8782 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0185 - accuracy: 0.2121 - val_loss: 1.5229 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6071 - accuracy: 0.1781 - val_loss: 0.5266 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5604 - accuracy: 0.1466 - val_loss: 0.6111 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5420 - accuracy: 0.1461 - val_loss: 0.5617 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5265 - accuracy: 0.1522 - val_loss: 0.5233 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4829 - accuracy: 0.1710 - val_loss: 0.4610 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4364 - accuracy: 0.1695 - val_loss: 0.4224 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1547 - val_loss: 0.4109 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4417 - accuracy: 0.1598 - val_loss: 0.4127 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4052 - accuracy: 0.1761 - val_loss: 0.4104 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4157 - accuracy: 0.1578 - val_loss: 0.4118 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4055 - accuracy: 0.1532 - val_loss: 0.4120 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4071 - accuracy: 0.1689 - val_loss: 0.4113 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4046 - accuracy: 0.1695 - val_loss: 0.4114 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 0.4095 - accuracy: 0.1360\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.136 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 30.4468 - accuracy: 0.1613 - val_loss: 24.6379 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 10.7907 - accuracy: 0.2177 - val_loss: 4.9079 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1955 - accuracy: 0.1608 - val_loss: 0.4895 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6263 - accuracy: 0.1461 - val_loss: 0.6419 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6018 - accuracy: 0.1350 - val_loss: 0.5702 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5297 - accuracy: 0.1370 - val_loss: 0.4917 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4563 - accuracy: 0.1334 - val_loss: 0.4255 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4152 - accuracy: 0.1481 - val_loss: 0.4102 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4108 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1375 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1324 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1334 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1350 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1380 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1441 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4101 - accuracy: 0.1380 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1442\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.144 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 14.0700 - accuracy: 0.2320 - val_loss: 4.2703 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.9231 - accuracy: 0.4076 - val_loss: 3.8542 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6401 - accuracy: 0.5310 - val_loss: 2.1575 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9151 - accuracy: 0.6558 - val_loss: 2.1055 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7325 - accuracy: 0.7041 - val_loss: 2.2086 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5539 - accuracy: 0.7426 - val_loss: 1.9900 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3727 - accuracy: 0.7944 - val_loss: 2.1352 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2633 - accuracy: 0.8650 - val_loss: 1.5768 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1126 - accuracy: 0.9421 - val_loss: 1.6851 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1448 - accuracy: 0.9299 - val_loss: 1.8290 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1150 - accuracy: 0.9437 - val_loss: 1.6276 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0749 - accuracy: 0.9675 - val_loss: 1.8764 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0835 - accuracy: 0.9665 - val_loss: 1.8866 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.5448 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 1.5503 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.5448 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5417 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5439 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.5657 - accuracy: 0.4473\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.447 total time=  56.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 12.0472 - accuracy: 0.2283 - val_loss: 5.0580 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.5151 - accuracy: 0.3876 - val_loss: 3.1006 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5413 - accuracy: 0.5028 - val_loss: 2.3179 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8306 - accuracy: 0.6388 - val_loss: 1.5001 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6213 - accuracy: 0.7042 - val_loss: 1.4312 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3840 - accuracy: 0.7955 - val_loss: 2.0054 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3397 - accuracy: 0.8280 - val_loss: 2.0877 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2868 - accuracy: 0.8564 - val_loss: 1.7533 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2028 - accuracy: 0.9021 - val_loss: 1.6534 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1453 - accuracy: 0.9249 - val_loss: 1.4907 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0272 - accuracy: 0.9893 - val_loss: 1.3571 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 1.3433 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 1.3529 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.3318 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.3410 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 1.3353 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.4216 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.4853 - accuracy: 0.4142\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.414 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.6775 - accuracy: 0.2177 - val_loss: 4.7846 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.3696 - accuracy: 0.4145 - val_loss: 2.4710 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1242 - accuracy: 0.5860 - val_loss: 2.2643 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1197 - accuracy: 0.6271 - val_loss: 2.2530 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1945 - accuracy: 0.6190 - val_loss: 2.1981 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4712 - accuracy: 0.7986 - val_loss: 2.1130 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3124 - accuracy: 0.8645 - val_loss: 1.6113 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2117 - accuracy: 0.9097 - val_loss: 1.5021 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1239 - accuracy: 0.9411 - val_loss: 1.6855 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0689 - accuracy: 0.9691 - val_loss: 1.5287 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0746 - accuracy: 0.9696 - val_loss: 1.3881 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 1.4775 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0579 - accuracy: 0.9756 - val_loss: 1.8347 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0833 - accuracy: 0.9655 - val_loss: 1.7260 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1164 - accuracy: 0.9543 - val_loss: 1.8082 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1013 - accuracy: 0.9574 - val_loss: 2.1133 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 1.5663 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 1.5575 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 1.7507 - accuracy: 0.4030\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.403 total time=  56.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.2606 - accuracy: 0.1782 - val_loss: 0.6286 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6056 - accuracy: 0.1797 - val_loss: 0.4767 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4649 - accuracy: 0.1934 - val_loss: 0.5044 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4380 - accuracy: 0.2218 - val_loss: 0.5175 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4368 - accuracy: 0.2442 - val_loss: 0.4447 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4146 - accuracy: 0.2787 - val_loss: 0.4649 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4045 - accuracy: 0.2939 - val_loss: 0.5334 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3883 - accuracy: 0.3340 - val_loss: 0.4188 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3710 - accuracy: 0.3421 - val_loss: 0.4718 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3581 - accuracy: 0.3746 - val_loss: 0.4553 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3435 - accuracy: 0.4046 - val_loss: 0.4734 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3366 - accuracy: 0.4142 - val_loss: 0.4381 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3276 - accuracy: 0.4472 - val_loss: 0.4954 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2654 - accuracy: 0.5406 - val_loss: 0.4229 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2454 - accuracy: 0.5782 - val_loss: 0.4464 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2381 - accuracy: 0.5858 - val_loss: 0.4549 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2320 - accuracy: 0.6010 - val_loss: 0.4507 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2257 - accuracy: 0.6112 - val_loss: 0.4668 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4179 - accuracy: 0.2546\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.255 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.1249 - accuracy: 0.1583 - val_loss: 0.7482 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5997 - accuracy: 0.1999 - val_loss: 0.5453 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4663 - accuracy: 0.2050 - val_loss: 0.4548 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4354 - accuracy: 0.2496 - val_loss: 0.4616 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4276 - accuracy: 0.2329 - val_loss: 0.4241 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4154 - accuracy: 0.2440 - val_loss: 0.5242 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4002 - accuracy: 0.3019 - val_loss: 0.4544 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3992 - accuracy: 0.3176 - val_loss: 0.4359 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3745 - accuracy: 0.3430 - val_loss: 0.4712 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3615 - accuracy: 0.3719 - val_loss: 0.5409 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3095 - accuracy: 0.4581 - val_loss: 0.3985 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2872 - accuracy: 0.5028 - val_loss: 0.4016 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2801 - accuracy: 0.5200 - val_loss: 0.4072 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2729 - accuracy: 0.5342 - val_loss: 0.4137 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2673 - accuracy: 0.5449 - val_loss: 0.4174 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2599 - accuracy: 0.5647 - val_loss: 0.4207 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2505 - accuracy: 0.5926 - val_loss: 0.4249 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2492 - accuracy: 0.5977 - val_loss: 0.4257 - val_accuracy: 0.3176 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2483 - accuracy: 0.5941 - val_loss: 0.4273 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2474 - accuracy: 0.6002 - val_loss: 0.4275 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4214 - accuracy: 0.3208\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.321 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 2.5312 - accuracy: 0.1761 - val_loss: 0.5311 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4717 - accuracy: 0.1618 - val_loss: 0.4732 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4636 - accuracy: 0.1958 - val_loss: 0.5129 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4458 - accuracy: 0.2075 - val_loss: 0.4757 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4265 - accuracy: 0.2324 - val_loss: 0.4257 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4167 - accuracy: 0.2516 - val_loss: 0.5200 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4048 - accuracy: 0.2684 - val_loss: 0.4653 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3916 - accuracy: 0.3075 - val_loss: 0.4293 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3802 - accuracy: 0.3146 - val_loss: 0.4872 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3660 - accuracy: 0.3582 - val_loss: 0.4763 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3064 - accuracy: 0.4302 - val_loss: 0.3963 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2911 - accuracy: 0.4754 - val_loss: 0.4076 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2841 - accuracy: 0.4916 - val_loss: 0.4095 - val_accuracy: 0.3446 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2780 - accuracy: 0.4957 - val_loss: 0.4115 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2722 - accuracy: 0.5180 - val_loss: 0.4164 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2666 - accuracy: 0.5297 - val_loss: 0.4214 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2581 - accuracy: 0.5413 - val_loss: 0.4226 - val_accuracy: 0.3392 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2569 - accuracy: 0.5429 - val_loss: 0.4249 - val_accuracy: 0.3419 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2563 - accuracy: 0.5474 - val_loss: 0.4240 - val_accuracy: 0.3405 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2556 - accuracy: 0.5530 - val_loss: 0.4270 - val_accuracy: 0.3378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4126 - accuracy: 0.3431\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.343 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 1.0688 - accuracy: 0.2041 - val_loss: 0.6785 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4537 - accuracy: 0.3426 - val_loss: 0.4453 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3323 - accuracy: 0.4970 - val_loss: 0.4346 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2947 - accuracy: 0.5472 - val_loss: 0.4381 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2424 - accuracy: 0.6655 - val_loss: 0.4251 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2141 - accuracy: 0.7269 - val_loss: 0.4245 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1757 - accuracy: 0.7975 - val_loss: 0.4602 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1376 - accuracy: 0.8726 - val_loss: 0.4623 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1052 - accuracy: 0.9193 - val_loss: 0.4862 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0931 - accuracy: 0.9365 - val_loss: 0.5358 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0820 - accuracy: 0.9386 - val_loss: 0.5514 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.5323 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0306 - accuracy: 0.9959 - val_loss: 0.5446 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0277 - accuracy: 0.9970 - val_loss: 0.5430 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0256 - accuracy: 0.9975 - val_loss: 0.5447 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.5557 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4143 - accuracy: 0.4158\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.416 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.0334 - accuracy: 0.1908 - val_loss: 0.4935 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4036 - accuracy: 0.3389 - val_loss: 0.4450 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3444 - accuracy: 0.4521 - val_loss: 0.4244 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3042 - accuracy: 0.5322 - val_loss: 0.4177 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2630 - accuracy: 0.6210 - val_loss: 0.4127 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2338 - accuracy: 0.6692 - val_loss: 0.4691 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2057 - accuracy: 0.7326 - val_loss: 0.4438 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1659 - accuracy: 0.8011 - val_loss: 0.5759 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1360 - accuracy: 0.8447 - val_loss: 0.5328 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1376 - accuracy: 0.8417 - val_loss: 0.5577 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0690 - accuracy: 0.9488 - val_loss: 0.5163 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0532 - accuracy: 0.9706 - val_loss: 0.5243 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0474 - accuracy: 0.9767 - val_loss: 0.5392 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0431 - accuracy: 0.9797 - val_loss: 0.5480 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0389 - accuracy: 0.9827 - val_loss: 0.5538 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4273 - accuracy: 0.3472\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.347 total time=  44.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.3323 - accuracy: 0.1837 - val_loss: 0.4747 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4289 - accuracy: 0.2481 - val_loss: 0.4245 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3968 - accuracy: 0.2796 - val_loss: 0.4390 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3752 - accuracy: 0.3364 - val_loss: 0.4201 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3538 - accuracy: 0.3886 - val_loss: 0.4141 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3360 - accuracy: 0.4353 - val_loss: 0.4279 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3105 - accuracy: 0.4947 - val_loss: 0.4368 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2891 - accuracy: 0.5408 - val_loss: 0.4365 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2693 - accuracy: 0.5835 - val_loss: 0.4498 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2423 - accuracy: 0.6256 - val_loss: 0.4828 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1918 - accuracy: 0.7296 - val_loss: 0.4634 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1789 - accuracy: 0.7570 - val_loss: 0.4686 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1727 - accuracy: 0.7626 - val_loss: 0.4790 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1676 - accuracy: 0.7717 - val_loss: 0.4795 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1628 - accuracy: 0.7788 - val_loss: 0.4930 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.3944 - accuracy: 0.2944\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.294 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.4886 - accuracy: 0.1645 - val_loss: 0.4709 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5235 - accuracy: 0.1543 - val_loss: 0.5328 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4949 - accuracy: 0.1772 - val_loss: 0.4504 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5051 - accuracy: 0.1558 - val_loss: 0.4758 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4787 - accuracy: 0.1868 - val_loss: 0.4610 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4613 - accuracy: 0.2086 - val_loss: 0.8147 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4633 - accuracy: 0.2320 - val_loss: 0.5287 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4408 - accuracy: 0.2305 - val_loss: 0.6464 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3813 - accuracy: 0.2858 - val_loss: 0.4348 - val_accuracy: 0.2608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3593 - accuracy: 0.3066 - val_loss: 0.4338 - val_accuracy: 0.2541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3538 - accuracy: 0.3178 - val_loss: 0.4527 - val_accuracy: 0.2635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3503 - accuracy: 0.3244 - val_loss: 0.4414 - val_accuracy: 0.2622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3457 - accuracy: 0.3208 - val_loss: 0.4455 - val_accuracy: 0.2595 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3415 - accuracy: 0.3411 - val_loss: 0.4454 - val_accuracy: 0.2581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3385 - accuracy: 0.3416 - val_loss: 0.4518 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3334 - accuracy: 0.3543 - val_loss: 0.4566 - val_accuracy: 0.2676 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3318 - accuracy: 0.3538 - val_loss: 0.4568 - val_accuracy: 0.2743 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3312 - accuracy: 0.3543 - val_loss: 0.4574 - val_accuracy: 0.2689 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3307 - accuracy: 0.3569 - val_loss: 0.4589 - val_accuracy: 0.2676 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3303 - accuracy: 0.3563 - val_loss: 0.4582 - val_accuracy: 0.2716 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4307 - accuracy: 0.2262\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.226 total time=  57.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 1.7889 - accuracy: 0.1507 - val_loss: 0.4934 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4992 - accuracy: 0.1608 - val_loss: 0.4469 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4871 - accuracy: 0.1755 - val_loss: 0.4398 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4678 - accuracy: 0.1928 - val_loss: 0.5521 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4615 - accuracy: 0.2045 - val_loss: 0.4805 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4530 - accuracy: 0.2156 - val_loss: 0.4796 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4718 - accuracy: 0.2344 - val_loss: 0.4288 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4322 - accuracy: 0.2552 - val_loss: 0.4845 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4321 - accuracy: 0.2527 - val_loss: 0.4937 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4202 - accuracy: 0.2790 - val_loss: 0.4480 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4109 - accuracy: 0.2704 - val_loss: 0.4335 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3944 - accuracy: 0.2938 - val_loss: 0.4310 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3493 - accuracy: 0.3415 - val_loss: 0.4283 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3289 - accuracy: 0.3749 - val_loss: 0.4412 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3214 - accuracy: 0.3947 - val_loss: 0.4514 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3138 - accuracy: 0.4089 - val_loss: 0.4429 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3086 - accuracy: 0.4130 - val_loss: 0.4453 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3032 - accuracy: 0.4262 - val_loss: 0.4616 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2968 - accuracy: 0.4297 - val_loss: 0.4607 - val_accuracy: 0.2892 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2958 - accuracy: 0.4282 - val_loss: 0.4601 - val_accuracy: 0.2824 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4323 - accuracy: 0.2772\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.277 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.0964 - accuracy: 0.1476 - val_loss: 0.5299 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5234 - accuracy: 0.1568 - val_loss: 0.5219 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4960 - accuracy: 0.1720 - val_loss: 0.5552 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4896 - accuracy: 0.1725 - val_loss: 0.5318 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4872 - accuracy: 0.1710 - val_loss: 0.5502 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4748 - accuracy: 0.1923 - val_loss: 0.5258 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4716 - accuracy: 0.2090 - val_loss: 0.5311 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4147 - accuracy: 0.1872 - val_loss: 0.4168 - val_accuracy: 0.1865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3863 - accuracy: 0.2374 - val_loss: 0.4152 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3812 - accuracy: 0.2456 - val_loss: 0.4184 - val_accuracy: 0.1905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3785 - accuracy: 0.2405 - val_loss: 0.4170 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3754 - accuracy: 0.2537 - val_loss: 0.4185 - val_accuracy: 0.1919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3719 - accuracy: 0.2623 - val_loss: 0.4221 - val_accuracy: 0.2216 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3683 - accuracy: 0.2740 - val_loss: 0.4195 - val_accuracy: 0.2284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3624 - accuracy: 0.2907 - val_loss: 0.4216 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3613 - accuracy: 0.2912 - val_loss: 0.4221 - val_accuracy: 0.2284 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3609 - accuracy: 0.2882 - val_loss: 0.4226 - val_accuracy: 0.2297 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3604 - accuracy: 0.2851 - val_loss: 0.4220 - val_accuracy: 0.2257 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3599 - accuracy: 0.2943 - val_loss: 0.4232 - val_accuracy: 0.2297 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.2213\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.221 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.4320 - accuracy: 0.1822 - val_loss: 0.4698 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4267 - accuracy: 0.2244 - val_loss: 0.4419 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4006 - accuracy: 0.2655 - val_loss: 0.4238 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3727 - accuracy: 0.3259 - val_loss: 0.4220 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3545 - accuracy: 0.3660 - val_loss: 0.4399 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3466 - accuracy: 0.3949 - val_loss: 0.4326 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3202 - accuracy: 0.4442 - val_loss: 0.4374 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3126 - accuracy: 0.4701 - val_loss: 0.4932 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3008 - accuracy: 0.4924 - val_loss: 0.4683 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2438 - accuracy: 0.6076 - val_loss: 0.4511 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2266 - accuracy: 0.6386 - val_loss: 0.4555 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2195 - accuracy: 0.6619 - val_loss: 0.4610 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2114 - accuracy: 0.6777 - val_loss: 0.4577 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2064 - accuracy: 0.6944 - val_loss: 0.4690 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4114 - accuracy: 0.2637\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.264 total time=  41.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.4099 - accuracy: 0.1857 - val_loss: 0.5539 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4427 - accuracy: 0.2943 - val_loss: 0.4660 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3643 - accuracy: 0.3962 - val_loss: 0.4422 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3340 - accuracy: 0.4779 - val_loss: 0.4598 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2968 - accuracy: 0.5403 - val_loss: 0.4395 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2660 - accuracy: 0.6043 - val_loss: 0.4917 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2465 - accuracy: 0.6281 - val_loss: 0.4725 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2009 - accuracy: 0.7108 - val_loss: 0.4894 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1615 - accuracy: 0.7864 - val_loss: 0.5526 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1340 - accuracy: 0.8346 - val_loss: 0.5558 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0765 - accuracy: 0.9198 - val_loss: 0.5160 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0617 - accuracy: 0.9498 - val_loss: 0.5236 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0553 - accuracy: 0.9584 - val_loss: 0.5362 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0504 - accuracy: 0.9670 - val_loss: 0.5386 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0464 - accuracy: 0.9726 - val_loss: 0.5492 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4297 - accuracy: 0.3421\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.342 total time=  44.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.5846 - accuracy: 0.1796 - val_loss: 0.4522 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4183 - accuracy: 0.2227 - val_loss: 0.4289 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3999 - accuracy: 0.2638 - val_loss: 0.4138 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3777 - accuracy: 0.3105 - val_loss: 0.4090 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3549 - accuracy: 0.3617 - val_loss: 0.4130 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3449 - accuracy: 0.3825 - val_loss: 0.4441 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3328 - accuracy: 0.4054 - val_loss: 0.4483 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3177 - accuracy: 0.4404 - val_loss: 0.4316 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3036 - accuracy: 0.4789 - val_loss: 0.4663 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2506 - accuracy: 0.5967 - val_loss: 0.4403 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2310 - accuracy: 0.6393 - val_loss: 0.4370 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2234 - accuracy: 0.6611 - val_loss: 0.4384 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2148 - accuracy: 0.6794 - val_loss: 0.4410 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2079 - accuracy: 0.6966 - val_loss: 0.4572 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4102 - accuracy: 0.2548\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.255 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.6971 - accuracy: 0.1853 - val_loss: 0.8396 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9643 - accuracy: 0.2152 - val_loss: 0.5119 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5381 - accuracy: 0.2416 - val_loss: 0.4365 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4262 - accuracy: 0.2431 - val_loss: 0.4809 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4066 - accuracy: 0.2878 - val_loss: 0.4711 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4016 - accuracy: 0.3330 - val_loss: 0.4896 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3747 - accuracy: 0.3832 - val_loss: 0.4925 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3492 - accuracy: 0.4208 - val_loss: 0.3955 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3325 - accuracy: 0.4467 - val_loss: 0.4812 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3076 - accuracy: 0.5107 - val_loss: 0.5118 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2989 - accuracy: 0.5244 - val_loss: 0.4329 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2785 - accuracy: 0.5716 - val_loss: 0.6529 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2587 - accuracy: 0.5959 - val_loss: 0.5408 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1902 - accuracy: 0.7294 - val_loss: 0.4580 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1541 - accuracy: 0.7731 - val_loss: 0.4889 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1433 - accuracy: 0.8000 - val_loss: 0.4838 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1329 - accuracy: 0.8168 - val_loss: 0.5056 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1237 - accuracy: 0.8289 - val_loss: 0.5292 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4034 - accuracy: 0.3164\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.316 total time=  52.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.5629 - accuracy: 0.1786 - val_loss: 0.7302 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7266 - accuracy: 0.2354 - val_loss: 0.5037 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4941 - accuracy: 0.2648 - val_loss: 0.4291 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4316 - accuracy: 0.2943 - val_loss: 0.4387 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3875 - accuracy: 0.3506 - val_loss: 0.4764 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3701 - accuracy: 0.3790 - val_loss: 0.5066 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3533 - accuracy: 0.4262 - val_loss: 0.4105 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3276 - accuracy: 0.4749 - val_loss: 0.4626 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3092 - accuracy: 0.5124 - val_loss: 0.4150 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2880 - accuracy: 0.5520 - val_loss: 0.5520 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2688 - accuracy: 0.5997 - val_loss: 0.4474 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2469 - accuracy: 0.6210 - val_loss: 0.8762 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1779 - accuracy: 0.7610 - val_loss: 0.4698 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1476 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1359 - accuracy: 0.8209 - val_loss: 0.4928 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1273 - accuracy: 0.8361 - val_loss: 0.5201 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1194 - accuracy: 0.8493 - val_loss: 0.5235 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4098 - accuracy: 0.3178\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.318 total time=  49.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 2.9937 - accuracy: 0.1776 - val_loss: 1.2039 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.6673 - accuracy: 0.2121 - val_loss: 0.4906 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4663 - accuracy: 0.2182 - val_loss: 0.5548 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4519 - accuracy: 0.2440 - val_loss: 0.4489 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4100 - accuracy: 0.2897 - val_loss: 0.4168 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4118 - accuracy: 0.3313 - val_loss: 0.4747 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3725 - accuracy: 0.3709 - val_loss: 0.4451 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3654 - accuracy: 0.4110 - val_loss: 0.4629 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3420 - accuracy: 0.4495 - val_loss: 0.4629 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3128 - accuracy: 0.4840 - val_loss: 0.5856 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2520 - accuracy: 0.5809 - val_loss: 0.4380 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2234 - accuracy: 0.6220 - val_loss: 0.4467 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2121 - accuracy: 0.6464 - val_loss: 0.4336 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2039 - accuracy: 0.6621 - val_loss: 0.4501 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1967 - accuracy: 0.6717 - val_loss: 0.4418 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4058 - accuracy: 0.2873\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.287 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.9578 - accuracy: 0.1954 - val_loss: 0.6019 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4790 - accuracy: 0.3350 - val_loss: 0.5303 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3939 - accuracy: 0.4147 - val_loss: 0.4437 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3293 - accuracy: 0.5173 - val_loss: 0.4762 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2968 - accuracy: 0.5701 - val_loss: 0.4345 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2376 - accuracy: 0.6970 - val_loss: 0.4347 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2047 - accuracy: 0.7442 - val_loss: 0.4494 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1691 - accuracy: 0.8335 - val_loss: 0.4734 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1423 - accuracy: 0.8619 - val_loss: 0.5575 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1232 - accuracy: 0.8898 - val_loss: 0.4967 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0759 - accuracy: 0.9650 - val_loss: 0.4960 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0672 - accuracy: 0.9716 - val_loss: 0.5015 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0626 - accuracy: 0.9777 - val_loss: 0.5017 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0590 - accuracy: 0.9797 - val_loss: 0.5099 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.5103 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4352 - accuracy: 0.3651\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.365 total time=  43.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.6602 - accuracy: 0.2045 - val_loss: 0.5505 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4553 - accuracy: 0.3343 - val_loss: 0.4463 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3521 - accuracy: 0.4526 - val_loss: 0.4872 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2989 - accuracy: 0.5571 - val_loss: 0.4365 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2892 - accuracy: 0.5997 - val_loss: 0.4449 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2575 - accuracy: 0.6474 - val_loss: 0.4416 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2070 - accuracy: 0.7316 - val_loss: 0.4398 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1696 - accuracy: 0.8123 - val_loss: 0.4779 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1627 - accuracy: 0.8133 - val_loss: 0.5222 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1053 - accuracy: 0.9173 - val_loss: 0.4810 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0860 - accuracy: 0.9432 - val_loss: 0.4868 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0798 - accuracy: 0.9503 - val_loss: 0.4865 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0753 - accuracy: 0.9538 - val_loss: 0.4879 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0711 - accuracy: 0.9599 - val_loss: 0.4918 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4393 - accuracy: 0.3279\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.328 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.9757 - accuracy: 0.1943 - val_loss: 0.5718 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4935 - accuracy: 0.3064 - val_loss: 0.5354 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4047 - accuracy: 0.3856 - val_loss: 0.4368 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3338 - accuracy: 0.4906 - val_loss: 0.4371 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2960 - accuracy: 0.5637 - val_loss: 0.4487 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2679 - accuracy: 0.6200 - val_loss: 0.4416 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2444 - accuracy: 0.6692 - val_loss: 0.4725 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2234 - accuracy: 0.7123 - val_loss: 0.4864 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1795 - accuracy: 0.8087 - val_loss: 0.4540 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1675 - accuracy: 0.8392 - val_loss: 0.4496 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1630 - accuracy: 0.8529 - val_loss: 0.4549 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1598 - accuracy: 0.8579 - val_loss: 0.4536 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1555 - accuracy: 0.8640 - val_loss: 0.4548 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4463 - accuracy: 0.2964\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.296 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.5645 - accuracy: 0.1909 - val_loss: 1.3732 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5850 - accuracy: 0.1822 - val_loss: 0.5381 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5418 - accuracy: 0.1878 - val_loss: 0.7524 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4535 - accuracy: 0.1975 - val_loss: 0.5381 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4554 - accuracy: 0.2091 - val_loss: 0.4723 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4703 - accuracy: 0.2147 - val_loss: 0.4989 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4256 - accuracy: 0.2406 - val_loss: 0.4731 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4145 - accuracy: 0.2594 - val_loss: 0.5313 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4184 - accuracy: 0.2416 - val_loss: 0.4667 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4042 - accuracy: 0.2802 - val_loss: 0.5174 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3966 - accuracy: 0.2944 - val_loss: 0.4637 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3862 - accuracy: 0.3305 - val_loss: 0.4594 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3897 - accuracy: 0.3137 - val_loss: 0.4666 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4003 - accuracy: 0.3234 - val_loss: 0.5166 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3826 - accuracy: 0.3198 - val_loss: 0.5693 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3688 - accuracy: 0.3396 - val_loss: 0.4455 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3584 - accuracy: 0.3584 - val_loss: 0.4735 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3633 - accuracy: 0.3629 - val_loss: 0.5000 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3518 - accuracy: 0.3883 - val_loss: 0.5074 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3473 - accuracy: 0.3858 - val_loss: 0.4870 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4851 - accuracy: 0.2434\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.243 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 5.5047 - accuracy: 0.1781 - val_loss: 0.8380 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5387 - accuracy: 0.1938 - val_loss: 0.4886 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4985 - accuracy: 0.1796 - val_loss: 0.8517 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4916 - accuracy: 0.1837 - val_loss: 0.4589 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4713 - accuracy: 0.2212 - val_loss: 0.5331 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4671 - accuracy: 0.2273 - val_loss: 0.5833 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4427 - accuracy: 0.2486 - val_loss: 0.4944 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4400 - accuracy: 0.2501 - val_loss: 0.4895 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4201 - accuracy: 0.2927 - val_loss: 0.4439 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4170 - accuracy: 0.2998 - val_loss: 0.4649 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4206 - accuracy: 0.3070 - val_loss: 0.4553 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3999 - accuracy: 0.3217 - val_loss: 0.4230 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3888 - accuracy: 0.3536 - val_loss: 0.4191 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3648 - accuracy: 0.3577 - val_loss: 0.4398 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3466 - accuracy: 0.3765 - val_loss: 0.4184 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3440 - accuracy: 0.4008 - val_loss: 0.5054 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3451 - accuracy: 0.3993 - val_loss: 0.4146 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3229 - accuracy: 0.4272 - val_loss: 0.4260 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3125 - accuracy: 0.4592 - val_loss: 0.4954 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3200 - accuracy: 0.4485 - val_loss: 0.4500 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4429 - accuracy: 0.3036\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.304 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.3415 - accuracy: 0.1583 - val_loss: 0.8523 - val_accuracy: 0.1270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5785 - accuracy: 0.1700 - val_loss: 0.4992 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4893 - accuracy: 0.1684 - val_loss: 0.4935 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4776 - accuracy: 0.1603 - val_loss: 0.4584 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4608 - accuracy: 0.1958 - val_loss: 0.4425 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4577 - accuracy: 0.1857 - val_loss: 0.4955 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4458 - accuracy: 0.2065 - val_loss: 0.4845 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4473 - accuracy: 0.2146 - val_loss: 0.4281 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4374 - accuracy: 0.2243 - val_loss: 0.4235 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4356 - accuracy: 0.2187 - val_loss: 2.5062 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4529 - accuracy: 0.2430 - val_loss: 0.4580 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4263 - accuracy: 0.2258 - val_loss: 0.4650 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4126 - accuracy: 0.2491 - val_loss: 0.4249 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4130 - accuracy: 0.2593 - val_loss: 0.5934 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3594 - accuracy: 0.2988 - val_loss: 0.4263 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3480 - accuracy: 0.3176 - val_loss: 0.4251 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3429 - accuracy: 0.3349 - val_loss: 0.4469 - val_accuracy: 0.2608 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3385 - accuracy: 0.3369 - val_loss: 0.4638 - val_accuracy: 0.2622 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3346 - accuracy: 0.3546 - val_loss: 0.4481 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4167 - accuracy: 0.1766\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.177 total time=  55.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.9778 - accuracy: 0.1726 - val_loss: 0.7099 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4958 - accuracy: 0.3234 - val_loss: 0.5356 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3876 - accuracy: 0.3807 - val_loss: 0.4493 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3467 - accuracy: 0.4569 - val_loss: 0.4886 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3084 - accuracy: 0.5208 - val_loss: 0.4698 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2761 - accuracy: 0.5827 - val_loss: 0.4635 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2342 - accuracy: 0.6619 - val_loss: 0.5100 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1890 - accuracy: 0.7442 - val_loss: 0.4881 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1269 - accuracy: 0.8635 - val_loss: 0.4748 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1135 - accuracy: 0.8904 - val_loss: 0.4793 - val_accuracy: 0.3716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1072 - accuracy: 0.9046 - val_loss: 0.4886 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1012 - accuracy: 0.9127 - val_loss: 0.4935 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0961 - accuracy: 0.9223 - val_loss: 0.4990 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4487 - accuracy: 0.2941\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.294 total time=  38.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.1248 - accuracy: 0.1801 - val_loss: 0.6238 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4876 - accuracy: 0.3054 - val_loss: 0.4851 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3705 - accuracy: 0.4084 - val_loss: 0.4560 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3220 - accuracy: 0.4855 - val_loss: 0.4540 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3127 - accuracy: 0.5271 - val_loss: 0.4684 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2721 - accuracy: 0.6022 - val_loss: 0.4650 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2157 - accuracy: 0.6981 - val_loss: 0.4757 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1929 - accuracy: 0.7316 - val_loss: 0.5109 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1534 - accuracy: 0.8016 - val_loss: 0.5529 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0939 - accuracy: 0.9183 - val_loss: 0.5244 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0769 - accuracy: 0.9447 - val_loss: 0.5325 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0696 - accuracy: 0.9579 - val_loss: 0.5351 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0646 - accuracy: 0.9619 - val_loss: 0.5541 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0597 - accuracy: 0.9670 - val_loss: 0.5550 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4531 - accuracy: 0.3168\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.317 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.6750 - accuracy: 0.2050 - val_loss: 0.9608 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5934 - accuracy: 0.3379 - val_loss: 0.6225 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3962 - accuracy: 0.4541 - val_loss: 0.5209 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3128 - accuracy: 0.5718 - val_loss: 0.5459 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2680 - accuracy: 0.6408 - val_loss: 0.5191 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2064 - accuracy: 0.7362 - val_loss: 0.5356 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1826 - accuracy: 0.7813 - val_loss: 0.5586 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1324 - accuracy: 0.8640 - val_loss: 0.5726 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0902 - accuracy: 0.9295 - val_loss: 0.5887 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0621 - accuracy: 0.9584 - val_loss: 0.6642 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 0.6271 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.6417 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.6317 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: 0.6470 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.6490 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5239 - accuracy: 0.3371\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.337 total time=  43.4s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 7s 51ms/step - loss: 5.9696 - accuracy: 0.2165 - val_loss: 1.2015 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 3s 38ms/step - loss: 0.7040 - accuracy: 0.2524 - val_loss: 0.4486 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.4304 - accuracy: 0.1705 - val_loss: 0.4443 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.4106 - accuracy: 0.2138 - val_loss: 0.4383 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 38ms/step - loss: 0.4017 - accuracy: 0.2226 - val_loss: 0.4212 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3940 - accuracy: 0.2436 - val_loss: 0.4236 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.3949 - accuracy: 0.2473 - val_loss: 0.4562 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3836 - accuracy: 0.2832 - val_loss: 0.4445 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3853 - accuracy: 0.2960 - val_loss: 0.4406 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3748 - accuracy: 0.3129 - val_loss: 0.4660 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3379 - accuracy: 0.3863 - val_loss: 0.4373 - val_accuracy: 0.2514 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3251 - accuracy: 0.4090 - val_loss: 0.4345 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3179 - accuracy: 0.4273 - val_loss: 0.4498 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.3077 - accuracy: 0.4428 - val_loss: 0.4547 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 38ms/step - loss: 0.3016 - accuracy: 0.4574 - val_loss: 0.4608 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'softmax', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_inceptionv3_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = resnet.ResNet50(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 64ms/step - loss: 1.7459 - accuracy: 0.3259 - val_loss: 0.6015 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4537 - accuracy: 0.5807 - val_loss: 0.5809 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2465 - accuracy: 0.7477 - val_loss: 0.6245 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1386 - accuracy: 0.8802 - val_loss: 0.2970 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0920 - accuracy: 0.9213 - val_loss: 0.4259 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0403 - accuracy: 0.9695 - val_loss: 0.3407 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0387 - accuracy: 0.9711 - val_loss: 0.3946 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0218 - accuracy: 0.9858 - val_loss: 0.4257 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0307 - accuracy: 0.9812 - val_loss: 0.4321 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.3930 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.3967 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4064 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.0493e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.5331e-04 - accuracy: 0.9995 - val_loss: 0.4382 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3249 - accuracy: 0.6927\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.693 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.8507 - accuracy: 0.3653 - val_loss: 0.6994 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.4326 - accuracy: 0.6794 - val_loss: 0.4296 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.2201 - accuracy: 0.8351 - val_loss: 0.3958 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0946 - accuracy: 0.9234 - val_loss: 0.6700 - val_accuracy: 0.5608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0758 - accuracy: 0.9472 - val_loss: 0.5041 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0456 - accuracy: 0.9756 - val_loss: 0.5593 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0320 - accuracy: 0.9838 - val_loss: 0.4386 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0285 - accuracy: 0.9838 - val_loss: 0.4384 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4355 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.4273e-04 - accuracy: 0.9995 - val_loss: 0.4457 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.6914e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0550e-05 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.3125e-06 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4334 - accuracy: 0.6609\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.661 total time=  42.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 60ms/step - loss: 1.5967 - accuracy: 0.3445 - val_loss: 0.5374 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3803 - accuracy: 0.5337 - val_loss: 0.3938 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2415 - accuracy: 0.7027 - val_loss: 0.2574 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1538 - accuracy: 0.8123 - val_loss: 0.2757 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1121 - accuracy: 0.8656 - val_loss: 0.3900 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0843 - accuracy: 0.8985 - val_loss: 0.2468 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0628 - accuracy: 0.9310 - val_loss: 0.2884 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0537 - accuracy: 0.9437 - val_loss: 0.3202 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0445 - accuracy: 0.9538 - val_loss: 0.4686 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0421 - accuracy: 0.9574 - val_loss: 0.3655 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0339 - accuracy: 0.9645 - val_loss: 0.5286 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0203 - accuracy: 0.9756 - val_loss: 0.3862 - val_accuracy: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0150 - accuracy: 0.9792 - val_loss: 0.4118 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9812 - val_loss: 0.4169 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0109 - accuracy: 0.9817 - val_loss: 0.4383 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0097 - accuracy: 0.9833 - val_loss: 0.4437 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2879 - accuracy: 0.6751\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.675 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.9606 - accuracy: 0.4772 - val_loss: 0.3469 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2203 - accuracy: 0.8431 - val_loss: 0.3492 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0618 - accuracy: 0.9635 - val_loss: 0.3147 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0201 - accuracy: 0.9964 - val_loss: 0.3178 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.3482 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.0614e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6561e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.4199e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7047e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.1878e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8566e-04 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8085e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7658e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7278e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.6857e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.2939 - accuracy: 0.7880\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.788 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.8299 - accuracy: 0.4140 - val_loss: 0.3746 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2023 - accuracy: 0.7752 - val_loss: 0.2967 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0712 - accuracy: 0.9411 - val_loss: 0.2282 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0208 - accuracy: 0.9904 - val_loss: 0.2398 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.2401 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.2492 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0038 - accuracy: 0.9975 - val_loss: 0.2544 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2604 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2289 - accuracy: 0.7574\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.757 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.9632 - accuracy: 0.4749 - val_loss: 0.4217 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1732 - accuracy: 0.8843 - val_loss: 0.3556 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0502 - accuracy: 0.9787 - val_loss: 0.3232 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.3081 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.3298 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3488 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.5775e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.3212e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.1356e-04 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0267e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9354e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.8504e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3525 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.742 total time=  44.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 59ms/step - loss: 2.0111 - accuracy: 0.3970 - val_loss: 0.4460 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3220 - accuracy: 0.6624 - val_loss: 0.4851 - val_accuracy: 0.5405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1731 - accuracy: 0.8102 - val_loss: 0.4414 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0971 - accuracy: 0.9030 - val_loss: 0.6213 - val_accuracy: 0.5514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0619 - accuracy: 0.9487 - val_loss: 0.3425 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0583 - accuracy: 0.9553 - val_loss: 0.3976 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0341 - accuracy: 0.9751 - val_loss: 0.3663 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0222 - accuracy: 0.9853 - val_loss: 0.6876 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0364 - accuracy: 0.9797 - val_loss: 0.6371 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0248 - accuracy: 0.9873 - val_loss: 0.4324 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0046 - accuracy: 0.9959 - val_loss: 0.4329 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.4583 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0998e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4958e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.6245e-05 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3429 - accuracy: 0.7282\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.728 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 1.5904 - accuracy: 0.4023 - val_loss: 0.4797 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3253 - accuracy: 0.6996 - val_loss: 0.4045 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2222 - accuracy: 0.8346 - val_loss: 0.3578 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0668 - accuracy: 0.9406 - val_loss: 0.3282 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0611 - accuracy: 0.9564 - val_loss: 0.4776 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0416 - accuracy: 0.9772 - val_loss: 0.5801 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0193 - accuracy: 0.9858 - val_loss: 0.4178 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0238 - accuracy: 0.9863 - val_loss: 0.3982 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0132 - accuracy: 0.9929 - val_loss: 0.6622 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9970 - val_loss: 0.4652 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4119e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5756e-05 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.1130e-06 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4353e-06 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3845 - accuracy: 0.6832\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.683 total time=  44.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 1.7195 - accuracy: 0.3724 - val_loss: 0.4845 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3366 - accuracy: 0.6317 - val_loss: 0.3765 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1534 - accuracy: 0.8189 - val_loss: 0.3026 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1072 - accuracy: 0.8980 - val_loss: 0.2766 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0604 - accuracy: 0.9396 - val_loss: 0.3501 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0407 - accuracy: 0.9635 - val_loss: 0.3129 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0416 - accuracy: 0.9619 - val_loss: 0.3207 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0203 - accuracy: 0.9863 - val_loss: 0.5684 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0312 - accuracy: 0.9822 - val_loss: 0.4155 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9949 - val_loss: 0.3995 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0036 - accuracy: 0.9964 - val_loss: 0.4152 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0020 - accuracy: 0.9975 - val_loss: 0.4279 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.3799e-04 - accuracy: 0.9995 - val_loss: 0.4483 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 5.9275e-04 - accuracy: 0.9995 - val_loss: 0.4613 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3115 - accuracy: 0.6883\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.688 total time=  44.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 0.8631 - accuracy: 0.4853 - val_loss: 0.3880 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1207 - accuracy: 0.9203 - val_loss: 0.3085 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.3115 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.2997 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0372e-04 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6499e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8883e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4173e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0486e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8203e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7958e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7712e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7457e-04 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7177e-04 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3206 - accuracy: 0.7830\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.783 total time=  44.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.6596 - accuracy: 0.4881 - val_loss: 0.2816 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1576 - accuracy: 0.8453 - val_loss: 0.2357 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357 - accuracy: 0.9711 - val_loss: 0.2240 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.2426 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2488 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.3898e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6054e-04 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.8613e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7824e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7037e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6252e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5439e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2397 - accuracy: 0.7442\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.744 total time=  41.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.7625 - accuracy: 0.4845 - val_loss: 0.2545 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1449 - accuracy: 0.8787 - val_loss: 0.2741 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0406 - accuracy: 0.9827 - val_loss: 0.2674 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.2834 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.2818 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2912 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2910 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2893 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2888 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.2888 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2678 - accuracy: 0.6802\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.680 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 3.1893 - accuracy: 0.3503 - val_loss: 0.8999 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4438 - accuracy: 0.7086 - val_loss: 0.5254 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.1861 - accuracy: 0.8609 - val_loss: 0.3576 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1030 - accuracy: 0.9279 - val_loss: 0.7051 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0838 - accuracy: 0.9472 - val_loss: 0.4470 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0419 - accuracy: 0.9777 - val_loss: 0.4443 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0376 - accuracy: 0.9812 - val_loss: 0.4649 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0224 - accuracy: 0.9893 - val_loss: 0.4442 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.4092 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1434e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.1722e-05 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.5568e-06 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.5813e-06 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.3747 - accuracy: 0.7170\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.717 total time=  42.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.3756 - accuracy: 0.3770 - val_loss: 0.6834 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.5277 - accuracy: 0.7306 - val_loss: 1.6028 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.3327 - accuracy: 0.8559 - val_loss: 0.4362 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1269 - accuracy: 0.9269 - val_loss: 0.6483 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1054 - accuracy: 0.9482 - val_loss: 0.6286 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0623 - accuracy: 0.9706 - val_loss: 0.7754 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.6999 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.9840 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.6011 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.4334e-04 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.9658e-05 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.1994e-06 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 9.2524e-07 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4926 - accuracy: 0.6812\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.681 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 60ms/step - loss: 3.5015 - accuracy: 0.3820 - val_loss: 0.8105 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4432 - accuracy: 0.7078 - val_loss: 0.4694 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2544 - accuracy: 0.8427 - val_loss: 0.5552 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0796 - accuracy: 0.9554 - val_loss: 0.6653 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0677 - accuracy: 0.9640 - val_loss: 0.5489 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0291 - accuracy: 0.9822 - val_loss: 0.4485 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0323 - accuracy: 0.9833 - val_loss: 0.6390 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0273 - accuracy: 0.9853 - val_loss: 0.5000 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5359 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0167 - accuracy: 0.9919 - val_loss: 0.7039 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.5225 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.6315e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5665e-05 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.6277e-06 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0049e-06 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 3.2897e-07 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.5055 - accuracy: 0.6761\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.676 total time=  51.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 1.2246 - accuracy: 0.4680 - val_loss: 0.3777 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1703 - accuracy: 0.9076 - val_loss: 0.4072 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0358 - accuracy: 0.9843 - val_loss: 0.4276 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.3717 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2086e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.7932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.6082e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4325e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0593e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7913e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4277e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3102e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2970e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2841e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.2568e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.3910 - accuracy: 0.7769\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.777 total time=  53.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 0.8311 - accuracy: 0.4795 - val_loss: 0.4126 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2352 - accuracy: 0.8463 - val_loss: 0.3899 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0831 - accuracy: 0.9619 - val_loss: 0.3882 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0308 - accuracy: 0.9914 - val_loss: 0.3640 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.3614 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.4068 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3813 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4036 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7594e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.5511e-04 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6156e-04 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0813e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8874e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.7871e-04 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.7215e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3920 - accuracy: 0.7492\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.749 total time=  47.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 1.7640 - accuracy: 0.4881 - val_loss: 0.5344 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1691 - accuracy: 0.9117 - val_loss: 0.4036 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 0.3603 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.3958 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9763e-04 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7494e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1852e-04 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1649e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1459e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1268e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.1078e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.4411 - accuracy: 0.7147\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.715 total time=  42.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 3.0155 - accuracy: 0.3802 - val_loss: 1.8955 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6131 - accuracy: 0.6787 - val_loss: 0.5046 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.2773 - accuracy: 0.8365 - val_loss: 0.5880 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1547 - accuracy: 0.9142 - val_loss: 0.7656 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0763 - accuracy: 0.9548 - val_loss: 0.4716 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0521 - accuracy: 0.9736 - val_loss: 0.6463 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0425 - accuracy: 0.9832 - val_loss: 0.9515 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.5897 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0323 - accuracy: 0.9853 - val_loss: 0.6685 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0140 - accuracy: 0.9929 - val_loss: 0.9228 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.5550 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.6851e-04 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 8.7037e-06 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4800e-06 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.9244e-07 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.4747 - accuracy: 0.7404\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.740 total time=  50.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.6503 - accuracy: 0.3688 - val_loss: 0.9860 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4127 - accuracy: 0.6702 - val_loss: 0.3172 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2051 - accuracy: 0.8402 - val_loss: 0.4782 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0943 - accuracy: 0.9224 - val_loss: 0.4500 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0570 - accuracy: 0.9604 - val_loss: 0.4847 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0403 - accuracy: 0.9746 - val_loss: 0.4300 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0325 - accuracy: 0.9751 - val_loss: 0.6598 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.4034 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.3875 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 9.0322e-04 - accuracy: 0.9995 - val_loss: 0.4240 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.6892e-04 - accuracy: 0.9995 - val_loss: 0.4311 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.7022e-04 - accuracy: 0.9995 - val_loss: 0.4385 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.3261 - accuracy: 0.6538\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.654 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 1.8896 - accuracy: 0.3815 - val_loss: 0.4360 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2945 - accuracy: 0.6494 - val_loss: 0.3656 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1843 - accuracy: 0.7971 - val_loss: 0.4644 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1019 - accuracy: 0.8950 - val_loss: 0.4877 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0638 - accuracy: 0.9366 - val_loss: 0.3467 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0516 - accuracy: 0.9533 - val_loss: 0.5165 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0521 - accuracy: 0.9584 - val_loss: 0.4776 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0155 - accuracy: 0.9888 - val_loss: 0.4648 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0190 - accuracy: 0.9863 - val_loss: 0.4493 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0228 - accuracy: 0.9853 - val_loss: 1.3234 - val_accuracy: 0.5878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0140 - accuracy: 0.9924 - val_loss: 0.6045 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.5640 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5477 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.0700e-04 - accuracy: 0.9995 - val_loss: 0.5433 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.0641e-04 - accuracy: 0.9995 - val_loss: 0.5507 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.3770 - accuracy: 0.6944\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.694 total time=  52.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9682 - accuracy: 0.5452 - val_loss: 0.3994 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.1452 - accuracy: 0.9173 - val_loss: 0.3044 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.3463 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.3136 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.3366 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3415 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.2288e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5215e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.3941e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.3261e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.2794e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.3196 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.767 total time=  40.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.2822 - accuracy: 0.4906 - val_loss: 0.4122 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1442 - accuracy: 0.8970 - val_loss: 0.3599 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0294 - accuracy: 0.9858 - val_loss: 0.3244 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.3028 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.1597e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5517e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.0898e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.7720e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.5435e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3857e-04 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3693e-04 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3516e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3347e-04 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.3166e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3388 - accuracy: 0.7665\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.766 total time=  51.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 0.9694 - accuracy: 0.5150 - val_loss: 0.3007 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1003 - accuracy: 0.9315 - val_loss: 0.3156 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0224 - accuracy: 0.9863 - val_loss: 0.2993 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.3027 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 8.7767e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.9061e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.9153e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.4015e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.0157e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7383e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5553e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5345e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5124e-04 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4684e-04 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.3399 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.742 total time=  49.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.4602 - accuracy: 0.4239 - val_loss: 0.3152 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1717 - accuracy: 0.7797 - val_loss: 0.2602 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0657 - accuracy: 0.9284 - val_loss: 0.2684 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0327 - accuracy: 0.9726 - val_loss: 0.2315 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0226 - accuracy: 0.9807 - val_loss: 0.2700 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0113 - accuracy: 0.9929 - val_loss: 0.3046 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0145 - accuracy: 0.9888 - val_loss: 0.3162 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.4663e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0113 - accuracy: 0.9924 - val_loss: 0.3843 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 6.7424e-05 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6193e-05 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.8381e-06 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 9.9842e-07 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.8417e-07 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2391 - accuracy: 0.7525\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.753 total time=  48.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 0.4623 - accuracy: 0.3623 - val_loss: 0.3015 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1872 - accuracy: 0.7372 - val_loss: 0.2579 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0692 - accuracy: 0.9269 - val_loss: 0.2010 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0259 - accuracy: 0.9777 - val_loss: 0.2270 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0080 - accuracy: 0.9954 - val_loss: 0.2742 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0057 - accuracy: 0.9959 - val_loss: 0.2658 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0302 - accuracy: 0.9833 - val_loss: 0.3172 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0471e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3761e-05 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 5.9502e-06 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.3539e-07 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.6853e-07 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.2079 - accuracy: 0.7320\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.732 total time=  46.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 0.4338 - accuracy: 0.4181 - val_loss: 0.2803 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1679 - accuracy: 0.7864 - val_loss: 0.2216 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0621 - accuracy: 0.9330 - val_loss: 0.3017 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0223 - accuracy: 0.9812 - val_loss: 0.2843 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0085 - accuracy: 0.9944 - val_loss: 0.3496 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0291 - accuracy: 0.9833 - val_loss: 0.2846 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.7239e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 6.0435e-05 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.4537e-05 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.0113e-06 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3549e-06 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.4422e-07 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2407 - accuracy: 0.6518\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.652 total time=  43.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3908 - accuracy: 0.4259 - val_loss: 0.2625 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1293 - accuracy: 0.8655 - val_loss: 0.1950 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.1906 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.2172 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 8.8907e-04 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 5.4408e-04 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.9134e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.2464e-04 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.1164e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.0296e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.9490e-04 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.8674e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2043 - accuracy: 0.7688\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.769 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.3564 - accuracy: 0.4713 - val_loss: 0.2384 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1080 - accuracy: 0.8869 - val_loss: 0.1885 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0228 - accuracy: 0.9893 - val_loss: 0.2022 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.2208 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 7.4398e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.9834e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.9482e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.8279e-04 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.7137e-04 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5983e-04 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.4814e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.2089 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.720 total time=  42.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.3375 - accuracy: 0.4942 - val_loss: 0.2243 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0999 - accuracy: 0.9006 - val_loss: 0.1897 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1935 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 7.0969e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.8195e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.8360e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.7279e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6207e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.5138e-04 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.4066e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2129 - accuracy: 0.6944\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.694 total time=  44.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 70ms/step - loss: 0.4784 - accuracy: 0.3990 - val_loss: 0.3068 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.1900 - accuracy: 0.7213 - val_loss: 0.3159 - val_accuracy: 0.5838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0790 - accuracy: 0.9066 - val_loss: 0.2312 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9635 - val_loss: 0.2501 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0206 - accuracy: 0.9863 - val_loss: 0.2737 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0083 - accuracy: 0.9949 - val_loss: 0.3763 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0072 - accuracy: 0.9934 - val_loss: 0.3407 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0130 - accuracy: 0.9924 - val_loss: 0.3311 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3142 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.0879e-04 - accuracy: 0.9990 - val_loss: 0.3307 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 5.1923e-04 - accuracy: 0.9990 - val_loss: 0.3532 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.7933e-04 - accuracy: 0.9990 - val_loss: 0.3697 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.2297e-04 - accuracy: 0.9995 - val_loss: 0.3880 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2383 - accuracy: 0.7170\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.717 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4760 - accuracy: 0.3749 - val_loss: 0.3020 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1879 - accuracy: 0.7245 - val_loss: 0.2332 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0733 - accuracy: 0.9107 - val_loss: 0.3616 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0277 - accuracy: 0.9665 - val_loss: 0.2618 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0147 - accuracy: 0.9893 - val_loss: 0.2669 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.3204 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0169 - accuracy: 0.9934 - val_loss: 0.3893 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 7.3186e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.4829e-05 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.2192e-05 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.0642e-06 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0726e-06 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2593 - accuracy: 0.6284\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.628 total time=  44.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.4612 - accuracy: 0.3932 - val_loss: 0.3181 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1790 - accuracy: 0.7504 - val_loss: 0.2938 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0793 - accuracy: 0.9016 - val_loss: 0.3171 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0328 - accuracy: 0.9630 - val_loss: 0.2652 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0160 - accuracy: 0.9843 - val_loss: 0.3444 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0114 - accuracy: 0.9899 - val_loss: 0.3435 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0111 - accuracy: 0.9914 - val_loss: 0.3830 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0078 - accuracy: 0.9939 - val_loss: 0.3578 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0066 - accuracy: 0.9959 - val_loss: 0.3874 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.8103e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.2922e-05 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 6.1122e-06 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.4832e-06 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.6812e-07 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2931 - accuracy: 0.6995\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.699 total time=  49.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.3981 - accuracy: 0.4264 - val_loss: 0.2706 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1329 - accuracy: 0.8345 - val_loss: 0.2244 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0277 - accuracy: 0.9858 - val_loss: 0.2196 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.2295 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2547 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 6.2357e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.1283e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.0441e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5225e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.4641e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.4038e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3428e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2814e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2196 - accuracy: 0.7465\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.746 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 0.3913 - accuracy: 0.4531 - val_loss: 0.2514 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1273 - accuracy: 0.8356 - val_loss: 0.2118 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0322 - accuracy: 0.9782 - val_loss: 0.2115 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.2233 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.2319 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2407 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.3755e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.9979e-04 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6389e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5467e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.4662e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3920e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.3202e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2419 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.720 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.4098 - accuracy: 0.4587 - val_loss: 0.2684 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1258 - accuracy: 0.8458 - val_loss: 0.2252 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0296 - accuracy: 0.9817 - val_loss: 0.2243 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.2513 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2555 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.8556e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.3862e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.7740e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.7012e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6301e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.5629e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4942e-04 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2411 - accuracy: 0.6904\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.690 total time=  49.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.5980 - accuracy: 0.4112 - val_loss: 0.3276 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1800 - accuracy: 0.7543 - val_loss: 0.2033 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0650 - accuracy: 0.9386 - val_loss: 0.1889 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0330 - accuracy: 0.9777 - val_loss: 0.1970 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0096 - accuracy: 0.9944 - val_loss: 0.2342 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9873 - val_loss: 0.2552 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.3114 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.3218e-05 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.7284e-06 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.4708e-06 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.4496e-07 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.7350e-07 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.1995 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.767 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 0.5521 - accuracy: 0.4419 - val_loss: 0.3342 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1719 - accuracy: 0.7854 - val_loss: 0.2233 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0642 - accuracy: 0.9335 - val_loss: 0.2009 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0428 - accuracy: 0.9680 - val_loss: 0.2487 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0193 - accuracy: 0.9873 - val_loss: 0.2475 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0066 - accuracy: 0.9964 - val_loss: 0.7150 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0115 - accuracy: 0.9944 - val_loss: 1.5044 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0427 - accuracy: 0.9782 - val_loss: 0.3110 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.3843e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.9892e-05 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 8.5165e-06 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.7455e-06 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.3437e-07 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2102 - accuracy: 0.7543\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.754 total time=  47.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.5279 - accuracy: 0.4444 - val_loss: 0.2531 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1542 - accuracy: 0.8128 - val_loss: 0.2205 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0554 - accuracy: 0.9472 - val_loss: 0.2325 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0264 - accuracy: 0.9777 - val_loss: 0.2226 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0169 - accuracy: 0.9924 - val_loss: 0.2505 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0128 - accuracy: 0.9929 - val_loss: 0.2845 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 0.3462 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.5913e-05 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3442e-05 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.4355e-06 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.0366e-06 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.7176e-07 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2254 - accuracy: 0.6893\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.689 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 76ms/step - loss: 0.3697 - accuracy: 0.5168 - val_loss: 0.2463 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0858 - accuracy: 0.9310 - val_loss: 0.1967 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0161 - accuracy: 0.9975 - val_loss: 0.2146 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.1615e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.2903e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.0028e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.8497e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.7079e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.5675e-04 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.4281e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.1954 - accuracy: 0.7728\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.773 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.4082 - accuracy: 0.5190 - val_loss: 0.2297 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0737 - accuracy: 0.9503 - val_loss: 0.1931 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0141 - accuracy: 0.9985 - val_loss: 0.1979 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 7.8490e-04 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.3289e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.1573e-04 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.9923e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.8232e-04 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.6529e-04 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2056 - accuracy: 0.7371\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.737 total time=  44.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.4068 - accuracy: 0.4881 - val_loss: 0.2276 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0866 - accuracy: 0.9259 - val_loss: 0.2022 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.2072 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 8.7355e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.0165e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.8107e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.6769e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.5443e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.4104e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.2747e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2165 - accuracy: 0.7310\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.731 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7172 - accuracy: 0.3838 - val_loss: 0.2961 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.2016 - accuracy: 0.7365 - val_loss: 0.2076 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0752 - accuracy: 0.9162 - val_loss: 0.2562 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0252 - accuracy: 0.9792 - val_loss: 0.2753 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0246 - accuracy: 0.9832 - val_loss: 0.2690 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0136 - accuracy: 0.9914 - val_loss: 0.9392 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0201 - accuracy: 0.9873 - val_loss: 0.3529 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.4163e-04 - accuracy: 0.9990 - val_loss: 0.3386 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 5.3338e-05 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.1206e-05 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4907e-06 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 7.1085e-07 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2137 - accuracy: 0.7221\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.722 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6468 - accuracy: 0.4160 - val_loss: 0.3272 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1920 - accuracy: 0.7580 - val_loss: 0.3644 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0651 - accuracy: 0.9269 - val_loss: 0.2324 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0349 - accuracy: 0.9721 - val_loss: 0.5722 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0108 - accuracy: 0.9919 - val_loss: 0.3024 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0177 - accuracy: 0.9909 - val_loss: 0.3031 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3199 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0296 - accuracy: 0.9848 - val_loss: 0.3635 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.0136e-04 - accuracy: 0.9995 - val_loss: 0.3465 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.2085e-05 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.3418e-06 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.6040e-07 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.0898e-07 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2437 - accuracy: 0.7117\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.712 total time=  51.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6220 - accuracy: 0.3886 - val_loss: 0.2882 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.2027 - accuracy: 0.7291 - val_loss: 0.3728 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0778 - accuracy: 0.9041 - val_loss: 0.2839 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0275 - accuracy: 0.9751 - val_loss: 0.2452 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9888 - val_loss: 0.2910 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0122 - accuracy: 0.9934 - val_loss: 0.3674 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.5226e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0341 - accuracy: 0.9858 - val_loss: 0.5193 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.8596e-05 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.8486e-06 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 7.7336e-07 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.1490e-07 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 8.5409e-08 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2673 - accuracy: 0.7178\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  54.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.5055 - accuracy: 0.4381 - val_loss: 0.2604 - val_accuracy: 0.6027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1067 - accuracy: 0.8954 - val_loss: 0.2029 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0253 - accuracy: 0.9883 - val_loss: 0.2207 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.1003e-04 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.8797e-04 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.8507e-04 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7415e-04 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6358e-04 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.5256e-04 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.4175e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2078 - accuracy: 0.7211\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.721 total time=  45.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4511 - accuracy: 0.4718 - val_loss: 0.2395 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0943 - accuracy: 0.9097 - val_loss: 0.1955 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.2001 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.9795e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.2581e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.4338e-04 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3397e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.2494e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.1550e-04 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.0629e-04 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2197 - accuracy: 0.7025\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.703 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4480 - accuracy: 0.5013 - val_loss: 0.2495 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0871 - accuracy: 0.9168 - val_loss: 0.2240 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0164 - accuracy: 0.9914 - val_loss: 0.2205 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.9068e-04 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.9911e-04 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.3321e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3080e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7689e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6385e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5760e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5125e-04 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2399 - accuracy: 0.7239\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.724 total time=  50.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 1.9405 - accuracy: 0.3553 - val_loss: 0.6769 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4523 - accuracy: 0.6015 - val_loss: 0.4211 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2244 - accuracy: 0.7751 - val_loss: 0.4222 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1339 - accuracy: 0.8706 - val_loss: 0.6565 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0630 - accuracy: 0.9406 - val_loss: 0.4367 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0488 - accuracy: 0.9629 - val_loss: 0.4465 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0299 - accuracy: 0.9812 - val_loss: 0.4697 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0112 - accuracy: 0.9934 - val_loss: 0.3705 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0026 - accuracy: 0.9980 - val_loss: 0.3953 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.5431e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1501e-04 - accuracy: 0.9995 - val_loss: 0.4187 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0394e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5329e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.1720e-05 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.1265e-05 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.3054e-05 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.6734e-05 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 6.1242e-05 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3974 - accuracy: 0.7373\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.737 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 2.7818 - accuracy: 0.3704 - val_loss: 1.1286 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.5190 - accuracy: 0.7159 - val_loss: 0.5771 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.2090 - accuracy: 0.8600 - val_loss: 0.4011 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.1278 - accuracy: 0.9249 - val_loss: 0.3896 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0740 - accuracy: 0.9564 - val_loss: 0.4423 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0662 - accuracy: 0.9670 - val_loss: 0.4424 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0389 - accuracy: 0.9822 - val_loss: 0.6519 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 0.5079 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.6406 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5027 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.8409e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.7914e-05 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.5620e-06 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.3479e-06 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4693 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.720 total time=  54.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 2.2279 - accuracy: 0.3800 - val_loss: 1.0416 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.5729 - accuracy: 0.6687 - val_loss: 0.5736 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2744 - accuracy: 0.8285 - val_loss: 0.6431 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1601 - accuracy: 0.9021 - val_loss: 0.5641 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1253 - accuracy: 0.9391 - val_loss: 0.8449 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0756 - accuracy: 0.9670 - val_loss: 0.5295 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0466 - accuracy: 0.9812 - val_loss: 0.6342 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0431 - accuracy: 0.9827 - val_loss: 0.7079 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0462 - accuracy: 0.9817 - val_loss: 0.7691 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.7026 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.6629 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.6156 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0868e-04 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0494e-05 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6560e-05 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.4588e-06 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.5556 - accuracy: 0.6964\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.696 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8593 - accuracy: 0.4777 - val_loss: 0.4386 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2296 - accuracy: 0.8660 - val_loss: 0.3927 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0562 - accuracy: 0.9711 - val_loss: 0.3619 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.3584 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.3839 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3706 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.1085e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 5.7572e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.0383e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.9092e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.8161e-04 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7370e-04 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6626e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3697 - accuracy: 0.7495\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.749 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 0.6834 - accuracy: 0.4718 - val_loss: 0.3505 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1928 - accuracy: 0.7945 - val_loss: 0.2635 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0739 - accuracy: 0.9340 - val_loss: 0.2765 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0264 - accuracy: 0.9782 - val_loss: 0.2686 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9858 - val_loss: 0.2565 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0122 - accuracy: 0.9909 - val_loss: 0.2733 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0064 - accuracy: 0.9944 - val_loss: 0.2946 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0040 - accuracy: 0.9964 - val_loss: 0.2891 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0024 - accuracy: 0.9975 - val_loss: 0.3020 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.3040 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.3059 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.3060 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.3057 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.3050 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3060 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2849 - accuracy: 0.7289\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.729 total time=  56.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8241 - accuracy: 0.5155 - val_loss: 0.4212 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1986 - accuracy: 0.8919 - val_loss: 0.4118 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0497 - accuracy: 0.9696 - val_loss: 0.3890 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.3711 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.4389 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 6.8950e-04 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.2278e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.8855e-04 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.5853e-04 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4089e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3931e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3735e-04 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3551e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3346e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.4314 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.723 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 1.8116 - accuracy: 0.3848 - val_loss: 0.3305 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.3526 - accuracy: 0.6462 - val_loss: 0.4027 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1826 - accuracy: 0.8081 - val_loss: 0.5504 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1108 - accuracy: 0.8949 - val_loss: 0.3539 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0762 - accuracy: 0.9310 - val_loss: 0.3224 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0384 - accuracy: 0.9690 - val_loss: 0.3896 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0286 - accuracy: 0.9761 - val_loss: 0.3931 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0602 - accuracy: 0.9660 - val_loss: 0.6729 - val_accuracy: 0.6243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0148 - accuracy: 0.9873 - val_loss: 0.5604 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0163 - accuracy: 0.9883 - val_loss: 0.4608 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 0.4584 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0045 - accuracy: 0.9959 - val_loss: 0.4868 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0032 - accuracy: 0.9975 - val_loss: 0.4929 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0024 - accuracy: 0.9975 - val_loss: 0.5175 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0016 - accuracy: 0.9980 - val_loss: 0.5221 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3202 - accuracy: 0.7312\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.731 total time=  58.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 1.7202 - accuracy: 0.3760 - val_loss: 0.9867 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4033 - accuracy: 0.6271 - val_loss: 0.4980 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1967 - accuracy: 0.7965 - val_loss: 0.3438 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1185 - accuracy: 0.8864 - val_loss: 0.3364 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0703 - accuracy: 0.9340 - val_loss: 0.4431 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0326 - accuracy: 0.9716 - val_loss: 0.3129 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0231 - accuracy: 0.9797 - val_loss: 0.3827 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0163 - accuracy: 0.9904 - val_loss: 0.4898 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0155 - accuracy: 0.9893 - val_loss: 0.5612 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.4632 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0154 - accuracy: 0.9929 - val_loss: 0.5640 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.5162 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4882e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6182e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0066e-04 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.4571e-04 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3289 - accuracy: 0.7299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.730 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.5376 - accuracy: 0.4044 - val_loss: 1.2600 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.3872 - accuracy: 0.6875 - val_loss: 0.6488 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1934 - accuracy: 0.8275 - val_loss: 0.3442 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1010 - accuracy: 0.9163 - val_loss: 0.5758 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0638 - accuracy: 0.9523 - val_loss: 0.3560 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0438 - accuracy: 0.9741 - val_loss: 0.5304 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0306 - accuracy: 0.9772 - val_loss: 0.4137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0309 - accuracy: 0.9762 - val_loss: 0.4436 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0041 - accuracy: 0.9964 - val_loss: 0.4151 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.0290e-04 - accuracy: 0.9995 - val_loss: 0.4298 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.9162e-04 - accuracy: 0.9995 - val_loss: 0.4576 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.8677e-04 - accuracy: 0.9995 - val_loss: 0.4567 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.6418e-04 - accuracy: 0.9995 - val_loss: 0.4743 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3718 - accuracy: 0.6924\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.692 total time=  51.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.6056 - accuracy: 0.3909 - val_loss: 0.3008 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1930 - accuracy: 0.7503 - val_loss: 0.2465 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0859 - accuracy: 0.8964 - val_loss: 0.2530 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0389 - accuracy: 0.9574 - val_loss: 0.2511 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0184 - accuracy: 0.9843 - val_loss: 0.2416 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0101 - accuracy: 0.9893 - val_loss: 0.2445 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0062 - accuracy: 0.9939 - val_loss: 0.2656 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 0.9959 - val_loss: 0.2750 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0025 - accuracy: 0.9964 - val_loss: 0.2676 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.2620 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.2287e-04 - accuracy: 0.9990 - val_loss: 0.2634 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.0127e-04 - accuracy: 0.9990 - val_loss: 0.2650 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 8.8093e-04 - accuracy: 0.9990 - val_loss: 0.2662 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.6046e-04 - accuracy: 0.9990 - val_loss: 0.2677 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 8.4128e-04 - accuracy: 0.9990 - val_loss: 0.2690 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 42ms/step - loss: 0.2544 - accuracy: 0.7465\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.746 total time=  57.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7788 - accuracy: 0.4384 - val_loss: 0.2841 - val_accuracy: 0.5878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1518 - accuracy: 0.8412 - val_loss: 0.2393 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0417 - accuracy: 0.9716 - val_loss: 0.2226 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.2367 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.2420 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2461 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 8.8605e-04 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.3536e-04 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.2475e-04 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.1394e-04 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.0442e-04 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.9441e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.8501e-04 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2518 - accuracy: 0.7371\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.737 total time=  51.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.8070 - accuracy: 0.4881 - val_loss: 0.3371 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1590 - accuracy: 0.8564 - val_loss: 0.3170 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0549 - accuracy: 0.9564 - val_loss: 0.3101 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0147 - accuracy: 0.9934 - val_loss: 0.2998 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.3103 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 9.3035e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.7739e-04 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1718e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.3923e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.0011e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.7237e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.5399e-04 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5196e-04 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.4781e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4568e-04 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.3500 - accuracy: 0.7452\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.745 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 3.3713 - accuracy: 0.3624 - val_loss: 0.7050 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6045 - accuracy: 0.7030 - val_loss: 0.5724 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.3079 - accuracy: 0.8396 - val_loss: 0.7162 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1384 - accuracy: 0.9305 - val_loss: 0.5412 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1023 - accuracy: 0.9579 - val_loss: 0.6793 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0677 - accuracy: 0.9741 - val_loss: 0.5927 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0500 - accuracy: 0.9878 - val_loss: 0.6428 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.6107 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0414 - accuracy: 0.9822 - val_loss: 0.5813 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.5569 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3549e-04 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 7.5731e-05 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.9655e-06 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 5.6824e-07 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.5471 - accuracy: 0.7525\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.753 total time=  55.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 3.8396 - accuracy: 0.4023 - val_loss: 1.0716 - val_accuracy: 0.5527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.8399 - accuracy: 0.7189 - val_loss: 0.6889 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.2794 - accuracy: 0.9006 - val_loss: 0.6034 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.1814 - accuracy: 0.9361 - val_loss: 0.5700 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1761 - accuracy: 0.9488 - val_loss: 0.6922 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0817 - accuracy: 0.9716 - val_loss: 0.7144 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0832 - accuracy: 0.9777 - val_loss: 1.0758 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.7356 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0329 - accuracy: 0.9873 - val_loss: 0.7682 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.6893 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.4280e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.3646e-05 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.4059e-06 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 8.3353e-07 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.6196 - accuracy: 0.7188\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.719 total time=  56.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 3.4062 - accuracy: 0.3912 - val_loss: 0.5478 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6296 - accuracy: 0.7103 - val_loss: 0.7612 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.2965 - accuracy: 0.8584 - val_loss: 0.4440 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1464 - accuracy: 0.9280 - val_loss: 0.4542 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0826 - accuracy: 0.9594 - val_loss: 0.7367 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0457 - accuracy: 0.9751 - val_loss: 0.6639 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0483 - accuracy: 0.9792 - val_loss: 0.5910 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 1.0921 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.6213 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.5695e-04 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 9.8373e-06 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.7288e-06 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 6.5684e-07 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4884 - accuracy: 0.7066\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.707 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 1.0787 - accuracy: 0.4731 - val_loss: 0.4416 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1405 - accuracy: 0.9005 - val_loss: 0.2956 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0380 - accuracy: 0.9863 - val_loss: 0.2847 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.2774 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2757 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.9422e-04 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.7044e-04 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.9188e-04 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.3887e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.0248e-04 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9815e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9409e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9002e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.8599e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3034 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.767 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 1.5164 - accuracy: 0.4810 - val_loss: 0.5557 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2236 - accuracy: 0.9077 - val_loss: 0.4673 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0718 - accuracy: 0.9777 - val_loss: 0.5828 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.5849 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.5093 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.8713e-04 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3180e-04 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0654e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 9.8663e-05 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.2513e-05 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.4877 - accuracy: 0.7472\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.747 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 1.0281 - accuracy: 0.5358 - val_loss: 0.4111 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1659 - accuracy: 0.9051 - val_loss: 0.4477 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 0.3842 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.5150 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.4478 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.4133 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 9.0845e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0494e-04 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.6132e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.4611e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.3793e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.4217 - accuracy: 0.7269\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.727 total time=  48.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 2.8220 - accuracy: 0.3954 - val_loss: 0.7620 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.4309 - accuracy: 0.6675 - val_loss: 0.5290 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1796 - accuracy: 0.8244 - val_loss: 0.4285 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0894 - accuracy: 0.9213 - val_loss: 0.2609 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0495 - accuracy: 0.9579 - val_loss: 0.4986 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0328 - accuracy: 0.9751 - val_loss: 0.5880 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0275 - accuracy: 0.9822 - val_loss: 0.4004 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0217 - accuracy: 0.9868 - val_loss: 0.5516 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0221 - accuracy: 0.9873 - val_loss: 0.4786 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0039 - accuracy: 0.9959 - val_loss: 0.4641 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.3978e-04 - accuracy: 0.9995 - val_loss: 0.4716 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3565e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.9611e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.1648e-05 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2964 - accuracy: 0.7181\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  52.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.0198 - accuracy: 0.3825 - val_loss: 0.4865 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3463 - accuracy: 0.6753 - val_loss: 0.5215 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1946 - accuracy: 0.8153 - val_loss: 0.4010 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0997 - accuracy: 0.9173 - val_loss: 0.5263 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0781 - accuracy: 0.9442 - val_loss: 0.3774 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0622 - accuracy: 0.9619 - val_loss: 0.5922 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0274 - accuracy: 0.9843 - val_loss: 0.6328 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9914 - val_loss: 0.5653 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0188 - accuracy: 0.9888 - val_loss: 0.5280 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0198 - accuracy: 0.9909 - val_loss: 0.7798 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5390 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3997e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.1171e-06 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.4297e-06 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.6783e-07 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3625 - accuracy: 0.7178\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  58.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.9768 - accuracy: 0.3704 - val_loss: 2.5535 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.3859 - accuracy: 0.7139 - val_loss: 0.4071 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1723 - accuracy: 0.8498 - val_loss: 0.3505 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0929 - accuracy: 0.9315 - val_loss: 0.3317 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0775 - accuracy: 0.9518 - val_loss: 0.4942 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0359 - accuracy: 0.9827 - val_loss: 0.3665 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0295 - accuracy: 0.9817 - val_loss: 0.5791 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0359 - accuracy: 0.9817 - val_loss: 0.4552 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0213 - accuracy: 0.9878 - val_loss: 0.4909 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.4483 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6928e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.8099e-05 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.1204e-06 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.0151e-06 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3928 - accuracy: 0.6802\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.680 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 1.0406 - accuracy: 0.4944 - val_loss: 0.4275 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1592 - accuracy: 0.9117 - val_loss: 0.3631 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: 0.4510 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.3583 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7691e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.7651e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3831e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1971e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0779e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0642e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0489e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0355e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0230e-04 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.3922 - accuracy: 0.7718\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.772 total time=  52.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8751 - accuracy: 0.5058 - val_loss: 0.3140 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1183 - accuracy: 0.9203 - val_loss: 0.3338 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2886 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.3469 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.3031 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.7582e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.0415e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.6139e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5827e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.5534e-04 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.4965e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3239 - accuracy: 0.7350\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.735 total time=  49.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 1.2943 - accuracy: 0.5028 - val_loss: 0.3176 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1062 - accuracy: 0.9244 - val_loss: 0.3223 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.2964 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.2726 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.5761e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.4852e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7410e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3024e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.0549e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0217e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.9917e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.9624e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.9302e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2891 - accuracy: 0.7472\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.747 total time=  52.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3891 - accuracy: 0.4259 - val_loss: 0.2746 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1594 - accuracy: 0.7909 - val_loss: 0.2041 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0601 - accuracy: 0.9355 - val_loss: 0.1801 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0233 - accuracy: 0.9817 - val_loss: 0.2426 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0126 - accuracy: 0.9898 - val_loss: 0.2602 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0135 - accuracy: 0.9883 - val_loss: 0.2644 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.5197e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0132 - accuracy: 0.9909 - val_loss: 0.3024 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.4176e-04 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.1559e-05 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.3783e-06 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.0465e-07 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.7714e-07 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.1742 - accuracy: 0.7779\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.778 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.3681 - accuracy: 0.4282 - val_loss: 0.2381 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1515 - accuracy: 0.8077 - val_loss: 0.2590 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0603 - accuracy: 0.9366 - val_loss: 0.2077 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0170 - accuracy: 0.9833 - val_loss: 0.2177 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0180 - accuracy: 0.9868 - val_loss: 0.2629 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0184 - accuracy: 0.9883 - val_loss: 0.2511 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0084 - accuracy: 0.9944 - val_loss: 0.3014 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.2717 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.7509e-05 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.8770e-05 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.9407e-06 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3004e-06 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4560e-07 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2365 - accuracy: 0.7381\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.738 total time=  50.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4058 - accuracy: 0.4282 - val_loss: 0.2627 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1620 - accuracy: 0.7727 - val_loss: 0.2505 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0667 - accuracy: 0.9274 - val_loss: 0.2706 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0245 - accuracy: 0.9807 - val_loss: 0.2363 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0101 - accuracy: 0.9924 - val_loss: 0.2733 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0034 - accuracy: 0.9970 - val_loss: 0.2946 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9893 - val_loss: 0.3015 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.9046e-05 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.3512 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.7977e-05 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.9840e-06 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0347e-06 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.7521e-07 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4871e-07 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2506 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.723 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.3737 - accuracy: 0.4401 - val_loss: 0.2380 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1200 - accuracy: 0.8690 - val_loss: 0.2220 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0278 - accuracy: 0.9868 - val_loss: 0.2318 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2482 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.6482e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.1607e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.1227e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.0006e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.8857e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7731e-04 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.6600e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2164 - accuracy: 0.7008\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.701 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 0.3359 - accuracy: 0.4911 - val_loss: 0.2403 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1074 - accuracy: 0.8864 - val_loss: 0.1824 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.1981 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.2068 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.7083e-04 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.2315e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.1727e-04 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.0334e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.9111e-04 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7898e-04 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6673e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2099 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.689 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.3640 - accuracy: 0.4531 - val_loss: 0.2423 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1231 - accuracy: 0.8564 - val_loss: 0.2057 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9817 - val_loss: 0.2012 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.8078e-04 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.5709e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3447e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6952e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6244e-04 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5553e-04 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.4849e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2209 - accuracy: 0.7320\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.732 total time=  49.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4612 - accuracy: 0.3959 - val_loss: 0.3961 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.1834 - accuracy: 0.7442 - val_loss: 0.2555 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0764 - accuracy: 0.9107 - val_loss: 0.2372 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0232 - accuracy: 0.9802 - val_loss: 0.3415 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0142 - accuracy: 0.9863 - val_loss: 0.2665 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 0.9959 - val_loss: 0.4597 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0140 - accuracy: 0.9909 - val_loss: 0.3829 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.8193e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3857e-05 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.1771e-06 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.2060e-06 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6534e-07 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.4807e-07 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2319 - accuracy: 0.7221\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.722 total time=  50.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.5264 - accuracy: 0.3993 - val_loss: 0.3561 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1964 - accuracy: 0.7174 - val_loss: 0.2068 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0737 - accuracy: 0.9112 - val_loss: 0.2711 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0209 - accuracy: 0.9843 - val_loss: 0.5604 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0162 - accuracy: 0.9883 - val_loss: 0.4216 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0068 - accuracy: 0.9934 - val_loss: 0.7184 - val_accuracy: 0.6189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 0.4429 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 0.3447 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.8095e-04 - accuracy: 0.9995 - val_loss: 0.3590 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.0439e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.5328e-05 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.5450e-05 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2284 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.689 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4291 - accuracy: 0.3876 - val_loss: 0.2858 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1836 - accuracy: 0.7281 - val_loss: 0.2316 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0776 - accuracy: 0.9087 - val_loss: 0.2543 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0267 - accuracy: 0.9726 - val_loss: 0.2780 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0094 - accuracy: 0.9909 - val_loss: 0.2821 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 0.3114 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0089 - accuracy: 0.9934 - val_loss: 0.3405 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.3365 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2968e-04 - accuracy: 0.9995 - val_loss: 0.3539 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.3762e-05 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0062e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.8368e-06 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2540 - accuracy: 0.6579\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.658 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.3748 - accuracy: 0.4452 - val_loss: 0.2489 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1287 - accuracy: 0.8467 - val_loss: 0.2165 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0315 - accuracy: 0.9792 - val_loss: 0.2299 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.2460 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.3343e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.0075e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.1066e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.0147e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.9247e-04 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.8401e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7540e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2354 - accuracy: 0.6633\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.663 total time=  44.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 0.3601 - accuracy: 0.4673 - val_loss: 0.2383 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1090 - accuracy: 0.8630 - val_loss: 0.2024 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0272 - accuracy: 0.9833 - val_loss: 0.2050 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.2217 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2356 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.5927e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.9630e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.3790e-04 - accuracy: 0.9995 - val_loss: 0.2555 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.5541e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.2893e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.1121e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.9756e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2174 - accuracy: 0.6995\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.699 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 0.4434 - accuracy: 0.3871 - val_loss: 0.2798 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1844 - accuracy: 0.7504 - val_loss: 0.2220 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0687 - accuracy: 0.9244 - val_loss: 0.2483 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0243 - accuracy: 0.9802 - val_loss: 0.2476 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0116 - accuracy: 0.9899 - val_loss: 0.2472 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0060 - accuracy: 0.9949 - val_loss: 0.2687 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0035 - accuracy: 0.9970 - val_loss: 0.2921 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 0.2828 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.2807 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.2806 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.2805 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.2813 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2515 - accuracy: 0.6294\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.629 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 72ms/step - loss: 0.5747 - accuracy: 0.3980 - val_loss: 0.3022 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1911 - accuracy: 0.7396 - val_loss: 0.2306 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0617 - accuracy: 0.9381 - val_loss: 0.3204 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0397 - accuracy: 0.9716 - val_loss: 0.2432 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0220 - accuracy: 0.9853 - val_loss: 0.2344 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0245 - accuracy: 0.9843 - val_loss: 0.2510 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 0.5200 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.3006 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 9.9434e-05 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.8945e-05 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.5329e-06 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.3207e-06 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2316 - accuracy: 0.6582\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.658 total time=  48.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 0.5501 - accuracy: 0.4135 - val_loss: 0.2509 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1987 - accuracy: 0.7367 - val_loss: 0.2653 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0906 - accuracy: 0.9107 - val_loss: 0.2362 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0321 - accuracy: 0.9756 - val_loss: 0.2968 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0197 - accuracy: 0.9878 - val_loss: 0.2686 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0262 - accuracy: 0.9878 - val_loss: 0.2785 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 0.3477 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0133 - accuracy: 0.9939 - val_loss: 0.3149 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.1510e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.2591e-05 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 8.0956e-06 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.0528e-06 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 5.9156e-07 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2364 - accuracy: 0.7015\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.702 total time=  52.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 0.5303 - accuracy: 0.4267 - val_loss: 0.2600 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1619 - accuracy: 0.7925 - val_loss: 0.2507 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0676 - accuracy: 0.9335 - val_loss: 0.3357 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0182 - accuracy: 0.9878 - val_loss: 0.3362 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0090 - accuracy: 0.9939 - val_loss: 0.4215 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0288 - accuracy: 0.9843 - val_loss: 0.2779 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0392 - accuracy: 0.9817 - val_loss: 0.3013 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.1895e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.6918e-05 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6776e-06 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 9.0461e-07 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2564 - accuracy: 0.6579\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.658 total time=  48.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.4145 - accuracy: 0.4492 - val_loss: 0.2555 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1083 - accuracy: 0.8934 - val_loss: 0.2170 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.2164 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 8.2522e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.4677e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.9807e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.2370e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0631e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.9775e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 2.8912e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2036 - accuracy: 0.7789\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.779 total time=  50.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3925 - accuracy: 0.4673 - val_loss: 0.2408 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1079 - accuracy: 0.8858 - val_loss: 0.1990 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0236 - accuracy: 0.9904 - val_loss: 0.1972 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.2125 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 6.9997e-04 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5950e-04 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.3811e-04 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.7866e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7134e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6433e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5757e-04 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5056e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2159 - accuracy: 0.7563\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.756 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.3756 - accuracy: 0.5271 - val_loss: 0.2423 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0744 - accuracy: 0.9335 - val_loss: 0.1915 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 0.2167 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2309 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.7559e-04 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.0797e-04 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.8477e-04 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.7187e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.5928e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.4653e-04 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.3366e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2041 - accuracy: 0.7188\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.719 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.5927 - accuracy: 0.3893 - val_loss: 0.3387 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.2050 - accuracy: 0.7183 - val_loss: 0.2866 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0750 - accuracy: 0.9198 - val_loss: 0.2751 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0412 - accuracy: 0.9660 - val_loss: 0.2409 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0119 - accuracy: 0.9919 - val_loss: 0.3166 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0125 - accuracy: 0.9934 - val_loss: 0.3184 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0158 - accuracy: 0.9929 - val_loss: 0.3529 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0116 - accuracy: 0.9944 - val_loss: 0.3917 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3728 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.5355e-05 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.3945e-07 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7788e-07 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.1277e-07 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2606 - accuracy: 0.7444\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.744 total time=  55.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6743 - accuracy: 0.3891 - val_loss: 0.2946 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1919 - accuracy: 0.7336 - val_loss: 0.2768 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0777 - accuracy: 0.9117 - val_loss: 0.3158 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9731 - val_loss: 0.3756 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0119 - accuracy: 0.9924 - val_loss: 0.3366 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0094 - accuracy: 0.9939 - val_loss: 0.3151 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.3131 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.0636e-04 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.9824e-05 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.4086e-06 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.6588e-07 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2939 - accuracy: 0.6254\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.625 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7068 - accuracy: 0.4115 - val_loss: 0.3358 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1801 - accuracy: 0.7697 - val_loss: 0.3840 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0720 - accuracy: 0.9264 - val_loss: 0.3247 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0447 - accuracy: 0.9660 - val_loss: 0.2455 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9843 - val_loss: 0.2754 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0067 - accuracy: 0.9949 - val_loss: 0.2861 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0250 - accuracy: 0.9873 - val_loss: 0.2934 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9893 - val_loss: 0.3858 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.8967e-04 - accuracy: 0.9995 - val_loss: 0.3593 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.1477e-05 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4489e-06 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.0963e-06 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1542e-07 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.2160e-07 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2646 - accuracy: 0.7096\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.710 total time=  55.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.4014 - accuracy: 0.4807 - val_loss: 0.2516 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0948 - accuracy: 0.8980 - val_loss: 0.1990 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0223 - accuracy: 0.9873 - val_loss: 0.2211 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.9161e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5225e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.1932e-04 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5909e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5241e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.4576e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3914e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.3248e-04 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2019 - accuracy: 0.7282\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.728 total time=  46.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4644 - accuracy: 0.4551 - val_loss: 0.2464 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0951 - accuracy: 0.9163 - val_loss: 0.2198 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.2255 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.1083e-04 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.7749e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.6435e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5060e-04 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.3890e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.2638e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.1397e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2371 - accuracy: 0.6863\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.686 total time=  46.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 77ms/step - loss: 0.4168 - accuracy: 0.5129 - val_loss: 0.2455 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0878 - accuracy: 0.9198 - val_loss: 0.2303 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.2366 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2528 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 9.2027e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.4966e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.3687e-04 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.2501e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.1339e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.0134e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.8942e-04 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2521 - accuracy: 0.6832\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.683 total time=  46.5s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 7s 60ms/step - loss: 0.6478 - accuracy: 0.5504 - val_loss: 0.3686 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1041 - accuracy: 0.9344 - val_loss: 0.2548 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.2718 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.2362 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2394 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2545 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 8.0776e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 2.9130e-04 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.4626e-04 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1947e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.8324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 2.1628e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.8324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1358e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1057e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 2.0763e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_resnet50_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xception_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = xception.Xception(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 80ms/step - loss: 5.5052 - accuracy: 0.1716 - val_loss: 0.5558 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.5941 - accuracy: 0.1523 - val_loss: 0.4440 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.4856 - accuracy: 0.1416 - val_loss: 0.5782 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4747 - accuracy: 0.1477 - val_loss: 0.4607 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.4579 - accuracy: 0.1629 - val_loss: 0.4575 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4623 - accuracy: 0.1467 - val_loss: 0.4341 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4630 - accuracy: 0.1386 - val_loss: 0.4465 - val_accuracy: 0.1149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4526 - accuracy: 0.1553 - val_loss: 0.4411 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4412 - accuracy: 0.1670 - val_loss: 0.4254 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4174 - accuracy: 0.1898 - val_loss: 0.4061 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.4034 - accuracy: 0.1909 - val_loss: 0.4090 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.4019 - accuracy: 0.1827 - val_loss: 0.4029 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4053 - accuracy: 0.2051 - val_loss: 0.4048 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.3943 - accuracy: 0.2005 - val_loss: 0.4067 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3906 - accuracy: 0.2036 - val_loss: 0.4029 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3877 - accuracy: 0.2198 - val_loss: 0.4078 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3877 - accuracy: 0.2112 - val_loss: 0.4169 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3805 - accuracy: 0.2162 - val_loss: 0.4194 - val_accuracy: 0.1932 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3784 - accuracy: 0.2157 - val_loss: 0.4325 - val_accuracy: 0.1959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3762 - accuracy: 0.2244 - val_loss: 0.4251 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 45ms/step - loss: 0.4131 - accuracy: 0.1846\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.185 total time= 1.3min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 5.9503 - accuracy: 0.1766 - val_loss: 0.5692 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5250 - accuracy: 0.1639 - val_loss: 0.4457 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4736 - accuracy: 0.1568 - val_loss: 0.5027 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4741 - accuracy: 0.1674 - val_loss: 0.4500 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4671 - accuracy: 0.1598 - val_loss: 0.5088 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4653 - accuracy: 0.1750 - val_loss: 0.4774 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4610 - accuracy: 0.1553 - val_loss: 0.4540 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4352 - accuracy: 0.1923 - val_loss: 0.4268 - val_accuracy: 0.1730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4149 - accuracy: 0.1963 - val_loss: 0.4180 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4098 - accuracy: 0.1974 - val_loss: 0.4190 - val_accuracy: 0.1824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4078 - accuracy: 0.1918 - val_loss: 0.4145 - val_accuracy: 0.1595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4060 - accuracy: 0.1923 - val_loss: 0.4215 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4047 - accuracy: 0.1877 - val_loss: 0.4169 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4029 - accuracy: 0.1857 - val_loss: 0.4220 - val_accuracy: 0.1581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4014 - accuracy: 0.1892 - val_loss: 0.4156 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3993 - accuracy: 0.1892 - val_loss: 0.4176 - val_accuracy: 0.1743 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3966 - accuracy: 0.1953 - val_loss: 0.4195 - val_accuracy: 0.1689 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3959 - accuracy: 0.1867 - val_loss: 0.4200 - val_accuracy: 0.1662 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3954 - accuracy: 0.1842 - val_loss: 0.4208 - val_accuracy: 0.1622 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3950 - accuracy: 0.1847 - val_loss: 0.4200 - val_accuracy: 0.1649 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 45ms/step - loss: 0.4262 - accuracy: 0.1553\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.155 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 5.1352 - accuracy: 0.1487 - val_loss: 1.5325 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5748 - accuracy: 0.1837 - val_loss: 0.9402 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7790 - accuracy: 0.1821 - val_loss: 0.4669 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4765 - accuracy: 0.1629 - val_loss: 0.6803 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4764 - accuracy: 0.1933 - val_loss: 0.5470 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4523 - accuracy: 0.2029 - val_loss: 0.4436 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4551 - accuracy: 0.2192 - val_loss: 0.4547 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4473 - accuracy: 0.2217 - val_loss: 0.5458 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4412 - accuracy: 0.2405 - val_loss: 0.4451 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4272 - accuracy: 0.2506 - val_loss: 0.4505 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4152 - accuracy: 0.2562 - val_loss: 0.5388 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3747 - accuracy: 0.2953 - val_loss: 0.4255 - val_accuracy: 0.2122 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3606 - accuracy: 0.3135 - val_loss: 0.4294 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3529 - accuracy: 0.3293 - val_loss: 0.4262 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3464 - accuracy: 0.3425 - val_loss: 0.4286 - val_accuracy: 0.2324 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3402 - accuracy: 0.3541 - val_loss: 0.4298 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3362 - accuracy: 0.3663 - val_loss: 0.4319 - val_accuracy: 0.2257 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3284 - accuracy: 0.3729 - val_loss: 0.4318 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3269 - accuracy: 0.3744 - val_loss: 0.4320 - val_accuracy: 0.2365 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3261 - accuracy: 0.3810 - val_loss: 0.4341 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4376 - accuracy: 0.2437\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.244 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.3497 - accuracy: 0.2051 - val_loss: 1.3589 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7989 - accuracy: 0.2421 - val_loss: 0.6050 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5106 - accuracy: 0.3076 - val_loss: 0.5616 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4061 - accuracy: 0.3817 - val_loss: 0.4710 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3814 - accuracy: 0.4452 - val_loss: 0.4874 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3720 - accuracy: 0.4574 - val_loss: 0.5427 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3291 - accuracy: 0.5147 - val_loss: 0.4607 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3164 - accuracy: 0.5416 - val_loss: 0.5047 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2950 - accuracy: 0.5792 - val_loss: 0.4668 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2467 - accuracy: 0.6487 - val_loss: 0.4643 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2052 - accuracy: 0.7274 - val_loss: 0.4677 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2004 - accuracy: 0.7376 - val_loss: 0.5423 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1571 - accuracy: 0.8137 - val_loss: 0.4930 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1303 - accuracy: 0.8690 - val_loss: 0.4931 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1212 - accuracy: 0.8782 - val_loss: 0.4803 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1139 - accuracy: 0.8954 - val_loss: 0.4834 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1088 - accuracy: 0.8990 - val_loss: 0.4849 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4513 - accuracy: 0.3347\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.335 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.3135 - accuracy: 0.2085 - val_loss: 1.3128 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8162 - accuracy: 0.3699 - val_loss: 0.7225 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5027 - accuracy: 0.4739 - val_loss: 0.5927 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3817 - accuracy: 0.5500 - val_loss: 0.5500 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3399 - accuracy: 0.5961 - val_loss: 0.5250 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2487 - accuracy: 0.7144 - val_loss: 0.5081 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2292 - accuracy: 0.7260 - val_loss: 0.5205 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2023 - accuracy: 0.7595 - val_loss: 0.5765 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1728 - accuracy: 0.8250 - val_loss: 0.6001 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1733 - accuracy: 0.8082 - val_loss: 0.6193 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1545 - accuracy: 0.8574 - val_loss: 0.6401 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0801 - accuracy: 0.9472 - val_loss: 0.5852 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0629 - accuracy: 0.9655 - val_loss: 0.5727 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0558 - accuracy: 0.9756 - val_loss: 0.5681 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0507 - accuracy: 0.9792 - val_loss: 0.5685 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.5734 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5296 - accuracy: 0.4213\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.421 total time=  54.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.9211 - accuracy: 0.2065 - val_loss: 1.1225 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7774 - accuracy: 0.2177 - val_loss: 0.5138 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4621 - accuracy: 0.2314 - val_loss: 0.4533 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4101 - accuracy: 0.3080 - val_loss: 0.4367 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3767 - accuracy: 0.3480 - val_loss: 0.4390 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3747 - accuracy: 0.3465 - val_loss: 0.4447 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3553 - accuracy: 0.3770 - val_loss: 0.4288 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3314 - accuracy: 0.4120 - val_loss: 0.4462 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3251 - accuracy: 0.4455 - val_loss: 0.4355 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3259 - accuracy: 0.4500 - val_loss: 0.4168 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2965 - accuracy: 0.4881 - val_loss: 0.4158 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2739 - accuracy: 0.5266 - val_loss: 0.4650 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2733 - accuracy: 0.5256 - val_loss: 0.4464 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2792 - accuracy: 0.5256 - val_loss: 0.4625 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2790 - accuracy: 0.5089 - val_loss: 0.4733 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2599 - accuracy: 0.5611 - val_loss: 0.4785 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2130 - accuracy: 0.6433 - val_loss: 0.4742 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2036 - accuracy: 0.6621 - val_loss: 0.4791 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1976 - accuracy: 0.6794 - val_loss: 0.4699 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1930 - accuracy: 0.6839 - val_loss: 0.4769 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4980 - accuracy: 0.3411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.341 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 5.4990 - accuracy: 0.1736 - val_loss: 0.4952 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5581 - accuracy: 0.1569 - val_loss: 0.4752 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5155 - accuracy: 0.1680 - val_loss: 0.5636 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5031 - accuracy: 0.1487 - val_loss: 0.5532 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4864 - accuracy: 0.1685 - val_loss: 0.5137 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4436 - accuracy: 0.1711 - val_loss: 0.4320 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4166 - accuracy: 0.1538 - val_loss: 0.4116 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4097 - accuracy: 0.1543 - val_loss: 0.4094 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4099 - accuracy: 0.1497 - val_loss: 0.4091 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4084 - accuracy: 0.1584 - val_loss: 0.4089 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.1457 - val_loss: 0.4096 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4098 - accuracy: 0.1487 - val_loss: 0.4086 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.1442 - val_loss: 0.4091 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.1528 - val_loss: 0.4092 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4087 - accuracy: 0.1528 - val_loss: 0.4088 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4076 - accuracy: 0.1538 - val_loss: 0.4092 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4071 - accuracy: 0.1452 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4065 - accuracy: 0.1584 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4063 - accuracy: 0.1589 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4064 - accuracy: 0.1589 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4087 - accuracy: 0.1298\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 6.8063 - accuracy: 0.1877 - val_loss: 0.6903 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.7548 - accuracy: 0.1862 - val_loss: 0.4629 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5444 - accuracy: 0.1466 - val_loss: 0.6246 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5122 - accuracy: 0.1644 - val_loss: 0.4629 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5078 - accuracy: 0.1639 - val_loss: 0.4757 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5114 - accuracy: 0.1801 - val_loss: 0.4614 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4965 - accuracy: 0.1745 - val_loss: 0.4497 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4391 - accuracy: 0.1649 - val_loss: 0.4384 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4160 - accuracy: 0.1583 - val_loss: 0.4152 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4174 - accuracy: 0.1593 - val_loss: 0.4193 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4106 - accuracy: 0.1573 - val_loss: 0.4177 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4164 - accuracy: 0.1598 - val_loss: 0.4150 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4048 - accuracy: 0.1598 - val_loss: 0.4164 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4103 - accuracy: 0.1583 - val_loss: 0.4146 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4137 - accuracy: 0.1547 - val_loss: 0.4169 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4098 - accuracy: 0.1684 - val_loss: 0.4164 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4045 - accuracy: 0.1593 - val_loss: 0.4186 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4041 - accuracy: 0.1553 - val_loss: 0.4219 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1583 - val_loss: 0.4198 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4032 - accuracy: 0.1659 - val_loss: 0.4195 - val_accuracy: 0.1324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4163 - accuracy: 0.1462\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.146 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 5.6652 - accuracy: 0.2197 - val_loss: 0.6042 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6326 - accuracy: 0.1583 - val_loss: 0.4518 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5090 - accuracy: 0.1629 - val_loss: 0.4827 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5171 - accuracy: 0.1542 - val_loss: 0.5580 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4942 - accuracy: 0.1715 - val_loss: 0.5320 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4801 - accuracy: 0.1811 - val_loss: 0.4874 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4357 - accuracy: 0.1649 - val_loss: 0.4212 - val_accuracy: 0.1257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4143 - accuracy: 0.1654 - val_loss: 0.4156 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4045 - accuracy: 0.1684 - val_loss: 0.4069 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4136 - accuracy: 0.1634 - val_loss: 0.4397 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4063 - accuracy: 0.1512 - val_loss: 0.4279 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4039 - accuracy: 0.1583 - val_loss: 0.4147 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4016 - accuracy: 0.1618 - val_loss: 0.4220 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4051 - accuracy: 0.1618 - val_loss: 0.4328 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4035 - accuracy: 0.1679 - val_loss: 0.4275 - val_accuracy: 0.1486 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4011 - accuracy: 0.1679 - val_loss: 0.4247 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4008 - accuracy: 0.1679 - val_loss: 0.4283 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4006 - accuracy: 0.1684 - val_loss: 0.4288 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4005 - accuracy: 0.1669 - val_loss: 0.4340 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4623 - accuracy: 0.1431\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.143 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.6823 - accuracy: 0.2274 - val_loss: 1.8645 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.1079 - accuracy: 0.4127 - val_loss: 1.2851 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6537 - accuracy: 0.5345 - val_loss: 0.8910 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3921 - accuracy: 0.6523 - val_loss: 0.7582 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2432 - accuracy: 0.7457 - val_loss: 0.7268 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1851 - accuracy: 0.8213 - val_loss: 0.7496 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1213 - accuracy: 0.8843 - val_loss: 0.6641 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0876 - accuracy: 0.9299 - val_loss: 0.7061 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1460 - accuracy: 0.8766 - val_loss: 0.8367 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1648 - accuracy: 0.8690 - val_loss: 0.9564 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1882 - accuracy: 0.8604 - val_loss: 0.9399 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1190 - accuracy: 0.9025 - val_loss: 1.0109 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0371 - accuracy: 0.9787 - val_loss: 0.8296 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0157 - accuracy: 0.9934 - val_loss: 0.8150 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.8089 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.8071 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.8080 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6637 - accuracy: 0.4787\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.479 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 3.4035 - accuracy: 0.2263 - val_loss: 1.3189 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9970 - accuracy: 0.3354 - val_loss: 0.9652 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5537 - accuracy: 0.3968 - val_loss: 0.6167 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4035 - accuracy: 0.4982 - val_loss: 0.5927 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3642 - accuracy: 0.5824 - val_loss: 0.6700 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3341 - accuracy: 0.6144 - val_loss: 0.6088 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2631 - accuracy: 0.6849 - val_loss: 0.5784 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2385 - accuracy: 0.7362 - val_loss: 0.5748 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1878 - accuracy: 0.7884 - val_loss: 0.5915 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1252 - accuracy: 0.8635 - val_loss: 0.6042 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1480 - accuracy: 0.8422 - val_loss: 0.8163 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2126 - accuracy: 0.7884 - val_loss: 0.8058 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1447 - accuracy: 0.8519 - val_loss: 0.6161 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0543 - accuracy: 0.9569 - val_loss: 0.6295 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0355 - accuracy: 0.9782 - val_loss: 0.6126 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0291 - accuracy: 0.9827 - val_loss: 0.6136 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0256 - accuracy: 0.9868 - val_loss: 0.6154 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0233 - accuracy: 0.9888 - val_loss: 0.6225 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5631 - accuracy: 0.4061\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.406 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.6407 - accuracy: 0.1684 - val_loss: 0.6456 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.5954 - accuracy: 0.1842 - val_loss: 0.5425 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4918 - accuracy: 0.1837 - val_loss: 0.4822 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4364 - accuracy: 0.1994 - val_loss: 0.4534 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4144 - accuracy: 0.2080 - val_loss: 0.4399 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3955 - accuracy: 0.2613 - val_loss: 0.4336 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3842 - accuracy: 0.2790 - val_loss: 0.4250 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3638 - accuracy: 0.3455 - val_loss: 0.4427 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3686 - accuracy: 0.3420 - val_loss: 0.4336 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3386 - accuracy: 0.3993 - val_loss: 0.4159 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3231 - accuracy: 0.4191 - val_loss: 0.4436 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3111 - accuracy: 0.4389 - val_loss: 0.4289 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2930 - accuracy: 0.4764 - val_loss: 0.3941 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2975 - accuracy: 0.4729 - val_loss: 0.4586 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2811 - accuracy: 0.4891 - val_loss: 0.4002 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2682 - accuracy: 0.5033 - val_loss: 0.4338 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2469 - accuracy: 0.5358 - val_loss: 0.4436 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2580 - accuracy: 0.5216 - val_loss: 0.4179 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2390 - accuracy: 0.5241 - val_loss: 0.4621 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2220 - accuracy: 0.5571 - val_loss: 0.4554 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4791 - accuracy: 0.3411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.341 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 16.1676 - accuracy: 0.2020 - val_loss: 5.8794 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.1707 - accuracy: 0.3563 - val_loss: 4.3980 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.0889 - accuracy: 0.3614 - val_loss: 1.3912 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0022 - accuracy: 0.3995 - val_loss: 1.2224 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8284 - accuracy: 0.3782 - val_loss: 1.1166 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6800 - accuracy: 0.3635 - val_loss: 0.8185 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4762 - accuracy: 0.3924 - val_loss: 0.6522 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4098 - accuracy: 0.4152 - val_loss: 0.4341 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3962 - accuracy: 0.4345 - val_loss: 0.4915 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3795 - accuracy: 0.4685 - val_loss: 0.4607 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3532 - accuracy: 0.4909 - val_loss: 0.4792 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3179 - accuracy: 0.5528 - val_loss: 0.5369 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3123 - accuracy: 0.5706 - val_loss: 0.6678 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2305 - accuracy: 0.6543 - val_loss: 0.4757 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1942 - accuracy: 0.6883 - val_loss: 0.4882 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1767 - accuracy: 0.7223 - val_loss: 0.4910 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1648 - accuracy: 0.7315 - val_loss: 0.5123 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1554 - accuracy: 0.7457 - val_loss: 0.5193 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4425 - accuracy: 0.2677\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.268 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 11.9017 - accuracy: 0.2146 - val_loss: 3.0427 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.2012 - accuracy: 0.3151 - val_loss: 2.2465 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.6211 - accuracy: 0.3810 - val_loss: 1.3941 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.1560 - accuracy: 0.4206 - val_loss: 1.8720 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.9191 - accuracy: 0.4313 - val_loss: 1.7520 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7793 - accuracy: 0.4389 - val_loss: 0.9572 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6372 - accuracy: 0.4835 - val_loss: 0.8658 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5694 - accuracy: 0.5292 - val_loss: 0.8564 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5141 - accuracy: 0.5566 - val_loss: 0.7473 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4293 - accuracy: 0.6296 - val_loss: 0.9127 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4148 - accuracy: 0.6454 - val_loss: 1.1852 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3518 - accuracy: 0.6880 - val_loss: 1.0806 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2997 - accuracy: 0.7098 - val_loss: 1.9999 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3358 - accuracy: 0.7225 - val_loss: 0.7486 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1171 - accuracy: 0.8848 - val_loss: 0.6578 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0798 - accuracy: 0.9239 - val_loss: 0.6551 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0625 - accuracy: 0.9411 - val_loss: 0.6692 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0518 - accuracy: 0.9503 - val_loss: 0.6893 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0448 - accuracy: 0.9630 - val_loss: 0.7029 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0388 - accuracy: 0.9680 - val_loss: 0.7238 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6501 - accuracy: 0.5198\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.520 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 67ms/step - loss: 12.8045 - accuracy: 0.2060 - val_loss: 4.1157 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.5314 - accuracy: 0.3232 - val_loss: 3.5098 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.8632 - accuracy: 0.3907 - val_loss: 1.5372 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2347 - accuracy: 0.4099 - val_loss: 1.0130 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6756 - accuracy: 0.3952 - val_loss: 0.4947 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4720 - accuracy: 0.3247 - val_loss: 0.4759 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4171 - accuracy: 0.3683 - val_loss: 0.5281 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3976 - accuracy: 0.4120 - val_loss: 0.7712 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3718 - accuracy: 0.4287 - val_loss: 0.4598 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3453 - accuracy: 0.4389 - val_loss: 0.4851 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3449 - accuracy: 0.5155 - val_loss: 0.4535 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3185 - accuracy: 0.5449 - val_loss: 0.4871 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2946 - accuracy: 0.5708 - val_loss: 0.5308 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2678 - accuracy: 0.6032 - val_loss: 0.4656 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2574 - accuracy: 0.6190 - val_loss: 0.5245 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2441 - accuracy: 0.6535 - val_loss: 0.6632 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1679 - accuracy: 0.7473 - val_loss: 0.5338 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1414 - accuracy: 0.7778 - val_loss: 0.5471 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1305 - accuracy: 0.8006 - val_loss: 0.5598 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1224 - accuracy: 0.8102 - val_loss: 0.5872 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.5906 - accuracy: 0.4244\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.424 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.8600 - accuracy: 0.2538 - val_loss: 2.0417 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.4707 - accuracy: 0.4964 - val_loss: 2.2634 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0574 - accuracy: 0.6025 - val_loss: 1.6186 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6084 - accuracy: 0.7518 - val_loss: 1.8510 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4340 - accuracy: 0.8112 - val_loss: 1.6404 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3753 - accuracy: 0.8594 - val_loss: 1.6452 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3024 - accuracy: 0.8919 - val_loss: 1.7159 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2188 - accuracy: 0.9127 - val_loss: 1.6316 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0555 - accuracy: 0.9873 - val_loss: 1.3458 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 1.3626 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 1.3423 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 1.3276 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 1.3254 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 1.3228 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.3243 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.3245 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 1.3216 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.3238 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.2094 - accuracy: 0.5497\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.550 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 5.9415 - accuracy: 0.2339 - val_loss: 2.0108 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.1935 - accuracy: 0.4531 - val_loss: 1.6824 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6947 - accuracy: 0.6058 - val_loss: 1.3327 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4625 - accuracy: 0.7215 - val_loss: 1.0725 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3814 - accuracy: 0.7859 - val_loss: 1.1545 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2525 - accuracy: 0.8447 - val_loss: 1.0405 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1443 - accuracy: 0.9097 - val_loss: 1.0849 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1291 - accuracy: 0.9224 - val_loss: 0.9856 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0737 - accuracy: 0.9665 - val_loss: 0.9476 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0612 - accuracy: 0.9701 - val_loss: 1.0374 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0503 - accuracy: 0.9777 - val_loss: 1.0567 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0700 - accuracy: 0.9589 - val_loss: 0.9429 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 1.0511 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.9877 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 1.0880 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1270 - accuracy: 0.9574 - val_loss: 1.5177 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1704 - accuracy: 0.9209 - val_loss: 1.3275 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 1.2893 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.2465 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 1.2421 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.2335 - accuracy: 0.5056\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.506 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 66ms/step - loss: 7.1412 - accuracy: 0.2572 - val_loss: 3.4562 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.1742 - accuracy: 0.5190 - val_loss: 2.2592 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.1864 - accuracy: 0.6398 - val_loss: 2.6801 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7535 - accuracy: 0.7539 - val_loss: 2.4887 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8697 - accuracy: 0.7418 - val_loss: 2.3548 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3721 - accuracy: 0.8711 - val_loss: 1.8297 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2275 - accuracy: 0.9112 - val_loss: 1.6885 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1557 - accuracy: 0.9406 - val_loss: 2.1141 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1304 - accuracy: 0.9493 - val_loss: 1.8272 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0761 - accuracy: 0.9741 - val_loss: 1.8069 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0725 - accuracy: 0.9746 - val_loss: 2.1625 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1018 - accuracy: 0.9716 - val_loss: 2.4308 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0449 - accuracy: 0.9899 - val_loss: 1.8441 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8455 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8477 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.9019 - accuracy: 0.4964\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.496 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 10.8204 - accuracy: 0.2127 - val_loss: 5.2057 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.8754 - accuracy: 0.2726 - val_loss: 1.1090 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9840 - accuracy: 0.2558 - val_loss: 0.8271 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5121 - accuracy: 0.2279 - val_loss: 0.4736 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4716 - accuracy: 0.2157 - val_loss: 0.4499 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4562 - accuracy: 0.2315 - val_loss: 0.4757 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4634 - accuracy: 0.2365 - val_loss: 0.4996 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4379 - accuracy: 0.2741 - val_loss: 0.4608 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4273 - accuracy: 0.3051 - val_loss: 0.4514 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3920 - accuracy: 0.3218 - val_loss: 0.4901 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3410 - accuracy: 0.3695 - val_loss: 0.4159 - val_accuracy: 0.2932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3193 - accuracy: 0.3883 - val_loss: 0.4191 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3083 - accuracy: 0.4046 - val_loss: 0.4305 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3010 - accuracy: 0.4157 - val_loss: 0.4336 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2941 - accuracy: 0.4442 - val_loss: 0.4323 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2847 - accuracy: 0.4624 - val_loss: 0.4564 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2754 - accuracy: 0.4660 - val_loss: 0.4428 - val_accuracy: 0.3162 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2726 - accuracy: 0.4751 - val_loss: 0.4424 - val_accuracy: 0.3189 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2712 - accuracy: 0.4802 - val_loss: 0.4426 - val_accuracy: 0.3257 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2701 - accuracy: 0.4853 - val_loss: 0.4440 - val_accuracy: 0.3243 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4385 - accuracy: 0.2982\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.298 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.6099 - accuracy: 0.2192 - val_loss: 4.2093 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.4111 - accuracy: 0.2522 - val_loss: 3.9088 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7599 - accuracy: 0.2197 - val_loss: 0.4722 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5016 - accuracy: 0.2009 - val_loss: 0.5086 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4831 - accuracy: 0.1948 - val_loss: 0.4900 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4778 - accuracy: 0.2466 - val_loss: 0.4966 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5144 - accuracy: 0.2222 - val_loss: 0.4833 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4558 - accuracy: 0.2466 - val_loss: 0.4668 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4035 - accuracy: 0.2669 - val_loss: 0.4319 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3839 - accuracy: 0.2841 - val_loss: 0.4101 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3657 - accuracy: 0.3130 - val_loss: 0.4805 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3599 - accuracy: 0.3262 - val_loss: 0.4386 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3472 - accuracy: 0.3374 - val_loss: 0.4372 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3411 - accuracy: 0.3359 - val_loss: 0.4265 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3426 - accuracy: 0.3475 - val_loss: 0.4382 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3179 - accuracy: 0.3658 - val_loss: 0.4302 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3137 - accuracy: 0.3729 - val_loss: 0.4297 - val_accuracy: 0.3068 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3122 - accuracy: 0.3714 - val_loss: 0.4313 - val_accuracy: 0.3068 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3098 - accuracy: 0.3744 - val_loss: 0.4566 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3079 - accuracy: 0.3760 - val_loss: 0.4598 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4208 - accuracy: 0.2051\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.205 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 10.6145 - accuracy: 0.2100 - val_loss: 1.8115 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0065 - accuracy: 0.2694 - val_loss: 2.1775 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6409 - accuracy: 0.2192 - val_loss: 0.5833 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5074 - accuracy: 0.1882 - val_loss: 0.5603 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4936 - accuracy: 0.1948 - val_loss: 0.4702 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4751 - accuracy: 0.2374 - val_loss: 0.4949 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4483 - accuracy: 0.2603 - val_loss: 0.4686 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4319 - accuracy: 0.2902 - val_loss: 0.4544 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4235 - accuracy: 0.2719 - val_loss: 0.4334 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3938 - accuracy: 0.2588 - val_loss: 0.4811 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3870 - accuracy: 0.2846 - val_loss: 0.4304 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4015 - accuracy: 0.2892 - val_loss: 0.4218 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3722 - accuracy: 0.3044 - val_loss: 0.4355 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3563 - accuracy: 0.3212 - val_loss: 0.4493 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3709 - accuracy: 0.3506 - val_loss: 0.4664 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3365 - accuracy: 0.3577 - val_loss: 0.4460 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3361 - accuracy: 0.3612 - val_loss: 0.6358 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3260 - accuracy: 0.3993 - val_loss: 0.4774 - val_accuracy: 0.2635 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3020 - accuracy: 0.4084 - val_loss: 0.4909 - val_accuracy: 0.2662 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2950 - accuracy: 0.4115 - val_loss: 0.5018 - val_accuracy: 0.2662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5559 - accuracy: 0.2508\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.251 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.3747 - accuracy: 0.2274 - val_loss: 1.9726 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.2960 - accuracy: 0.4919 - val_loss: 1.5817 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7789 - accuracy: 0.6147 - val_loss: 1.3406 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5329 - accuracy: 0.7218 - val_loss: 1.6418 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5286 - accuracy: 0.7239 - val_loss: 1.2553 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2385 - accuracy: 0.8553 - val_loss: 1.0790 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2135 - accuracy: 0.8655 - val_loss: 1.0127 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.9315 - val_loss: 1.1420 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1442 - accuracy: 0.9350 - val_loss: 1.2628 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1201 - accuracy: 0.9371 - val_loss: 1.2545 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1006 - accuracy: 0.9543 - val_loss: 1.4586 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0840 - accuracy: 0.9548 - val_loss: 1.2354 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 1.1063 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 1.0924 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.0879 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.0684 - accuracy: 0.4970\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.497 total time=  56.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 5.9824 - accuracy: 0.2826 - val_loss: 3.0074 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6419 - accuracy: 0.4617 - val_loss: 1.6540 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7847 - accuracy: 0.6058 - val_loss: 1.3486 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4630 - accuracy: 0.6941 - val_loss: 1.0652 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3268 - accuracy: 0.7900 - val_loss: 1.0924 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2423 - accuracy: 0.8529 - val_loss: 1.1766 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1967 - accuracy: 0.8757 - val_loss: 1.0912 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1204 - accuracy: 0.9153 - val_loss: 1.0949 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0773 - accuracy: 0.9498 - val_loss: 1.1099 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 1.0016 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 1.0093 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 1.0061 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.0043 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 1.0078 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 1.0097 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.9788 - accuracy: 0.5188\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.519 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 7.5201 - accuracy: 0.2430 - val_loss: 2.6581 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.5065 - accuracy: 0.4987 - val_loss: 1.6695 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8421 - accuracy: 0.6367 - val_loss: 1.4283 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4758 - accuracy: 0.7468 - val_loss: 1.4070 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3420 - accuracy: 0.8138 - val_loss: 1.2610 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1676 - accuracy: 0.9097 - val_loss: 1.3455 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0884 - accuracy: 0.9482 - val_loss: 1.0706 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 1.1348 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1173 - accuracy: 0.9518 - val_loss: 1.3531 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0885 - accuracy: 0.9650 - val_loss: 1.3676 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1969 - accuracy: 0.9224 - val_loss: 1.6708 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1392 - accuracy: 0.9209 - val_loss: 1.4407 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 1.2830 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 1.2814 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2752 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.5459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.1392 - accuracy: 0.4904\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.490 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.0429 - accuracy: 0.2107 - val_loss: 0.4692 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4465 - accuracy: 0.3213 - val_loss: 0.4607 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4012 - accuracy: 0.3832 - val_loss: 0.4503 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3241 - accuracy: 0.5061 - val_loss: 0.4681 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2911 - accuracy: 0.5756 - val_loss: 0.4299 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2415 - accuracy: 0.6523 - val_loss: 0.4255 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2054 - accuracy: 0.7284 - val_loss: 0.4477 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1675 - accuracy: 0.7726 - val_loss: 0.4418 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1552 - accuracy: 0.8041 - val_loss: 0.4573 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1128 - accuracy: 0.8558 - val_loss: 0.6656 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1143 - accuracy: 0.8655 - val_loss: 0.8913 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0552 - accuracy: 0.9371 - val_loss: 0.5785 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0304 - accuracy: 0.9660 - val_loss: 0.6091 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0239 - accuracy: 0.9751 - val_loss: 0.6455 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0193 - accuracy: 0.9817 - val_loss: 0.6885 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0155 - accuracy: 0.9863 - val_loss: 0.7483 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4031 - accuracy: 0.4452\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.445 total time=  55.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.8678 - accuracy: 0.1852 - val_loss: 0.5140 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4354 - accuracy: 0.2648 - val_loss: 0.4307 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3874 - accuracy: 0.3440 - val_loss: 0.4029 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3475 - accuracy: 0.4236 - val_loss: 0.4172 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3113 - accuracy: 0.5221 - val_loss: 0.4125 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2848 - accuracy: 0.5764 - val_loss: 0.4502 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2421 - accuracy: 0.6367 - val_loss: 0.5032 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2135 - accuracy: 0.6890 - val_loss: 0.4599 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1501 - accuracy: 0.7854 - val_loss: 0.4313 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1257 - accuracy: 0.8260 - val_loss: 0.4452 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1152 - accuracy: 0.8427 - val_loss: 0.4490 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1060 - accuracy: 0.8574 - val_loss: 0.4571 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0985 - accuracy: 0.8691 - val_loss: 0.4822 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4087 - accuracy: 0.2954\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.295 total time=  45.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.2713 - accuracy: 0.1862 - val_loss: 0.4706 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4283 - accuracy: 0.3070 - val_loss: 0.4527 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3824 - accuracy: 0.3688 - val_loss: 0.4215 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3509 - accuracy: 0.4546 - val_loss: 0.4048 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3157 - accuracy: 0.5277 - val_loss: 0.3974 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2715 - accuracy: 0.5936 - val_loss: 0.4510 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2457 - accuracy: 0.6408 - val_loss: 0.4714 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2108 - accuracy: 0.6920 - val_loss: 0.5174 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1876 - accuracy: 0.7392 - val_loss: 0.5180 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1723 - accuracy: 0.7661 - val_loss: 0.5195 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1025 - accuracy: 0.8549 - val_loss: 0.4768 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0839 - accuracy: 0.8772 - val_loss: 0.4947 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0760 - accuracy: 0.8889 - val_loss: 0.5104 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0699 - accuracy: 0.9001 - val_loss: 0.5319 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0639 - accuracy: 0.9051 - val_loss: 0.5444 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4160 - accuracy: 0.3462\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.346 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.7033 - accuracy: 0.2157 - val_loss: 0.4179 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3887 - accuracy: 0.3127 - val_loss: 0.4074 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3489 - accuracy: 0.4091 - val_loss: 0.4008 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3145 - accuracy: 0.4731 - val_loss: 0.3864 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2775 - accuracy: 0.5584 - val_loss: 0.4240 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2403 - accuracy: 0.6416 - val_loss: 0.4316 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1941 - accuracy: 0.7178 - val_loss: 0.4266 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1639 - accuracy: 0.7635 - val_loss: 0.4676 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1399 - accuracy: 0.8152 - val_loss: 0.4835 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0907 - accuracy: 0.8843 - val_loss: 0.4614 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0759 - accuracy: 0.9091 - val_loss: 0.4635 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0698 - accuracy: 0.9157 - val_loss: 0.4758 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0639 - accuracy: 0.9264 - val_loss: 0.4785 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0595 - accuracy: 0.9310 - val_loss: 0.4822 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3749 - accuracy: 0.3793\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.379 total time=  47.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9310 - accuracy: 0.2232 - val_loss: 0.5465 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.4054 - val_loss: 0.4265 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3066 - accuracy: 0.5373 - val_loss: 0.4295 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2665 - accuracy: 0.6286 - val_loss: 0.3821 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1999 - accuracy: 0.7463 - val_loss: 0.4403 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1729 - accuracy: 0.7849 - val_loss: 0.4365 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1291 - accuracy: 0.8524 - val_loss: 0.4557 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0926 - accuracy: 0.9077 - val_loss: 0.4866 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0793 - accuracy: 0.9320 - val_loss: 0.4583 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.4599 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.4690 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: 0.4730 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.4790 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0184 - accuracy: 0.9985 - val_loss: 0.4859 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3968 - accuracy: 0.4325\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.432 total time=  47.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 0.8404 - accuracy: 0.2253 - val_loss: 0.4767 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3783 - accuracy: 0.4165 - val_loss: 0.4379 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3062 - accuracy: 0.5353 - val_loss: 0.3769 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2252 - accuracy: 0.6976 - val_loss: 0.3807 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1760 - accuracy: 0.7884 - val_loss: 0.3800 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1479 - accuracy: 0.8331 - val_loss: 0.4310 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1093 - accuracy: 0.8935 - val_loss: 0.4453 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0795 - accuracy: 0.9356 - val_loss: 0.4949 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.4490 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 0.4499 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0273 - accuracy: 0.9964 - val_loss: 0.4558 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0248 - accuracy: 0.9959 - val_loss: 0.4634 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0227 - accuracy: 0.9975 - val_loss: 0.4705 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4019 - accuracy: 0.4020\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.402 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.3193 - accuracy: 0.1629 - val_loss: 0.4798 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4765 - accuracy: 0.2274 - val_loss: 0.4701 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4497 - accuracy: 0.2624 - val_loss: 0.4782 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4104 - accuracy: 0.3289 - val_loss: 0.4690 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3835 - accuracy: 0.3904 - val_loss: 0.4700 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3614 - accuracy: 0.4345 - val_loss: 0.4975 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3259 - accuracy: 0.4929 - val_loss: 0.4382 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2942 - accuracy: 0.5330 - val_loss: 0.4555 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2794 - accuracy: 0.5787 - val_loss: 0.5091 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2614 - accuracy: 0.6102 - val_loss: 0.4564 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2289 - accuracy: 0.6584 - val_loss: 0.4816 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2083 - accuracy: 0.7086 - val_loss: 0.4931 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1460 - accuracy: 0.7766 - val_loss: 0.5095 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1302 - accuracy: 0.8010 - val_loss: 0.5254 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1208 - accuracy: 0.8107 - val_loss: 0.5442 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1142 - accuracy: 0.8198 - val_loss: 0.5795 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1086 - accuracy: 0.8249 - val_loss: 0.5816 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4536 - accuracy: 0.2748\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.275 total time=  58.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.3856 - accuracy: 0.2090 - val_loss: 0.4332 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4659 - accuracy: 0.2659 - val_loss: 0.4360 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4201 - accuracy: 0.3044 - val_loss: 0.4357 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3907 - accuracy: 0.3719 - val_loss: 0.4152 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3576 - accuracy: 0.4277 - val_loss: 0.6280 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3452 - accuracy: 0.4515 - val_loss: 0.4414 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3014 - accuracy: 0.5175 - val_loss: 0.4208 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2902 - accuracy: 0.5388 - val_loss: 0.4180 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2776 - accuracy: 0.5784 - val_loss: 0.6176 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2122 - accuracy: 0.6565 - val_loss: 0.4416 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1805 - accuracy: 0.7047 - val_loss: 0.4630 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1689 - accuracy: 0.7179 - val_loss: 0.4676 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1609 - accuracy: 0.7372 - val_loss: 0.4812 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1520 - accuracy: 0.7549 - val_loss: 0.4905 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4325 - accuracy: 0.2883\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.288 total time=  48.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.1776 - accuracy: 0.1705 - val_loss: 0.6458 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4831 - accuracy: 0.2151 - val_loss: 0.4741 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4329 - accuracy: 0.2725 - val_loss: 0.5094 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4143 - accuracy: 0.3257 - val_loss: 0.4772 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3857 - accuracy: 0.3683 - val_loss: 0.4816 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3551 - accuracy: 0.4323 - val_loss: 0.5940 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3229 - accuracy: 0.4825 - val_loss: 0.6627 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2786 - accuracy: 0.5256 - val_loss: 0.4215 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2300 - accuracy: 0.6068 - val_loss: 0.4303 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2178 - accuracy: 0.6261 - val_loss: 0.4333 - val_accuracy: 0.3770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2072 - accuracy: 0.6494 - val_loss: 0.4503 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1977 - accuracy: 0.6657 - val_loss: 0.4519 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1891 - accuracy: 0.6895 - val_loss: 0.4597 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1765 - accuracy: 0.7128 - val_loss: 0.4631 - val_accuracy: 0.3946 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1747 - accuracy: 0.7220 - val_loss: 0.4657 - val_accuracy: 0.3932 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1734 - accuracy: 0.7189 - val_loss: 0.4678 - val_accuracy: 0.3973 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1724 - accuracy: 0.7220 - val_loss: 0.4704 - val_accuracy: 0.3946 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1714 - accuracy: 0.7215 - val_loss: 0.4714 - val_accuracy: 0.3959 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4482 - accuracy: 0.3299\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.330 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 66ms/step - loss: 0.9025 - accuracy: 0.1919 - val_loss: 0.4529 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4290 - accuracy: 0.2553 - val_loss: 0.4204 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3841 - accuracy: 0.3259 - val_loss: 0.4364 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3535 - accuracy: 0.4157 - val_loss: 0.4014 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3258 - accuracy: 0.4711 - val_loss: 0.3975 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2792 - accuracy: 0.5599 - val_loss: 0.4062 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2450 - accuracy: 0.6269 - val_loss: 0.4397 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2173 - accuracy: 0.6736 - val_loss: 0.4817 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1972 - accuracy: 0.7213 - val_loss: 0.4363 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1780 - accuracy: 0.7457 - val_loss: 0.4802 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1354 - accuracy: 0.8157 - val_loss: 0.4623 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1135 - accuracy: 0.8386 - val_loss: 0.4731 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1049 - accuracy: 0.8497 - val_loss: 0.4781 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0982 - accuracy: 0.8584 - val_loss: 0.4795 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0931 - accuracy: 0.8726 - val_loss: 0.4854 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3984 - accuracy: 0.3174\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.317 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9646 - accuracy: 0.2040 - val_loss: 0.4468 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4044 - accuracy: 0.3146 - val_loss: 0.3981 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3596 - accuracy: 0.4135 - val_loss: 0.4044 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3132 - accuracy: 0.5028 - val_loss: 0.3817 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2698 - accuracy: 0.5830 - val_loss: 0.4022 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2217 - accuracy: 0.6814 - val_loss: 0.4184 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1866 - accuracy: 0.7311 - val_loss: 0.4332 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1669 - accuracy: 0.7727 - val_loss: 0.4670 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1372 - accuracy: 0.8082 - val_loss: 0.6012 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0950 - accuracy: 0.8858 - val_loss: 0.4508 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0661 - accuracy: 0.9310 - val_loss: 0.4467 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0600 - accuracy: 0.9346 - val_loss: 0.4522 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0552 - accuracy: 0.9422 - val_loss: 0.4584 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0514 - accuracy: 0.9482 - val_loss: 0.4654 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4009 - accuracy: 0.3584\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.358 total time=  47.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 0.9231 - accuracy: 0.1684 - val_loss: 0.4341 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4207 - accuracy: 0.2029 - val_loss: 0.4382 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3984 - accuracy: 0.2750 - val_loss: 0.4278 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3754 - accuracy: 0.3288 - val_loss: 0.4186 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3511 - accuracy: 0.3836 - val_loss: 0.4235 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3233 - accuracy: 0.4409 - val_loss: 0.4398 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3055 - accuracy: 0.4901 - val_loss: 0.4415 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2881 - accuracy: 0.5124 - val_loss: 0.4450 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2572 - accuracy: 0.5738 - val_loss: 0.4116 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2214 - accuracy: 0.6372 - val_loss: 0.4318 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1979 - accuracy: 0.6834 - val_loss: 0.4669 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1822 - accuracy: 0.7159 - val_loss: 0.4806 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1837 - accuracy: 0.7194 - val_loss: 0.6045 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1756 - accuracy: 0.7357 - val_loss: 0.4910 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1322 - accuracy: 0.8102 - val_loss: 0.4930 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1136 - accuracy: 0.8290 - val_loss: 0.4906 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1046 - accuracy: 0.8463 - val_loss: 0.5005 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0993 - accuracy: 0.8503 - val_loss: 0.5002 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0932 - accuracy: 0.8605 - val_loss: 0.5161 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4371 - accuracy: 0.3695\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.370 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.9326 - accuracy: 0.2056 - val_loss: 0.6462 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5670 - accuracy: 0.3071 - val_loss: 0.4608 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4045 - accuracy: 0.4447 - val_loss: 0.4301 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3457 - accuracy: 0.5066 - val_loss: 0.4466 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2741 - accuracy: 0.6036 - val_loss: 0.4298 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2410 - accuracy: 0.6655 - val_loss: 0.5170 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1999 - accuracy: 0.7391 - val_loss: 0.4860 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1616 - accuracy: 0.7980 - val_loss: 0.5845 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1412 - accuracy: 0.8320 - val_loss: 0.4906 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1033 - accuracy: 0.8766 - val_loss: 0.6589 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0412 - accuracy: 0.9569 - val_loss: 0.5678 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0257 - accuracy: 0.9812 - val_loss: 0.6088 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0198 - accuracy: 0.9838 - val_loss: 0.6343 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0155 - accuracy: 0.9883 - val_loss: 0.6728 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0122 - accuracy: 0.9914 - val_loss: 0.7084 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3993 - accuracy: 0.4554\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.455 total time=  53.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.8246 - accuracy: 0.2222 - val_loss: 0.6217 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5194 - accuracy: 0.2897 - val_loss: 0.4815 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4136 - accuracy: 0.3709 - val_loss: 0.4212 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3656 - accuracy: 0.4713 - val_loss: 0.4348 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2991 - accuracy: 0.5596 - val_loss: 0.4106 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2561 - accuracy: 0.6352 - val_loss: 0.4694 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2167 - accuracy: 0.7057 - val_loss: 0.5981 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1834 - accuracy: 0.7681 - val_loss: 0.5098 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1508 - accuracy: 0.8108 - val_loss: 0.6310 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1294 - accuracy: 0.8407 - val_loss: 1.0169 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1013 - accuracy: 0.8935 - val_loss: 0.5232 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0445 - accuracy: 0.9554 - val_loss: 0.5535 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0350 - accuracy: 0.9680 - val_loss: 0.5841 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0283 - accuracy: 0.9751 - val_loss: 0.6091 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0234 - accuracy: 0.9807 - val_loss: 0.6413 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4173 - accuracy: 0.3695\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.370 total time=  52.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.6154 - accuracy: 0.2268 - val_loss: 0.7838 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4706 - accuracy: 0.2978 - val_loss: 0.4600 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3782 - accuracy: 0.4135 - val_loss: 0.4849 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3332 - accuracy: 0.4845 - val_loss: 0.4417 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2834 - accuracy: 0.5698 - val_loss: 0.4818 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2524 - accuracy: 0.6438 - val_loss: 0.4149 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2124 - accuracy: 0.7007 - val_loss: 0.5114 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1715 - accuracy: 0.7580 - val_loss: 0.6691 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1429 - accuracy: 0.8097 - val_loss: 0.4357 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1258 - accuracy: 0.8397 - val_loss: 0.5717 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1003 - accuracy: 0.8721 - val_loss: 0.5777 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0404 - accuracy: 0.9599 - val_loss: 0.5900 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0296 - accuracy: 0.9721 - val_loss: 0.5926 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0239 - accuracy: 0.9782 - val_loss: 0.6091 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0201 - accuracy: 0.9807 - val_loss: 0.6429 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0169 - accuracy: 0.9843 - val_loss: 0.6890 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4232 - accuracy: 0.3980\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.398 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.2015 - accuracy: 0.2376 - val_loss: 0.5862 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4073 - accuracy: 0.4066 - val_loss: 0.4840 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2858 - accuracy: 0.5975 - val_loss: 0.4364 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2349 - accuracy: 0.6838 - val_loss: 0.4099 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1776 - accuracy: 0.7934 - val_loss: 0.4397 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1523 - accuracy: 0.8381 - val_loss: 0.4645 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1052 - accuracy: 0.9015 - val_loss: 0.4586 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0783 - accuracy: 0.9431 - val_loss: 0.4693 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0600 - accuracy: 0.9665 - val_loss: 0.5156 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 0.4817 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0246 - accuracy: 0.9985 - val_loss: 0.4929 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.4967 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.5018 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0182 - accuracy: 0.9990 - val_loss: 0.5098 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3934 - accuracy: 0.4462\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.446 total time=  48.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.2355 - accuracy: 0.2344 - val_loss: 0.5575 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.4592 - val_loss: 0.4961 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2874 - accuracy: 0.6088 - val_loss: 0.4138 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2261 - accuracy: 0.7118 - val_loss: 0.4388 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1695 - accuracy: 0.8077 - val_loss: 0.4339 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1273 - accuracy: 0.8828 - val_loss: 0.4979 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0974 - accuracy: 0.9137 - val_loss: 0.4712 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0627 - accuracy: 0.9594 - val_loss: 0.5233 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.4885 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0263 - accuracy: 0.9949 - val_loss: 0.4937 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0242 - accuracy: 0.9964 - val_loss: 0.4973 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.5047 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.5069 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4291 - accuracy: 0.4071\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.407 total time=  44.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.2395 - accuracy: 0.2374 - val_loss: 0.5830 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4260 - accuracy: 0.3902 - val_loss: 0.4481 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3176 - accuracy: 0.5282 - val_loss: 0.4410 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2490 - accuracy: 0.6494 - val_loss: 0.3982 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1899 - accuracy: 0.7570 - val_loss: 0.4116 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1506 - accuracy: 0.8305 - val_loss: 0.4074 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1119 - accuracy: 0.8848 - val_loss: 0.4412 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0853 - accuracy: 0.9290 - val_loss: 0.4777 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0813 - accuracy: 0.9356 - val_loss: 0.4682 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.4694 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.4787 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0230 - accuracy: 0.9959 - val_loss: 0.4850 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.4936 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9985 - val_loss: 0.4987 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3944 - accuracy: 0.3878\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.388 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 2.2252 - accuracy: 0.1954 - val_loss: 0.4525 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5102 - accuracy: 0.2355 - val_loss: 0.4593 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4390 - accuracy: 0.2893 - val_loss: 0.4476 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4075 - accuracy: 0.3381 - val_loss: 0.4355 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3815 - accuracy: 0.3944 - val_loss: 0.4991 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3697 - accuracy: 0.4462 - val_loss: 0.4459 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3229 - accuracy: 0.4949 - val_loss: 0.4311 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3009 - accuracy: 0.5269 - val_loss: 0.4743 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2850 - accuracy: 0.5655 - val_loss: 0.4166 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2526 - accuracy: 0.6102 - val_loss: 0.5497 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2633 - accuracy: 0.6178 - val_loss: 0.5051 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2201 - accuracy: 0.6726 - val_loss: 0.6993 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2101 - accuracy: 0.7076 - val_loss: 0.5486 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1864 - accuracy: 0.7157 - val_loss: 0.6184 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1312 - accuracy: 0.7924 - val_loss: 0.5425 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1133 - accuracy: 0.8152 - val_loss: 0.5609 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1026 - accuracy: 0.8345 - val_loss: 0.5851 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0954 - accuracy: 0.8421 - val_loss: 0.5894 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0888 - accuracy: 0.8614 - val_loss: 0.6188 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4045 - accuracy: 0.3834\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.383 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.0734 - accuracy: 0.2035 - val_loss: 0.5787 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4821 - accuracy: 0.2684 - val_loss: 0.4336 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4082 - accuracy: 0.3420 - val_loss: 0.4706 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3925 - accuracy: 0.3886 - val_loss: 0.4952 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3573 - accuracy: 0.4551 - val_loss: 0.3919 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3197 - accuracy: 0.5043 - val_loss: 0.4275 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2832 - accuracy: 0.5718 - val_loss: 0.5985 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2471 - accuracy: 0.6230 - val_loss: 0.6497 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2442 - accuracy: 0.6662 - val_loss: 0.4693 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2133 - accuracy: 0.6991 - val_loss: 0.4549 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1290 - accuracy: 0.8052 - val_loss: 0.4665 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1145 - accuracy: 0.8224 - val_loss: 0.4847 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1058 - accuracy: 0.8371 - val_loss: 0.5040 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0975 - accuracy: 0.8549 - val_loss: 0.5200 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0907 - accuracy: 0.8620 - val_loss: 0.5331 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.3259\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.326 total time=  52.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.4726 - accuracy: 0.1999 - val_loss: 0.5295 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4946 - accuracy: 0.2643 - val_loss: 0.4611 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4527 - accuracy: 0.2958 - val_loss: 0.4883 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3998 - accuracy: 0.3678 - val_loss: 0.4584 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3690 - accuracy: 0.4394 - val_loss: 0.4588 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3203 - accuracy: 0.5043 - val_loss: 0.6283 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2828 - accuracy: 0.5830 - val_loss: 0.4684 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2422 - accuracy: 0.6383 - val_loss: 0.5524 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2238 - accuracy: 0.6819 - val_loss: 0.5750 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1490 - accuracy: 0.7950 - val_loss: 0.4657 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1136 - accuracy: 0.8366 - val_loss: 0.4934 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1022 - accuracy: 0.8498 - val_loss: 0.4988 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0917 - accuracy: 0.8605 - val_loss: 0.5152 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0836 - accuracy: 0.8782 - val_loss: 0.5392 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4781 - accuracy: 0.2934\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.293 total time=  49.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.5127 - accuracy: 0.2036 - val_loss: 0.5828 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4514 - accuracy: 0.3853 - val_loss: 0.5196 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3508 - accuracy: 0.5147 - val_loss: 0.4934 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2758 - accuracy: 0.6426 - val_loss: 0.5075 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2222 - accuracy: 0.7173 - val_loss: 0.4624 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1679 - accuracy: 0.8051 - val_loss: 0.4872 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1431 - accuracy: 0.8477 - val_loss: 0.5057 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1032 - accuracy: 0.9086 - val_loss: 0.5063 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1014 - accuracy: 0.9061 - val_loss: 0.5999 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0725 - accuracy: 0.9371 - val_loss: 0.6265 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9812 - val_loss: 0.5833 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.5806 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9959 - val_loss: 0.5902 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.5925 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.6010 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4419 - accuracy: 0.4168\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.417 total time=  51.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.5962 - accuracy: 0.2349 - val_loss: 0.5666 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4325 - accuracy: 0.3653 - val_loss: 0.4262 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3295 - accuracy: 0.5084 - val_loss: 0.4535 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3145 - accuracy: 0.5622 - val_loss: 0.4016 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2425 - accuracy: 0.6707 - val_loss: 0.4310 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1990 - accuracy: 0.7316 - val_loss: 0.4313 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1764 - accuracy: 0.7752 - val_loss: 0.4170 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1307 - accuracy: 0.8529 - val_loss: 0.4513 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1031 - accuracy: 0.8879 - val_loss: 0.4538 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0599 - accuracy: 0.9508 - val_loss: 0.4424 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0473 - accuracy: 0.9691 - val_loss: 0.4439 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0424 - accuracy: 0.9726 - val_loss: 0.4566 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0387 - accuracy: 0.9751 - val_loss: 0.4615 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0354 - accuracy: 0.9797 - val_loss: 0.4630 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4010 - accuracy: 0.3909\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.391 total time=  47.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.6701 - accuracy: 0.2253 - val_loss: 0.7232 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4916 - accuracy: 0.3968 - val_loss: 0.5248 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3447 - accuracy: 0.5449 - val_loss: 0.5561 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2691 - accuracy: 0.6433 - val_loss: 0.5357 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2299 - accuracy: 0.7265 - val_loss: 0.4558 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1564 - accuracy: 0.8280 - val_loss: 0.4842 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1236 - accuracy: 0.8808 - val_loss: 0.5435 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0938 - accuracy: 0.9224 - val_loss: 0.5425 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1034 - accuracy: 0.9137 - val_loss: 0.5676 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0589 - accuracy: 0.9619 - val_loss: 0.6511 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0324 - accuracy: 0.9833 - val_loss: 0.5566 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.5551 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 0.5592 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0154 - accuracy: 0.9990 - val_loss: 0.5622 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 0.5640 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4729 - accuracy: 0.4335\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.434 total time=  51.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 10.0597 - accuracy: 0.1985 - val_loss: 5.8165 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.2921 - accuracy: 0.2675 - val_loss: 3.4235 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0706 - accuracy: 0.2548 - val_loss: 0.8960 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.9501 - accuracy: 0.2193 - val_loss: 0.5305 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5942 - accuracy: 0.1807 - val_loss: 0.4767 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4935 - accuracy: 0.1391 - val_loss: 0.4485 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4823 - accuracy: 0.1609 - val_loss: 0.4616 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4744 - accuracy: 0.1868 - val_loss: 0.5462 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4722 - accuracy: 0.1873 - val_loss: 0.4396 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4657 - accuracy: 0.2137 - val_loss: 0.4535 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4531 - accuracy: 0.1914 - val_loss: 0.4839 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4386 - accuracy: 0.2330 - val_loss: 0.4538 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4222 - accuracy: 0.2487 - val_loss: 0.4379 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4069 - accuracy: 0.2503 - val_loss: 0.4469 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3924 - accuracy: 0.2472 - val_loss: 0.4227 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3808 - accuracy: 0.2944 - val_loss: 0.3985 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3647 - accuracy: 0.3152 - val_loss: 0.4064 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3595 - accuracy: 0.3203 - val_loss: 0.4282 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3503 - accuracy: 0.3299 - val_loss: 0.3958 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3530 - accuracy: 0.3340 - val_loss: 0.4041 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3984 - accuracy: 0.2181\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.218 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 10.6362 - accuracy: 0.2171 - val_loss: 11.7141 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.7425 - accuracy: 0.2430 - val_loss: 0.5393 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4889 - accuracy: 0.1695 - val_loss: 0.4626 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4845 - accuracy: 0.1603 - val_loss: 0.5218 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4705 - accuracy: 0.1771 - val_loss: 0.5078 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4629 - accuracy: 0.1639 - val_loss: 0.4593 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5043 - accuracy: 0.1847 - val_loss: 0.5189 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4484 - accuracy: 0.1872 - val_loss: 0.4671 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4492 - accuracy: 0.1938 - val_loss: 0.4616 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4317 - accuracy: 0.2227 - val_loss: 0.4668 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4190 - accuracy: 0.2248 - val_loss: 0.4734 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3812 - accuracy: 0.2912 - val_loss: 0.4484 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3739 - accuracy: 0.2948 - val_loss: 0.4483 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3687 - accuracy: 0.2983 - val_loss: 0.4481 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3625 - accuracy: 0.3044 - val_loss: 0.4561 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3577 - accuracy: 0.3090 - val_loss: 0.4515 - val_accuracy: 0.2446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3524 - accuracy: 0.3019 - val_loss: 0.4525 - val_accuracy: 0.2473 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3492 - accuracy: 0.3161 - val_loss: 0.4616 - val_accuracy: 0.2270 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3465 - accuracy: 0.3130 - val_loss: 0.4598 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3405 - accuracy: 0.3161 - val_loss: 0.4604 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4500 - accuracy: 0.2152\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.215 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 9.0199 - accuracy: 0.2146 - val_loss: 2.8702 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2904 - accuracy: 0.2912 - val_loss: 0.7251 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5577 - accuracy: 0.2227 - val_loss: 0.5339 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5000 - accuracy: 0.1938 - val_loss: 0.4904 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4929 - accuracy: 0.1994 - val_loss: 0.5112 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4755 - accuracy: 0.2177 - val_loss: 0.4758 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4437 - accuracy: 0.2511 - val_loss: 0.5222 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4338 - accuracy: 0.2725 - val_loss: 0.4542 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4263 - accuracy: 0.2719 - val_loss: 0.4865 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4134 - accuracy: 0.2821 - val_loss: 0.4737 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3944 - accuracy: 0.3237 - val_loss: 0.5779 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3812 - accuracy: 0.3364 - val_loss: 0.5143 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3768 - accuracy: 0.3247 - val_loss: 0.4687 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3186 - accuracy: 0.4033 - val_loss: 0.4578 - val_accuracy: 0.2838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3020 - accuracy: 0.4262 - val_loss: 0.4748 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2933 - accuracy: 0.4592 - val_loss: 0.4718 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2874 - accuracy: 0.4556 - val_loss: 0.4789 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2814 - accuracy: 0.4683 - val_loss: 0.4908 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4465 - accuracy: 0.2426\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.243 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.9431 - accuracy: 0.2391 - val_loss: 1.3224 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9202 - accuracy: 0.4381 - val_loss: 1.2962 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6501 - accuracy: 0.5239 - val_loss: 0.8601 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4092 - accuracy: 0.6492 - val_loss: 0.7221 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2562 - accuracy: 0.7954 - val_loss: 0.7577 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1782 - accuracy: 0.8447 - val_loss: 0.6899 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1071 - accuracy: 0.9208 - val_loss: 0.7446 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1050 - accuracy: 0.9239 - val_loss: 0.7094 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0678 - accuracy: 0.9533 - val_loss: 0.7219 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0483 - accuracy: 0.9761 - val_loss: 0.7609 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0520 - accuracy: 0.9746 - val_loss: 0.8069 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0264 - accuracy: 0.9898 - val_loss: 0.6943 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0162 - accuracy: 0.9985 - val_loss: 0.6950 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 0.6931 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 0.6971 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0139 - accuracy: 0.9990 - val_loss: 0.6969 - val_accuracy: 0.5311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.6430 - accuracy: 0.4797\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.480 total time=  54.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.2970 - accuracy: 0.2303 - val_loss: 0.9432 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8849 - accuracy: 0.3952 - val_loss: 0.8404 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5455 - accuracy: 0.5246 - val_loss: 0.7580 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3992 - accuracy: 0.5951 - val_loss: 0.7485 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3213 - accuracy: 0.6900 - val_loss: 0.6150 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3231 - accuracy: 0.6743 - val_loss: 0.6977 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2016 - accuracy: 0.7849 - val_loss: 0.6528 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1652 - accuracy: 0.8371 - val_loss: 0.6859 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1141 - accuracy: 0.8767 - val_loss: 0.6773 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0984 - accuracy: 0.9061 - val_loss: 0.6953 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0531 - accuracy: 0.9589 - val_loss: 0.6553 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0408 - accuracy: 0.9731 - val_loss: 0.6582 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0376 - accuracy: 0.9772 - val_loss: 0.6532 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0347 - accuracy: 0.9802 - val_loss: 0.6514 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0327 - accuracy: 0.9848 - val_loss: 0.6566 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6063 - accuracy: 0.4335\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.434 total time=  50.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.6544 - accuracy: 0.1695 - val_loss: 0.6999 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6816 - accuracy: 0.1563 - val_loss: 0.6531 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6197 - accuracy: 0.1481 - val_loss: 0.4888 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4560 - accuracy: 0.1578 - val_loss: 0.4497 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4542 - accuracy: 0.1598 - val_loss: 0.4619 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4356 - accuracy: 0.1801 - val_loss: 0.4630 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4273 - accuracy: 0.1740 - val_loss: 0.4482 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4253 - accuracy: 0.1710 - val_loss: 0.4437 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4238 - accuracy: 0.1715 - val_loss: 0.4246 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4176 - accuracy: 0.1700 - val_loss: 0.4242 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4188 - accuracy: 0.1842 - val_loss: 0.4198 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4151 - accuracy: 0.1781 - val_loss: 0.4276 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4161 - accuracy: 0.1913 - val_loss: 0.4205 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4137 - accuracy: 0.2171 - val_loss: 0.4453 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4203 - accuracy: 0.2385 - val_loss: 0.4206 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4042 - accuracy: 0.2770 - val_loss: 0.4402 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3933 - accuracy: 0.2993 - val_loss: 0.4213 - val_accuracy: 0.2243 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3822 - accuracy: 0.3034 - val_loss: 0.4245 - val_accuracy: 0.2054 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3792 - accuracy: 0.3125 - val_loss: 0.4295 - val_accuracy: 0.1919 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3776 - accuracy: 0.3237 - val_loss: 0.4240 - val_accuracy: 0.2135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4290 - accuracy: 0.2122\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.212 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 4.7961 - accuracy: 0.1792 - val_loss: 0.5416 - val_accuracy: 0.1257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5964 - accuracy: 0.1508 - val_loss: 0.5253 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5362 - accuracy: 0.1721 - val_loss: 0.4502 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5065 - accuracy: 0.1665 - val_loss: 0.5212 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4909 - accuracy: 0.1553 - val_loss: 0.4467 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4454 - accuracy: 0.1746 - val_loss: 0.4764 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4219 - accuracy: 0.1599 - val_loss: 0.4096 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4081 - accuracy: 0.1569 - val_loss: 0.4075 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.1579 - val_loss: 0.4077 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4058 - accuracy: 0.1447 - val_loss: 0.4083 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4087 - accuracy: 0.1548 - val_loss: 0.4077 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4075 - accuracy: 0.1533 - val_loss: 0.4080 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4061 - accuracy: 0.1574 - val_loss: 0.4085 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1533 - val_loss: 0.4084 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1533 - val_loss: 0.4087 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4054 - accuracy: 0.1528 - val_loss: 0.4097 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4048 - accuracy: 0.1538 - val_loss: 0.4119 - val_accuracy: 0.1689 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4047 - accuracy: 0.1487 - val_loss: 0.4135 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4107 - accuracy: 0.1318\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.132 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 2.4554 - accuracy: 0.1740 - val_loss: 0.5744 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5478 - accuracy: 0.1542 - val_loss: 0.5549 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5145 - accuracy: 0.1720 - val_loss: 0.4512 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4982 - accuracy: 0.1720 - val_loss: 0.4904 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4665 - accuracy: 0.1887 - val_loss: 0.4507 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4321 - accuracy: 0.1527 - val_loss: 0.4167 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4121 - accuracy: 0.1537 - val_loss: 0.4221 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4053 - accuracy: 0.1563 - val_loss: 0.4203 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4056 - accuracy: 0.1679 - val_loss: 0.4323 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4121 - accuracy: 0.1644 - val_loss: 0.4313 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4028 - accuracy: 0.1776 - val_loss: 0.4296 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3990 - accuracy: 0.1776 - val_loss: 0.4295 - val_accuracy: 0.1581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3980 - accuracy: 0.1816 - val_loss: 0.4361 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3971 - accuracy: 0.1842 - val_loss: 0.4400 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3966 - accuracy: 0.1842 - val_loss: 0.4435 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3960 - accuracy: 0.1852 - val_loss: 0.4457 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4293 - accuracy: 0.1452\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.145 total time=  54.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 4.8071 - accuracy: 0.1837 - val_loss: 0.4874 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5810 - accuracy: 0.1832 - val_loss: 0.5046 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5103 - accuracy: 0.1821 - val_loss: 0.4755 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4977 - accuracy: 0.1730 - val_loss: 0.4818 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4631 - accuracy: 0.2090 - val_loss: 0.4772 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4476 - accuracy: 0.1969 - val_loss: 0.4481 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4203 - accuracy: 0.2136 - val_loss: 0.4190 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3997 - accuracy: 0.2268 - val_loss: 0.4263 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3922 - accuracy: 0.2192 - val_loss: 0.4329 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3825 - accuracy: 0.2456 - val_loss: 0.8398 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3827 - accuracy: 0.2582 - val_loss: 0.4607 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3849 - accuracy: 0.2638 - val_loss: 0.4215 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3649 - accuracy: 0.2572 - val_loss: 0.4368 - val_accuracy: 0.2324 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3574 - accuracy: 0.2745 - val_loss: 0.4527 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3543 - accuracy: 0.2867 - val_loss: 0.4609 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3517 - accuracy: 0.2958 - val_loss: 0.4657 - val_accuracy: 0.2230 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3493 - accuracy: 0.3009 - val_loss: 0.4920 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4245 - accuracy: 0.1898\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.190 total time=  58.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 2.6756 - accuracy: 0.2081 - val_loss: 1.5019 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8827 - accuracy: 0.3360 - val_loss: 0.7153 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5041 - accuracy: 0.4249 - val_loss: 0.5799 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4249 - accuracy: 0.4990 - val_loss: 0.5225 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3615 - accuracy: 0.5091 - val_loss: 0.5378 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2816 - accuracy: 0.6157 - val_loss: 0.4882 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2551 - accuracy: 0.6523 - val_loss: 0.4995 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2165 - accuracy: 0.6939 - val_loss: 0.5023 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1907 - accuracy: 0.7558 - val_loss: 0.5504 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1664 - accuracy: 0.7756 - val_loss: 0.5961 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1377 - accuracy: 0.8127 - val_loss: 0.5358 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0878 - accuracy: 0.8888 - val_loss: 0.5493 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0714 - accuracy: 0.9046 - val_loss: 0.5434 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0630 - accuracy: 0.9254 - val_loss: 0.5435 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0585 - accuracy: 0.9294 - val_loss: 0.5473 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0553 - accuracy: 0.9360 - val_loss: 0.5603 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4809 - accuracy: 0.4047\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.405 total time=  54.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 4.3642 - accuracy: 0.2664 - val_loss: 1.6447 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0664 - accuracy: 0.5074 - val_loss: 1.3888 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6840 - accuracy: 0.6134 - val_loss: 0.9778 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4919 - accuracy: 0.7128 - val_loss: 1.0265 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3013 - accuracy: 0.7976 - val_loss: 0.9671 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2387 - accuracy: 0.8498 - val_loss: 1.0511 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1466 - accuracy: 0.9077 - val_loss: 1.0696 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1335 - accuracy: 0.9127 - val_loss: 1.0496 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1083 - accuracy: 0.9391 - val_loss: 0.9406 - val_accuracy: 0.5135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0617 - accuracy: 0.9655 - val_loss: 1.0275 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0825 - accuracy: 0.9523 - val_loss: 1.1474 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0472 - accuracy: 0.9746 - val_loss: 1.1394 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0356 - accuracy: 0.9827 - val_loss: 1.0729 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0664 - accuracy: 0.9635 - val_loss: 1.3178 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0197 - accuracy: 0.9909 - val_loss: 1.0740 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.9518 - accuracy: 0.4832\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.483 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.0215 - accuracy: 0.2136 - val_loss: 0.8739 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7591 - accuracy: 0.2841 - val_loss: 0.6529 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5155 - accuracy: 0.3004 - val_loss: 0.4578 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3951 - accuracy: 0.4115 - val_loss: 0.4726 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3617 - accuracy: 0.4318 - val_loss: 0.4617 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3081 - accuracy: 0.5200 - val_loss: 0.4580 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2948 - accuracy: 0.5449 - val_loss: 0.4479 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2655 - accuracy: 0.6083 - val_loss: 0.4481 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2274 - accuracy: 0.6672 - val_loss: 0.4799 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1984 - accuracy: 0.7215 - val_loss: 0.4910 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1895 - accuracy: 0.7397 - val_loss: 0.4754 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1983 - accuracy: 0.7347 - val_loss: 0.5104 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1475 - accuracy: 0.8001 - val_loss: 0.4930 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1200 - accuracy: 0.8356 - val_loss: 0.4863 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1117 - accuracy: 0.8519 - val_loss: 0.4998 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1041 - accuracy: 0.8666 - val_loss: 0.4994 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0996 - accuracy: 0.8706 - val_loss: 0.4977 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4443 - accuracy: 0.3503\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.350 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 16.3008 - accuracy: 0.2091 - val_loss: 6.9387 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.1344 - accuracy: 0.2873 - val_loss: 3.7083 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.8754 - accuracy: 0.2919 - val_loss: 1.5015 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1121 - accuracy: 0.2985 - val_loss: 1.1896 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6237 - accuracy: 0.2761 - val_loss: 0.7126 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5603 - accuracy: 0.2513 - val_loss: 0.5376 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4777 - accuracy: 0.2629 - val_loss: 0.7299 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4457 - accuracy: 0.3051 - val_loss: 0.4680 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4310 - accuracy: 0.3137 - val_loss: 0.4195 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3979 - accuracy: 0.3690 - val_loss: 0.5456 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3690 - accuracy: 0.3812 - val_loss: 0.6157 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3658 - accuracy: 0.4076 - val_loss: 0.6232 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3697 - accuracy: 0.4269 - val_loss: 0.4161 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3223 - accuracy: 0.4772 - val_loss: 0.4528 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3141 - accuracy: 0.5086 - val_loss: 0.4074 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3011 - accuracy: 0.5102 - val_loss: 0.4090 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2915 - accuracy: 0.5325 - val_loss: 0.5079 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2818 - accuracy: 0.5503 - val_loss: 0.5376 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2893 - accuracy: 0.5695 - val_loss: 0.4610 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2675 - accuracy: 0.5924 - val_loss: 0.4430 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4157 - accuracy: 0.4178\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.418 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 12.3264 - accuracy: 0.2258 - val_loss: 9.4183 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5840 - accuracy: 0.3156 - val_loss: 1.7684 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6277 - accuracy: 0.3592 - val_loss: 1.9953 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1550 - accuracy: 0.3881 - val_loss: 1.0767 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0018 - accuracy: 0.4302 - val_loss: 1.1689 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.8577 - accuracy: 0.4500 - val_loss: 1.3589 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6962 - accuracy: 0.5104 - val_loss: 0.7851 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6057 - accuracy: 0.5317 - val_loss: 1.2678 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5150 - accuracy: 0.5652 - val_loss: 1.1714 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4488 - accuracy: 0.5972 - val_loss: 0.8724 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4356 - accuracy: 0.6413 - val_loss: 0.7654 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3849 - accuracy: 0.6657 - val_loss: 0.7294 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3362 - accuracy: 0.6870 - val_loss: 0.8033 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3125 - accuracy: 0.7174 - val_loss: 0.8465 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3298 - accuracy: 0.7412 - val_loss: 0.8387 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2384 - accuracy: 0.7686 - val_loss: 1.1566 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2306 - accuracy: 0.7889 - val_loss: 1.0689 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1135 - accuracy: 0.8787 - val_loss: 0.7647 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0563 - accuracy: 0.9386 - val_loss: 0.7713 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0447 - accuracy: 0.9619 - val_loss: 0.7773 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.7733 - accuracy: 0.4914\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.491 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.4303 - accuracy: 0.2121 - val_loss: 2.7728 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6942 - accuracy: 0.3009 - val_loss: 1.8511 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5430 - accuracy: 0.3166 - val_loss: 1.1423 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.8848 - accuracy: 0.3902 - val_loss: 1.8346 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7930 - accuracy: 0.4348 - val_loss: 0.8140 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6432 - accuracy: 0.4515 - val_loss: 1.0543 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5439 - accuracy: 0.5348 - val_loss: 0.7910 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4646 - accuracy: 0.5637 - val_loss: 0.5889 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3604 - accuracy: 0.6256 - val_loss: 0.6966 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3314 - accuracy: 0.6479 - val_loss: 0.8401 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3007 - accuracy: 0.6895 - val_loss: 0.4910 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2707 - accuracy: 0.7215 - val_loss: 0.4999 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2397 - accuracy: 0.7311 - val_loss: 0.6772 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2170 - accuracy: 0.7859 - val_loss: 0.5277 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2064 - accuracy: 0.8042 - val_loss: 0.7883 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1751 - accuracy: 0.8321 - val_loss: 0.6238 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0622 - accuracy: 0.9432 - val_loss: 0.5357 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0501 - accuracy: 0.9625 - val_loss: 0.5817 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0433 - accuracy: 0.9660 - val_loss: 0.5485 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0380 - accuracy: 0.9751 - val_loss: 0.5789 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.6191 - accuracy: 0.4731\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.473 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.7286 - accuracy: 0.2467 - val_loss: 2.1646 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.5378 - accuracy: 0.3914 - val_loss: 1.8009 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9709 - accuracy: 0.5513 - val_loss: 1.2120 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5657 - accuracy: 0.6741 - val_loss: 1.1775 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3890 - accuracy: 0.7558 - val_loss: 1.4453 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3810 - accuracy: 0.7995 - val_loss: 1.5860 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3211 - accuracy: 0.8198 - val_loss: 1.1809 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1406 - accuracy: 0.9254 - val_loss: 1.1085 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1338 - accuracy: 0.9345 - val_loss: 1.0428 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1064 - accuracy: 0.9543 - val_loss: 1.1561 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0994 - accuracy: 0.9619 - val_loss: 1.2676 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0971 - accuracy: 0.9569 - val_loss: 1.2814 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0740 - accuracy: 0.9812 - val_loss: 1.2356 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0748 - accuracy: 0.9716 - val_loss: 1.2568 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 1.1444 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 1.1396 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 1.1414 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 1.1340 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 1.1378 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.9897 - accuracy: 0.4848\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.485 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.0997 - accuracy: 0.2445 - val_loss: 4.7656 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.2088 - accuracy: 0.4668 - val_loss: 2.1461 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8336 - accuracy: 0.6616 - val_loss: 1.7626 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5194 - accuracy: 0.7433 - val_loss: 1.6808 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3796 - accuracy: 0.7889 - val_loss: 1.9178 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2953 - accuracy: 0.8463 - val_loss: 1.4536 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1803 - accuracy: 0.9082 - val_loss: 1.7274 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1576 - accuracy: 0.9153 - val_loss: 1.5488 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1314 - accuracy: 0.9406 - val_loss: 1.6309 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1702 - accuracy: 0.9214 - val_loss: 1.6783 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1473 - accuracy: 0.9417 - val_loss: 1.5920 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 1.4001 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 1.3874 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3754 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.5108 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 1.2778 - accuracy: 0.5076\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.508 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.0984 - accuracy: 0.2704 - val_loss: 2.9347 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.0989 - accuracy: 0.4394 - val_loss: 2.3632 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9700 - accuracy: 0.6372 - val_loss: 1.4591 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4942 - accuracy: 0.7610 - val_loss: 1.5753 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3559 - accuracy: 0.8067 - val_loss: 1.4308 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2638 - accuracy: 0.8691 - val_loss: 1.4862 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1446 - accuracy: 0.9269 - val_loss: 1.5721 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0883 - accuracy: 0.9579 - val_loss: 1.3057 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0534 - accuracy: 0.9767 - val_loss: 1.2541 - val_accuracy: 0.5135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0641 - accuracy: 0.9746 - val_loss: 1.4448 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 1.4330 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 1.4112 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0522 - accuracy: 0.9873 - val_loss: 1.6171 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 1.7047 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 1.3309 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3192 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.4510 - accuracy: 0.4995\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.499 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.0688 - accuracy: 0.1863 - val_loss: 6.7405 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5562 - accuracy: 0.2381 - val_loss: 1.1755 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9845 - accuracy: 0.2264 - val_loss: 0.7389 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5696 - accuracy: 0.1898 - val_loss: 0.5176 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4995 - accuracy: 0.1858 - val_loss: 0.4668 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5126 - accuracy: 0.1949 - val_loss: 0.4820 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4786 - accuracy: 0.2081 - val_loss: 0.5365 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4701 - accuracy: 0.2223 - val_loss: 0.4585 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4464 - accuracy: 0.2213 - val_loss: 0.4709 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4360 - accuracy: 0.2350 - val_loss: 0.4664 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4211 - accuracy: 0.2421 - val_loss: 0.4164 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4026 - accuracy: 0.2371 - val_loss: 0.4268 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3857 - accuracy: 0.2609 - val_loss: 0.4182 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3815 - accuracy: 0.2782 - val_loss: 0.4115 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3759 - accuracy: 0.2949 - val_loss: 0.4115 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3677 - accuracy: 0.3132 - val_loss: 0.4408 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3664 - accuracy: 0.3127 - val_loss: 0.4283 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3537 - accuracy: 0.3396 - val_loss: 0.5111 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4151 - accuracy: 0.3472 - val_loss: 0.4242 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3265 - accuracy: 0.3558 - val_loss: 0.4319 - val_accuracy: 0.2568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4185 - accuracy: 0.2677\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.268 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 13.9954 - accuracy: 0.2131 - val_loss: 3.0591 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.2401 - accuracy: 0.3090 - val_loss: 0.9560 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7502 - accuracy: 0.2308 - val_loss: 0.5149 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5030 - accuracy: 0.2171 - val_loss: 0.5077 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4801 - accuracy: 0.2374 - val_loss: 0.4599 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4776 - accuracy: 0.2486 - val_loss: 0.5172 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4455 - accuracy: 0.2988 - val_loss: 0.4444 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4128 - accuracy: 0.3029 - val_loss: 0.4335 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3987 - accuracy: 0.3222 - val_loss: 0.3949 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3847 - accuracy: 0.3455 - val_loss: 0.4087 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3613 - accuracy: 0.3374 - val_loss: 0.4019 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3515 - accuracy: 0.3450 - val_loss: 0.4842 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3413 - accuracy: 0.3785 - val_loss: 0.4174 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3624 - accuracy: 0.4074 - val_loss: 0.5214 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2893 - accuracy: 0.4566 - val_loss: 0.4527 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2742 - accuracy: 0.4617 - val_loss: 0.4518 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2670 - accuracy: 0.4713 - val_loss: 0.4615 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2624 - accuracy: 0.4810 - val_loss: 0.4754 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2592 - accuracy: 0.4901 - val_loss: 0.4700 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4599 - accuracy: 0.2751\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.275 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.3090 - accuracy: 0.1938 - val_loss: 4.1237 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.1433 - accuracy: 0.3029 - val_loss: 1.9857 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.8178 - accuracy: 0.3628 - val_loss: 1.3559 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1489 - accuracy: 0.3683 - val_loss: 1.2563 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7567 - accuracy: 0.3902 - val_loss: 0.5928 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4759 - accuracy: 0.3765 - val_loss: 0.5045 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4298 - accuracy: 0.4099 - val_loss: 0.5129 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4045 - accuracy: 0.4571 - val_loss: 0.5230 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3648 - accuracy: 0.5084 - val_loss: 0.4753 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3614 - accuracy: 0.5145 - val_loss: 0.5251 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3376 - accuracy: 0.5408 - val_loss: 0.7912 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3018 - accuracy: 0.5906 - val_loss: 0.5432 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3060 - accuracy: 0.6225 - val_loss: 0.4936 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2639 - accuracy: 0.6570 - val_loss: 0.5343 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1817 - accuracy: 0.7316 - val_loss: 0.5133 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1430 - accuracy: 0.7839 - val_loss: 0.5401 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1276 - accuracy: 0.8057 - val_loss: 0.5485 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1175 - accuracy: 0.8229 - val_loss: 0.5780 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1097 - accuracy: 0.8311 - val_loss: 0.6081 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.5248 - accuracy: 0.3726\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.373 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.2526 - accuracy: 0.2548 - val_loss: 2.4995 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6491 - accuracy: 0.4807 - val_loss: 1.6375 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7565 - accuracy: 0.6076 - val_loss: 1.3089 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4283 - accuracy: 0.7365 - val_loss: 1.1571 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3489 - accuracy: 0.7731 - val_loss: 1.0421 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2159 - accuracy: 0.8457 - val_loss: 0.9606 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1487 - accuracy: 0.8904 - val_loss: 0.9579 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1312 - accuracy: 0.9188 - val_loss: 1.1841 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0976 - accuracy: 0.9269 - val_loss: 1.2708 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0631 - accuracy: 0.9599 - val_loss: 1.0406 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0258 - accuracy: 0.9888 - val_loss: 1.0863 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9975 - val_loss: 1.0645 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 1.0319 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0345 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.8288 - accuracy: 0.4939\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.494 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.7317 - accuracy: 0.2567 - val_loss: 1.5107 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0757 - accuracy: 0.4110 - val_loss: 1.2117 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5273 - accuracy: 0.5302 - val_loss: 0.7017 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3895 - accuracy: 0.5530 - val_loss: 0.5481 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3193 - accuracy: 0.5890 - val_loss: 0.5504 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2585 - accuracy: 0.6728 - val_loss: 0.4708 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2063 - accuracy: 0.7321 - val_loss: 0.5330 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1626 - accuracy: 0.8102 - val_loss: 0.5368 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1595 - accuracy: 0.8341 - val_loss: 0.6050 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1550 - accuracy: 0.8194 - val_loss: 0.5804 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0943 - accuracy: 0.9001 - val_loss: 0.6271 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0506 - accuracy: 0.9543 - val_loss: 0.5681 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0372 - accuracy: 0.9665 - val_loss: 0.5677 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0346 - accuracy: 0.9696 - val_loss: 0.5597 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0301 - accuracy: 0.9767 - val_loss: 0.5669 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0278 - accuracy: 0.9792 - val_loss: 0.5765 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4896 - accuracy: 0.4213\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.421 total time=  54.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.9616 - accuracy: 0.2461 - val_loss: 2.2350 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.2614 - accuracy: 0.4622 - val_loss: 1.2905 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7221 - accuracy: 0.5606 - val_loss: 0.9237 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3526 - accuracy: 0.7057 - val_loss: 0.7974 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2003 - accuracy: 0.8077 - val_loss: 0.6290 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1214 - accuracy: 0.8879 - val_loss: 0.7586 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0923 - accuracy: 0.9254 - val_loss: 0.7402 - val_accuracy: 0.5122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0758 - accuracy: 0.9528 - val_loss: 0.7404 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0541 - accuracy: 0.9731 - val_loss: 0.6978 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0428 - accuracy: 0.9741 - val_loss: 0.7877 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.7296 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.7248 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.7237 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.7086 - accuracy: 0.4558\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.456 total time=  51.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.9562 - accuracy: 0.1924 - val_loss: 1.0761 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4575 - accuracy: 0.2772 - val_loss: 0.4428 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3904 - accuracy: 0.3452 - val_loss: 0.3923 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3546 - accuracy: 0.4228 - val_loss: 0.4019 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3088 - accuracy: 0.5168 - val_loss: 0.4220 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2824 - accuracy: 0.5614 - val_loss: 0.4093 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2420 - accuracy: 0.6431 - val_loss: 0.4202 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2085 - accuracy: 0.7051 - val_loss: 0.4238 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1295 - accuracy: 0.8208 - val_loss: 0.4147 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1097 - accuracy: 0.8553 - val_loss: 0.4327 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0978 - accuracy: 0.8736 - val_loss: 0.4408 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0897 - accuracy: 0.8843 - val_loss: 0.4444 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0826 - accuracy: 0.8939 - val_loss: 0.4574 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4055 - accuracy: 0.2972\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.297 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.3930 - accuracy: 0.1923 - val_loss: 0.4846 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4380 - accuracy: 0.2968 - val_loss: 0.4483 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3841 - accuracy: 0.3729 - val_loss: 0.4050 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3377 - accuracy: 0.4723 - val_loss: 0.4211 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2957 - accuracy: 0.5378 - val_loss: 0.4169 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2611 - accuracy: 0.6124 - val_loss: 0.4871 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2372 - accuracy: 0.6474 - val_loss: 0.4465 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2012 - accuracy: 0.7194 - val_loss: 0.4843 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1297 - accuracy: 0.8204 - val_loss: 0.4406 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1070 - accuracy: 0.8519 - val_loss: 0.4470 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0964 - accuracy: 0.8656 - val_loss: 0.4571 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0869 - accuracy: 0.8828 - val_loss: 0.4851 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0788 - accuracy: 0.8929 - val_loss: 0.4943 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4133 - accuracy: 0.3157\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.316 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.1389 - accuracy: 0.1953 - val_loss: 0.4521 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4414 - accuracy: 0.2664 - val_loss: 0.4617 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3899 - accuracy: 0.3501 - val_loss: 0.4241 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3501 - accuracy: 0.4338 - val_loss: 0.4072 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3146 - accuracy: 0.5079 - val_loss: 0.4534 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2827 - accuracy: 0.5865 - val_loss: 0.3989 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2495 - accuracy: 0.6494 - val_loss: 0.4131 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2141 - accuracy: 0.7002 - val_loss: 0.5108 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1900 - accuracy: 0.7433 - val_loss: 0.5876 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1657 - accuracy: 0.7727 - val_loss: 0.5399 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1435 - accuracy: 0.8031 - val_loss: 0.5371 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0800 - accuracy: 0.8864 - val_loss: 0.5063 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0662 - accuracy: 0.9041 - val_loss: 0.5368 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0582 - accuracy: 0.9168 - val_loss: 0.5479 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0522 - accuracy: 0.9229 - val_loss: 0.5825 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0476 - accuracy: 0.9325 - val_loss: 0.5928 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4103 - accuracy: 0.3909\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.391 total time=  55.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.9177 - accuracy: 0.1980 - val_loss: 0.4396 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4005 - accuracy: 0.3305 - val_loss: 0.4009 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3427 - accuracy: 0.4477 - val_loss: 0.3960 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2946 - accuracy: 0.5386 - val_loss: 0.4040 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2637 - accuracy: 0.6066 - val_loss: 0.3826 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2193 - accuracy: 0.6838 - val_loss: 0.3731 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1865 - accuracy: 0.7442 - val_loss: 0.4130 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1611 - accuracy: 0.7883 - val_loss: 0.4290 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1403 - accuracy: 0.8213 - val_loss: 0.5313 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1390 - accuracy: 0.8213 - val_loss: 0.4718 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1109 - accuracy: 0.8629 - val_loss: 0.4981 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0665 - accuracy: 0.9249 - val_loss: 0.4537 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0548 - accuracy: 0.9376 - val_loss: 0.4592 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0500 - accuracy: 0.9447 - val_loss: 0.4655 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0463 - accuracy: 0.9497 - val_loss: 0.4650 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0432 - accuracy: 0.9543 - val_loss: 0.4733 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3841 - accuracy: 0.4249\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.425 total time=  54.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.8792 - accuracy: 0.2212 - val_loss: 0.4916 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4020 - accuracy: 0.3638 - val_loss: 0.4299 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3346 - accuracy: 0.4830 - val_loss: 0.4009 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2736 - accuracy: 0.5961 - val_loss: 0.3947 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2202 - accuracy: 0.7007 - val_loss: 0.4170 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1713 - accuracy: 0.7747 - val_loss: 0.4408 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1301 - accuracy: 0.8442 - val_loss: 0.4684 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0966 - accuracy: 0.8929 - val_loss: 0.4745 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0700 - accuracy: 0.9254 - val_loss: 0.5264 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0358 - accuracy: 0.9756 - val_loss: 0.5067 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0285 - accuracy: 0.9822 - val_loss: 0.5165 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0247 - accuracy: 0.9868 - val_loss: 0.5238 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0221 - accuracy: 0.9909 - val_loss: 0.5337 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.5470 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4004 - accuracy: 0.3797\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.380 total time=  47.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9308 - accuracy: 0.2207 - val_loss: 0.4652 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3975 - accuracy: 0.3952 - val_loss: 0.4221 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3142 - accuracy: 0.5185 - val_loss: 0.3853 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2590 - accuracy: 0.6469 - val_loss: 0.4066 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2331 - accuracy: 0.6895 - val_loss: 0.4214 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1816 - accuracy: 0.7763 - val_loss: 0.4092 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1354 - accuracy: 0.8468 - val_loss: 0.4219 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1128 - accuracy: 0.8889 - val_loss: 0.4568 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0636 - accuracy: 0.9564 - val_loss: 0.4147 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0505 - accuracy: 0.9711 - val_loss: 0.4185 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0463 - accuracy: 0.9751 - val_loss: 0.4239 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0424 - accuracy: 0.9782 - val_loss: 0.4299 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0393 - accuracy: 0.9792 - val_loss: 0.4351 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4005 - accuracy: 0.3482\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.348 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.9974 - accuracy: 0.1817 - val_loss: 0.5140 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4630 - accuracy: 0.2076 - val_loss: 0.4774 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4398 - accuracy: 0.2457 - val_loss: 0.4967 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4207 - accuracy: 0.3030 - val_loss: 0.4597 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4012 - accuracy: 0.3558 - val_loss: 0.4882 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3661 - accuracy: 0.4310 - val_loss: 0.4950 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3453 - accuracy: 0.4721 - val_loss: 0.4249 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3178 - accuracy: 0.5234 - val_loss: 0.5614 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2853 - accuracy: 0.5614 - val_loss: 0.4912 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2770 - accuracy: 0.6091 - val_loss: 0.5243 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2502 - accuracy: 0.6223 - val_loss: 0.5238 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2286 - accuracy: 0.6721 - val_loss: 0.5437 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1740 - accuracy: 0.7147 - val_loss: 0.4905 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1489 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1376 - accuracy: 0.7640 - val_loss: 0.5095 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1293 - accuracy: 0.7817 - val_loss: 0.5403 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1242 - accuracy: 0.7888 - val_loss: 0.5499 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4146 - accuracy: 0.3195\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.319 total time=  58.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.1148 - accuracy: 0.1735 - val_loss: 0.4966 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4708 - accuracy: 0.1989 - val_loss: 0.4685 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4432 - accuracy: 0.2699 - val_loss: 0.4058 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4054 - accuracy: 0.3415 - val_loss: 0.4029 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3840 - accuracy: 0.3805 - val_loss: 0.4439 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3532 - accuracy: 0.4191 - val_loss: 0.4583 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3264 - accuracy: 0.4800 - val_loss: 0.5167 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3084 - accuracy: 0.5175 - val_loss: 0.4063 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2898 - accuracy: 0.5327 - val_loss: 0.4621 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2264 - accuracy: 0.6240 - val_loss: 0.4223 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2076 - accuracy: 0.6438 - val_loss: 0.4222 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1972 - accuracy: 0.6646 - val_loss: 0.4267 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1888 - accuracy: 0.6763 - val_loss: 0.4316 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1819 - accuracy: 0.6875 - val_loss: 0.4330 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4214 - accuracy: 0.2914\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.291 total time=  49.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.5116 - accuracy: 0.1842 - val_loss: 0.4772 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4609 - accuracy: 0.2131 - val_loss: 0.4937 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4363 - accuracy: 0.2593 - val_loss: 0.4252 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.3201 - val_loss: 0.4541 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3734 - accuracy: 0.3912 - val_loss: 0.4981 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3384 - accuracy: 0.4541 - val_loss: 0.4465 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3162 - accuracy: 0.5104 - val_loss: 0.4876 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2960 - accuracy: 0.5515 - val_loss: 0.4681 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2091 - accuracy: 0.6494 - val_loss: 0.4668 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1894 - accuracy: 0.6865 - val_loss: 0.4767 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1774 - accuracy: 0.7057 - val_loss: 0.4978 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1688 - accuracy: 0.7179 - val_loss: 0.4940 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1602 - accuracy: 0.7311 - val_loss: 0.4939 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4267 - accuracy: 0.2650\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.265 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.8589 - accuracy: 0.1904 - val_loss: 0.4509 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4337 - accuracy: 0.2437 - val_loss: 0.4244 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3901 - accuracy: 0.3193 - val_loss: 0.4194 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3560 - accuracy: 0.3939 - val_loss: 0.4123 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3208 - accuracy: 0.4812 - val_loss: 0.3786 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2929 - accuracy: 0.5320 - val_loss: 0.3848 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2676 - accuracy: 0.5843 - val_loss: 0.4115 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2448 - accuracy: 0.6315 - val_loss: 0.3995 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2175 - accuracy: 0.6777 - val_loss: 0.4261 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1880 - accuracy: 0.7284 - val_loss: 0.4280 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1429 - accuracy: 0.7985 - val_loss: 0.4338 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1258 - accuracy: 0.8178 - val_loss: 0.4354 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1185 - accuracy: 0.8274 - val_loss: 0.4495 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1120 - accuracy: 0.8330 - val_loss: 0.4421 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1065 - accuracy: 0.8447 - val_loss: 0.4524 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3920 - accuracy: 0.3327\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.333 total time=  51.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.3386 - accuracy: 0.2171 - val_loss: 0.6290 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4429 - accuracy: 0.3648 - val_loss: 0.4480 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3289 - accuracy: 0.5216 - val_loss: 0.4239 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2765 - accuracy: 0.5967 - val_loss: 0.4264 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2508 - accuracy: 0.6504 - val_loss: 0.4352 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1928 - accuracy: 0.7412 - val_loss: 0.4625 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1667 - accuracy: 0.8047 - val_loss: 0.4861 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1435 - accuracy: 0.8168 - val_loss: 0.4837 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0819 - accuracy: 0.9209 - val_loss: 0.4599 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0676 - accuracy: 0.9411 - val_loss: 0.4604 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0604 - accuracy: 0.9528 - val_loss: 0.4672 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0558 - accuracy: 0.9609 - val_loss: 0.4669 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0517 - accuracy: 0.9640 - val_loss: 0.4729 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4438 - accuracy: 0.3756\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.376 total time=  44.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.9468 - accuracy: 0.1700 - val_loss: 0.4394 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4276 - accuracy: 0.1892 - val_loss: 0.4399 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4095 - accuracy: 0.2501 - val_loss: 0.4206 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3762 - accuracy: 0.3232 - val_loss: 0.4232 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3489 - accuracy: 0.3810 - val_loss: 0.4067 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3355 - accuracy: 0.4328 - val_loss: 0.4625 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3133 - accuracy: 0.4830 - val_loss: 0.4127 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2729 - accuracy: 0.5581 - val_loss: 0.4290 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2669 - accuracy: 0.5632 - val_loss: 0.4569 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2711 - accuracy: 0.5713 - val_loss: 0.4693 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2161 - accuracy: 0.6697 - val_loss: 0.4184 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1881 - accuracy: 0.7169 - val_loss: 0.4170 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1767 - accuracy: 0.7362 - val_loss: 0.4167 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1673 - accuracy: 0.7534 - val_loss: 0.4252 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1603 - accuracy: 0.7595 - val_loss: 0.4241 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4202 - accuracy: 0.2721\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.272 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 1.4700 - accuracy: 0.1873 - val_loss: 0.5629 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4871 - accuracy: 0.2782 - val_loss: 0.4211 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4043 - accuracy: 0.3914 - val_loss: 0.4503 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3448 - accuracy: 0.4670 - val_loss: 0.4159 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2876 - accuracy: 0.5736 - val_loss: 0.4697 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2614 - accuracy: 0.6249 - val_loss: 0.3906 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2150 - accuracy: 0.7091 - val_loss: 0.4349 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1819 - accuracy: 0.7640 - val_loss: 0.5132 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1575 - accuracy: 0.8030 - val_loss: 0.5679 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1322 - accuracy: 0.8452 - val_loss: 0.5645 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1120 - accuracy: 0.8635 - val_loss: 0.8196 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0428 - accuracy: 0.9589 - val_loss: 0.5906 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0286 - accuracy: 0.9741 - val_loss: 0.6143 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0229 - accuracy: 0.9812 - val_loss: 0.6316 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0180 - accuracy: 0.9868 - val_loss: 0.6914 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0148 - accuracy: 0.9878 - val_loss: 0.7127 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3817 - accuracy: 0.4118\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.412 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.3149 - accuracy: 0.2212 - val_loss: 0.6311 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4623 - accuracy: 0.3125 - val_loss: 0.4256 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3875 - accuracy: 0.3856 - val_loss: 0.3893 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3293 - accuracy: 0.4881 - val_loss: 0.4872 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2872 - accuracy: 0.5748 - val_loss: 0.4331 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2472 - accuracy: 0.6413 - val_loss: 0.4005 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1987 - accuracy: 0.7270 - val_loss: 0.4978 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1852 - accuracy: 0.7681 - val_loss: 0.4928 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0963 - accuracy: 0.8904 - val_loss: 0.4666 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0770 - accuracy: 0.9127 - val_loss: 0.4810 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0667 - accuracy: 0.9264 - val_loss: 0.4961 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0588 - accuracy: 0.9381 - val_loss: 0.5152 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0504 - accuracy: 0.9533 - val_loss: 0.5429 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4039 - accuracy: 0.3340\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.334 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 1.7854 - accuracy: 0.2014 - val_loss: 0.5310 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4735 - accuracy: 0.3019 - val_loss: 0.4217 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4001 - accuracy: 0.3912 - val_loss: 0.4008 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3516 - accuracy: 0.4688 - val_loss: 0.4513 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2933 - accuracy: 0.5540 - val_loss: 0.4440 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2502 - accuracy: 0.6403 - val_loss: 0.5609 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2079 - accuracy: 0.7215 - val_loss: 0.4195 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1904 - accuracy: 0.7448 - val_loss: 0.4677 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1046 - accuracy: 0.8721 - val_loss: 0.4301 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0772 - accuracy: 0.9122 - val_loss: 0.4466 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0653 - accuracy: 0.9274 - val_loss: 0.4640 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0557 - accuracy: 0.9437 - val_loss: 0.4967 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0485 - accuracy: 0.9538 - val_loss: 0.5188 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4151 - accuracy: 0.3198\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.320 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.3284 - accuracy: 0.2178 - val_loss: 0.6541 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4384 - accuracy: 0.4325 - val_loss: 0.4551 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3119 - accuracy: 0.5751 - val_loss: 0.4566 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2335 - accuracy: 0.7061 - val_loss: 0.4151 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1793 - accuracy: 0.7975 - val_loss: 0.4434 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1325 - accuracy: 0.8711 - val_loss: 0.4696 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0942 - accuracy: 0.9350 - val_loss: 0.4671 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0955 - accuracy: 0.9264 - val_loss: 0.5030 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0712 - accuracy: 0.9574 - val_loss: 0.5254 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0385 - accuracy: 0.9909 - val_loss: 0.4963 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0259 - accuracy: 0.9970 - val_loss: 0.4981 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 0.5008 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.5053 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.5093 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4006 - accuracy: 0.4645\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.465 total time=  48.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.4306 - accuracy: 0.2603 - val_loss: 0.8863 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4525 - accuracy: 0.4505 - val_loss: 0.4760 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2904 - accuracy: 0.6038 - val_loss: 0.4472 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2023 - accuracy: 0.7509 - val_loss: 0.4327 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1529 - accuracy: 0.8427 - val_loss: 0.4798 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1215 - accuracy: 0.8838 - val_loss: 0.4589 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0908 - accuracy: 0.9351 - val_loss: 0.5032 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0728 - accuracy: 0.9503 - val_loss: 0.5767 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0650 - accuracy: 0.9579 - val_loss: 0.5086 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.5087 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0224 - accuracy: 0.9970 - val_loss: 0.5107 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0200 - accuracy: 0.9980 - val_loss: 0.5172 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0182 - accuracy: 0.9995 - val_loss: 0.5229 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 0.5285 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4195 - accuracy: 0.4548\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.455 total time=  48.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.3174 - accuracy: 0.2141 - val_loss: 0.5482 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4380 - accuracy: 0.4084 - val_loss: 0.4325 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3159 - accuracy: 0.5576 - val_loss: 0.4485 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2404 - accuracy: 0.6646 - val_loss: 0.4072 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1805 - accuracy: 0.7742 - val_loss: 0.4168 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1390 - accuracy: 0.8605 - val_loss: 0.4234 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1079 - accuracy: 0.9066 - val_loss: 0.4703 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0886 - accuracy: 0.9310 - val_loss: 0.4595 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0825 - accuracy: 0.9391 - val_loss: 0.4906 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 0.4801 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0301 - accuracy: 0.9934 - val_loss: 0.4758 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0259 - accuracy: 0.9964 - val_loss: 0.4815 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0237 - accuracy: 0.9970 - val_loss: 0.4837 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0218 - accuracy: 0.9970 - val_loss: 0.4869 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4408 - accuracy: 0.4142\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.414 total time=  47.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.5718 - accuracy: 0.1878 - val_loss: 0.7332 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5610 - accuracy: 0.2609 - val_loss: 0.4548 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4490 - accuracy: 0.3107 - val_loss: 0.6866 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3988 - accuracy: 0.3832 - val_loss: 0.5234 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3510 - accuracy: 0.4706 - val_loss: 0.4188 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3068 - accuracy: 0.5665 - val_loss: 0.4369 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2675 - accuracy: 0.6081 - val_loss: 0.4452 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2339 - accuracy: 0.6701 - val_loss: 0.5750 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2134 - accuracy: 0.7239 - val_loss: 0.5070 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1800 - accuracy: 0.7579 - val_loss: 0.5608 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1022 - accuracy: 0.8543 - val_loss: 0.4727 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0791 - accuracy: 0.8888 - val_loss: 0.4957 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0695 - accuracy: 0.9005 - val_loss: 0.5083 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0621 - accuracy: 0.9157 - val_loss: 0.5320 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0555 - accuracy: 0.9254 - val_loss: 0.5557 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4270 - accuracy: 0.3692\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.369 total time=  53.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 2.5489 - accuracy: 0.2243 - val_loss: 0.9351 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5142 - accuracy: 0.2714 - val_loss: 0.4617 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4281 - accuracy: 0.3176 - val_loss: 0.5260 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3928 - accuracy: 0.4170 - val_loss: 0.4637 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3349 - accuracy: 0.4926 - val_loss: 0.4355 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3231 - accuracy: 0.5403 - val_loss: 0.4566 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2718 - accuracy: 0.6083 - val_loss: 0.4565 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2425 - accuracy: 0.6545 - val_loss: 0.5005 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2161 - accuracy: 0.6991 - val_loss: 0.4998 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1845 - accuracy: 0.7549 - val_loss: 0.6107 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1127 - accuracy: 0.8442 - val_loss: 0.4925 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0885 - accuracy: 0.8803 - val_loss: 0.5073 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0788 - accuracy: 0.8929 - val_loss: 0.5203 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0708 - accuracy: 0.9087 - val_loss: 0.5463 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0644 - accuracy: 0.9168 - val_loss: 0.5559 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4725 - accuracy: 0.3289\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.329 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 2.7738 - accuracy: 0.1928 - val_loss: 0.7901 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5683 - accuracy: 0.2801 - val_loss: 0.5519 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4665 - accuracy: 0.3278 - val_loss: 0.4504 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3919 - accuracy: 0.4028 - val_loss: 0.4215 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3405 - accuracy: 0.5003 - val_loss: 0.4161 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2964 - accuracy: 0.5728 - val_loss: 0.4201 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2646 - accuracy: 0.6372 - val_loss: 0.5464 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2292 - accuracy: 0.6849 - val_loss: 0.4725 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1995 - accuracy: 0.7078 - val_loss: 0.5129 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1650 - accuracy: 0.7884 - val_loss: 0.5056 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1034 - accuracy: 0.8625 - val_loss: 0.4851 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0782 - accuracy: 0.8924 - val_loss: 0.5211 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0686 - accuracy: 0.9036 - val_loss: 0.5178 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0609 - accuracy: 0.9188 - val_loss: 0.5383 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0540 - accuracy: 0.9300 - val_loss: 0.5622 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4498 - accuracy: 0.3685\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.369 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.5251 - accuracy: 0.2193 - val_loss: 0.7246 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5049 - accuracy: 0.3777 - val_loss: 0.5025 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3285 - accuracy: 0.5299 - val_loss: 0.5157 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2415 - accuracy: 0.6766 - val_loss: 0.4411 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1862 - accuracy: 0.7766 - val_loss: 0.4629 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.8558 - val_loss: 0.4851 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0913 - accuracy: 0.9325 - val_loss: 0.4901 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0663 - accuracy: 0.9569 - val_loss: 0.5430 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0583 - accuracy: 0.9548 - val_loss: 0.5644 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0285 - accuracy: 0.9934 - val_loss: 0.5538 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 0.5559 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.5596 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.5662 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.5725 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.3996 - accuracy: 0.4320\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.432 total time=  47.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.9432 - accuracy: 0.2486 - val_loss: 0.7832 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5377 - accuracy: 0.4211 - val_loss: 0.5269 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3237 - accuracy: 0.5677 - val_loss: 0.4693 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2392 - accuracy: 0.7144 - val_loss: 0.4877 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1943 - accuracy: 0.7752 - val_loss: 0.4678 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1554 - accuracy: 0.8366 - val_loss: 0.4514 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1077 - accuracy: 0.8924 - val_loss: 0.4938 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0752 - accuracy: 0.9427 - val_loss: 0.5210 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0495 - accuracy: 0.9772 - val_loss: 0.5553 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0328 - accuracy: 0.9868 - val_loss: 0.5519 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.6309 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 0.5910 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5954 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4666 - accuracy: 0.4437\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.444 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.5766 - accuracy: 0.2324 - val_loss: 0.6372 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4506 - accuracy: 0.3800 - val_loss: 0.4842 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3510 - accuracy: 0.5013 - val_loss: 0.4813 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2914 - accuracy: 0.5921 - val_loss: 0.4442 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2345 - accuracy: 0.6859 - val_loss: 0.4469 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2128 - accuracy: 0.7362 - val_loss: 0.4573 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.8371 - val_loss: 0.4825 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1041 - accuracy: 0.8879 - val_loss: 0.4803 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0713 - accuracy: 0.9315 - val_loss: 0.4907 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0376 - accuracy: 0.9817 - val_loss: 0.4940 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0306 - accuracy: 0.9868 - val_loss: 0.4980 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.4997 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.5075 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.5106 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4922 - accuracy: 0.3563\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.356 total time=  48.2s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 6s 56ms/step - loss: 6.1633 - accuracy: 0.2700 - val_loss: 4.4618 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.7228 - accuracy: 0.4533 - val_loss: 1.6559 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7875 - accuracy: 0.5907 - val_loss: 1.1847 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5867 - accuracy: 0.6644 - val_loss: 1.0168 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.3306 - accuracy: 0.7994 - val_loss: 1.0194 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.2066 - accuracy: 0.8572 - val_loss: 1.0069 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.1678 - accuracy: 0.8775 - val_loss: 0.9040 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1229 - accuracy: 0.9279 - val_loss: 0.9315 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0713 - accuracy: 0.9597 - val_loss: 0.9885 - val_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.0489 - accuracy: 0.9770 - val_loss: 0.9011 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0485 - accuracy: 0.9760 - val_loss: 0.9804 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0678 - accuracy: 0.9709 - val_loss: 1.0659 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1192 - accuracy: 0.9381 - val_loss: 1.0599 - val_accuracy: 0.5514 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0679 - accuracy: 0.9712 - val_loss: 1.1884 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1189 - accuracy: 0.9476 - val_loss: 1.1364 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 1.0720 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 1.0506 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 1.0451 - val_accuracy: 0.5541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.5527 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.5581 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_xception_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.75  \n",
    "InceptionV3: {'activation': 'softmax', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.43  \n",
    "ResNet50: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.76  \n",
    "Xception: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
