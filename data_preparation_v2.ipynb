{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.applications import vgg16, inception_v3, resnet, xception\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(target_size):\n",
    "    x, y = [], []\n",
    "    base_path = \"./data/images/\"\n",
    "\n",
    "    for dir in os.listdir(base_path):\n",
    "        for image in os.listdir(os.path.join(base_path, dir)):\n",
    "            image_path = os.path.join(base_path, dir, image)\n",
    "            image = Image.open(image_path)\n",
    "            rgb_image = image.copy().convert(\"RGB\")\n",
    "            x.append(np.array(rgb_image.resize(target_size), dtype=np.uint8))\n",
    "            y.append(dir)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"./data/metadata.csv\")\n",
    "meta_filter = metadata[[\"Channel\", \"Category\"]]\n",
    "meta_filter = meta_filter.drop_duplicates()\n",
    "meta_dict = meta_filter.set_index(\"Channel\")[\"Category\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: Abroad in Japan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[100])\n",
    "print(f\"class: {y[100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Science', 'Blog,Entertainment', 'Comedy,Informative', 'Tech', 'Automobile', 'Food,Entertainment', 'Food', 'Automobile,Comedy', 'VideoGames', 'Blog', 'Informative', 'Tech,Comedy', 'Entertainment', 'Comedy', 'News', 'Tech,News', 'Tech,Informative', 'Blog,Science', 'Entertainment,Comedy', 'Entertainment,Blog', 'Comedy,Entertainment', 'Blog,Comedy'}\n"
     ]
    }
   ],
   "source": [
    "print(set(meta_dict.values()))\n",
    "\n",
    "coarse_dict = {\n",
    "    'automotive': ['Automobile,Comedy', 'Automobile'],\n",
    "    'blog': ['Blog,Comedy', 'Blog,Entertainment', 'Blog', 'Blog,Science'],\n",
    "    'comedy': ['Comedy', 'Comedy,Informative', 'Comedy,Entertainment'],\n",
    "    'entertainment': ['Entertainment,Blog', 'Entertainment,Comedy', 'Entertainment'],\n",
    "    'food': ['Food', 'Food,Entertainment'],\n",
    "    'information': ['Science', 'News', 'Informative'],\n",
    "    'technology': ['VideoGames', 'Tech,Comedy', 'Tech,News', 'Tech,Informative', 'Tech'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fine = [meta_dict[item] for item in y]\n",
    "\n",
    "y_coarse = []\n",
    "for item in y_fine:\n",
    "    for key, value in coarse_dict.items():\n",
    "        if item in value:\n",
    "            y_coarse.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Fine: 2244 ---  Length Coarse: 2244\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length Fine: {len(y_fine)} ---  Length Coarse: {len(y_coarse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Tech,Informative --- Coarse: technology\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Entertainment --- Coarse: entertainment\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food,Entertainment --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Tech,Comedy --- Coarse: technology\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Blog --- Coarse: blog\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Comedy --- Coarse: comedy\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: Blog,Science --- Coarse: blog\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Blog,Entertainment --- Coarse: blog\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Comedy,Informative --- Coarse: comedy\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Blog,Comedy --- Coarse: blog\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech,News --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Food --- Coarse: food\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Entertainment,Comedy --- Coarse: entertainment\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Comedy,Entertainment --- Coarse: comedy\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Entertainment,Blog --- Coarse: entertainment\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Automobile,Comedy --- Coarse: automotive\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: News --- Coarse: information\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: VideoGames --- Coarse: technology\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Informative --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Science --- Coarse: information\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n",
      "Fine: Tech --- Coarse: technology\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(y_fine):\n",
    "    print(f\"Fine: {item} --- Coarse: {y_coarse[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blog': 234, 'comedy': 174, 'entertainment': 164, 'technology': 513, 'automotive': 261, 'information': 660, 'food': 238}\n"
     ]
    }
   ],
   "source": [
    "set_y_coarse = set(y_coarse)\n",
    "count_dict = {}\n",
    "for item in set_y_coarse:\n",
    "    count_dict[item] = y_coarse.count(item)\n",
    "\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/Data/CSV/distribution_v2.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Category\", \"Count\"])\n",
    "    for category, occurence in count_dict.items():\n",
    "        writer.writerow([category, occurence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_coarse)\n",
    "y_one_hot = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "x = np.array(x)\n",
    "n_samples, width, height, n_channels = x.shape\n",
    "\n",
    "x_flat = x.reshape(n_samples, -1)\n",
    "\n",
    "x, y_one_hot = sm.fit_resample(x_flat, y_one_hot)\n",
    "x = x.reshape(-1, width, height, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automotive       660\n",
      "blog             660\n",
      "comedy           660\n",
      "entertainment    660\n",
      "food             660\n",
      "information      660\n",
      "technology       660\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_distribution = pd.DataFrame([le.classes_[np.argmax(line)] for line in y_one_hot])\n",
    "print(value_distribution.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 2956 --- Validation Size: 740 --- Test Size: 924\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_one_hot, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "\n",
    "print(f\"Train Size: {len(y_train)} --- Validation Size: {len(y_val)} --- Test Size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x_test, \n",
    "    y_test,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn(n_filter_1, n_filter_2, kernel_size, pool_size, n_hidden, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(n_filter_1, kernel_size=kernel_size, activation=\"relu\", input_shape=target_size+(3,)))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Conv2D(n_filter_2, kernel_size=kernel_size, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(le.classes_), activation=activation))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-03), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 19ms/step - loss: 115.8884 - accuracy: 0.2076 - val_loss: 1.8121 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4751 - accuracy: 0.4964 - val_loss: 1.8476 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.8346 - accuracy: 0.7472 - val_loss: 1.7991 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4996 - accuracy: 0.8741 - val_loss: 2.2075 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3295 - accuracy: 0.9234 - val_loss: 2.3968 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2387 - accuracy: 0.9528 - val_loss: 2.5436 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.9655 - val_loss: 2.9875 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1478 - accuracy: 0.9711 - val_loss: 2.9448 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1153 - accuracy: 0.9726 - val_loss: 2.7896 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0867 - accuracy: 0.9782 - val_loss: 2.8741 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0836 - accuracy: 0.9787 - val_loss: 2.9257 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0788 - accuracy: 0.9817 - val_loss: 2.8681 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0615 - accuracy: 0.9853 - val_loss: 2.9276 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8589 - accuracy: 0.4199\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.420 total time=  17.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 114.3203 - accuracy: 0.1720 - val_loss: 1.8599 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6289 - accuracy: 0.4028 - val_loss: 1.8046 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0378 - accuracy: 0.6641 - val_loss: 1.6580 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5609 - accuracy: 0.8300 - val_loss: 1.6584 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3598 - accuracy: 0.8884 - val_loss: 1.7344 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2998 - accuracy: 0.9173 - val_loss: 1.7567 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2697 - accuracy: 0.9300 - val_loss: 2.0290 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2101 - accuracy: 0.9411 - val_loss: 2.4908 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1579 - accuracy: 0.9548 - val_loss: 2.1733 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1552 - accuracy: 0.9574 - val_loss: 2.1567 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1385 - accuracy: 0.9584 - val_loss: 2.2063 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1174 - accuracy: 0.9665 - val_loss: 2.2134 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1099 - accuracy: 0.9645 - val_loss: 2.1756 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.6969 - accuracy: 0.4051\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.405 total time=  11.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 156.4781 - accuracy: 0.1603 - val_loss: 1.8705 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7517 - accuracy: 0.2765 - val_loss: 1.7463 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4679 - accuracy: 0.4054 - val_loss: 1.5807 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1954 - accuracy: 0.5079 - val_loss: 1.4877 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0271 - accuracy: 0.5743 - val_loss: 1.4915 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8819 - accuracy: 0.6357 - val_loss: 1.4699 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7707 - accuracy: 0.6814 - val_loss: 1.5070 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6793 - accuracy: 0.7093 - val_loss: 1.5324 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6317 - accuracy: 0.7362 - val_loss: 1.5187 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5340 - accuracy: 0.7768 - val_loss: 1.4927 - val_accuracy: 0.5716 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5304 - accuracy: 0.7834 - val_loss: 1.5566 - val_accuracy: 0.5486 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4878 - accuracy: 0.8016 - val_loss: 1.5461 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4717 - accuracy: 0.8021 - val_loss: 1.5365 - val_accuracy: 0.5622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4268 - accuracy: 0.8052 - val_loss: 1.6126 - val_accuracy: 0.5622 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4027 - accuracy: 0.8123 - val_loss: 1.6685 - val_accuracy: 0.5595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4125 - accuracy: 0.8204 - val_loss: 1.6052 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.4973 - accuracy: 0.4437\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.444 total time=  14.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 30.9719 - accuracy: 0.1706 - val_loss: 1.9142 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.8216 - accuracy: 0.2695 - val_loss: 1.8037 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6602 - accuracy: 0.3614 - val_loss: 1.7630 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.4216 - accuracy: 0.4624 - val_loss: 1.7628 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.2253 - accuracy: 0.5259 - val_loss: 1.6910 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.9955 - accuracy: 0.6513 - val_loss: 1.7444 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.8211 - accuracy: 0.6975 - val_loss: 1.7989 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6986 - accuracy: 0.7503 - val_loss: 1.8226 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5597 - accuracy: 0.8000 - val_loss: 1.9109 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5343 - accuracy: 0.8142 - val_loss: 2.0329 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4523 - accuracy: 0.8360 - val_loss: 1.9651 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4299 - accuracy: 0.8426 - val_loss: 1.9957 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3742 - accuracy: 0.8589 - val_loss: 2.0694 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3682 - accuracy: 0.8589 - val_loss: 2.0544 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3528 - accuracy: 0.8670 - val_loss: 2.1134 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6876 - accuracy: 0.4006\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.401 total time=  11.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 38.0436 - accuracy: 0.1649 - val_loss: 1.8990 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.6661 - accuracy: 0.3810 - val_loss: 1.7841 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.1864 - accuracy: 0.5961 - val_loss: 1.7094 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.8066 - accuracy: 0.7397 - val_loss: 1.6985 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5362 - accuracy: 0.8356 - val_loss: 1.8477 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4011 - accuracy: 0.8853 - val_loss: 2.0274 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2967 - accuracy: 0.9143 - val_loss: 1.9244 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2698 - accuracy: 0.9290 - val_loss: 2.1929 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2677 - accuracy: 0.9209 - val_loss: 2.0881 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1769 - accuracy: 0.9472 - val_loss: 2.1168 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1490 - accuracy: 0.9554 - val_loss: 2.2721 - val_accuracy: 0.5378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1430 - accuracy: 0.9554 - val_loss: 2.2470 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 2.3047 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9619 - val_loss: 2.2927 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7644 - accuracy: 0.4020\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.402 total time=  10.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 17.1721 - accuracy: 0.1892 - val_loss: 1.8820 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.6574 - accuracy: 0.3780 - val_loss: 1.8686 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.2048 - accuracy: 0.5632 - val_loss: 1.8781 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.7593 - accuracy: 0.7407 - val_loss: 2.0297 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4824 - accuracy: 0.8554 - val_loss: 2.2609 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3833 - accuracy: 0.8990 - val_loss: 2.2758 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3484 - accuracy: 0.9077 - val_loss: 2.6073 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2067 - accuracy: 0.9411 - val_loss: 2.4278 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1690 - accuracy: 0.9518 - val_loss: 2.4439 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1582 - accuracy: 0.9589 - val_loss: 2.4937 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1416 - accuracy: 0.9589 - val_loss: 2.5372 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1093 - accuracy: 0.9716 - val_loss: 2.5910 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.9033 - accuracy: 0.2832\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.283 total time=   9.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 190.0707 - accuracy: 0.2066 - val_loss: 1.8568 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4476 - accuracy: 0.5218 - val_loss: 1.7521 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6566 - accuracy: 0.8086 - val_loss: 1.7423 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2470 - accuracy: 0.9386 - val_loss: 2.4145 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1240 - accuracy: 0.9721 - val_loss: 2.2165 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0885 - accuracy: 0.9797 - val_loss: 2.3801 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0479 - accuracy: 0.9914 - val_loss: 2.4788 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0796 - accuracy: 0.9838 - val_loss: 3.0879 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0270 - accuracy: 0.9939 - val_loss: 2.5376 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 2.7504 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 2.6609 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 2.7420 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 2.8254 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6432 - accuracy: 0.4655\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.466 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 206.4755 - accuracy: 0.1735 - val_loss: 1.8581 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5149 - accuracy: 0.4510 - val_loss: 1.6050 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7908 - accuracy: 0.7565 - val_loss: 1.7801 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3176 - accuracy: 0.9259 - val_loss: 1.9876 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2514 - accuracy: 0.9406 - val_loss: 2.3795 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1525 - accuracy: 0.9691 - val_loss: 2.3111 - val_accuracy: 0.5243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0691 - accuracy: 0.9853 - val_loss: 2.6659 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0436 - accuracy: 0.9904 - val_loss: 2.6172 - val_accuracy: 0.5378 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 2.6293 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0329 - accuracy: 0.9934 - val_loss: 2.7789 - val_accuracy: 0.5378 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 2.7130 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0409 - accuracy: 0.9924 - val_loss: 2.7075 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7883 - accuracy: 0.4173\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.417 total time=  11.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 148.9402 - accuracy: 0.1979 - val_loss: 1.8822 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3801 - accuracy: 0.5403 - val_loss: 1.9377 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6503 - accuracy: 0.8209 - val_loss: 2.1909 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2377 - accuracy: 0.9346 - val_loss: 3.4277 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2510 - accuracy: 0.9589 - val_loss: 2.7554 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1958 - accuracy: 0.9685 - val_loss: 3.3018 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0733 - accuracy: 0.9858 - val_loss: 3.5823 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0636 - accuracy: 0.9868 - val_loss: 3.6288 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0572 - accuracy: 0.9904 - val_loss: 3.6955 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0334 - accuracy: 0.9914 - val_loss: 3.8644 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 3.8822 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9150 - accuracy: 0.2437\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.244 total time=  10.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 51.3026 - accuracy: 0.1685 - val_loss: 1.9391 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.7611 - accuracy: 0.3563 - val_loss: 1.8058 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.2282 - accuracy: 0.6091 - val_loss: 1.7523 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6625 - accuracy: 0.8030 - val_loss: 1.9644 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3620 - accuracy: 0.9071 - val_loss: 2.0624 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2389 - accuracy: 0.9365 - val_loss: 2.7035 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9701 - val_loss: 2.6920 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9741 - val_loss: 3.1067 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0745 - accuracy: 0.9868 - val_loss: 2.7468 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0577 - accuracy: 0.9878 - val_loss: 2.8322 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0652 - accuracy: 0.9853 - val_loss: 2.7964 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0489 - accuracy: 0.9904 - val_loss: 2.8880 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0491 - accuracy: 0.9904 - val_loss: 2.9392 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.7874 - accuracy: 0.3499\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.350 total time=   9.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 39.8434 - accuracy: 0.1837 - val_loss: 1.8716 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.6168 - accuracy: 0.4272 - val_loss: 1.7465 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.0032 - accuracy: 0.6880 - val_loss: 1.7305 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5121 - accuracy: 0.8453 - val_loss: 1.7549 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2819 - accuracy: 0.9178 - val_loss: 2.1481 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2012 - accuracy: 0.9457 - val_loss: 2.3445 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1527 - accuracy: 0.9589 - val_loss: 2.4964 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1203 - accuracy: 0.9630 - val_loss: 2.1372 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0986 - accuracy: 0.9736 - val_loss: 2.5764 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0651 - accuracy: 0.9792 - val_loss: 2.6112 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0835 - accuracy: 0.9772 - val_loss: 2.5182 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0604 - accuracy: 0.9843 - val_loss: 2.6103 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0488 - accuracy: 0.9883 - val_loss: 2.6331 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.7755 - accuracy: 0.3990\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.399 total time=   9.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 48.0332 - accuracy: 0.1664 - val_loss: 1.8935 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.6567 - accuracy: 0.3729 - val_loss: 1.8829 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.1810 - accuracy: 0.5794 - val_loss: 1.9387 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.7751 - accuracy: 0.7362 - val_loss: 2.2100 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5424 - accuracy: 0.8346 - val_loss: 2.7189 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4541 - accuracy: 0.8737 - val_loss: 3.0025 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2538 - accuracy: 0.9315 - val_loss: 3.5903 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1737 - accuracy: 0.9589 - val_loss: 3.1978 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1230 - accuracy: 0.9731 - val_loss: 3.4291 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1234 - accuracy: 0.9716 - val_loss: 3.4551 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1206 - accuracy: 0.9711 - val_loss: 3.5590 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1040 - accuracy: 0.9746 - val_loss: 3.6128 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.9624 - accuracy: 0.2609\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.261 total time=   9.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 184.7957 - accuracy: 0.1685 - val_loss: 1.8824 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.5915 - accuracy: 0.4244 - val_loss: 1.8068 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.0195 - accuracy: 0.6574 - val_loss: 1.8841 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6161 - accuracy: 0.8132 - val_loss: 2.0926 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4655 - accuracy: 0.8766 - val_loss: 2.0816 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3379 - accuracy: 0.9107 - val_loss: 2.1665 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3075 - accuracy: 0.9249 - val_loss: 1.9798 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2222 - accuracy: 0.9396 - val_loss: 2.2085 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1729 - accuracy: 0.9538 - val_loss: 2.2648 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1599 - accuracy: 0.9594 - val_loss: 2.2819 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1543 - accuracy: 0.9553 - val_loss: 2.3285 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1665 - accuracy: 0.9513 - val_loss: 2.2622 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.7305 - accuracy: 0.3499\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.350 total time=  13.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 212.7705 - accuracy: 0.1613 - val_loss: 1.9090 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.8465 - accuracy: 0.2364 - val_loss: 1.8765 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.6369 - accuracy: 0.3841 - val_loss: 1.8094 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3302 - accuracy: 0.5540 - val_loss: 2.0895 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.8918 - accuracy: 0.7194 - val_loss: 1.9360 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5816 - accuracy: 0.8194 - val_loss: 1.9322 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3644 - accuracy: 0.8945 - val_loss: 2.0594 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2848 - accuracy: 0.9264 - val_loss: 2.7927 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1794 - accuracy: 0.9467 - val_loss: 2.7282 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1622 - accuracy: 0.9508 - val_loss: 2.6737 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1509 - accuracy: 0.9614 - val_loss: 2.7489 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1418 - accuracy: 0.9569 - val_loss: 2.5640 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 2.7081 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8253 - accuracy: 0.2863\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.286 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 284.4470 - accuracy: 0.1806 - val_loss: 1.8872 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7145 - accuracy: 0.3516 - val_loss: 1.8004 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3585 - accuracy: 0.5266 - val_loss: 1.8058 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.9329 - accuracy: 0.6941 - val_loss: 1.7746 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6140 - accuracy: 0.8194 - val_loss: 1.7639 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4225 - accuracy: 0.8813 - val_loss: 1.7697 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3397 - accuracy: 0.9143 - val_loss: 1.8457 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3071 - accuracy: 0.9107 - val_loss: 1.8717 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2573 - accuracy: 0.9203 - val_loss: 2.3337 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2809 - accuracy: 0.9351 - val_loss: 2.1777 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1841 - accuracy: 0.9417 - val_loss: 1.9698 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1521 - accuracy: 0.9503 - val_loss: 1.9438 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1493 - accuracy: 0.9548 - val_loss: 2.0124 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1306 - accuracy: 0.9523 - val_loss: 2.0368 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1177 - accuracy: 0.9630 - val_loss: 2.0689 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8381 - accuracy: 0.4142\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.414 total time=  16.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 53.1939 - accuracy: 0.1772 - val_loss: 1.9219 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8388 - accuracy: 0.2629 - val_loss: 1.8529 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5430 - accuracy: 0.4431 - val_loss: 1.7645 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1298 - accuracy: 0.6091 - val_loss: 1.6851 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.8390 - accuracy: 0.7168 - val_loss: 1.7599 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6433 - accuracy: 0.7843 - val_loss: 1.7570 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4967 - accuracy: 0.8426 - val_loss: 1.8125 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4031 - accuracy: 0.8766 - val_loss: 1.8718 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3055 - accuracy: 0.8888 - val_loss: 2.3237 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2741 - accuracy: 0.9107 - val_loss: 2.0347 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2243 - accuracy: 0.9320 - val_loss: 2.0482 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2219 - accuracy: 0.9228 - val_loss: 2.1239 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2151 - accuracy: 0.9299 - val_loss: 2.0862 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1824 - accuracy: 0.9411 - val_loss: 2.1162 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6603 - accuracy: 0.4067\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.407 total time=  11.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 56.4648 - accuracy: 0.1547 - val_loss: 1.9400 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9046 - accuracy: 0.1958 - val_loss: 1.8599 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7943 - accuracy: 0.2755 - val_loss: 1.8370 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.5665 - accuracy: 0.4181 - val_loss: 1.7450 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3289 - accuracy: 0.5150 - val_loss: 1.6879 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.0064 - accuracy: 0.6438 - val_loss: 1.6234 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.8034 - accuracy: 0.7179 - val_loss: 1.8502 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6180 - accuracy: 0.7813 - val_loss: 1.7823 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.8108 - val_loss: 1.8132 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4379 - accuracy: 0.8478 - val_loss: 2.0599 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3873 - accuracy: 0.8600 - val_loss: 2.1423 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3267 - accuracy: 0.8899 - val_loss: 2.1063 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2605 - accuracy: 0.9011 - val_loss: 2.2471 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2657 - accuracy: 0.8985 - val_loss: 2.2272 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2241 - accuracy: 0.9112 - val_loss: 2.1647 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2368 - accuracy: 0.9082 - val_loss: 2.2515 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6116 - accuracy: 0.4518\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.452 total time=  13.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 63.0609 - accuracy: 0.1801 - val_loss: 1.8824 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.7880 - accuracy: 0.2988 - val_loss: 1.8030 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4191 - accuracy: 0.4789 - val_loss: 2.0253 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9460 - accuracy: 0.6778 - val_loss: 2.0162 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6836 - accuracy: 0.7894 - val_loss: 2.3528 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4705 - accuracy: 0.8676 - val_loss: 2.5052 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3134 - accuracy: 0.8990 - val_loss: 2.3879 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2056 - accuracy: 0.9498 - val_loss: 2.7631 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1861 - accuracy: 0.9482 - val_loss: 2.8283 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1427 - accuracy: 0.9625 - val_loss: 2.8291 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1343 - accuracy: 0.9630 - val_loss: 2.8709 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1305 - accuracy: 0.9660 - val_loss: 2.8583 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8256 - accuracy: 0.2772\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.277 total time=  10.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 239.4063 - accuracy: 0.2259 - val_loss: 1.8024 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.3511 - accuracy: 0.5391 - val_loss: 1.8240 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6132 - accuracy: 0.8152 - val_loss: 1.8339 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3153 - accuracy: 0.9218 - val_loss: 1.9664 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1841 - accuracy: 0.9513 - val_loss: 1.8220 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1163 - accuracy: 0.9756 - val_loss: 2.2277 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0804 - accuracy: 0.9787 - val_loss: 2.2070 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 2.2661 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0530 - accuracy: 0.9883 - val_loss: 2.1995 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 2.2597 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 2.3138 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8304 - accuracy: 0.2546\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.255 total time=  12.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 273.0076 - accuracy: 0.2212 - val_loss: 1.7808 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3126 - accuracy: 0.5951 - val_loss: 1.5971 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6036 - accuracy: 0.8422 - val_loss: 1.8404 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2328 - accuracy: 0.9376 - val_loss: 1.8644 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1012 - accuracy: 0.9716 - val_loss: 2.4367 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1080 - accuracy: 0.9767 - val_loss: 2.4134 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: 3.1356 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0880 - accuracy: 0.9858 - val_loss: 2.5920 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0465 - accuracy: 0.9934 - val_loss: 2.4488 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0475 - accuracy: 0.9893 - val_loss: 2.6648 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0278 - accuracy: 0.9959 - val_loss: 2.7329 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0299 - accuracy: 0.9944 - val_loss: 2.7483 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7158 - accuracy: 0.4426\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.443 total time=  13.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 303.5562 - accuracy: 0.2040 - val_loss: 1.8355 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.5245 - accuracy: 0.4668 - val_loss: 1.7902 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.8005 - accuracy: 0.7727 - val_loss: 1.9793 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2987 - accuracy: 0.9219 - val_loss: 2.3457 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1244 - accuracy: 0.9726 - val_loss: 3.4562 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1396 - accuracy: 0.9746 - val_loss: 2.9534 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1307 - accuracy: 0.9802 - val_loss: 3.2850 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1418 - accuracy: 0.9782 - val_loss: 3.0591 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0973 - accuracy: 0.9878 - val_loss: 3.1690 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0549 - accuracy: 0.9883 - val_loss: 3.1673 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0331 - accuracy: 0.9914 - val_loss: 3.1793 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0479 - accuracy: 0.9893 - val_loss: 3.1011 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9119 - accuracy: 0.3411\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.341 total time=  14.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 57.6287 - accuracy: 0.2208 - val_loss: 1.8036 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4531 - accuracy: 0.4843 - val_loss: 1.6616 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8125 - accuracy: 0.7355 - val_loss: 1.7927 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4366 - accuracy: 0.8690 - val_loss: 2.1115 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2729 - accuracy: 0.9340 - val_loss: 2.1174 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2126 - accuracy: 0.9528 - val_loss: 2.2630 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1192 - accuracy: 0.9716 - val_loss: 3.5680 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1308 - accuracy: 0.9761 - val_loss: 2.6255 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0629 - accuracy: 0.9832 - val_loss: 2.6970 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0674 - accuracy: 0.9848 - val_loss: 2.6615 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0531 - accuracy: 0.9878 - val_loss: 2.7080 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0553 - accuracy: 0.9898 - val_loss: 2.6747 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6828 - accuracy: 0.3925\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.392 total time=  10.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 45.1966 - accuracy: 0.1903 - val_loss: 1.8587 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6462 - accuracy: 0.4150 - val_loss: 1.7193 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1134 - accuracy: 0.6555 - val_loss: 1.7941 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6153 - accuracy: 0.8184 - val_loss: 1.7813 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4031 - accuracy: 0.8929 - val_loss: 2.1697 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2689 - accuracy: 0.9381 - val_loss: 2.0215 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2310 - accuracy: 0.9452 - val_loss: 2.5400 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1377 - accuracy: 0.9726 - val_loss: 2.4082 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1005 - accuracy: 0.9736 - val_loss: 2.4764 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0925 - accuracy: 0.9782 - val_loss: 2.4699 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0799 - accuracy: 0.9787 - val_loss: 2.6373 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0703 - accuracy: 0.9802 - val_loss: 2.5976 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7749 - accuracy: 0.3350\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.335 total time=  10.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 40.0424 - accuracy: 0.1837 - val_loss: 1.8717 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6036 - accuracy: 0.4044 - val_loss: 1.7479 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9903 - accuracy: 0.6585 - val_loss: 1.8531 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5184 - accuracy: 0.8437 - val_loss: 2.0514 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2990 - accuracy: 0.9173 - val_loss: 2.3773 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2229 - accuracy: 0.9401 - val_loss: 2.5097 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1916 - accuracy: 0.9462 - val_loss: 3.2136 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0896 - accuracy: 0.9772 - val_loss: 3.0078 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0775 - accuracy: 0.9812 - val_loss: 3.0794 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0443 - accuracy: 0.9904 - val_loss: 3.2520 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0460 - accuracy: 0.9883 - val_loss: 3.2995 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0610 - accuracy: 0.9868 - val_loss: 3.3075 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8519 - accuracy: 0.3036\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.304 total time=  10.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 55.4628 - accuracy: 0.1904 - val_loss: 1.8844 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5502 - accuracy: 0.4442 - val_loss: 1.8287 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8904 - accuracy: 0.7234 - val_loss: 2.3836 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4667 - accuracy: 0.8701 - val_loss: 2.2741 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4251 - accuracy: 0.8873 - val_loss: 2.3765 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2964 - accuracy: 0.9234 - val_loss: 3.3841 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1697 - accuracy: 0.9604 - val_loss: 2.8731 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1032 - accuracy: 0.9756 - val_loss: 3.3676 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9893 - val_loss: 3.7540 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0688 - accuracy: 0.9848 - val_loss: 3.6558 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0604 - accuracy: 0.9888 - val_loss: 3.7732 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0792 - accuracy: 0.9853 - val_loss: 3.5909 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.7965 - accuracy: 0.3276\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.328 total time=  16.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 67.6948 - accuracy: 0.1847 - val_loss: 1.9185 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8503 - accuracy: 0.2679 - val_loss: 1.8683 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5684 - accuracy: 0.4155 - val_loss: 1.7284 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9760 - accuracy: 0.6925 - val_loss: 1.6912 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5516 - accuracy: 0.8346 - val_loss: 2.0783 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.3111 - accuracy: 0.9036 - val_loss: 2.0001 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2830 - accuracy: 0.9305 - val_loss: 2.4354 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2366 - accuracy: 0.9371 - val_loss: 2.6138 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1639 - accuracy: 0.9462 - val_loss: 2.7927 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1515 - accuracy: 0.9579 - val_loss: 2.3773 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1329 - accuracy: 0.9665 - val_loss: 2.3810 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1271 - accuracy: 0.9716 - val_loss: 2.4945 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1051 - accuracy: 0.9691 - val_loss: 2.6329 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0873 - accuracy: 0.9746 - val_loss: 2.6529 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.8396 - accuracy: 0.4132\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.413 total time=  18.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 52.9841 - accuracy: 0.1801 - val_loss: 1.8703 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7036 - accuracy: 0.3623 - val_loss: 1.8007 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2792 - accuracy: 0.5733 - val_loss: 2.0765 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6884 - accuracy: 0.7854 - val_loss: 2.1953 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3935 - accuracy: 0.8950 - val_loss: 2.5251 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1949 - accuracy: 0.9518 - val_loss: 3.0451 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1900 - accuracy: 0.9655 - val_loss: 3.4697 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1153 - accuracy: 0.9762 - val_loss: 3.4116 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0906 - accuracy: 0.9853 - val_loss: 3.4990 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0785 - accuracy: 0.9858 - val_loss: 3.6297 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0878 - accuracy: 0.9878 - val_loss: 3.5890 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0667 - accuracy: 0.9863 - val_loss: 3.6805 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8197 - accuracy: 0.3015\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.302 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 30.9833 - accuracy: 0.1624 - val_loss: 1.8870 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7740 - accuracy: 0.2959 - val_loss: 1.8220 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.5104 - accuracy: 0.4360 - val_loss: 1.8221 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.1528 - accuracy: 0.5832 - val_loss: 1.9856 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8848 - accuracy: 0.6909 - val_loss: 2.1491 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6389 - accuracy: 0.7919 - val_loss: 2.1865 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5669 - accuracy: 0.8142 - val_loss: 2.4554 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4003 - accuracy: 0.8782 - val_loss: 2.5185 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3710 - accuracy: 0.8863 - val_loss: 2.5903 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3351 - accuracy: 0.8959 - val_loss: 2.6934 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2813 - accuracy: 0.9112 - val_loss: 2.7113 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2695 - accuracy: 0.9168 - val_loss: 2.7451 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8608 - accuracy: 0.2231\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.223 total time=  14.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 12.9144 - accuracy: 0.1715 - val_loss: 1.8739 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6897 - accuracy: 0.3333 - val_loss: 1.7804 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.3357 - accuracy: 0.5074 - val_loss: 1.9270 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.9530 - accuracy: 0.6682 - val_loss: 2.1962 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.7407 - accuracy: 0.7468 - val_loss: 2.4838 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4801 - accuracy: 0.8422 - val_loss: 2.6859 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4070 - accuracy: 0.8752 - val_loss: 3.0295 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2765 - accuracy: 0.9325 - val_loss: 2.9605 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2362 - accuracy: 0.9366 - val_loss: 2.9297 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2022 - accuracy: 0.9442 - val_loss: 3.1251 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1735 - accuracy: 0.9538 - val_loss: 3.1202 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1496 - accuracy: 0.9574 - val_loss: 3.2437 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8082 - accuracy: 0.3228\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.323 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 27.1538 - accuracy: 0.1689 - val_loss: 1.8853 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7339 - accuracy: 0.3059 - val_loss: 1.8436 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4122 - accuracy: 0.4587 - val_loss: 1.9412 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.1159 - accuracy: 0.5764 - val_loss: 2.2546 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8836 - accuracy: 0.6783 - val_loss: 2.4392 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6781 - accuracy: 0.7671 - val_loss: 2.5614 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5516 - accuracy: 0.8209 - val_loss: 2.9171 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3834 - accuracy: 0.8716 - val_loss: 3.1343 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3366 - accuracy: 0.8940 - val_loss: 3.2319 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3178 - accuracy: 0.8955 - val_loss: 3.2614 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2920 - accuracy: 0.9031 - val_loss: 3.3334 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2794 - accuracy: 0.9122 - val_loss: 3.2957 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8545 - accuracy: 0.2355\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.236 total time=  14.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 38.9677 - accuracy: 0.2066 - val_loss: 1.8665 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5183 - accuracy: 0.4482 - val_loss: 1.9794 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8796 - accuracy: 0.7015 - val_loss: 2.8926 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.8239 - val_loss: 3.3029 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4031 - accuracy: 0.8746 - val_loss: 3.7086 - val_accuracy: 0.3770 - lr: 0.0010racy: 0.\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.2438 - accuracy: 0.9274 - val_loss: 4.3588 - val_accuracy: 0.4122 - lr: 0.0010- accuracy - ETA: 0s - loss: 0.2442 - accuracy: 0.92\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.1649 - accuracy: 0.9624 - val_loss: 4.5931 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1266 - accuracy: 0.9695 - val_loss: 4.8086 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1160 - accuracy: 0.9706 - val_loss: 5.0005 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1077 - accuracy: 0.9761 - val_loss: 4.9381 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1018 - accuracy: 0.9761 - val_loss: 5.0710 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8570 - accuracy: 0.2394\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.239 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 67.2894 - accuracy: 0.1938 - val_loss: 1.8722 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7146 - accuracy: 0.3587 - val_loss: 1.8079 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1410 - accuracy: 0.6261 - val_loss: 2.0560 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6751 - accuracy: 0.8143 - val_loss: 2.3629 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.3152 - accuracy: 0.9153 - val_loss: 3.2795 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1888 - accuracy: 0.9589 - val_loss: 3.6111 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1551 - accuracy: 0.9767 - val_loss: 4.0275 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0954 - accuracy: 0.9822 - val_loss: 3.7507 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0671 - accuracy: 0.9878 - val_loss: 3.6226 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0551 - accuracy: 0.9883 - val_loss: 3.9505 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0536 - accuracy: 0.9914 - val_loss: 3.9808 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0443 - accuracy: 0.9899 - val_loss: 4.0435 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8505 - accuracy: 0.2893\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.289 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 51.5542 - accuracy: 0.1923 - val_loss: 1.8863 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7243 - accuracy: 0.3643 - val_loss: 1.8582 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1729 - accuracy: 0.5850 - val_loss: 1.9637 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4906 - accuracy: 0.8473 - val_loss: 2.4096 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2532 - accuracy: 0.9361 - val_loss: 2.6826 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1713 - accuracy: 0.9594 - val_loss: 2.9869 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1643 - accuracy: 0.9660 - val_loss: 3.4330 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1010 - accuracy: 0.9797 - val_loss: 3.2318 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0524 - accuracy: 0.9904 - val_loss: 3.3984 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9863 - val_loss: 3.4944 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0593 - accuracy: 0.9904 - val_loss: 3.4901 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0518 - accuracy: 0.9909 - val_loss: 3.5040 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9098 - accuracy: 0.2863\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.286 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 19.3295 - accuracy: 0.1904 - val_loss: 1.8765 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.6879 - accuracy: 0.3340 - val_loss: 1.8804 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.1523 - accuracy: 0.5843 - val_loss: 2.0865 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6583 - accuracy: 0.7848 - val_loss: 2.2246 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4523 - accuracy: 0.8706 - val_loss: 2.4757 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3202 - accuracy: 0.9183 - val_loss: 2.6912 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2194 - accuracy: 0.9548 - val_loss: 2.6436 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1196 - accuracy: 0.9756 - val_loss: 2.8504 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1061 - accuracy: 0.9772 - val_loss: 2.9554 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0989 - accuracy: 0.9782 - val_loss: 3.0488 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0807 - accuracy: 0.9843 - val_loss: 3.1120 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8777 - accuracy: 0.2130\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.213 total time=  12.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 16.0835 - accuracy: 0.1852 - val_loss: 1.8649 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.6144 - accuracy: 0.3805 - val_loss: 1.9117 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.1877 - accuracy: 0.5804 - val_loss: 2.2386 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.7614 - accuracy: 0.7418 - val_loss: 2.3231 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4479 - accuracy: 0.8524 - val_loss: 2.7733 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3523 - accuracy: 0.9061 - val_loss: 3.1864 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2050 - accuracy: 0.9396 - val_loss: 3.4289 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1484 - accuracy: 0.9584 - val_loss: 3.4409 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1472 - accuracy: 0.9584 - val_loss: 3.4684 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1235 - accuracy: 0.9691 - val_loss: 3.4919 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1102 - accuracy: 0.9670 - val_loss: 3.5937 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8678 - accuracy: 0.2386\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.239 total time=  12.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 19.6775 - accuracy: 0.1862 - val_loss: 1.8743 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7012 - accuracy: 0.3369 - val_loss: 1.8496 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.3315 - accuracy: 0.4952 - val_loss: 1.9932 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.9365 - accuracy: 0.6662 - val_loss: 2.2178 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6110 - accuracy: 0.7925 - val_loss: 2.7345 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5137 - accuracy: 0.8356 - val_loss: 3.1926 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3733 - accuracy: 0.8864 - val_loss: 3.0570 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2581 - accuracy: 0.9280 - val_loss: 3.6157 - val_accuracy: 0.3568 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2068 - accuracy: 0.9346 - val_loss: 3.6322 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1843 - accuracy: 0.9432 - val_loss: 3.7512 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1628 - accuracy: 0.9554 - val_loss: 3.7846 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1439 - accuracy: 0.9579 - val_loss: 4.0168 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8820 - accuracy: 0.2193\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.219 total time=  14.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 95.6518 - accuracy: 0.2000 - val_loss: 1.8817 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.7277 - accuracy: 0.3497 - val_loss: 1.8454 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.2719 - accuracy: 0.5822 - val_loss: 2.1675 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.7783 - accuracy: 0.7716 - val_loss: 2.2810 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.4297 - accuracy: 0.8817 - val_loss: 2.3543 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2932 - accuracy: 0.9254 - val_loss: 2.9432 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2618 - accuracy: 0.9457 - val_loss: 3.3934 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1285 - accuracy: 0.9695 - val_loss: 3.0992 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1085 - accuracy: 0.9812 - val_loss: 3.1576 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0923 - accuracy: 0.9807 - val_loss: 3.0851 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1020 - accuracy: 0.9772 - val_loss: 3.3001 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0715 - accuracy: 0.9843 - val_loss: 3.1389 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.8195 - accuracy: 0.2941\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.294 total time=  17.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 129.0309 - accuracy: 0.1583 - val_loss: 1.9296 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.8737 - accuracy: 0.2643 - val_loss: 1.9083 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.7510 - accuracy: 0.3298 - val_loss: 1.7658 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.3143 - accuracy: 0.5500 - val_loss: 1.7380 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.8296 - accuracy: 0.7402 - val_loss: 1.7753 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.5159 - accuracy: 0.8442 - val_loss: 2.0367 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.3146 - accuracy: 0.9056 - val_loss: 2.2003 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2747 - accuracy: 0.9274 - val_loss: 2.2163 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2362 - accuracy: 0.9361 - val_loss: 2.1459 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1756 - accuracy: 0.9533 - val_loss: 2.2462 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1463 - accuracy: 0.9609 - val_loss: 2.3325 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1402 - accuracy: 0.9599 - val_loss: 2.4210 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1372 - accuracy: 0.9625 - val_loss: 2.4333 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1131 - accuracy: 0.9655 - val_loss: 2.4998 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.7989 - accuracy: 0.3756\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.376 total time=  20.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 106.4371 - accuracy: 0.1882 - val_loss: 1.8776 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.6644 - accuracy: 0.3942 - val_loss: 1.7831 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.1125 - accuracy: 0.6190 - val_loss: 1.8993 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.5783 - accuracy: 0.8280 - val_loss: 2.2865 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.3189 - accuracy: 0.9269 - val_loss: 3.0226 - val_accuracy: 0.5135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2334 - accuracy: 0.9513 - val_loss: 2.7914 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1774 - accuracy: 0.9614 - val_loss: 3.9778 - val_accuracy: 0.5162 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0916 - accuracy: 0.9848 - val_loss: 3.6381 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0671 - accuracy: 0.9868 - val_loss: 3.7533 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0677 - accuracy: 0.9873 - val_loss: 3.5859 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0631 - accuracy: 0.9904 - val_loss: 3.6475 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0539 - accuracy: 0.9909 - val_loss: 3.7362 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8072 - accuracy: 0.3401\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.340 total time=  17.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 34.1989 - accuracy: 0.1599 - val_loss: 1.8938 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7874 - accuracy: 0.3005 - val_loss: 1.8882 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4157 - accuracy: 0.4888 - val_loss: 1.8861 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.9766 - accuracy: 0.6706 - val_loss: 2.0606 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6369 - accuracy: 0.8030 - val_loss: 2.5668 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4221 - accuracy: 0.8680 - val_loss: 2.7587 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2756 - accuracy: 0.9117 - val_loss: 3.0642 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2539 - accuracy: 0.9274 - val_loss: 2.6970 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2386 - accuracy: 0.9487 - val_loss: 2.8078 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1941 - accuracy: 0.9579 - val_loss: 3.0420 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1682 - accuracy: 0.9563 - val_loss: 2.9507 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1357 - accuracy: 0.9695 - val_loss: 3.1260 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1050 - accuracy: 0.9736 - val_loss: 3.2012 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8735 - accuracy: 0.3529\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.353 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 27.5337 - accuracy: 0.1334 - val_loss: 1.9465 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9424 - accuracy: 0.1573 - val_loss: 1.9395 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.9264 - accuracy: 0.1669 - val_loss: 1.9471 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9201 - accuracy: 0.1755 - val_loss: 1.9237 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9088 - accuracy: 0.1963 - val_loss: 1.9117 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8957 - accuracy: 0.1999 - val_loss: 1.9276 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8766 - accuracy: 0.2055 - val_loss: 1.8869 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8252 - accuracy: 0.2380 - val_loss: 1.8962 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8806 - accuracy: 0.2065 - val_loss: 3.5834 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.0013 - accuracy: 0.1497 - val_loss: 1.9467 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9449 - accuracy: 0.1512 - val_loss: 1.9457 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9434 - accuracy: 0.1522 - val_loss: 1.9383 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9448 - accuracy: 0.1542 - val_loss: 1.9388 - val_accuracy: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9401 - accuracy: 0.1537 - val_loss: 1.9383 - val_accuracy: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9409 - accuracy: 0.1537 - val_loss: 1.9369 - val_accuracy: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9382 - accuracy: 0.1547 - val_loss: 1.9359 - val_accuracy: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9376 - accuracy: 0.1547 - val_loss: 1.9359 - val_accuracy: 0.1432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9087 - accuracy: 0.1939\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.194 total time=  19.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 25.0813 - accuracy: 0.1938 - val_loss: 1.8417 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6915 - accuracy: 0.3288 - val_loss: 1.8218 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2774 - accuracy: 0.5403 - val_loss: 1.8622 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8927 - accuracy: 0.7062 - val_loss: 2.0974 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6676 - accuracy: 0.7950 - val_loss: 2.3006 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4337 - accuracy: 0.8737 - val_loss: 2.6817 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4261 - accuracy: 0.8681 - val_loss: 2.7332 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2758 - accuracy: 0.9290 - val_loss: 2.8221 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2215 - accuracy: 0.9366 - val_loss: 2.8580 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1581 - accuracy: 0.9548 - val_loss: 2.9949 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1445 - accuracy: 0.9685 - val_loss: 3.0896 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1513 - accuracy: 0.9660 - val_loss: 3.0232 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8980 - accuracy: 0.2690\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.269 total time=  14.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 176.3783 - accuracy: 0.2015 - val_loss: 1.8325 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3479 - accuracy: 0.5584 - val_loss: 1.7797 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6558 - accuracy: 0.8051 - val_loss: 2.5978 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.3014 - accuracy: 0.9183 - val_loss: 3.1397 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2263 - accuracy: 0.9503 - val_loss: 3.4527 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1132 - accuracy: 0.9756 - val_loss: 4.5160 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1039 - accuracy: 0.9802 - val_loss: 4.0399 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0431 - accuracy: 0.9934 - val_loss: 4.3778 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0229 - accuracy: 0.9949 - val_loss: 4.1283 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0439 - accuracy: 0.9939 - val_loss: 4.1958 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0318 - accuracy: 0.9949 - val_loss: 4.4003 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0172 - accuracy: 0.9959 - val_loss: 4.4668 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.7841 - accuracy: 0.3174\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.317 total time=  18.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 31ms/step - loss: 222.5247 - accuracy: 0.1958 - val_loss: 1.8071 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.5379 - accuracy: 0.4632 - val_loss: 1.7713 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8783 - accuracy: 0.7062 - val_loss: 2.2654 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4173 - accuracy: 0.8721 - val_loss: 3.8285 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2333 - accuracy: 0.9437 - val_loss: 4.0819 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 2.8980 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2370 - accuracy: 0.9401 - val_loss: 6.0323 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0816 - accuracy: 0.9853 - val_loss: 5.1707 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0473 - accuracy: 0.9924 - val_loss: 5.5275 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0271 - accuracy: 0.9959 - val_loss: 6.0197 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0547 - accuracy: 0.9924 - val_loss: 6.1084 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 6.2660 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.7876 - accuracy: 0.3371\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.337 total time=  18.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 189.7931 - accuracy: 0.2014 - val_loss: 1.8320 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4990 - accuracy: 0.4820 - val_loss: 1.9731 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8170 - accuracy: 0.7428 - val_loss: 2.4982 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4085 - accuracy: 0.8853 - val_loss: 3.7783 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1857 - accuracy: 0.9477 - val_loss: 3.4960 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1781 - accuracy: 0.9640 - val_loss: 3.4490 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0706 - accuracy: 0.9843 - val_loss: 4.1061 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0576 - accuracy: 0.9848 - val_loss: 4.0598 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0484 - accuracy: 0.9883 - val_loss: 4.0953 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0600 - accuracy: 0.9888 - val_loss: 3.8553 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0400 - accuracy: 0.9919 - val_loss: 4.1684 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8654 - accuracy: 0.2416\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.242 total time=  16.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 52.1387 - accuracy: 0.1675 - val_loss: 1.9163 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7426 - accuracy: 0.3264 - val_loss: 1.8705 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4678 - accuracy: 0.4508 - val_loss: 1.9682 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.0796 - accuracy: 0.5995 - val_loss: 2.0476 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.7561 - accuracy: 0.7310 - val_loss: 2.5272 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5190 - accuracy: 0.8259 - val_loss: 2.6460 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3894 - accuracy: 0.8746 - val_loss: 3.1788 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2543 - accuracy: 0.9228 - val_loss: 3.2959 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2062 - accuracy: 0.9360 - val_loss: 3.3605 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1823 - accuracy: 0.9406 - val_loss: 3.4227 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1862 - accuracy: 0.9401 - val_loss: 3.5757 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1688 - accuracy: 0.9513 - val_loss: 3.5994 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8837 - accuracy: 0.2272\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.227 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 49.0106 - accuracy: 0.1928 - val_loss: 1.8577 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6323 - accuracy: 0.3998 - val_loss: 1.8161 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1250 - accuracy: 0.6002 - val_loss: 2.2951 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6897 - accuracy: 0.7757 - val_loss: 2.4196 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4241 - accuracy: 0.8711 - val_loss: 3.1863 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2006 - accuracy: 0.9351 - val_loss: 3.2456 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1562 - accuracy: 0.9589 - val_loss: 3.7724 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0841 - accuracy: 0.9838 - val_loss: 3.8866 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0584 - accuracy: 0.9868 - val_loss: 3.9524 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0607 - accuracy: 0.9848 - val_loss: 3.9494 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 3.9009 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0413 - accuracy: 0.9909 - val_loss: 3.9930 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8953 - accuracy: 0.3188\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.319 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 64.7197 - accuracy: 0.1801 - val_loss: 1.9042 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7947 - accuracy: 0.2755 - val_loss: 1.8922 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.5167 - accuracy: 0.4099 - val_loss: 1.9902 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1036 - accuracy: 0.5946 - val_loss: 2.4938 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8065 - accuracy: 0.7281 - val_loss: 2.6498 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6846 - accuracy: 0.7889 - val_loss: 3.3418 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4582 - accuracy: 0.8437 - val_loss: 3.3451 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3382 - accuracy: 0.9082 - val_loss: 3.6816 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2725 - accuracy: 0.9264 - val_loss: 3.8916 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2403 - accuracy: 0.9320 - val_loss: 4.1273 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2262 - accuracy: 0.9346 - val_loss: 4.1490 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2149 - accuracy: 0.9406 - val_loss: 4.2190 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9196 - accuracy: 0.2294\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.229 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 63.5219 - accuracy: 0.1487 - val_loss: 1.8934 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8155 - accuracy: 0.2553 - val_loss: 1.9331 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.5193 - accuracy: 0.4244 - val_loss: 1.8529 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1529 - accuracy: 0.5934 - val_loss: 2.1598 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8200 - accuracy: 0.7305 - val_loss: 2.6783 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.6418 - accuracy: 0.8076 - val_loss: 3.2535 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4026 - accuracy: 0.8751 - val_loss: 3.9605 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3417 - accuracy: 0.9061 - val_loss: 4.5560 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2140 - accuracy: 0.9452 - val_loss: 4.5042 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1953 - accuracy: 0.9487 - val_loss: 4.3785 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1704 - accuracy: 0.9553 - val_loss: 4.5007 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1497 - accuracy: 0.9579 - val_loss: 4.7255 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1637 - accuracy: 0.9604 - val_loss: 4.4547 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8264 - accuracy: 0.2647\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.265 total time=  13.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 73.0310 - accuracy: 0.1578 - val_loss: 1.9219 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.9083 - accuracy: 0.2435 - val_loss: 1.9264 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.7219 - accuracy: 0.3445 - val_loss: 1.9069 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3929 - accuracy: 0.5119 - val_loss: 1.9106 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1535 - accuracy: 0.6038 - val_loss: 1.8403 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8682 - accuracy: 0.7118 - val_loss: 1.9579 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6722 - accuracy: 0.7854 - val_loss: 2.2898 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5461 - accuracy: 0.8214 - val_loss: 2.3931 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5638 - accuracy: 0.8376 - val_loss: 2.1517 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4183 - accuracy: 0.8701 - val_loss: 2.3163 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3653 - accuracy: 0.8884 - val_loss: 2.4467 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2782 - accuracy: 0.9137 - val_loss: 2.4505 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2731 - accuracy: 0.9219 - val_loss: 2.3875 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2301 - accuracy: 0.9280 - val_loss: 2.4369 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2415 - accuracy: 0.9249 - val_loss: 2.4193 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8749 - accuracy: 0.3827\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.383 total time=  15.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 38.8544 - accuracy: 0.1669 - val_loss: 1.9081 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8546 - accuracy: 0.2232 - val_loss: 1.8615 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.7095 - accuracy: 0.3110 - val_loss: 1.8864 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.4836 - accuracy: 0.4368 - val_loss: 1.9879 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1473 - accuracy: 0.5738 - val_loss: 2.4229 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9166 - accuracy: 0.6662 - val_loss: 3.2433 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.7373 - accuracy: 0.7382 - val_loss: 3.4835 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5503 - accuracy: 0.8407 - val_loss: 3.9348 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5479 - accuracy: 0.8437 - val_loss: 3.8425 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4477 - accuracy: 0.8513 - val_loss: 3.9955 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4614 - accuracy: 0.8661 - val_loss: 3.9369 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3724 - accuracy: 0.8782 - val_loss: 4.0269 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9386 - accuracy: 0.1878\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.188 total time=  12.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 16ms/step - loss: 33.9157 - accuracy: 0.1695 - val_loss: 1.8889 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7990 - accuracy: 0.2589 - val_loss: 1.8857 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5821 - accuracy: 0.3701 - val_loss: 1.8698 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4380 - accuracy: 0.4371 - val_loss: 2.1695 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3248 - accuracy: 0.4914 - val_loss: 2.2756 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1541 - accuracy: 0.5579 - val_loss: 2.7705 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0416 - accuracy: 0.6234 - val_loss: 2.8572 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9652 - accuracy: 0.6477 - val_loss: 2.3860 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8164 - accuracy: 0.7041 - val_loss: 2.9568 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7246 - accuracy: 0.7279 - val_loss: 2.9880 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7063 - accuracy: 0.7411 - val_loss: 3.1167 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7034 - accuracy: 0.7350 - val_loss: 3.1580 - val_accuracy: 0.3230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6867 - accuracy: 0.7487 - val_loss: 3.1489 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8739 - accuracy: 0.2079\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.208 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 11.3001 - accuracy: 0.1608 - val_loss: 1.8811 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7824 - accuracy: 0.2841 - val_loss: 1.8073 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5071 - accuracy: 0.4201 - val_loss: 1.8220 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2144 - accuracy: 0.5708 - val_loss: 1.9095 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0548 - accuracy: 0.6185 - val_loss: 2.1293 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8463 - accuracy: 0.6976 - val_loss: 2.2793 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6340 - accuracy: 0.7859 - val_loss: 2.4924 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4098 - accuracy: 0.8691 - val_loss: 2.8246 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3847 - accuracy: 0.8823 - val_loss: 2.7991 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3265 - accuracy: 0.9031 - val_loss: 2.7988 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2841 - accuracy: 0.9112 - val_loss: 2.9366 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2685 - accuracy: 0.9214 - val_loss: 2.9459 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8448 - accuracy: 0.2812\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.281 total time=  10.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 16.6128 - accuracy: 0.1730 - val_loss: 1.8851 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8211 - accuracy: 0.2415 - val_loss: 1.8552 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6373 - accuracy: 0.3404 - val_loss: 1.9187 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4204 - accuracy: 0.4678 - val_loss: 2.0820 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2314 - accuracy: 0.5429 - val_loss: 2.4317 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0192 - accuracy: 0.6408 - val_loss: 2.5280 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8337 - accuracy: 0.7012 - val_loss: 2.8621 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6561 - accuracy: 0.7773 - val_loss: 3.0095 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6302 - accuracy: 0.7889 - val_loss: 3.1802 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5467 - accuracy: 0.8097 - val_loss: 3.1772 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5160 - accuracy: 0.8163 - val_loss: 3.2334 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5072 - accuracy: 0.8219 - val_loss: 3.3641 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8849 - accuracy: 0.1959\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.196 total time=  10.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 62.7172 - accuracy: 0.2025 - val_loss: 1.8832 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.6591 - accuracy: 0.3660 - val_loss: 2.0400 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3161 - accuracy: 0.5010 - val_loss: 2.1078 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9881 - accuracy: 0.6518 - val_loss: 2.8426 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.7197 - accuracy: 0.7371 - val_loss: 3.0221 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6120 - accuracy: 0.7898 - val_loss: 3.8583 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4819 - accuracy: 0.8442 - val_loss: 4.9952 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3535 - accuracy: 0.8741 - val_loss: 5.5118 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3183 - accuracy: 0.8883 - val_loss: 5.6936 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2764 - accuracy: 0.9036 - val_loss: 5.7875 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2688 - accuracy: 0.9142 - val_loss: 5.4346 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8892 - accuracy: 0.1978\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.198 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 77.2180 - accuracy: 0.2040 - val_loss: 1.9065 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.6106 - accuracy: 0.3815 - val_loss: 1.9405 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1584 - accuracy: 0.5814 - val_loss: 2.1857 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.7366 - accuracy: 0.7336 - val_loss: 2.9193 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5839 - accuracy: 0.8113 - val_loss: 3.3121 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4689 - accuracy: 0.8559 - val_loss: 4.6674 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3074 - accuracy: 0.9148 - val_loss: 4.6680 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2156 - accuracy: 0.9335 - val_loss: 4.7565 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1966 - accuracy: 0.9467 - val_loss: 4.9951 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1779 - accuracy: 0.9427 - val_loss: 5.1185 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1665 - accuracy: 0.9518 - val_loss: 4.8141 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8682 - accuracy: 0.2274\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.227 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 62.6527 - accuracy: 0.1497 - val_loss: 1.9088 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8279 - accuracy: 0.2537 - val_loss: 1.9191 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.6814 - accuracy: 0.3151 - val_loss: 2.2500 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.5188 - accuracy: 0.3841 - val_loss: 2.2188 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3914 - accuracy: 0.4394 - val_loss: 3.2627 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.2375 - accuracy: 0.5119 - val_loss: 3.2159 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.0404 - accuracy: 0.5819 - val_loss: 3.5946 - val_accuracy: 0.2730 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9836 - accuracy: 0.6022 - val_loss: 3.9386 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9478 - accuracy: 0.6154 - val_loss: 4.0104 - val_accuracy: 0.2730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9179 - accuracy: 0.6220 - val_loss: 4.3087 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8831 - accuracy: 0.6479 - val_loss: 4.2849 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9012 - accuracy: 0.1797\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.180 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 22.0917 - accuracy: 0.1695 - val_loss: 1.8899 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.8094 - accuracy: 0.2604 - val_loss: 1.8605 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6590 - accuracy: 0.3208 - val_loss: 1.9169 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5437 - accuracy: 0.3701 - val_loss: 1.9513 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3756 - accuracy: 0.4350 - val_loss: 2.1037 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2596 - accuracy: 0.5086 - val_loss: 2.4608 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1789 - accuracy: 0.5640 - val_loss: 2.6464 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9304 - accuracy: 0.6442 - val_loss: 2.9324 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8608 - accuracy: 0.6695 - val_loss: 3.0241 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8269 - accuracy: 0.6883 - val_loss: 3.0929 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7842 - accuracy: 0.7041 - val_loss: 3.1355 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7716 - accuracy: 0.7112 - val_loss: 3.1885 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8691 - accuracy: 0.1897\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.190 total time=  10.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 26.9197 - accuracy: 0.1740 - val_loss: 1.8751 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8012 - accuracy: 0.2608 - val_loss: 1.8877 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6662 - accuracy: 0.3374 - val_loss: 1.8944 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5176 - accuracy: 0.4074 - val_loss: 2.1201 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3000 - accuracy: 0.5190 - val_loss: 2.3706 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0467 - accuracy: 0.6195 - val_loss: 2.6235 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7796 - accuracy: 0.7189 - val_loss: 2.8522 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7225 - accuracy: 0.7367 - val_loss: 2.9595 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7000 - accuracy: 0.7443 - val_loss: 3.0372 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6597 - accuracy: 0.7585 - val_loss: 2.9501 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6302 - accuracy: 0.7692 - val_loss: 3.1816 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8962 - accuracy: 0.1929\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.193 total time=  10.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 16ms/step - loss: 28.8170 - accuracy: 0.1689 - val_loss: 1.8917 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8106 - accuracy: 0.2522 - val_loss: 1.8664 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5942 - accuracy: 0.3790 - val_loss: 1.9488 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3589 - accuracy: 0.4962 - val_loss: 1.9711 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1176 - accuracy: 0.5951 - val_loss: 2.2873 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9334 - accuracy: 0.6621 - val_loss: 2.3901 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7648 - accuracy: 0.7296 - val_loss: 2.5267 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5986 - accuracy: 0.8052 - val_loss: 2.7921 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5290 - accuracy: 0.8184 - val_loss: 2.8703 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4924 - accuracy: 0.8305 - val_loss: 2.9562 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4564 - accuracy: 0.8453 - val_loss: 3.0316 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4458 - accuracy: 0.8529 - val_loss: 3.0529 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8625 - accuracy: 0.2152\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.215 total time=  11.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 24ms/step - loss: 146.9503 - accuracy: 0.1843 - val_loss: 1.8845 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8171 - accuracy: 0.2629 - val_loss: 1.9547 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6192 - accuracy: 0.3685 - val_loss: 2.0466 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3455 - accuracy: 0.5117 - val_loss: 2.1917 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0352 - accuracy: 0.6147 - val_loss: 2.3841 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8494 - accuracy: 0.7147 - val_loss: 3.0722 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5848 - accuracy: 0.7990 - val_loss: 3.8395 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5039 - accuracy: 0.8234 - val_loss: 3.9310 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4836 - accuracy: 0.8335 - val_loss: 4.0156 - val_accuracy: 0.3811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4550 - accuracy: 0.8462 - val_loss: 3.8449 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4032 - accuracy: 0.8635 - val_loss: 3.9815 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8719 - accuracy: 0.1897\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.190 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 24ms/step - loss: 58.9478 - accuracy: 0.1933 - val_loss: 1.8440 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6512 - accuracy: 0.3851 - val_loss: 1.9528 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1699 - accuracy: 0.6144 - val_loss: 2.2228 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7185 - accuracy: 0.7763 - val_loss: 2.1823 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4935 - accuracy: 0.8539 - val_loss: 2.8653 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4210 - accuracy: 0.8889 - val_loss: 2.6126 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2712 - accuracy: 0.9401 - val_loss: 3.7575 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1753 - accuracy: 0.9528 - val_loss: 3.6810 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1575 - accuracy: 0.9599 - val_loss: 3.8426 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1551 - accuracy: 0.9599 - val_loss: 3.9008 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1478 - accuracy: 0.9675 - val_loss: 3.8533 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2609\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.261 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 95.5629 - accuracy: 0.1608 - val_loss: 1.9573 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8796 - accuracy: 0.2116 - val_loss: 1.8777 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7981 - accuracy: 0.2582 - val_loss: 1.8980 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6457 - accuracy: 0.3602 - val_loss: 2.2392 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3639 - accuracy: 0.4789 - val_loss: 2.0649 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0942 - accuracy: 0.6185 - val_loss: 2.8230 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8042 - accuracy: 0.7204 - val_loss: 2.9493 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6545 - accuracy: 0.8275 - val_loss: 3.4095 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4438 - accuracy: 0.8569 - val_loss: 3.6142 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4339 - accuracy: 0.8656 - val_loss: 3.7961 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3549 - accuracy: 0.8858 - val_loss: 3.8096 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3277 - accuracy: 0.8945 - val_loss: 3.9665 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8963 - accuracy: 0.1868\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.187 total time=  15.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 28.4279 - accuracy: 0.1812 - val_loss: 1.8844 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7812 - accuracy: 0.2777 - val_loss: 1.8246 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6321 - accuracy: 0.3447 - val_loss: 1.8984 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4476 - accuracy: 0.4284 - val_loss: 1.9196 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2844 - accuracy: 0.5147 - val_loss: 2.5349 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1054 - accuracy: 0.5822 - val_loss: 2.5126 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9995 - accuracy: 0.6492 - val_loss: 2.7341 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8187 - accuracy: 0.7122 - val_loss: 2.9569 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7585 - accuracy: 0.7234 - val_loss: 3.0309 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6934 - accuracy: 0.7487 - val_loss: 3.1125 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6617 - accuracy: 0.7599 - val_loss: 3.2121 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6290 - accuracy: 0.7650 - val_loss: 3.3271 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8429 - accuracy: 0.2454\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.245 total time=  11.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 47.1568 - accuracy: 0.1776 - val_loss: 1.8920 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7751 - accuracy: 0.2988 - val_loss: 1.8310 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4736 - accuracy: 0.4444 - val_loss: 1.8950 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4044 - accuracy: 0.4652 - val_loss: 1.9837 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0410 - accuracy: 0.6109 - val_loss: 2.2335 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8387 - accuracy: 0.7073 - val_loss: 2.8117 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6085 - accuracy: 0.7955 - val_loss: 2.6843 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3770 - accuracy: 0.8843 - val_loss: 2.9508 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2932 - accuracy: 0.9061 - val_loss: 3.0759 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2786 - accuracy: 0.9153 - val_loss: 3.1312 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2526 - accuracy: 0.9280 - val_loss: 3.2068 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2389 - accuracy: 0.9315 - val_loss: 3.2364 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8481 - accuracy: 0.2792\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.279 total time=  11.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 26.1521 - accuracy: 0.1832 - val_loss: 1.8575 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7491 - accuracy: 0.3019 - val_loss: 1.8295 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4838 - accuracy: 0.4419 - val_loss: 1.8245 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1978 - accuracy: 0.5703 - val_loss: 1.9454 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9772 - accuracy: 0.6672 - val_loss: 2.2969 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7644 - accuracy: 0.7382 - val_loss: 2.4112 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6561 - accuracy: 0.8001 - val_loss: 2.7159 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5477 - accuracy: 0.8300 - val_loss: 2.8962 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3391 - accuracy: 0.9087 - val_loss: 3.2100 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2799 - accuracy: 0.9163 - val_loss: 3.2824 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2780 - accuracy: 0.9198 - val_loss: 3.2354 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2542 - accuracy: 0.9269 - val_loss: 3.3959 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2321 - accuracy: 0.9376 - val_loss: 3.3861 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8740 - accuracy: 0.3198\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.320 total time=  12.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 93.3910 - accuracy: 0.1782 - val_loss: 1.9332 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7051 - accuracy: 0.3325 - val_loss: 1.9644 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3249 - accuracy: 0.4985 - val_loss: 2.1900 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9921 - accuracy: 0.6569 - val_loss: 2.4580 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8334 - accuracy: 0.7142 - val_loss: 3.1593 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5788 - accuracy: 0.8198 - val_loss: 4.1775 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3969 - accuracy: 0.8792 - val_loss: 4.8061 - val_accuracy: 0.3811 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3022 - accuracy: 0.9010 - val_loss: 5.1017 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2634 - accuracy: 0.9132 - val_loss: 5.3609 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2324 - accuracy: 0.9244 - val_loss: 5.5138 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2156 - accuracy: 0.9284 - val_loss: 5.8395 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8973 - accuracy: 0.2089\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.209 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 94.8565 - accuracy: 0.2232 - val_loss: 1.9312 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6945 - accuracy: 0.3389 - val_loss: 1.8853 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5609 - accuracy: 0.4160 - val_loss: 2.2043 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2569 - accuracy: 0.5236 - val_loss: 2.1294 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0127 - accuracy: 0.6347 - val_loss: 3.1111 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7979 - accuracy: 0.7215 - val_loss: 2.5104 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9105 - accuracy: 0.6748 - val_loss: 4.7761 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5499 - accuracy: 0.8118 - val_loss: 4.8678 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5066 - accuracy: 0.8280 - val_loss: 5.0806 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4273 - accuracy: 0.8478 - val_loss: 5.1062 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3995 - accuracy: 0.8564 - val_loss: 5.0033 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.3820 - accuracy: 0.8595 - val_loss: 5.2510 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9695 - accuracy: 0.2345\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.235 total time=  15.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 184.0272 - accuracy: 0.1644 - val_loss: 1.9394 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8128 - accuracy: 0.2552 - val_loss: 1.8612 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5702 - accuracy: 0.4069 - val_loss: 1.9340 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2440 - accuracy: 0.5616 - val_loss: 2.1153 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9030 - accuracy: 0.6880 - val_loss: 3.2306 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6346 - accuracy: 0.7732 - val_loss: 2.9463 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4673 - accuracy: 0.8605 - val_loss: 3.5351 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3350 - accuracy: 0.9066 - val_loss: 3.8439 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2893 - accuracy: 0.9178 - val_loss: 4.0570 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2295 - accuracy: 0.9249 - val_loss: 4.0234 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2196 - accuracy: 0.9340 - val_loss: 4.3624 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2006 - accuracy: 0.9376 - val_loss: 4.2019 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8950 - accuracy: 0.2548\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.255 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 36.1367 - accuracy: 0.1670 - val_loss: 1.8785 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.8374 - accuracy: 0.2340 - val_loss: 1.8868 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6591 - accuracy: 0.3401 - val_loss: 1.9239 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4203 - accuracy: 0.4624 - val_loss: 2.1551 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2992 - accuracy: 0.5188 - val_loss: 2.2550 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0713 - accuracy: 0.5934 - val_loss: 2.6771 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8411 - accuracy: 0.6873 - val_loss: 2.7695 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7783 - accuracy: 0.7127 - val_loss: 2.7562 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7368 - accuracy: 0.7183 - val_loss: 2.8209 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6847 - accuracy: 0.7492 - val_loss: 2.9269 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6493 - accuracy: 0.7584 - val_loss: 2.9877 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8747 - accuracy: 0.1917\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.192 total time=  10.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 44.7386 - accuracy: 0.1908 - val_loss: 1.8362 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6803 - accuracy: 0.3567 - val_loss: 1.8675 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2468 - accuracy: 0.5586 - val_loss: 2.0358 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8523 - accuracy: 0.6956 - val_loss: 2.2139 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6277 - accuracy: 0.7935 - val_loss: 2.4219 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4440 - accuracy: 0.8584 - val_loss: 3.1449 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2620 - accuracy: 0.9234 - val_loss: 3.0723 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2122 - accuracy: 0.9366 - val_loss: 3.1620 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1749 - accuracy: 0.9503 - val_loss: 3.3183 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1505 - accuracy: 0.9579 - val_loss: 3.4410 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1538 - accuracy: 0.9625 - val_loss: 3.4278 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8671 - accuracy: 0.2619\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.262 total time=  10.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 24.9754 - accuracy: 0.1598 - val_loss: 1.9066 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7933 - accuracy: 0.2714 - val_loss: 1.9093 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5614 - accuracy: 0.3790 - val_loss: 2.1643 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3890 - accuracy: 0.4576 - val_loss: 2.4733 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1883 - accuracy: 0.5429 - val_loss: 2.5189 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0612 - accuracy: 0.6144 - val_loss: 2.9013 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8313 - accuracy: 0.6925 - val_loss: 3.1998 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7823 - accuracy: 0.7164 - val_loss: 3.2091 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7151 - accuracy: 0.7255 - val_loss: 3.2123 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6993 - accuracy: 0.7331 - val_loss: 3.3017 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6820 - accuracy: 0.7534 - val_loss: 3.3660 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9276 - accuracy: 0.2152\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.215 total time=  10.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 22.1762 - accuracy: 0.1685 - val_loss: 1.9025 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8366 - accuracy: 0.2340 - val_loss: 1.9034 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6770 - accuracy: 0.3305 - val_loss: 1.9558 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5512 - accuracy: 0.4208 - val_loss: 2.0881 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2583 - accuracy: 0.5162 - val_loss: 2.7810 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9646 - accuracy: 0.6462 - val_loss: 3.3942 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7395 - accuracy: 0.7563 - val_loss: 3.2389 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6321 - accuracy: 0.7843 - val_loss: 3.1830 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.5839 - accuracy: 0.7949 - val_loss: 3.5025 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5502 - accuracy: 0.8142 - val_loss: 3.4270 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5421 - accuracy: 0.8294 - val_loss: 3.7338 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.9130 - accuracy: 0.1755\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.175 total time=  17.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 29ms/step - loss: 28.9253 - accuracy: 0.1593 - val_loss: 1.9182 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8717 - accuracy: 0.2258 - val_loss: 1.8997 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7365 - accuracy: 0.2902 - val_loss: 2.0738 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5690 - accuracy: 0.3638 - val_loss: 2.1455 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4219 - accuracy: 0.4389 - val_loss: 3.0449 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2609 - accuracy: 0.5008 - val_loss: 2.8956 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0588 - accuracy: 0.5926 - val_loss: 3.0955 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8960 - accuracy: 0.6591 - val_loss: 3.5877 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8672 - accuracy: 0.6712 - val_loss: 3.6846 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8304 - accuracy: 0.6844 - val_loss: 3.9077 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7824 - accuracy: 0.6920 - val_loss: 3.9093 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7495 - accuracy: 0.7027 - val_loss: 4.1137 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.9014 - accuracy: 0.2051\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.205 total time=  18.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 51.6614 - accuracy: 0.1669 - val_loss: 1.9341 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8709 - accuracy: 0.2050 - val_loss: 1.9022 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7670 - accuracy: 0.2740 - val_loss: 1.9319 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6229 - accuracy: 0.3628 - val_loss: 2.3905 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4375 - accuracy: 0.4404 - val_loss: 2.4958 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3832 - accuracy: 0.4962 - val_loss: 2.9332 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.1233 - accuracy: 0.5758 - val_loss: 3.0842 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9631 - accuracy: 0.6367 - val_loss: 3.6617 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8872 - accuracy: 0.6667 - val_loss: 4.0507 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8301 - accuracy: 0.6859 - val_loss: 4.1006 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7977 - accuracy: 0.7073 - val_loss: 3.9516 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7598 - accuracy: 0.7128 - val_loss: 4.1635 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 7ms/step - loss: 1.9237 - accuracy: 0.1868\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.187 total time=  18.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 14.3439 - accuracy: 0.1614 - val_loss: 1.9362 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8801 - accuracy: 0.2041 - val_loss: 1.8914 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8071 - accuracy: 0.2563 - val_loss: 1.8974 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7141 - accuracy: 0.3015 - val_loss: 1.9092 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6181 - accuracy: 0.3518 - val_loss: 2.0800 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5106 - accuracy: 0.4020 - val_loss: 2.5741 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4329 - accuracy: 0.4274 - val_loss: 2.2885 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2778 - accuracy: 0.4843 - val_loss: 2.5183 - val_accuracy: 0.2878 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2589 - accuracy: 0.4995 - val_loss: 2.5914 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2387 - accuracy: 0.5096 - val_loss: 2.6610 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1865 - accuracy: 0.5213 - val_loss: 2.7664 - val_accuracy: 0.2878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1681 - accuracy: 0.5310 - val_loss: 2.7808 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8788 - accuracy: 0.2008\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.201 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 8.1041 - accuracy: 0.1735 - val_loss: 1.8937 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8478 - accuracy: 0.2314 - val_loss: 1.9120 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7347 - accuracy: 0.2882 - val_loss: 1.9427 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6910 - accuracy: 0.3257 - val_loss: 1.9527 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6444 - accuracy: 0.3222 - val_loss: 2.4785 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5156 - accuracy: 0.3866 - val_loss: 2.2238 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3635 - accuracy: 0.4546 - val_loss: 2.4499 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3198 - accuracy: 0.4764 - val_loss: 2.5141 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2980 - accuracy: 0.4779 - val_loss: 2.6728 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2627 - accuracy: 0.4901 - val_loss: 2.6333 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2416 - accuracy: 0.5013 - val_loss: 2.6931 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9098 - accuracy: 0.1736\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.174 total time=  14.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 15.2458 - accuracy: 0.1608 - val_loss: 1.8964 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8510 - accuracy: 0.2141 - val_loss: 1.8723 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7688 - accuracy: 0.2501 - val_loss: 1.8940 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6784 - accuracy: 0.3070 - val_loss: 1.9134 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6622 - accuracy: 0.3212 - val_loss: 2.1010 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5338 - accuracy: 0.3648 - val_loss: 2.2362 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4487 - accuracy: 0.4170 - val_loss: 2.5264 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3462 - accuracy: 0.4729 - val_loss: 2.6358 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2870 - accuracy: 0.4987 - val_loss: 2.7114 - val_accuracy: 0.2932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2052 - accuracy: 0.5211 - val_loss: 2.7885 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1847 - accuracy: 0.5327 - val_loss: 2.7073 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1750 - accuracy: 0.5368 - val_loss: 2.7918 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9051 - accuracy: 0.2162\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.216 total time=  15.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 33.4293 - accuracy: 0.1518 - val_loss: 1.9417 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.8843 - accuracy: 0.2086 - val_loss: 1.8894 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7185 - accuracy: 0.3041 - val_loss: 2.0637 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4718 - accuracy: 0.4193 - val_loss: 2.3869 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2742 - accuracy: 0.5249 - val_loss: 2.9058 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0394 - accuracy: 0.6076 - val_loss: 2.2127 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9122 - accuracy: 0.6741 - val_loss: 3.5586 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6893 - accuracy: 0.7401 - val_loss: 3.8829 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6585 - accuracy: 0.7609 - val_loss: 3.7950 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6073 - accuracy: 0.7766 - val_loss: 3.9718 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5913 - accuracy: 0.7807 - val_loss: 4.0386 - val_accuracy: 0.3230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5528 - accuracy: 0.7904 - val_loss: 3.9567 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8772 - accuracy: 0.2039\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.204 total time=  18.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 59.4344 - accuracy: 0.1542 - val_loss: 1.8823 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.8457 - accuracy: 0.2425 - val_loss: 1.8638 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6182 - accuracy: 0.3557 - val_loss: 1.9789 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4126 - accuracy: 0.4505 - val_loss: 2.5425 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.1485 - accuracy: 0.5525 - val_loss: 2.9030 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9269 - accuracy: 0.6479 - val_loss: 4.2354 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0638 - accuracy: 0.6124 - val_loss: 4.5769 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7185 - accuracy: 0.7407 - val_loss: 5.1803 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6574 - accuracy: 0.7702 - val_loss: 5.3750 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5668 - accuracy: 0.7920 - val_loss: 5.9683 - val_accuracy: 0.3716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5301 - accuracy: 0.8001 - val_loss: 6.4408 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5072 - accuracy: 0.8087 - val_loss: 6.2976 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8583 - accuracy: 0.2162\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.216 total time=  18.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 20.1159 - accuracy: 0.1791 - val_loss: 1.8946 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8394 - accuracy: 0.2369 - val_loss: 1.9152 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7834 - accuracy: 0.2598 - val_loss: 1.8996 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6360 - accuracy: 0.3298 - val_loss: 2.0677 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.4480 - accuracy: 0.4378 - val_loss: 2.0526 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2726 - accuracy: 0.5271 - val_loss: 2.2888 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0113 - accuracy: 0.6190 - val_loss: 2.6683 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9320 - accuracy: 0.6616 - val_loss: 2.9652 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8597 - accuracy: 0.6809 - val_loss: 3.1392 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8000 - accuracy: 0.7042 - val_loss: 3.3321 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7526 - accuracy: 0.7215 - val_loss: 3.4114 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9073 - accuracy: 0.1746\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.175 total time=  16.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 10.1623 - accuracy: 0.1360 - val_loss: 1.9096 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8764 - accuracy: 0.1853 - val_loss: 1.8818 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7638 - accuracy: 0.2604 - val_loss: 1.9410 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6478 - accuracy: 0.3193 - val_loss: 2.0613 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5313 - accuracy: 0.3528 - val_loss: 2.3390 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3915 - accuracy: 0.4310 - val_loss: 2.3669 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3626 - accuracy: 0.4584 - val_loss: 2.5534 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1993 - accuracy: 0.5198 - val_loss: 3.0415 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1198 - accuracy: 0.5442 - val_loss: 3.0608 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0873 - accuracy: 0.5660 - val_loss: 2.9942 - val_accuracy: 0.3027 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0608 - accuracy: 0.5721 - val_loss: 3.0768 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0264 - accuracy: 0.5873 - val_loss: 3.2152 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8762 - accuracy: 0.2089\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.209 total time=  15.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 12.4191 - accuracy: 0.1821 - val_loss: 1.9105 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8371 - accuracy: 0.2349 - val_loss: 1.9577 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7374 - accuracy: 0.2796 - val_loss: 1.9574 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6131 - accuracy: 0.3288 - val_loss: 2.1906 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5662 - accuracy: 0.3658 - val_loss: 2.2288 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4408 - accuracy: 0.4277 - val_loss: 2.5200 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2380 - accuracy: 0.4997 - val_loss: 2.7555 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1763 - accuracy: 0.5368 - val_loss: 2.7343 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1331 - accuracy: 0.5556 - val_loss: 2.9127 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0840 - accuracy: 0.5728 - val_loss: 2.9470 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0536 - accuracy: 0.5895 - val_loss: 3.0548 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9211 - accuracy: 0.1878\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.188 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 8.2537 - accuracy: 0.1761 - val_loss: 1.9013 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8297 - accuracy: 0.2192 - val_loss: 1.8969 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7384 - accuracy: 0.2836 - val_loss: 1.9224 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6355 - accuracy: 0.3171 - val_loss: 2.0535 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5132 - accuracy: 0.3765 - val_loss: 2.1573 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5015 - accuracy: 0.4008 - val_loss: 2.5388 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3190 - accuracy: 0.4663 - val_loss: 2.5054 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1838 - accuracy: 0.5160 - val_loss: 2.6990 - val_accuracy: 0.2865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1339 - accuracy: 0.5383 - val_loss: 2.9049 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0948 - accuracy: 0.5474 - val_loss: 2.8972 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0631 - accuracy: 0.5718 - val_loss: 3.0472 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0539 - accuracy: 0.5708 - val_loss: 3.1456 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9560 - accuracy: 0.1756\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.176 total time=  15.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 32ms/step - loss: 102.5724 - accuracy: 0.1645 - val_loss: 1.9136 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8439 - accuracy: 0.2497 - val_loss: 1.8815 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.6410 - accuracy: 0.3609 - val_loss: 1.9208 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.4088 - accuracy: 0.4563 - val_loss: 2.1351 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2130 - accuracy: 0.5345 - val_loss: 2.8350 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0281 - accuracy: 0.6178 - val_loss: 3.6806 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.8362 - accuracy: 0.6792 - val_loss: 3.4132 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.6827 - accuracy: 0.7406 - val_loss: 4.0039 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.6603 - accuracy: 0.7624 - val_loss: 4.1176 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.5957 - accuracy: 0.7761 - val_loss: 4.4315 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5912 - accuracy: 0.7772 - val_loss: 4.6553 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5637 - accuracy: 0.7848 - val_loss: 4.2211 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.8892 - accuracy: 0.2150\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.215 total time=  20.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 32ms/step - loss: 98.1906 - accuracy: 0.1933 - val_loss: 1.9139 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8347 - accuracy: 0.2532 - val_loss: 1.8848 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.7135 - accuracy: 0.3044 - val_loss: 2.0166 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.5412 - accuracy: 0.4008 - val_loss: 2.2303 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.3204 - accuracy: 0.4982 - val_loss: 3.0363 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.1908 - accuracy: 0.5850 - val_loss: 2.7507 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.9098 - accuracy: 0.6865 - val_loss: 3.1909 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.7003 - accuracy: 0.7524 - val_loss: 4.1728 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6231 - accuracy: 0.7747 - val_loss: 4.2061 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.6102 - accuracy: 0.7894 - val_loss: 4.0495 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.5825 - accuracy: 0.8077 - val_loss: 4.1133 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5106 - accuracy: 0.8194 - val_loss: 4.6836 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.9353 - accuracy: 0.2091\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.209 total time=  20.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 28ms/step - loss: 76.0145 - accuracy: 0.1735 - val_loss: 1.8991 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8060 - accuracy: 0.2648 - val_loss: 1.8647 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.5864 - accuracy: 0.3800 - val_loss: 2.0634 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.4567 - accuracy: 0.4612 - val_loss: 2.4080 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.1533 - accuracy: 0.5596 - val_loss: 2.5177 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.9716 - accuracy: 0.6565 - val_loss: 3.3544 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.8430 - accuracy: 0.7088 - val_loss: 3.4306 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.6698 - accuracy: 0.7692 - val_loss: 3.7466 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6226 - accuracy: 0.7727 - val_loss: 3.7923 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5777 - accuracy: 0.7874 - val_loss: 3.9856 - val_accuracy: 0.3243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.6074 - accuracy: 0.7986 - val_loss: 4.0796 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5415 - accuracy: 0.8092 - val_loss: 3.9643 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8918 - accuracy: 0.2203\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.220 total time=  20.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 24ms/step - loss: 22.3677 - accuracy: 0.1553 - val_loss: 1.8620 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8458 - accuracy: 0.2142 - val_loss: 1.8571 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6932 - accuracy: 0.3000 - val_loss: 1.9452 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5331 - accuracy: 0.3893 - val_loss: 1.9500 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4248 - accuracy: 0.4365 - val_loss: 2.4675 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2255 - accuracy: 0.5345 - val_loss: 2.1512 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0889 - accuracy: 0.6025 - val_loss: 2.6363 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9172 - accuracy: 0.6624 - val_loss: 2.9186 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7804 - accuracy: 0.7112 - val_loss: 3.0852 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7378 - accuracy: 0.7274 - val_loss: 2.9955 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7014 - accuracy: 0.7416 - val_loss: 2.9949 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6583 - accuracy: 0.7543 - val_loss: 3.1840 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.8831 - accuracy: 0.1795\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.180 total time=  15.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 24ms/step - loss: 27.3515 - accuracy: 0.1613 - val_loss: 1.9185 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8862 - accuracy: 0.2035 - val_loss: 2.0880 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7943 - accuracy: 0.2618 - val_loss: 1.9725 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6031 - accuracy: 0.3511 - val_loss: 2.0258 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4606 - accuracy: 0.4099 - val_loss: 2.1321 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2944 - accuracy: 0.4972 - val_loss: 2.5028 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1482 - accuracy: 0.5606 - val_loss: 2.6373 - val_accuracy: 0.2973 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1073 - accuracy: 0.5687 - val_loss: 2.9709 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0563 - accuracy: 0.5840 - val_loss: 2.8492 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0234 - accuracy: 0.6063 - val_loss: 3.2206 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9864 - accuracy: 0.6154 - val_loss: 3.1477 - val_accuracy: 0.2932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.9293 - accuracy: 0.1563\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.156 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 24.2880 - accuracy: 0.1689 - val_loss: 1.8968 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8728 - accuracy: 0.2187 - val_loss: 1.9154 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7899 - accuracy: 0.2435 - val_loss: 1.9332 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6893 - accuracy: 0.2856 - val_loss: 2.0401 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5931 - accuracy: 0.3491 - val_loss: 2.1267 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4773 - accuracy: 0.4028 - val_loss: 2.3077 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3534 - accuracy: 0.4510 - val_loss: 2.4497 - val_accuracy: 0.2676 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3183 - accuracy: 0.4556 - val_loss: 2.5111 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2821 - accuracy: 0.4754 - val_loss: 2.5666 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2753 - accuracy: 0.4769 - val_loss: 2.5748 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2371 - accuracy: 0.4962 - val_loss: 2.6298 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9130 - accuracy: 0.1868\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.187 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 94.2174 - accuracy: 0.1914 - val_loss: 1.8997 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 1.8084 - accuracy: 0.2589 - val_loss: 1.8771 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.6317 - accuracy: 0.3614 - val_loss: 1.9367 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.4984 - accuracy: 0.4228 - val_loss: 2.0333 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2977 - accuracy: 0.5036 - val_loss: 2.5921 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0499 - accuracy: 0.6208 - val_loss: 2.7140 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8768 - accuracy: 0.6904 - val_loss: 3.6838 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6273 - accuracy: 0.7756 - val_loss: 3.7562 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5693 - accuracy: 0.7883 - val_loss: 4.1434 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5277 - accuracy: 0.7959 - val_loss: 4.1689 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4942 - accuracy: 0.8071 - val_loss: 4.3854 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4599 - accuracy: 0.8254 - val_loss: 4.4603 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9045 - accuracy: 0.2150\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.215 total time=  20.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 53.9291 - accuracy: 0.1766 - val_loss: 1.9061 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 1.8675 - accuracy: 0.2227 - val_loss: 1.8861 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.7494 - accuracy: 0.2917 - val_loss: 2.0268 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.5899 - accuracy: 0.3648 - val_loss: 2.3484 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.4890 - accuracy: 0.4490 - val_loss: 2.0973 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2748 - accuracy: 0.5221 - val_loss: 2.4342 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0564 - accuracy: 0.6017 - val_loss: 3.2734 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8017 - accuracy: 0.6885 - val_loss: 3.8944 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7328 - accuracy: 0.7179 - val_loss: 3.9689 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7079 - accuracy: 0.7260 - val_loss: 4.1233 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6522 - accuracy: 0.7494 - val_loss: 4.2967 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6186 - accuracy: 0.7626 - val_loss: 4.3573 - val_accuracy: 0.3568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9189 - accuracy: 0.2081\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.208 total time=  20.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 29ms/step - loss: 131.5538 - accuracy: 0.1629 - val_loss: 1.9199 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 1.8816 - accuracy: 0.1984 - val_loss: 1.8702 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.7733 - accuracy: 0.2567 - val_loss: 1.8804 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.6449 - accuracy: 0.3333 - val_loss: 2.1710 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.4688 - accuracy: 0.4186 - val_loss: 2.1664 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2562 - accuracy: 0.5003 - val_loss: 3.0175 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.1396 - accuracy: 0.5708 - val_loss: 3.1061 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.9313 - accuracy: 0.6408 - val_loss: 4.1622 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8631 - accuracy: 0.6585 - val_loss: 4.1298 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8162 - accuracy: 0.6687 - val_loss: 4.5806 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7877 - accuracy: 0.6778 - val_loss: 4.2326 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7567 - accuracy: 0.6971 - val_loss: 4.6246 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9199 - accuracy: 0.1827\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.183 total time=  20.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 23.4419 - accuracy: 0.1604 - val_loss: 1.8966 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8277 - accuracy: 0.2452 - val_loss: 1.8896 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7169 - accuracy: 0.2904 - val_loss: 2.0254 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5669 - accuracy: 0.3589 - val_loss: 1.9867 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3867 - accuracy: 0.4421 - val_loss: 2.2338 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3371 - accuracy: 0.4934 - val_loss: 2.7723 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1713 - accuracy: 0.5569 - val_loss: 3.3291 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9787 - accuracy: 0.6254 - val_loss: 3.3000 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9174 - accuracy: 0.6472 - val_loss: 3.3680 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8818 - accuracy: 0.6569 - val_loss: 3.5776 - val_accuracy: 0.2973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8438 - accuracy: 0.6741 - val_loss: 3.5902 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8059 - accuracy: 0.6868 - val_loss: 3.6924 - val_accuracy: 0.3054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8850 - accuracy: 0.1734\n",
      "[CV 1/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.173 total time=  15.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 33.6959 - accuracy: 0.1791 - val_loss: 1.8879 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8661 - accuracy: 0.2207 - val_loss: 1.8805 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7869 - accuracy: 0.2481 - val_loss: 1.9609 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7098 - accuracy: 0.3054 - val_loss: 2.1279 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6175 - accuracy: 0.3425 - val_loss: 2.1766 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5275 - accuracy: 0.3947 - val_loss: 2.3401 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4542 - accuracy: 0.4191 - val_loss: 2.6080 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2975 - accuracy: 0.4698 - val_loss: 2.9485 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2532 - accuracy: 0.4886 - val_loss: 3.0142 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2124 - accuracy: 0.5094 - val_loss: 3.0164 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1815 - accuracy: 0.5216 - val_loss: 3.1317 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1422 - accuracy: 0.5454 - val_loss: 3.2656 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8966 - accuracy: 0.1838\n",
      "[CV 2/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.184 total time=  15.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 20.9753 - accuracy: 0.1654 - val_loss: 1.9217 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8544 - accuracy: 0.2192 - val_loss: 1.8996 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7632 - accuracy: 0.2537 - val_loss: 1.9605 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6841 - accuracy: 0.2917 - val_loss: 2.2021 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5775 - accuracy: 0.3480 - val_loss: 2.2842 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4970 - accuracy: 0.3831 - val_loss: 2.5638 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3985 - accuracy: 0.4328 - val_loss: 3.3215 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2593 - accuracy: 0.4866 - val_loss: 3.1588 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2020 - accuracy: 0.5053 - val_loss: 3.2284 - val_accuracy: 0.2973 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1650 - accuracy: 0.5277 - val_loss: 3.3591 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1252 - accuracy: 0.5424 - val_loss: 3.3701 - val_accuracy: 0.3054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0911 - accuracy: 0.5601 - val_loss: 3.4536 - val_accuracy: 0.2973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8904 - accuracy: 0.1898\n",
      "[CV 3/3] END activation=sigmoid, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.190 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 91.1918 - accuracy: 0.1726 - val_loss: 1.8389 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6095 - accuracy: 0.3853 - val_loss: 1.6425 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0568 - accuracy: 0.5964 - val_loss: 1.5720 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6909 - accuracy: 0.7477 - val_loss: 1.5077 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5374 - accuracy: 0.8071 - val_loss: 1.7217 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4725 - accuracy: 0.8467 - val_loss: 1.6714 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3875 - accuracy: 0.8619 - val_loss: 1.6731 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3153 - accuracy: 0.8792 - val_loss: 1.7690 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2807 - accuracy: 0.8980 - val_loss: 1.7195 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2486 - accuracy: 0.9081 - val_loss: 1.6739 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2495 - accuracy: 0.9010 - val_loss: 1.6566 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2326 - accuracy: 0.9127 - val_loss: 1.7507 - val_accuracy: 0.5459 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2022 - accuracy: 0.9188 - val_loss: 1.7595 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1868 - accuracy: 0.9279 - val_loss: 1.7078 - val_accuracy: 0.5608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.4913 - accuracy: 0.5132\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.513 total time=  12.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 81.8950 - accuracy: 0.1887 - val_loss: 1.8433 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6281 - accuracy: 0.3678 - val_loss: 1.6589 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1057 - accuracy: 0.6093 - val_loss: 1.5920 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7762 - accuracy: 0.7341 - val_loss: 1.6091 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5789 - accuracy: 0.7950 - val_loss: 1.6246 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5068 - accuracy: 0.8366 - val_loss: 1.7067 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3861 - accuracy: 0.8701 - val_loss: 1.6815 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2996 - accuracy: 0.8904 - val_loss: 1.7288 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2409 - accuracy: 0.8985 - val_loss: 1.8144 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2430 - accuracy: 0.9051 - val_loss: 1.8554 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1947 - accuracy: 0.9264 - val_loss: 1.9543 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2112 - accuracy: 0.9153 - val_loss: 1.9028 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1804 - accuracy: 0.9234 - val_loss: 1.9545 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.6492 - accuracy: 0.4020\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.402 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 16ms/step - loss: 130.0007 - accuracy: 0.1745 - val_loss: 1.8932 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6840 - accuracy: 0.3232 - val_loss: 1.7598 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4167 - accuracy: 0.4678 - val_loss: 1.6270 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1329 - accuracy: 0.5672 - val_loss: 1.6419 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9254 - accuracy: 0.6621 - val_loss: 1.6077 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7107 - accuracy: 0.7220 - val_loss: 1.5470 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6795 - accuracy: 0.7565 - val_loss: 1.5607 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5861 - accuracy: 0.7965 - val_loss: 1.6622 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5237 - accuracy: 0.8133 - val_loss: 1.6847 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4700 - accuracy: 0.8239 - val_loss: 2.0631 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4367 - accuracy: 0.8483 - val_loss: 1.5214 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3951 - accuracy: 0.8615 - val_loss: 1.5933 - val_accuracy: 0.5122 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3585 - accuracy: 0.8782 - val_loss: 1.7849 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3340 - accuracy: 0.8757 - val_loss: 1.6250 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3341 - accuracy: 0.8874 - val_loss: 1.7290 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2733 - accuracy: 0.8975 - val_loss: 1.6545 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2582 - accuracy: 0.9097 - val_loss: 1.6882 - val_accuracy: 0.5581 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2230 - accuracy: 0.9168 - val_loss: 1.6962 - val_accuracy: 0.5743 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2207 - accuracy: 0.9127 - val_loss: 1.6601 - val_accuracy: 0.5595 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1939 - accuracy: 0.9280 - val_loss: 1.7332 - val_accuracy: 0.5581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 2.0009 - accuracy: 0.5320\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.532 total time=  18.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 18.6489 - accuracy: 0.1558 - val_loss: 1.9319 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.9271 - accuracy: 0.1635 - val_loss: 1.9183 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.8900 - accuracy: 0.2350 - val_loss: 1.8310 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6339 - accuracy: 0.3934 - val_loss: 1.7160 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.2651 - accuracy: 0.5360 - val_loss: 1.6656 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.9161 - accuracy: 0.6685 - val_loss: 1.6595 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7087 - accuracy: 0.7558 - val_loss: 1.6149 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6017 - accuracy: 0.7949 - val_loss: 1.7254 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5470 - accuracy: 0.8173 - val_loss: 1.6865 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4807 - accuracy: 0.8254 - val_loss: 1.7525 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4578 - accuracy: 0.8421 - val_loss: 1.6014 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4408 - accuracy: 0.8548 - val_loss: 1.7899 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4029 - accuracy: 0.8563 - val_loss: 1.9205 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3510 - accuracy: 0.8736 - val_loss: 1.8587 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4082 - accuracy: 0.8650 - val_loss: 1.9766 - val_accuracy: 0.5365 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3590 - accuracy: 0.8838 - val_loss: 1.9942 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2608 - accuracy: 0.9020 - val_loss: 1.9874 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2534 - accuracy: 0.9061 - val_loss: 2.0185 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2507 - accuracy: 0.9127 - val_loss: 2.0246 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2214 - accuracy: 0.9142 - val_loss: 2.0776 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.8583 - accuracy: 0.5365\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.537 total time=  15.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 31.3560 - accuracy: 0.1507 - val_loss: 1.9133 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.8468 - accuracy: 0.2445 - val_loss: 1.8625 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6313 - accuracy: 0.3648 - val_loss: 1.8092 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.4021 - accuracy: 0.4805 - val_loss: 1.7746 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.1433 - accuracy: 0.5809 - val_loss: 1.8117 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.9367 - accuracy: 0.6565 - val_loss: 1.8460 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7652 - accuracy: 0.7149 - val_loss: 1.8491 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6584 - accuracy: 0.7524 - val_loss: 1.9963 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6027 - accuracy: 0.7864 - val_loss: 1.9087 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4921 - accuracy: 0.8102 - val_loss: 2.0058 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4684 - accuracy: 0.8163 - val_loss: 2.0475 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4177 - accuracy: 0.8376 - val_loss: 2.1090 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4155 - accuracy: 0.8336 - val_loss: 2.1426 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3990 - accuracy: 0.8427 - val_loss: 2.1729 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8324 - accuracy: 0.3340\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.334 total time=  11.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 33.6903 - accuracy: 0.1593 - val_loss: 1.9174 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.8416 - accuracy: 0.2623 - val_loss: 1.8191 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6185 - accuracy: 0.3927 - val_loss: 1.7371 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.3351 - accuracy: 0.5292 - val_loss: 1.7013 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.0465 - accuracy: 0.6535 - val_loss: 1.7350 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7618 - accuracy: 0.7412 - val_loss: 1.7351 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6073 - accuracy: 0.7971 - val_loss: 1.9152 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4971 - accuracy: 0.8361 - val_loss: 1.9051 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4245 - accuracy: 0.8737 - val_loss: 1.9776 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2893 - accuracy: 0.9082 - val_loss: 2.1020 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2836 - accuracy: 0.9046 - val_loss: 2.0587 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2709 - accuracy: 0.9148 - val_loss: 2.1722 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2277 - accuracy: 0.9224 - val_loss: 2.2576 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2062 - accuracy: 0.9381 - val_loss: 2.2026 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.7852 - accuracy: 0.3421\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.342 total time=  11.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 162.2733 - accuracy: 0.1873 - val_loss: 1.8431 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.4912 - accuracy: 0.4711 - val_loss: 1.7708 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6948 - accuracy: 0.8010 - val_loss: 1.9978 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2702 - accuracy: 0.9335 - val_loss: 2.4458 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1171 - accuracy: 0.9772 - val_loss: 2.8075 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0784 - accuracy: 0.9838 - val_loss: 3.2190 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0691 - accuracy: 0.9893 - val_loss: 3.3139 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0464 - accuracy: 0.9924 - val_loss: 3.1111 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0196 - accuracy: 0.9959 - val_loss: 3.3754 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0314 - accuracy: 0.9944 - val_loss: 3.3765 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0454 - accuracy: 0.9934 - val_loss: 3.3840 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 3.1731 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7678 - accuracy: 0.3327\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.333 total time=  11.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 244.4689 - accuracy: 0.2156 - val_loss: 1.8109 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.4129 - accuracy: 0.5378 - val_loss: 1.6542 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6645 - accuracy: 0.8179 - val_loss: 1.6617 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2702 - accuracy: 0.9442 - val_loss: 1.8794 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1124 - accuracy: 0.9726 - val_loss: 2.3474 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0727 - accuracy: 0.9863 - val_loss: 2.1108 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0665 - accuracy: 0.9863 - val_loss: 2.4568 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0483 - accuracy: 0.9919 - val_loss: 2.5041 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0716 - accuracy: 0.9904 - val_loss: 2.4800 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0352 - accuracy: 0.9929 - val_loss: 2.4272 - val_accuracy: 0.5311 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 2.5057 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0227 - accuracy: 0.9964 - val_loss: 2.5985 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7712 - accuracy: 0.3848\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.385 total time=  11.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 131.5583 - accuracy: 0.1943 - val_loss: 1.8774 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5202 - accuracy: 0.4759 - val_loss: 1.8865 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8141 - accuracy: 0.7478 - val_loss: 2.3813 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4229 - accuracy: 0.8787 - val_loss: 2.4108 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2315 - accuracy: 0.9523 - val_loss: 2.5895 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1286 - accuracy: 0.9696 - val_loss: 3.0799 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0804 - accuracy: 0.9802 - val_loss: 2.8842 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0641 - accuracy: 0.9858 - val_loss: 3.0565 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0602 - accuracy: 0.9904 - val_loss: 3.1356 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0683 - accuracy: 0.9853 - val_loss: 3.0875 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0510 - accuracy: 0.9893 - val_loss: 3.0900 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8968 - accuracy: 0.2518\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.252 total time=  10.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 36.9009 - accuracy: 0.1858 - val_loss: 1.8852 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6552 - accuracy: 0.3594 - val_loss: 1.8279 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.1243 - accuracy: 0.6315 - val_loss: 1.9527 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6453 - accuracy: 0.7970 - val_loss: 2.1048 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4043 - accuracy: 0.8838 - val_loss: 2.6110 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2551 - accuracy: 0.9360 - val_loss: 2.6133 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1851 - accuracy: 0.9513 - val_loss: 2.7588 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1406 - accuracy: 0.9665 - val_loss: 2.9528 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1009 - accuracy: 0.9766 - val_loss: 3.0329 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0922 - accuracy: 0.9807 - val_loss: 3.0819 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0954 - accuracy: 0.9792 - val_loss: 2.9802 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0811 - accuracy: 0.9843 - val_loss: 3.0997 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7828 - accuracy: 0.3012\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.301 total time=   9.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 29.1562 - accuracy: 0.1776 - val_loss: 1.8753 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.7364 - accuracy: 0.3141 - val_loss: 1.8876 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.4230 - accuracy: 0.4703 - val_loss: 1.8662 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.9930 - accuracy: 0.6418 - val_loss: 2.2626 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6968 - accuracy: 0.7590 - val_loss: 2.7245 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5295 - accuracy: 0.8361 - val_loss: 3.1812 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4729 - accuracy: 0.8569 - val_loss: 3.8775 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3737 - accuracy: 0.8990 - val_loss: 3.8309 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2949 - accuracy: 0.9259 - val_loss: 3.6776 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1979 - accuracy: 0.9447 - val_loss: 3.7609 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1851 - accuracy: 0.9554 - val_loss: 3.7974 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1654 - accuracy: 0.9569 - val_loss: 3.8121 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1564 - accuracy: 0.9564 - val_loss: 4.0344 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.8853 - accuracy: 0.3046\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.305 total time=  10.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 56.5793 - accuracy: 0.1735 - val_loss: 1.8614 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.6416 - accuracy: 0.3678 - val_loss: 1.8315 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.1257 - accuracy: 0.5921 - val_loss: 2.0863 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7308 - accuracy: 0.7392 - val_loss: 2.7008 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5405 - accuracy: 0.8285 - val_loss: 2.5472 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3860 - accuracy: 0.8874 - val_loss: 3.1941 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3126 - accuracy: 0.9102 - val_loss: 3.5785 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1979 - accuracy: 0.9493 - val_loss: 3.8270 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1637 - accuracy: 0.9488 - val_loss: 3.9118 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1631 - accuracy: 0.9528 - val_loss: 3.8362 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1528 - accuracy: 0.9518 - val_loss: 3.9872 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1382 - accuracy: 0.9594 - val_loss: 4.0164 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8465 - accuracy: 0.3046\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.305 total time=   9.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 193.0741 - accuracy: 0.1680 - val_loss: 1.8881 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7404 - accuracy: 0.2975 - val_loss: 1.6611 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.4480 - accuracy: 0.4467 - val_loss: 1.6045 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.1469 - accuracy: 0.5487 - val_loss: 1.5768 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.9533 - accuracy: 0.6406 - val_loss: 1.9126 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.8557 - accuracy: 0.6843 - val_loss: 1.5294 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6665 - accuracy: 0.7518 - val_loss: 1.6016 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5636 - accuracy: 0.7914 - val_loss: 1.5811 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5174 - accuracy: 0.7995 - val_loss: 1.5359 - val_accuracy: 0.5351 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4606 - accuracy: 0.8279 - val_loss: 1.7279 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4281 - accuracy: 0.8513 - val_loss: 1.5988 - val_accuracy: 0.5432 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3550 - accuracy: 0.8751 - val_loss: 1.5447 - val_accuracy: 0.5378 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3347 - accuracy: 0.8721 - val_loss: 1.5447 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2827 - accuracy: 0.8985 - val_loss: 1.5593 - val_accuracy: 0.5541 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3172 - accuracy: 0.8787 - val_loss: 1.6189 - val_accuracy: 0.5622 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3006 - accuracy: 0.8817 - val_loss: 1.6102 - val_accuracy: 0.5581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.4315 - accuracy: 0.5254\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.525 total time=  17.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 230.6791 - accuracy: 0.1745 - val_loss: 1.8667 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.6265 - accuracy: 0.4003 - val_loss: 1.7720 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.0233 - accuracy: 0.6646 - val_loss: 1.7073 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.6380 - accuracy: 0.8108 - val_loss: 2.0795 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3744 - accuracy: 0.8945 - val_loss: 2.1260 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3102 - accuracy: 0.9198 - val_loss: 2.6119 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2653 - accuracy: 0.9406 - val_loss: 2.3435 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1869 - accuracy: 0.9589 - val_loss: 2.5054 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1273 - accuracy: 0.9685 - val_loss: 2.4276 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1262 - accuracy: 0.9670 - val_loss: 2.4251 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1129 - accuracy: 0.9741 - val_loss: 2.3263 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1089 - accuracy: 0.9711 - val_loss: 2.3858 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1046 - accuracy: 0.9741 - val_loss: 2.3876 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.7726 - accuracy: 0.4112\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.411 total time=  14.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 227.8440 - accuracy: 0.1847 - val_loss: 1.8498 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.5805 - accuracy: 0.4272 - val_loss: 1.6629 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.9010 - accuracy: 0.7235 - val_loss: 1.7933 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5003 - accuracy: 0.8792 - val_loss: 1.8277 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2353 - accuracy: 0.9310 - val_loss: 2.0501 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1630 - accuracy: 0.9630 - val_loss: 2.0398 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1365 - accuracy: 0.9660 - val_loss: 2.2773 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1250 - accuracy: 0.9782 - val_loss: 2.2089 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1060 - accuracy: 0.9777 - val_loss: 2.2635 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0820 - accuracy: 0.9822 - val_loss: 2.1905 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0715 - accuracy: 0.9838 - val_loss: 2.2378 - val_accuracy: 0.5459 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 2.2414 - val_accuracy: 0.5378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7202 - accuracy: 0.3878\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.388 total time=  13.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 40.8068 - accuracy: 0.1964 - val_loss: 1.8318 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4978 - accuracy: 0.4660 - val_loss: 1.6888 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8889 - accuracy: 0.7020 - val_loss: 1.7555 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5054 - accuracy: 0.8503 - val_loss: 1.7823 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2806 - accuracy: 0.9173 - val_loss: 1.9913 - val_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2361 - accuracy: 0.9406 - val_loss: 1.9490 - val_accuracy: 0.5162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1900 - accuracy: 0.9523 - val_loss: 2.1856 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1093 - accuracy: 0.9777 - val_loss: 2.1531 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0855 - accuracy: 0.9777 - val_loss: 2.2181 - val_accuracy: 0.5608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0773 - accuracy: 0.9812 - val_loss: 2.2712 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0688 - accuracy: 0.9807 - val_loss: 2.2797 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0612 - accuracy: 0.9853 - val_loss: 2.3185 - val_accuracy: 0.5568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7126 - accuracy: 0.3955\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.396 total time=  10.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 66.7733 - accuracy: 0.1512 - val_loss: 1.9462 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9459 - accuracy: 0.1456 - val_loss: 1.9464 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9457 - accuracy: 0.1405 - val_loss: 1.9467 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9455 - accuracy: 0.1441 - val_loss: 1.9469 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9454 - accuracy: 0.1507 - val_loss: 1.9469 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9454 - accuracy: 0.1507 - val_loss: 1.9471 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.1507 - val_loss: 1.9472 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.1507 - val_loss: 1.9472 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.1507 - val_loss: 1.9472 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.1507 - val_loss: 1.9472 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.1507 - val_loss: 1.9472 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9460 - accuracy: 0.1421\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.142 total time=   9.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 89.5648 - accuracy: 0.1497 - val_loss: 1.9120 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8294 - accuracy: 0.2283 - val_loss: 1.8591 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6568 - accuracy: 0.3323 - val_loss: 1.9085 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4283 - accuracy: 0.4439 - val_loss: 1.8588 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1607 - accuracy: 0.5637 - val_loss: 1.8331 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9702 - accuracy: 0.6535 - val_loss: 1.8915 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7370 - accuracy: 0.7367 - val_loss: 1.8234 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5939 - accuracy: 0.7976 - val_loss: 1.9872 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4800 - accuracy: 0.8427 - val_loss: 1.9326 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4370 - accuracy: 0.8569 - val_loss: 2.6456 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4011 - accuracy: 0.8696 - val_loss: 1.8756 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3474 - accuracy: 0.8864 - val_loss: 2.2708 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2998 - accuracy: 0.9072 - val_loss: 2.3362 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2396 - accuracy: 0.9219 - val_loss: 2.5830 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2134 - accuracy: 0.9239 - val_loss: 2.6660 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1968 - accuracy: 0.9351 - val_loss: 2.6570 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1984 - accuracy: 0.9386 - val_loss: 2.6236 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8199 - accuracy: 0.4365\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.437 total time=  14.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 348.9834 - accuracy: 0.1792 - val_loss: 1.8781 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5587 - accuracy: 0.4447 - val_loss: 1.8397 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8164 - accuracy: 0.7533 - val_loss: 2.4354 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3982 - accuracy: 0.8858 - val_loss: 2.5319 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2174 - accuracy: 0.9487 - val_loss: 3.0537 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1249 - accuracy: 0.9690 - val_loss: 3.5570 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1912 - accuracy: 0.9594 - val_loss: 3.2153 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1553 - accuracy: 0.9726 - val_loss: 3.2543 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0854 - accuracy: 0.9822 - val_loss: 3.4881 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0565 - accuracy: 0.9848 - val_loss: 3.7954 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0588 - accuracy: 0.9868 - val_loss: 3.8223 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0389 - accuracy: 0.9904 - val_loss: 3.8963 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8260 - accuracy: 0.2921\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.292 total time=  14.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 136.9778 - accuracy: 0.2217 - val_loss: 1.7521 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2913 - accuracy: 0.5733 - val_loss: 1.5333 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5306 - accuracy: 0.8529 - val_loss: 1.4313 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1684 - accuracy: 0.9604 - val_loss: 1.5829 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0910 - accuracy: 0.9787 - val_loss: 1.7395 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0679 - accuracy: 0.9838 - val_loss: 1.6949 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 2.1029 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0684 - accuracy: 0.9868 - val_loss: 1.8519 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 1.8438 - val_accuracy: 0.5608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0326 - accuracy: 0.9924 - val_loss: 1.8244 - val_accuracy: 0.5635 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 1.8558 - val_accuracy: 0.5676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0235 - accuracy: 0.9959 - val_loss: 1.9033 - val_accuracy: 0.5743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 1.9459 - val_accuracy: 0.5892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.5844 - accuracy: 0.5462\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.546 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 322.9977 - accuracy: 0.2283 - val_loss: 1.8159 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2604 - accuracy: 0.5997 - val_loss: 1.8416 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5677 - accuracy: 0.8407 - val_loss: 2.1584 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2630 - accuracy: 0.9295 - val_loss: 2.9466 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1700 - accuracy: 0.9680 - val_loss: 3.1258 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1178 - accuracy: 0.9782 - val_loss: 3.0800 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0572 - accuracy: 0.9873 - val_loss: 3.4835 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0821 - accuracy: 0.9888 - val_loss: 3.7361 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0397 - accuracy: 0.9914 - val_loss: 3.5282 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 3.7373 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 3.9536 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8346 - accuracy: 0.3066\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.307 total time=  13.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 81.5202 - accuracy: 0.2030 - val_loss: 1.8447 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6231 - accuracy: 0.3904 - val_loss: 1.7768 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0948 - accuracy: 0.6254 - val_loss: 1.8778 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6952 - accuracy: 0.7873 - val_loss: 2.0244 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4058 - accuracy: 0.8812 - val_loss: 2.5141 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2570 - accuracy: 0.9234 - val_loss: 3.0052 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2173 - accuracy: 0.9462 - val_loss: 2.8704 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1288 - accuracy: 0.9635 - val_loss: 3.0400 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0978 - accuracy: 0.9751 - val_loss: 3.0861 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0939 - accuracy: 0.9751 - val_loss: 3.1243 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0946 - accuracy: 0.9802 - val_loss: 3.2579 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0775 - accuracy: 0.9802 - val_loss: 3.3511 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8291 - accuracy: 0.2890\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.289 total time=  10.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 44.0196 - accuracy: 0.1613 - val_loss: 1.9231 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7836 - accuracy: 0.2811 - val_loss: 1.8159 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4576 - accuracy: 0.4480 - val_loss: 1.5595 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1366 - accuracy: 0.5992 - val_loss: 1.5453 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8521 - accuracy: 0.7002 - val_loss: 1.5284 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5954 - accuracy: 0.7864 - val_loss: 1.6032 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5044 - accuracy: 0.8265 - val_loss: 1.5852 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4282 - accuracy: 0.8468 - val_loss: 1.5008 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3336 - accuracy: 0.8909 - val_loss: 1.7728 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2734 - accuracy: 0.9036 - val_loss: 1.6197 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2458 - accuracy: 0.9148 - val_loss: 1.7342 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2683 - accuracy: 0.9122 - val_loss: 1.9051 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1911 - accuracy: 0.9340 - val_loss: 1.6996 - val_accuracy: 0.5635 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1627 - accuracy: 0.9401 - val_loss: 1.7475 - val_accuracy: 0.5703 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1525 - accuracy: 0.9457 - val_loss: 1.8912 - val_accuracy: 0.5689 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1395 - accuracy: 0.9447 - val_loss: 1.8180 - val_accuracy: 0.5770 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1288 - accuracy: 0.9528 - val_loss: 1.8705 - val_accuracy: 0.5703 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1180 - accuracy: 0.9604 - val_loss: 1.8888 - val_accuracy: 0.5892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.5910 - accuracy: 0.5411\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.541 total time=  15.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 114.0195 - accuracy: 0.1953 - val_loss: 1.8543 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5251 - accuracy: 0.4460 - val_loss: 1.8110 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9167 - accuracy: 0.6895 - val_loss: 2.1300 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5212 - accuracy: 0.8483 - val_loss: 2.3782 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2855 - accuracy: 0.9168 - val_loss: 2.4377 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1902 - accuracy: 0.9493 - val_loss: 2.8882 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1523 - accuracy: 0.9680 - val_loss: 3.1511 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0989 - accuracy: 0.9792 - val_loss: 3.1190 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0834 - accuracy: 0.9817 - val_loss: 3.0455 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0974 - accuracy: 0.9848 - val_loss: 3.1307 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0484 - accuracy: 0.9883 - val_loss: 3.1160 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0489 - accuracy: 0.9888 - val_loss: 3.1681 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7809 - accuracy: 0.3381\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.338 total time=  10.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 28.4448 - accuracy: 0.1807 - val_loss: 1.8691 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7895 - accuracy: 0.2711 - val_loss: 1.8300 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6256 - accuracy: 0.3563 - val_loss: 1.6985 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3781 - accuracy: 0.4518 - val_loss: 1.6368 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2241 - accuracy: 0.5132 - val_loss: 1.4805 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0503 - accuracy: 0.6025 - val_loss: 1.6976 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9250 - accuracy: 0.6452 - val_loss: 1.5426 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8341 - accuracy: 0.6741 - val_loss: 1.6022 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7687 - accuracy: 0.7025 - val_loss: 1.5197 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7501 - accuracy: 0.7015 - val_loss: 1.6144 - val_accuracy: 0.5122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6344 - accuracy: 0.7518 - val_loss: 1.5033 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6095 - accuracy: 0.7589 - val_loss: 1.5021 - val_accuracy: 0.5554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5946 - accuracy: 0.7579 - val_loss: 1.5712 - val_accuracy: 0.5527 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5533 - accuracy: 0.7711 - val_loss: 1.6129 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5395 - accuracy: 0.7822 - val_loss: 1.6075 - val_accuracy: 0.5568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.5005 - accuracy: 0.4462\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.446 total time=  19.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 102.2555 - accuracy: 0.1882 - val_loss: 1.8501 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5436 - accuracy: 0.4495 - val_loss: 1.7068 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9493 - accuracy: 0.6986 - val_loss: 1.9123 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5300 - accuracy: 0.8498 - val_loss: 1.8446 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3793 - accuracy: 0.9082 - val_loss: 2.5372 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2541 - accuracy: 0.9274 - val_loss: 2.3586 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1567 - accuracy: 0.9635 - val_loss: 3.1299 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1459 - accuracy: 0.9741 - val_loss: 2.9025 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1264 - accuracy: 0.9741 - val_loss: 2.8392 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0883 - accuracy: 0.9807 - val_loss: 2.8690 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0797 - accuracy: 0.9777 - val_loss: 2.8180 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0893 - accuracy: 0.9843 - val_loss: 2.8953 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 6ms/step - loss: 1.6982 - accuracy: 0.3919\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.392 total time=  15.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 80.2673 - accuracy: 0.2090 - val_loss: 1.8208 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4314 - accuracy: 0.5033 - val_loss: 1.6128 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8313 - accuracy: 0.7529 - val_loss: 1.5976 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3980 - accuracy: 0.8924 - val_loss: 1.7177 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2766 - accuracy: 0.9310 - val_loss: 1.8856 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2022 - accuracy: 0.9498 - val_loss: 2.0317 - val_accuracy: 0.5905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1255 - accuracy: 0.9635 - val_loss: 1.8341 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1221 - accuracy: 0.9716 - val_loss: 2.1522 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1173 - accuracy: 0.9726 - val_loss: 1.8540 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0539 - accuracy: 0.9858 - val_loss: 2.0138 - val_accuracy: 0.5649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0512 - accuracy: 0.9904 - val_loss: 2.0362 - val_accuracy: 0.5676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9853 - val_loss: 2.0405 - val_accuracy: 0.5784 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0760 - accuracy: 0.9833 - val_loss: 1.9529 - val_accuracy: 0.5784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.6982 - accuracy: 0.4863\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.486 total time=  16.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 13.4125 - accuracy: 0.1624 - val_loss: 1.9001 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7812 - accuracy: 0.3081 - val_loss: 1.8508 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.4921 - accuracy: 0.4442 - val_loss: 1.8590 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.0975 - accuracy: 0.6005 - val_loss: 1.9531 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.7779 - accuracy: 0.7452 - val_loss: 2.0891 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.5465 - accuracy: 0.8254 - val_loss: 2.4610 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4400 - accuracy: 0.8706 - val_loss: 2.6638 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3287 - accuracy: 0.9025 - val_loss: 2.6483 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2794 - accuracy: 0.9218 - val_loss: 2.5450 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2589 - accuracy: 0.9249 - val_loss: 2.6191 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2470 - accuracy: 0.9335 - val_loss: 2.6403 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2058 - accuracy: 0.9396 - val_loss: 2.6695 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8951 - accuracy: 0.2444\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.244 total time=  13.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 15.9071 - accuracy: 0.1826 - val_loss: 1.9028 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7469 - accuracy: 0.3191 - val_loss: 1.8518 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.5014 - accuracy: 0.4363 - val_loss: 1.8988 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.0305 - accuracy: 0.6317 - val_loss: 1.8224 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.7148 - accuracy: 0.7626 - val_loss: 2.0485 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4412 - accuracy: 0.8661 - val_loss: 2.0243 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3437 - accuracy: 0.8980 - val_loss: 2.6422 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2590 - accuracy: 0.9178 - val_loss: 2.5619 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2545 - accuracy: 0.9295 - val_loss: 2.3764 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1659 - accuracy: 0.9564 - val_loss: 2.4196 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1286 - accuracy: 0.9625 - val_loss: 2.4621 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1106 - accuracy: 0.9696 - val_loss: 2.4425 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1041 - accuracy: 0.9691 - val_loss: 2.4656 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1095 - accuracy: 0.9680 - val_loss: 2.4800 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8804 - accuracy: 0.3604\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.360 total time=  16.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 25.6618 - accuracy: 0.1664 - val_loss: 1.8933 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.8058 - accuracy: 0.2765 - val_loss: 1.8615 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4585 - accuracy: 0.4683 - val_loss: 1.9013 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1169 - accuracy: 0.6124 - val_loss: 2.2475 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8209 - accuracy: 0.7220 - val_loss: 2.3702 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5846 - accuracy: 0.8097 - val_loss: 2.4255 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4881 - accuracy: 0.8549 - val_loss: 2.7160 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.3278 - accuracy: 0.9097 - val_loss: 2.8721 - val_accuracy: 0.4041 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2853 - accuracy: 0.9168 - val_loss: 3.0211 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2471 - accuracy: 0.9315 - val_loss: 3.0854 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2389 - accuracy: 0.9325 - val_loss: 3.0436 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2323 - accuracy: 0.9391 - val_loss: 3.0778 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8707 - accuracy: 0.2538\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.254 total time=  13.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 103.1639 - accuracy: 0.1893 - val_loss: 1.9008 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6071 - accuracy: 0.3919 - val_loss: 1.9366 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9547 - accuracy: 0.6761 - val_loss: 2.4202 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5212 - accuracy: 0.8426 - val_loss: 3.2901 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5069 - accuracy: 0.8426 - val_loss: 3.3450 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2698 - accuracy: 0.9228 - val_loss: 4.3903 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1351 - accuracy: 0.9655 - val_loss: 4.6991 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1076 - accuracy: 0.9716 - val_loss: 4.6838 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 4.7040 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0639 - accuracy: 0.9848 - val_loss: 4.9269 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0674 - accuracy: 0.9832 - val_loss: 4.8657 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8794 - accuracy: 0.2008\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.201 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 78.7536 - accuracy: 0.1882 - val_loss: 1.8220 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4758 - accuracy: 0.5079 - val_loss: 1.8032 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7688 - accuracy: 0.7534 - val_loss: 2.2650 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3485 - accuracy: 0.8904 - val_loss: 3.2319 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2004 - accuracy: 0.9482 - val_loss: 3.6056 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1716 - accuracy: 0.9584 - val_loss: 3.2550 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1368 - accuracy: 0.9660 - val_loss: 3.9768 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1132 - accuracy: 0.9721 - val_loss: 3.5973 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0699 - accuracy: 0.9827 - val_loss: 3.9311 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0692 - accuracy: 0.9827 - val_loss: 3.9580 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1059 - accuracy: 0.9843 - val_loss: 3.8035 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0537 - accuracy: 0.9873 - val_loss: 4.1261 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8830 - accuracy: 0.3208\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.321 total time=  15.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 61.2442 - accuracy: 0.1923 - val_loss: 1.8555 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4420 - accuracy: 0.4977 - val_loss: 1.8815 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8149 - accuracy: 0.7600 - val_loss: 1.9410 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4440 - accuracy: 0.8803 - val_loss: 3.0826 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2622 - accuracy: 0.9305 - val_loss: 3.2468 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1250 - accuracy: 0.9691 - val_loss: 2.9198 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1087 - accuracy: 0.9812 - val_loss: 3.5094 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0781 - accuracy: 0.9843 - val_loss: 3.4935 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1105 - accuracy: 0.9863 - val_loss: 3.6518 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0510 - accuracy: 0.9883 - val_loss: 3.5696 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0388 - accuracy: 0.9924 - val_loss: 3.9228 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8538 - accuracy: 0.2508\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.251 total time=  14.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 16.4368 - accuracy: 0.1716 - val_loss: 1.8985 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8049 - accuracy: 0.2736 - val_loss: 1.8800 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.5298 - accuracy: 0.4061 - val_loss: 1.8788 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1641 - accuracy: 0.5589 - val_loss: 2.4057 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.9075 - accuracy: 0.6772 - val_loss: 2.7253 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6627 - accuracy: 0.7711 - val_loss: 3.0456 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5052 - accuracy: 0.8360 - val_loss: 3.4348 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3967 - accuracy: 0.8716 - val_loss: 3.6220 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2532 - accuracy: 0.9218 - val_loss: 3.9886 - val_accuracy: 0.3811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2326 - accuracy: 0.9249 - val_loss: 4.0346 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2184 - accuracy: 0.9325 - val_loss: 4.0433 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1891 - accuracy: 0.9340 - val_loss: 4.1140 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1801 - accuracy: 0.9426 - val_loss: 4.2779 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8856 - accuracy: 0.2617\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.262 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 24.6325 - accuracy: 0.1791 - val_loss: 1.8582 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6326 - accuracy: 0.3836 - val_loss: 1.8095 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2576 - accuracy: 0.5332 - val_loss: 2.1367 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8597 - accuracy: 0.7017 - val_loss: 2.3244 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5759 - accuracy: 0.8092 - val_loss: 2.6572 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.8630 - val_loss: 2.9252 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3668 - accuracy: 0.8945 - val_loss: 3.4840 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2299 - accuracy: 0.9376 - val_loss: 3.5691 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1692 - accuracy: 0.9543 - val_loss: 3.8132 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1616 - accuracy: 0.9548 - val_loss: 3.8450 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1292 - accuracy: 0.9609 - val_loss: 3.9086 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1181 - accuracy: 0.9696 - val_loss: 3.9336 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8437 - accuracy: 0.2914\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.291 total time=  14.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 28.6354 - accuracy: 0.1933 - val_loss: 1.8740 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6785 - accuracy: 0.3506 - val_loss: 1.8837 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3049 - accuracy: 0.5190 - val_loss: 2.0195 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8807 - accuracy: 0.6981 - val_loss: 2.5433 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6073 - accuracy: 0.7981 - val_loss: 2.7928 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4795 - accuracy: 0.8579 - val_loss: 3.2200 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3023 - accuracy: 0.9229 - val_loss: 3.4887 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2328 - accuracy: 0.9351 - val_loss: 3.5306 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2037 - accuracy: 0.9386 - val_loss: 3.6037 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1987 - accuracy: 0.9472 - val_loss: 3.6960 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1777 - accuracy: 0.9533 - val_loss: 3.7117 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8898 - accuracy: 0.2041\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.204 total time=  13.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 119.0552 - accuracy: 0.1650 - val_loss: 1.9053 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7666 - accuracy: 0.3112 - val_loss: 1.8080 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2034 - accuracy: 0.6056 - val_loss: 1.7840 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.6769 - accuracy: 0.7959 - val_loss: 2.0541 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.3865 - accuracy: 0.9000 - val_loss: 2.5111 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2530 - accuracy: 0.9345 - val_loss: 2.1388 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1852 - accuracy: 0.9594 - val_loss: 2.9076 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2344 - accuracy: 0.9548 - val_loss: 3.5222 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1945 - accuracy: 0.9711 - val_loss: 2.9718 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1235 - accuracy: 0.9772 - val_loss: 3.0608 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0753 - accuracy: 0.9848 - val_loss: 3.2240 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0879 - accuracy: 0.9802 - val_loss: 3.2315 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0758 - accuracy: 0.9817 - val_loss: 3.1463 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.7389 - accuracy: 0.3773\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.377 total time=  19.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 98.7313 - accuracy: 0.1943 - val_loss: 1.8428 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5662 - accuracy: 0.4531 - val_loss: 1.8765 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.8892 - accuracy: 0.7123 - val_loss: 2.1926 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4663 - accuracy: 0.8600 - val_loss: 2.3934 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.3096 - accuracy: 0.9178 - val_loss: 2.9722 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2076 - accuracy: 0.9518 - val_loss: 3.5489 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1302 - accuracy: 0.9685 - val_loss: 3.8467 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1641 - accuracy: 0.9772 - val_loss: 3.7952 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.0782 - accuracy: 0.9833 - val_loss: 3.8878 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1315 - accuracy: 0.9843 - val_loss: 3.9294 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0610 - accuracy: 0.9883 - val_loss: 4.0459 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8582 - accuracy: 0.2569\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.257 total time=  16.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 142.5041 - accuracy: 0.1948 - val_loss: 1.8703 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6161 - accuracy: 0.4231 - val_loss: 1.8400 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 1.0583 - accuracy: 0.6322 - val_loss: 1.9809 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.6117 - accuracy: 0.8224 - val_loss: 2.3687 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2928 - accuracy: 0.9077 - val_loss: 3.0619 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2952 - accuracy: 0.9285 - val_loss: 2.4340 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.2677 - accuracy: 0.9340 - val_loss: 3.4344 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2232 - accuracy: 0.9482 - val_loss: 3.1330 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 22ms/step - loss: 0.1341 - accuracy: 0.9726 - val_loss: 3.1265 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1211 - accuracy: 0.9741 - val_loss: 3.1623 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0812 - accuracy: 0.9843 - val_loss: 3.2808 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0705 - accuracy: 0.9822 - val_loss: 3.1537 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8861 - accuracy: 0.2853\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.285 total time=  17.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 26.9761 - accuracy: 0.1548 - val_loss: 1.8769 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7388 - accuracy: 0.3360 - val_loss: 1.7486 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3296 - accuracy: 0.5137 - val_loss: 1.7992 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.9467 - accuracy: 0.6756 - val_loss: 1.8900 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6134 - accuracy: 0.7985 - val_loss: 2.1515 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4781 - accuracy: 0.8371 - val_loss: 2.2796 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3269 - accuracy: 0.9046 - val_loss: 2.4328 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2298 - accuracy: 0.9350 - val_loss: 2.5548 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1602 - accuracy: 0.9548 - val_loss: 2.6111 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1676 - accuracy: 0.9518 - val_loss: 2.7229 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1570 - accuracy: 0.9574 - val_loss: 2.6228 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1291 - accuracy: 0.9645 - val_loss: 2.6911 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.7632 - accuracy: 0.2789\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.279 total time=  14.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 25.5082 - accuracy: 0.1761 - val_loss: 1.8536 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6405 - accuracy: 0.3978 - val_loss: 1.7598 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2308 - accuracy: 0.5550 - val_loss: 1.8555 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8504 - accuracy: 0.7164 - val_loss: 2.2742 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6776 - accuracy: 0.7935 - val_loss: 2.0554 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5051 - accuracy: 0.8468 - val_loss: 2.4576 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3230 - accuracy: 0.9092 - val_loss: 2.5943 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2077 - accuracy: 0.9452 - val_loss: 2.6906 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2092 - accuracy: 0.9503 - val_loss: 2.7128 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1582 - accuracy: 0.9609 - val_loss: 2.7349 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1472 - accuracy: 0.9619 - val_loss: 2.7821 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1333 - accuracy: 0.9655 - val_loss: 2.7753 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8119 - accuracy: 0.3350\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.335 total time=  14.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 31.7032 - accuracy: 0.1791 - val_loss: 1.8856 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7219 - accuracy: 0.3480 - val_loss: 1.7220 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3044 - accuracy: 0.5403 - val_loss: 1.7277 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.8510 - accuracy: 0.7245 - val_loss: 1.7713 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6374 - accuracy: 0.8102 - val_loss: 1.9219 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4431 - accuracy: 0.8574 - val_loss: 2.2462 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3465 - accuracy: 0.8970 - val_loss: 2.0771 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2282 - accuracy: 0.9229 - val_loss: 2.1162 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1893 - accuracy: 0.9432 - val_loss: 2.1766 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1583 - accuracy: 0.9508 - val_loss: 2.1557 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1523 - accuracy: 0.9482 - val_loss: 2.1638 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1357 - accuracy: 0.9614 - val_loss: 2.3006 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.7598 - accuracy: 0.3188\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.319 total time=  14.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 183.7249 - accuracy: 0.1919 - val_loss: 1.8766 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5328 - accuracy: 0.4482 - val_loss: 1.9763 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0633 - accuracy: 0.6467 - val_loss: 2.5282 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5773 - accuracy: 0.8279 - val_loss: 2.8129 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2716 - accuracy: 0.9299 - val_loss: 4.3725 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1476 - accuracy: 0.9655 - val_loss: 3.1750 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1876 - accuracy: 0.9675 - val_loss: 3.5586 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0828 - accuracy: 0.9878 - val_loss: 3.9308 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0486 - accuracy: 0.9929 - val_loss: 4.1841 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0475 - accuracy: 0.9924 - val_loss: 4.3355 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0388 - accuracy: 0.9909 - val_loss: 4.2928 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8810 - accuracy: 0.2120\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.212 total time=  17.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 145.7022 - accuracy: 0.2273 - val_loss: 1.8093 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4633 - accuracy: 0.5058 - val_loss: 1.8106 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7491 - accuracy: 0.7560 - val_loss: 2.3409 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.3311 - accuracy: 0.9051 - val_loss: 3.0415 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.2932 - accuracy: 0.9493 - val_loss: 2.3622 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1824 - accuracy: 0.9630 - val_loss: 2.3342 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1053 - accuracy: 0.9767 - val_loss: 2.8933 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.0770 - accuracy: 0.9848 - val_loss: 2.8597 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0478 - accuracy: 0.9883 - val_loss: 3.1112 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 3.2436 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.0581 - accuracy: 0.9863 - val_loss: 3.2252 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8597 - accuracy: 0.2609\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.261 total time=  17.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 167.9546 - accuracy: 0.1730 - val_loss: 1.8579 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5852 - accuracy: 0.4226 - val_loss: 2.0096 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9087 - accuracy: 0.7083 - val_loss: 2.0859 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4160 - accuracy: 0.8787 - val_loss: 2.7931 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.2569 - accuracy: 0.9381 - val_loss: 3.8518 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.1438 - accuracy: 0.9670 - val_loss: 3.5160 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0764 - accuracy: 0.9833 - val_loss: 4.5431 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 4.5361 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0619 - accuracy: 0.9827 - val_loss: 4.4622 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.0424 - accuracy: 0.9888 - val_loss: 4.6209 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.0345 - accuracy: 0.9914 - val_loss: 4.8633 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9023 - accuracy: 0.2315\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.231 total time=  17.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 44.4989 - accuracy: 0.2091 - val_loss: 1.8592 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6139 - accuracy: 0.3853 - val_loss: 1.8496 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1403 - accuracy: 0.6122 - val_loss: 2.0705 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6594 - accuracy: 0.7706 - val_loss: 2.5971 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4415 - accuracy: 0.8665 - val_loss: 2.9748 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4189 - accuracy: 0.8731 - val_loss: 3.9281 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3331 - accuracy: 0.9091 - val_loss: 3.7936 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1905 - accuracy: 0.9518 - val_loss: 3.7950 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1550 - accuracy: 0.9655 - val_loss: 3.9189 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1239 - accuracy: 0.9670 - val_loss: 3.9342 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0976 - accuracy: 0.9741 - val_loss: 4.0865 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1146 - accuracy: 0.9721 - val_loss: 3.9936 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8265 - accuracy: 0.3083\n",
      "[CV 1/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.308 total time=  14.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 64.8614 - accuracy: 0.1755 - val_loss: 1.8700 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7315 - accuracy: 0.3095 - val_loss: 1.8785 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3883 - accuracy: 0.4774 - val_loss: 1.9329 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0178 - accuracy: 0.6256 - val_loss: 2.1373 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.7387 - accuracy: 0.7377 - val_loss: 3.0852 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.5359 - accuracy: 0.8194 - val_loss: 4.0507 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3423 - accuracy: 0.8884 - val_loss: 3.7719 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2818 - accuracy: 0.9112 - val_loss: 3.9196 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2863 - accuracy: 0.9173 - val_loss: 4.0521 - val_accuracy: 0.3811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2298 - accuracy: 0.9254 - val_loss: 4.0009 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2151 - accuracy: 0.9295 - val_loss: 4.0617 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8755 - accuracy: 0.2122\n",
      "[CV 2/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.212 total time=  13.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 36.4033 - accuracy: 0.1826 - val_loss: 1.8579 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6390 - accuracy: 0.3770 - val_loss: 1.8465 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1123 - accuracy: 0.6063 - val_loss: 2.1152 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.7307 - accuracy: 0.7539 - val_loss: 3.4765 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4591 - accuracy: 0.8473 - val_loss: 3.0038 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3634 - accuracy: 0.9001 - val_loss: 3.8125 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3225 - accuracy: 0.9056 - val_loss: 3.5851 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2204 - accuracy: 0.9361 - val_loss: 4.0314 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1947 - accuracy: 0.9513 - val_loss: 4.0646 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1456 - accuracy: 0.9574 - val_loss: 4.3175 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1260 - accuracy: 0.9655 - val_loss: 4.3313 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1074 - accuracy: 0.9701 - val_loss: 4.4897 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9284 - accuracy: 0.3056\n",
      "[CV 3/3] END activation=softmax, kernel_size=3, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.306 total time=  14.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 78.8172 - accuracy: 0.1675 - val_loss: 1.9030 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.7478 - accuracy: 0.3173 - val_loss: 1.8976 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.4496 - accuracy: 0.4629 - val_loss: 1.9996 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1091 - accuracy: 0.6096 - val_loss: 2.6556 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.9143 - accuracy: 0.7081 - val_loss: 2.9122 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6255 - accuracy: 0.7827 - val_loss: 3.0274 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5223 - accuracy: 0.8325 - val_loss: 3.5497 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4260 - accuracy: 0.8756 - val_loss: 3.8069 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3228 - accuracy: 0.8924 - val_loss: 3.9904 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3203 - accuracy: 0.9010 - val_loss: 4.0614 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2835 - accuracy: 0.9117 - val_loss: 4.0249 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3131 - accuracy: 0.9244 - val_loss: 4.2144 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8687 - accuracy: 0.2434\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.243 total time=  12.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 18ms/step - loss: 71.3035 - accuracy: 0.1720 - val_loss: 1.8933 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8255 - accuracy: 0.2557 - val_loss: 1.8653 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.5943 - accuracy: 0.3988 - val_loss: 2.1181 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3322 - accuracy: 0.5043 - val_loss: 2.1070 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.0084 - accuracy: 0.6220 - val_loss: 2.3646 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8023 - accuracy: 0.7352 - val_loss: 2.9898 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5725 - accuracy: 0.8072 - val_loss: 3.8766 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4135 - accuracy: 0.8757 - val_loss: 3.9233 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3708 - accuracy: 0.8899 - val_loss: 3.7703 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3410 - accuracy: 0.8985 - val_loss: 3.8867 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3205 - accuracy: 0.9026 - val_loss: 4.0410 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2742 - accuracy: 0.9056 - val_loss: 4.1466 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8795 - accuracy: 0.2132\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.213 total time=  13.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 31.6513 - accuracy: 0.1669 - val_loss: 1.8845 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8197 - accuracy: 0.2664 - val_loss: 1.8270 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.4632 - accuracy: 0.4713 - val_loss: 1.9325 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.0174 - accuracy: 0.6454 - val_loss: 2.1665 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.7471 - accuracy: 0.7641 - val_loss: 2.9370 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5525 - accuracy: 0.8265 - val_loss: 3.5100 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3864 - accuracy: 0.8909 - val_loss: 3.6840 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2708 - accuracy: 0.9249 - val_loss: 3.8010 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2080 - accuracy: 0.9371 - val_loss: 3.9944 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1926 - accuracy: 0.9488 - val_loss: 3.9678 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1816 - accuracy: 0.9503 - val_loss: 4.1908 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1466 - accuracy: 0.9579 - val_loss: 4.1922 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8534 - accuracy: 0.2355\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.236 total time=  12.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 18.7647 - accuracy: 0.1629 - val_loss: 1.9066 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8379 - accuracy: 0.2391 - val_loss: 1.8743 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7051 - accuracy: 0.3102 - val_loss: 1.9212 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5652 - accuracy: 0.3614 - val_loss: 2.1533 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3773 - accuracy: 0.4563 - val_loss: 2.0256 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2572 - accuracy: 0.5122 - val_loss: 2.5460 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1519 - accuracy: 0.5701 - val_loss: 2.6067 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9738 - accuracy: 0.6675 - val_loss: 2.7160 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8574 - accuracy: 0.6909 - val_loss: 2.6706 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8205 - accuracy: 0.6980 - val_loss: 2.7216 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7746 - accuracy: 0.7213 - val_loss: 2.8741 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7623 - accuracy: 0.7228 - val_loss: 2.8526 - val_accuracy: 0.3770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8584 - accuracy: 0.2150\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.215 total time=  10.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 27.8780 - accuracy: 0.1684 - val_loss: 1.9053 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8597 - accuracy: 0.2248 - val_loss: 1.9114 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7042 - accuracy: 0.3064 - val_loss: 1.8984 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4930 - accuracy: 0.4267 - val_loss: 1.9456 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3349 - accuracy: 0.5033 - val_loss: 1.9364 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0964 - accuracy: 0.6073 - val_loss: 2.2898 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8417 - accuracy: 0.6986 - val_loss: 2.9808 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7957 - accuracy: 0.7265 - val_loss: 2.8080 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5659 - accuracy: 0.8087 - val_loss: 3.0217 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4971 - accuracy: 0.8239 - val_loss: 2.9782 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4624 - accuracy: 0.8437 - val_loss: 3.1080 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3996 - accuracy: 0.8554 - val_loss: 3.1326 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3746 - accuracy: 0.8747 - val_loss: 3.1563 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9518 - accuracy: 0.2528\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.253 total time=  11.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 9.9168 - accuracy: 0.1821 - val_loss: 1.9014 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7529 - accuracy: 0.2968 - val_loss: 1.8719 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4792 - accuracy: 0.4500 - val_loss: 1.8859 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1783 - accuracy: 0.5550 - val_loss: 2.0451 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9621 - accuracy: 0.6560 - val_loss: 2.4455 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6796 - accuracy: 0.7544 - val_loss: 2.4926 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5412 - accuracy: 0.8239 - val_loss: 2.8695 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3863 - accuracy: 0.8803 - val_loss: 3.1136 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3608 - accuracy: 0.8879 - val_loss: 3.0723 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3331 - accuracy: 0.9066 - val_loss: 3.1363 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2936 - accuracy: 0.9117 - val_loss: 3.2062 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2813 - accuracy: 0.9183 - val_loss: 3.1928 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8626 - accuracy: 0.2640\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.264 total time=  10.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 75.6526 - accuracy: 0.1695 - val_loss: 1.9232 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.7873 - accuracy: 0.2741 - val_loss: 1.9492 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.5856 - accuracy: 0.3939 - val_loss: 2.0053 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.2996 - accuracy: 0.5010 - val_loss: 2.0188 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.1282 - accuracy: 0.5883 - val_loss: 3.0473 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8731 - accuracy: 0.6919 - val_loss: 4.2413 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6950 - accuracy: 0.7574 - val_loss: 4.0710 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5809 - accuracy: 0.8036 - val_loss: 4.3554 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5458 - accuracy: 0.8198 - val_loss: 4.4114 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4999 - accuracy: 0.8310 - val_loss: 4.5359 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4575 - accuracy: 0.8411 - val_loss: 4.7358 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9110 - accuracy: 0.1704\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.170 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 45.9844 - accuracy: 0.1826 - val_loss: 1.8989 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.8045 - accuracy: 0.2653 - val_loss: 1.9160 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.6186 - accuracy: 0.3739 - val_loss: 1.9470 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3181 - accuracy: 0.5226 - val_loss: 2.1314 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.0380 - accuracy: 0.6474 - val_loss: 2.4492 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.7822 - accuracy: 0.7407 - val_loss: 3.1765 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5907 - accuracy: 0.8138 - val_loss: 3.6516 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4921 - accuracy: 0.8346 - val_loss: 3.8435 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3890 - accuracy: 0.8630 - val_loss: 4.1090 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3775 - accuracy: 0.8864 - val_loss: 4.0931 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3121 - accuracy: 0.8975 - val_loss: 4.3332 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9175 - accuracy: 0.1868\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.187 total time=  12.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 60.4903 - accuracy: 0.2085 - val_loss: 1.8637 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.6622 - accuracy: 0.3841 - val_loss: 1.9404 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.2609 - accuracy: 0.5469 - val_loss: 2.3240 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8277 - accuracy: 0.7220 - val_loss: 3.1182 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.5141 - accuracy: 0.8397 - val_loss: 3.1309 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.4718 - accuracy: 0.8874 - val_loss: 3.7028 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2364 - accuracy: 0.9305 - val_loss: 3.9264 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1710 - accuracy: 0.9513 - val_loss: 3.9762 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1998 - accuracy: 0.9625 - val_loss: 4.2664 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1451 - accuracy: 0.9569 - val_loss: 4.2668 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1212 - accuracy: 0.9635 - val_loss: 4.1373 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8807 - accuracy: 0.2447\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.245 total time=  12.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 16ms/step - loss: 31.6536 - accuracy: 0.1746 - val_loss: 1.8867 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7743 - accuracy: 0.2726 - val_loss: 1.9436 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5312 - accuracy: 0.3797 - val_loss: 1.9657 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3572 - accuracy: 0.4685 - val_loss: 1.9636 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2208 - accuracy: 0.5401 - val_loss: 2.4785 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0924 - accuracy: 0.5822 - val_loss: 2.5532 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8877 - accuracy: 0.6645 - val_loss: 2.7751 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8513 - accuracy: 0.6655 - val_loss: 2.8346 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8106 - accuracy: 0.6858 - val_loss: 2.8746 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7856 - accuracy: 0.6970 - val_loss: 2.9243 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7660 - accuracy: 0.7015 - val_loss: 2.9697 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8946 - accuracy: 0.1704\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.170 total time=  10.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 20.8433 - accuracy: 0.1791 - val_loss: 1.8819 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8233 - accuracy: 0.2633 - val_loss: 1.8975 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6432 - accuracy: 0.3460 - val_loss: 1.9210 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.4382 - accuracy: 0.4429 - val_loss: 2.1187 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2238 - accuracy: 0.5302 - val_loss: 2.4143 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.0581 - accuracy: 0.6053 - val_loss: 2.3465 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8678 - accuracy: 0.6865 - val_loss: 2.7273 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7590 - accuracy: 0.7199 - val_loss: 2.9577 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7114 - accuracy: 0.7514 - val_loss: 3.0068 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6580 - accuracy: 0.7656 - val_loss: 3.1768 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6046 - accuracy: 0.7798 - val_loss: 3.1464 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9108 - accuracy: 0.2020\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.202 total time=  10.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 20.9191 - accuracy: 0.1740 - val_loss: 1.8939 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.8386 - accuracy: 0.2380 - val_loss: 1.8743 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.7226 - accuracy: 0.2877 - val_loss: 1.9264 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6147 - accuracy: 0.3455 - val_loss: 2.0044 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3988 - accuracy: 0.4460 - val_loss: 2.1874 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.2923 - accuracy: 0.5089 - val_loss: 2.3890 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.1369 - accuracy: 0.5647 - val_loss: 2.6649 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.9537 - accuracy: 0.6383 - val_loss: 3.0472 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8823 - accuracy: 0.6692 - val_loss: 3.1973 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8427 - accuracy: 0.6819 - val_loss: 3.2556 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.8055 - accuracy: 0.6809 - val_loss: 3.2749 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.7822 - accuracy: 0.7017 - val_loss: 3.3054 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8957 - accuracy: 0.1827\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.183 total time=  10.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 114.7929 - accuracy: 0.1939 - val_loss: 1.9095 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7981 - accuracy: 0.2751 - val_loss: 1.8901 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5034 - accuracy: 0.4269 - val_loss: 2.0451 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1745 - accuracy: 0.5904 - val_loss: 2.4327 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8827 - accuracy: 0.7066 - val_loss: 2.9616 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6245 - accuracy: 0.7858 - val_loss: 3.2526 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6861 - accuracy: 0.7914 - val_loss: 3.6240 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4469 - accuracy: 0.8761 - val_loss: 4.1817 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3853 - accuracy: 0.8782 - val_loss: 4.2985 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4281 - accuracy: 0.8868 - val_loss: 4.2692 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3370 - accuracy: 0.9020 - val_loss: 4.4733 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3421 - accuracy: 0.9061 - val_loss: 4.5251 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8476 - accuracy: 0.2556\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.256 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 98.5764 - accuracy: 0.1882 - val_loss: 1.9324 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7628 - accuracy: 0.3135 - val_loss: 1.8260 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3641 - accuracy: 0.4926 - val_loss: 2.1630 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8794 - accuracy: 0.7037 - val_loss: 2.6795 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6113 - accuracy: 0.7960 - val_loss: 3.1784 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3598 - accuracy: 0.8894 - val_loss: 3.5009 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2636 - accuracy: 0.9320 - val_loss: 3.4047 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2209 - accuracy: 0.9503 - val_loss: 4.0940 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1625 - accuracy: 0.9599 - val_loss: 4.0285 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1271 - accuracy: 0.9675 - val_loss: 4.3464 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1230 - accuracy: 0.9655 - val_loss: 4.3967 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1200 - accuracy: 0.9711 - val_loss: 4.5988 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8576 - accuracy: 0.2599\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.260 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 132.4849 - accuracy: 0.1755 - val_loss: 1.8927 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8445 - accuracy: 0.2471 - val_loss: 1.9001 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.1792 - accuracy: 0.2065 - val_loss: 1.9073 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8061 - accuracy: 0.2440 - val_loss: 1.9028 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6637 - accuracy: 0.3267 - val_loss: 2.1645 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5022 - accuracy: 0.4262 - val_loss: 2.4843 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2004 - accuracy: 0.5393 - val_loss: 2.4850 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1242 - accuracy: 0.5657 - val_loss: 2.8421 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0638 - accuracy: 0.5951 - val_loss: 2.8511 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9796 - accuracy: 0.6327 - val_loss: 2.9922 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9301 - accuracy: 0.6459 - val_loss: 3.0332 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9158 - accuracy: 0.2051\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.205 total time=  14.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 29.6572 - accuracy: 0.1670 - val_loss: 1.8813 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7812 - accuracy: 0.2766 - val_loss: 1.8511 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5945 - accuracy: 0.3716 - val_loss: 1.8306 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3490 - accuracy: 0.5081 - val_loss: 2.0578 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0783 - accuracy: 0.6137 - val_loss: 2.2540 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8328 - accuracy: 0.7025 - val_loss: 2.3811 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6253 - accuracy: 0.7817 - val_loss: 2.9579 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5511 - accuracy: 0.8218 - val_loss: 2.8248 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3643 - accuracy: 0.8949 - val_loss: 2.9798 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2957 - accuracy: 0.9061 - val_loss: 3.1192 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2652 - accuracy: 0.9137 - val_loss: 3.2160 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2660 - accuracy: 0.9203 - val_loss: 3.1710 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2174 - accuracy: 0.9335 - val_loss: 3.2594 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8164 - accuracy: 0.2748\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.275 total time=  12.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 30.3031 - accuracy: 0.1715 - val_loss: 1.8817 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.8610 - accuracy: 0.2283 - val_loss: 1.8520 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7418 - accuracy: 0.2836 - val_loss: 1.8758 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5879 - accuracy: 0.3683 - val_loss: 1.9546 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3885 - accuracy: 0.4581 - val_loss: 2.1382 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2765 - accuracy: 0.5114 - val_loss: 2.4618 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0642 - accuracy: 0.6007 - val_loss: 2.8414 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8359 - accuracy: 0.7067 - val_loss: 2.9777 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7488 - accuracy: 0.7281 - val_loss: 3.0488 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7100 - accuracy: 0.7402 - val_loss: 3.1537 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7144 - accuracy: 0.7418 - val_loss: 3.1200 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6535 - accuracy: 0.7570 - val_loss: 3.3071 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8905 - accuracy: 0.2041\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.204 total time=  11.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 24.2965 - accuracy: 0.1563 - val_loss: 1.8819 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.7923 - accuracy: 0.3059 - val_loss: 1.8174 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5338 - accuracy: 0.4419 - val_loss: 1.8780 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2220 - accuracy: 0.5520 - val_loss: 1.9778 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9672 - accuracy: 0.6672 - val_loss: 2.2440 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7126 - accuracy: 0.7504 - val_loss: 2.5516 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5108 - accuracy: 0.8285 - val_loss: 2.8343 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3692 - accuracy: 0.8864 - val_loss: 2.8829 - val_accuracy: 0.4041 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3372 - accuracy: 0.8965 - val_loss: 2.9492 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3108 - accuracy: 0.9031 - val_loss: 3.0091 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2930 - accuracy: 0.9087 - val_loss: 3.0341 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2748 - accuracy: 0.9153 - val_loss: 3.0362 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8360 - accuracy: 0.2721\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.272 total time=  11.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 134.4836 - accuracy: 0.1792 - val_loss: 1.8734 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7419 - accuracy: 0.3437 - val_loss: 1.8921 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4397 - accuracy: 0.4665 - val_loss: 2.2535 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0365 - accuracy: 0.6340 - val_loss: 2.7291 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6936 - accuracy: 0.7741 - val_loss: 4.6180 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5014 - accuracy: 0.8543 - val_loss: 2.7921 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4082 - accuracy: 0.8898 - val_loss: 3.9841 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2858 - accuracy: 0.9178 - val_loss: 4.1518 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2569 - accuracy: 0.9249 - val_loss: 4.0249 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2054 - accuracy: 0.9431 - val_loss: 4.3398 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1856 - accuracy: 0.9497 - val_loss: 4.6160 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8776 - accuracy: 0.1968\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.197 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 137.1584 - accuracy: 0.1715 - val_loss: 1.8895 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8059 - accuracy: 0.2608 - val_loss: 1.8583 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5341 - accuracy: 0.4089 - val_loss: 2.1038 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2071 - accuracy: 0.5789 - val_loss: 3.0411 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7592 - accuracy: 0.7382 - val_loss: 2.9939 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5652 - accuracy: 0.8199 - val_loss: 5.6513 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5277 - accuracy: 0.8437 - val_loss: 7.6561 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3183 - accuracy: 0.9127 - val_loss: 5.5663 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2154 - accuracy: 0.9356 - val_loss: 6.0200 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1621 - accuracy: 0.9498 - val_loss: 6.1442 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1452 - accuracy: 0.9518 - val_loss: 6.7229 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1281 - accuracy: 0.9630 - val_loss: 6.8367 - val_accuracy: 0.4527 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8763 - accuracy: 0.2396\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.240 total time=  15.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 23ms/step - loss: 81.0982 - accuracy: 0.1887 - val_loss: 1.8626 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7091 - accuracy: 0.3577 - val_loss: 1.9009 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4306 - accuracy: 0.4754 - val_loss: 2.0768 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0910 - accuracy: 0.6205 - val_loss: 2.4200 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7360 - accuracy: 0.7468 - val_loss: 3.9250 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6202 - accuracy: 0.8067 - val_loss: 4.8446 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4679 - accuracy: 0.8574 - val_loss: 4.6064 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3583 - accuracy: 0.8914 - val_loss: 5.0296 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3009 - accuracy: 0.9026 - val_loss: 5.2564 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2709 - accuracy: 0.9066 - val_loss: 5.2438 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2454 - accuracy: 0.9143 - val_loss: 5.5660 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9157 - accuracy: 0.2142\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.214 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 40.0755 - accuracy: 0.1858 - val_loss: 1.9043 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7346 - accuracy: 0.2995 - val_loss: 1.9485 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.4615 - accuracy: 0.4482 - val_loss: 2.1233 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1108 - accuracy: 0.6107 - val_loss: 2.0570 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7945 - accuracy: 0.7051 - val_loss: 2.5754 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5527 - accuracy: 0.8056 - val_loss: 2.6660 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3392 - accuracy: 0.8827 - val_loss: 3.0807 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2802 - accuracy: 0.9061 - val_loss: 3.1452 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2604 - accuracy: 0.9173 - val_loss: 3.1665 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2328 - accuracy: 0.9254 - val_loss: 3.2769 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2042 - accuracy: 0.9371 - val_loss: 3.3380 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8985 - accuracy: 0.1734\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.173 total time=  10.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 31.5660 - accuracy: 0.1887 - val_loss: 1.8798 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7655 - accuracy: 0.2998 - val_loss: 1.8655 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5548 - accuracy: 0.3957 - val_loss: 1.9297 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3376 - accuracy: 0.4866 - val_loss: 2.1928 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1593 - accuracy: 0.5662 - val_loss: 2.5132 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9281 - accuracy: 0.6555 - val_loss: 2.7067 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7768 - accuracy: 0.7194 - val_loss: 2.8322 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6334 - accuracy: 0.7813 - val_loss: 3.3524 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5543 - accuracy: 0.8021 - val_loss: 3.4410 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4962 - accuracy: 0.8290 - val_loss: 3.4879 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4759 - accuracy: 0.8361 - val_loss: 3.6623 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4407 - accuracy: 0.8478 - val_loss: 3.6835 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8911 - accuracy: 0.2386\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.239 total time=  11.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 48.1349 - accuracy: 0.1908 - val_loss: 1.8823 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.8477 - accuracy: 0.2476 - val_loss: 1.8868 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6939 - accuracy: 0.2933 - val_loss: 1.9638 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5536 - accuracy: 0.3886 - val_loss: 1.9601 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3730 - accuracy: 0.4622 - val_loss: 2.2113 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1321 - accuracy: 0.5840 - val_loss: 2.7155 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8819 - accuracy: 0.6778 - val_loss: 2.9036 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7952 - accuracy: 0.6930 - val_loss: 3.0075 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7660 - accuracy: 0.7164 - val_loss: 3.0056 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7068 - accuracy: 0.7387 - val_loss: 3.1396 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6541 - accuracy: 0.7529 - val_loss: 3.3231 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9077 - accuracy: 0.2010\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=32, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.201 total time=  10.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 51.5977 - accuracy: 0.1731 - val_loss: 1.9282 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8478 - accuracy: 0.2411 - val_loss: 1.9229 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6815 - accuracy: 0.3320 - val_loss: 2.1042 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4553 - accuracy: 0.4284 - val_loss: 2.6465 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3254 - accuracy: 0.5188 - val_loss: 2.5089 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2130 - accuracy: 0.5898 - val_loss: 3.1236 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0424 - accuracy: 0.6411 - val_loss: 2.7857 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8345 - accuracy: 0.7096 - val_loss: 3.1174 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7762 - accuracy: 0.7223 - val_loss: 3.1617 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7450 - accuracy: 0.7472 - val_loss: 3.1524 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6857 - accuracy: 0.7579 - val_loss: 3.3667 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6694 - accuracy: 0.7629 - val_loss: 3.4781 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9227 - accuracy: 0.2231\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.223 total time=  18.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 29.2343 - accuracy: 0.1771 - val_loss: 1.8801 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8102 - accuracy: 0.2496 - val_loss: 1.8442 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5949 - accuracy: 0.3734 - val_loss: 1.9081 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3652 - accuracy: 0.4764 - val_loss: 2.2063 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0856 - accuracy: 0.5830 - val_loss: 2.4504 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9152 - accuracy: 0.6667 - val_loss: 3.3333 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7804 - accuracy: 0.7179 - val_loss: 3.1222 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6569 - accuracy: 0.7859 - val_loss: 4.0375 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5677 - accuracy: 0.8148 - val_loss: 4.2787 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5301 - accuracy: 0.8209 - val_loss: 4.4399 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4932 - accuracy: 0.8229 - val_loss: 4.2406 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4826 - accuracy: 0.8351 - val_loss: 4.5198 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8774 - accuracy: 0.2548\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.255 total time=  18.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 30.6219 - accuracy: 0.1755 - val_loss: 1.9203 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8433 - accuracy: 0.2319 - val_loss: 1.8615 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7024 - accuracy: 0.3176 - val_loss: 1.9987 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6859 - accuracy: 0.3323 - val_loss: 2.0459 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4885 - accuracy: 0.4363 - val_loss: 2.5497 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2410 - accuracy: 0.5221 - val_loss: 3.3450 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0425 - accuracy: 0.5941 - val_loss: 2.8563 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8884 - accuracy: 0.6565 - val_loss: 3.6035 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7958 - accuracy: 0.6870 - val_loss: 4.1238 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7451 - accuracy: 0.6996 - val_loss: 3.9818 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7239 - accuracy: 0.7123 - val_loss: 3.9778 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6898 - accuracy: 0.7286 - val_loss: 4.4015 - val_accuracy: 0.3446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8842 - accuracy: 0.1858\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=2;, score=0.186 total time=  18.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 8.5009 - accuracy: 0.1386 - val_loss: 1.9328 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.9019 - accuracy: 0.1761 - val_loss: 1.8961 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8006 - accuracy: 0.2411 - val_loss: 1.8685 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6996 - accuracy: 0.2883 - val_loss: 1.9234 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5656 - accuracy: 0.3548 - val_loss: 2.0086 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3983 - accuracy: 0.4431 - val_loss: 2.0461 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2582 - accuracy: 0.5178 - val_loss: 2.4372 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1253 - accuracy: 0.5807 - val_loss: 2.3722 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9606 - accuracy: 0.6462 - val_loss: 2.7083 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8580 - accuracy: 0.6878 - val_loss: 2.6721 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8542 - accuracy: 0.6919 - val_loss: 2.7412 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8336 - accuracy: 0.7066 - val_loss: 2.7211 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7939 - accuracy: 0.7091 - val_loss: 2.7710 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.8621 - accuracy: 0.1968\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.197 total time=  16.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 10.0143 - accuracy: 0.1319 - val_loss: 1.9271 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8954 - accuracy: 0.1821 - val_loss: 1.8948 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8063 - accuracy: 0.2669 - val_loss: 1.8689 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7302 - accuracy: 0.3009 - val_loss: 1.9096 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5867 - accuracy: 0.3623 - val_loss: 1.9486 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4875 - accuracy: 0.4044 - val_loss: 2.0352 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3961 - accuracy: 0.4475 - val_loss: 2.0815 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2821 - accuracy: 0.5028 - val_loss: 2.4485 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1346 - accuracy: 0.5561 - val_loss: 2.6879 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0886 - accuracy: 0.5713 - val_loss: 2.7081 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0462 - accuracy: 0.5809 - val_loss: 2.7598 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0168 - accuracy: 0.5977 - val_loss: 2.8288 - val_accuracy: 0.2973 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9927 - accuracy: 0.6007 - val_loss: 2.8446 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9115 - accuracy: 0.2041\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.204 total time=  16.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 21ms/step - loss: 11.4566 - accuracy: 0.1700 - val_loss: 1.8897 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8706 - accuracy: 0.2111 - val_loss: 1.8784 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7978 - accuracy: 0.2572 - val_loss: 1.9801 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7046 - accuracy: 0.3014 - val_loss: 2.0156 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6459 - accuracy: 0.3318 - val_loss: 2.0985 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5279 - accuracy: 0.3876 - val_loss: 2.3461 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3626 - accuracy: 0.4602 - val_loss: 2.3364 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2017 - accuracy: 0.5205 - val_loss: 2.6110 - val_accuracy: 0.2730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1422 - accuracy: 0.5454 - val_loss: 2.7385 - val_accuracy: 0.2838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0914 - accuracy: 0.5571 - val_loss: 2.7504 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0628 - accuracy: 0.5733 - val_loss: 2.9056 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0442 - accuracy: 0.5850 - val_loss: 3.0627 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.9073 - accuracy: 0.1980\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=64, pool_size=3;, score=0.198 total time=  15.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 26.2467 - accuracy: 0.1817 - val_loss: 1.9302 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.8511 - accuracy: 0.2406 - val_loss: 1.8967 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6785 - accuracy: 0.3102 - val_loss: 2.0928 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4830 - accuracy: 0.4142 - val_loss: 2.0458 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.2865 - accuracy: 0.5066 - val_loss: 2.8817 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.1104 - accuracy: 0.5797 - val_loss: 3.8209 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9673 - accuracy: 0.6482 - val_loss: 2.9838 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.8902 - accuracy: 0.6761 - val_loss: 4.6854 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6828 - accuracy: 0.7477 - val_loss: 4.8649 - val_accuracy: 0.3230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6029 - accuracy: 0.7706 - val_loss: 5.0899 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.5754 - accuracy: 0.7817 - val_loss: 5.1821 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.5254 - accuracy: 0.8061 - val_loss: 5.4399 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9131 - accuracy: 0.1917\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.192 total time=  18.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 46.5075 - accuracy: 0.1553 - val_loss: 1.9394 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.9192 - accuracy: 0.1806 - val_loss: 1.9263 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 1.8506 - accuracy: 0.2212 - val_loss: 1.9236 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.7661 - accuracy: 0.2755 - val_loss: 2.0187 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6757 - accuracy: 0.3064 - val_loss: 2.2444 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.5412 - accuracy: 0.3714 - val_loss: 2.5761 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.4534 - accuracy: 0.4267 - val_loss: 2.8996 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3024 - accuracy: 0.4952 - val_loss: 3.1425 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0997 - accuracy: 0.5677 - val_loss: 3.7200 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.0242 - accuracy: 0.5901 - val_loss: 3.9684 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9740 - accuracy: 0.6068 - val_loss: 4.0746 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9384 - accuracy: 0.6261 - val_loss: 4.3376 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.9068 - accuracy: 0.6474 - val_loss: 4.4064 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9903 - accuracy: 0.1787\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.179 total time=  19.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 31ms/step - loss: 51.3772 - accuracy: 0.1867 - val_loss: 1.9149 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.8209 - accuracy: 0.2557 - val_loss: 1.9434 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.6178 - accuracy: 0.3597 - val_loss: 2.1932 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.3527 - accuracy: 0.4749 - val_loss: 2.0912 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 1.1152 - accuracy: 0.5789 - val_loss: 2.5649 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.9788 - accuracy: 0.6489 - val_loss: 3.0479 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.7732 - accuracy: 0.7215 - val_loss: 3.8646 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6829 - accuracy: 0.7473 - val_loss: 3.9494 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6608 - accuracy: 0.7478 - val_loss: 3.8899 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.6241 - accuracy: 0.7686 - val_loss: 4.0809 - val_accuracy: 0.3243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 24ms/step - loss: 0.5961 - accuracy: 0.7773 - val_loss: 3.9247 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9290 - accuracy: 0.1888\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=2;, score=0.189 total time=  17.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 15.1433 - accuracy: 0.1650 - val_loss: 1.9114 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8714 - accuracy: 0.1934 - val_loss: 1.8954 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7924 - accuracy: 0.2477 - val_loss: 1.9430 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6698 - accuracy: 0.3015 - val_loss: 2.0269 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5668 - accuracy: 0.3437 - val_loss: 2.1618 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5487 - accuracy: 0.3822 - val_loss: 2.3144 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4339 - accuracy: 0.4152 - val_loss: 2.3414 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3050 - accuracy: 0.4751 - val_loss: 2.7352 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2288 - accuracy: 0.5015 - val_loss: 2.7535 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1924 - accuracy: 0.5183 - val_loss: 2.8077 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1577 - accuracy: 0.5355 - val_loss: 2.7959 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1421 - accuracy: 0.5386 - val_loss: 2.8249 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9025 - accuracy: 0.1714\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.171 total time=  15.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 9.7597 - accuracy: 0.1766 - val_loss: 1.9135 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8683 - accuracy: 0.2126 - val_loss: 1.8769 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7568 - accuracy: 0.2841 - val_loss: 1.9106 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6223 - accuracy: 0.3298 - val_loss: 1.9989 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4714 - accuracy: 0.3942 - val_loss: 2.2078 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4123 - accuracy: 0.4313 - val_loss: 2.1623 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3375 - accuracy: 0.4678 - val_loss: 3.1910 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1944 - accuracy: 0.5211 - val_loss: 3.0535 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1417 - accuracy: 0.5368 - val_loss: 2.9434 - val_accuracy: 0.2797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1119 - accuracy: 0.5424 - val_loss: 3.0526 - val_accuracy: 0.2851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1119 - accuracy: 0.5540 - val_loss: 3.0859 - val_accuracy: 0.2878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0667 - accuracy: 0.5616 - val_loss: 3.1281 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9137 - accuracy: 0.1858\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.186 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 14.8225 - accuracy: 0.1350 - val_loss: 1.9493 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.9036 - accuracy: 0.1887 - val_loss: 1.8817 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8411 - accuracy: 0.2207 - val_loss: 1.9211 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7950 - accuracy: 0.2415 - val_loss: 2.0593 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7073 - accuracy: 0.2907 - val_loss: 2.0005 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5964 - accuracy: 0.3399 - val_loss: 2.2527 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5360 - accuracy: 0.3805 - val_loss: 2.1484 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5207 - accuracy: 0.3861 - val_loss: 2.2831 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4607 - accuracy: 0.4054 - val_loss: 2.3895 - val_accuracy: 0.2581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3848 - accuracy: 0.4399 - val_loss: 2.5859 - val_accuracy: 0.2649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3328 - accuracy: 0.4505 - val_loss: 2.8395 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3070 - accuracy: 0.4637 - val_loss: 2.6845 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9432 - accuracy: 0.1726\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=32, n_hidden=128, pool_size=3;, score=0.173 total time=  15.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 28ms/step - loss: 74.5518 - accuracy: 0.1650 - val_loss: 1.9051 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8158 - accuracy: 0.2660 - val_loss: 1.8842 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.5775 - accuracy: 0.3827 - val_loss: 2.0478 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.3223 - accuracy: 0.4995 - val_loss: 2.3452 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0539 - accuracy: 0.6127 - val_loss: 2.9105 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8632 - accuracy: 0.6888 - val_loss: 4.0460 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.7692 - accuracy: 0.7482 - val_loss: 4.4536 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.5858 - accuracy: 0.8112 - val_loss: 4.2534 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.5366 - accuracy: 0.8254 - val_loss: 4.5799 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.4846 - accuracy: 0.8279 - val_loss: 4.5740 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4414 - accuracy: 0.8416 - val_loss: 4.5716 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4201 - accuracy: 0.8528 - val_loss: 5.0085 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8688 - accuracy: 0.2110\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.211 total time=  20.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 28ms/step - loss: 85.1144 - accuracy: 0.1639 - val_loss: 1.9044 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8600 - accuracy: 0.2451 - val_loss: 1.8797 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.6391 - accuracy: 0.3597 - val_loss: 1.9548 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.3392 - accuracy: 0.5195 - val_loss: 1.9688 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.0264 - accuracy: 0.6662 - val_loss: 1.9838 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.7731 - accuracy: 0.7514 - val_loss: 2.4437 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6426 - accuracy: 0.7960 - val_loss: 2.9313 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4904 - accuracy: 0.8529 - val_loss: 2.8138 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.4327 - accuracy: 0.8666 - val_loss: 2.9588 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.3728 - accuracy: 0.8858 - val_loss: 3.0926 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 0.3339 - accuracy: 0.8975 - val_loss: 3.1792 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.3041 - accuracy: 0.9117 - val_loss: 3.4184 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8701 - accuracy: 0.2396\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.240 total time=  20.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 29ms/step - loss: 62.9977 - accuracy: 0.1750 - val_loss: 1.9152 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8402 - accuracy: 0.2440 - val_loss: 1.8704 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.6958 - accuracy: 0.3039 - val_loss: 1.9429 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.5293 - accuracy: 0.3983 - val_loss: 2.3985 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.2946 - accuracy: 0.5008 - val_loss: 3.4411 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 25ms/step - loss: 1.1583 - accuracy: 0.5890 - val_loss: 2.8074 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0232 - accuracy: 0.6220 - val_loss: 3.5051 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7580 - accuracy: 0.7174 - val_loss: 3.7207 - val_accuracy: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7350 - accuracy: 0.7220 - val_loss: 3.8198 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6711 - accuracy: 0.7514 - val_loss: 4.1411 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6433 - accuracy: 0.7661 - val_loss: 4.1290 - val_accuracy: 0.3716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6035 - accuracy: 0.7798 - val_loss: 4.3280 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9183 - accuracy: 0.1838\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=2;, score=0.184 total time=  20.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 27.8403 - accuracy: 0.1893 - val_loss: 1.8860 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7954 - accuracy: 0.2731 - val_loss: 1.8983 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6740 - accuracy: 0.3457 - val_loss: 1.8709 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4832 - accuracy: 0.4218 - val_loss: 1.9663 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2548 - accuracy: 0.5289 - val_loss: 2.2034 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0924 - accuracy: 0.5924 - val_loss: 2.6991 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9085 - accuracy: 0.6665 - val_loss: 2.8082 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7897 - accuracy: 0.7198 - val_loss: 2.7121 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6031 - accuracy: 0.7893 - val_loss: 3.0449 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5562 - accuracy: 0.7995 - val_loss: 3.2595 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5339 - accuracy: 0.8096 - val_loss: 3.2623 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5139 - accuracy: 0.8208 - val_loss: 3.2785 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.4850 - accuracy: 0.8345 - val_loss: 3.3893 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8449 - accuracy: 0.2505\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.251 total time=  16.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 34.5577 - accuracy: 0.1695 - val_loss: 1.8897 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8209 - accuracy: 0.2430 - val_loss: 1.8786 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6352 - accuracy: 0.3359 - val_loss: 1.9235 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5229 - accuracy: 0.3902 - val_loss: 2.0930 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3923 - accuracy: 0.4581 - val_loss: 2.4485 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2953 - accuracy: 0.5033 - val_loss: 2.2290 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1861 - accuracy: 0.5383 - val_loss: 2.7380 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9952 - accuracy: 0.6119 - val_loss: 2.7047 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9412 - accuracy: 0.6235 - val_loss: 2.7162 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9258 - accuracy: 0.6393 - val_loss: 2.7759 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8838 - accuracy: 0.6484 - val_loss: 2.8338 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.8636 - accuracy: 0.6611 - val_loss: 2.8003 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8771 - accuracy: 0.2030\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.203 total time=  15.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 21.3671 - accuracy: 0.1644 - val_loss: 1.9069 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8782 - accuracy: 0.1923 - val_loss: 1.8765 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8230 - accuracy: 0.2369 - val_loss: 1.9160 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7186 - accuracy: 0.2790 - val_loss: 1.9293 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5710 - accuracy: 0.3531 - val_loss: 1.9933 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4680 - accuracy: 0.4160 - val_loss: 2.0983 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3463 - accuracy: 0.4749 - val_loss: 2.1904 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1962 - accuracy: 0.5317 - val_loss: 2.3955 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1408 - accuracy: 0.5566 - val_loss: 2.4443 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0815 - accuracy: 0.5738 - val_loss: 2.5658 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0607 - accuracy: 0.5789 - val_loss: 2.5371 - val_accuracy: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0304 - accuracy: 0.5941 - val_loss: 2.6103 - val_accuracy: 0.3230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9144 - accuracy: 0.1929\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=64, pool_size=3;, score=0.193 total time=  15.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 109.9334 - accuracy: 0.1563 - val_loss: 1.8942 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8206 - accuracy: 0.2431 - val_loss: 1.9041 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.6962 - accuracy: 0.3005 - val_loss: 2.1612 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.5245 - accuracy: 0.3939 - val_loss: 2.2253 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2615 - accuracy: 0.5193 - val_loss: 2.8958 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0698 - accuracy: 0.5883 - val_loss: 4.5932 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8327 - accuracy: 0.6949 - val_loss: 4.3408 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.7592 - accuracy: 0.7239 - val_loss: 4.3640 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6903 - accuracy: 0.7396 - val_loss: 4.6429 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6262 - accuracy: 0.7609 - val_loss: 4.9490 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.5814 - accuracy: 0.7736 - val_loss: 4.9648 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.8840 - accuracy: 0.1755\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.175 total time=  19.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 91.0069 - accuracy: 0.1745 - val_loss: 1.9219 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8570 - accuracy: 0.2344 - val_loss: 1.9515 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.7387 - accuracy: 0.2887 - val_loss: 2.0918 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.5519 - accuracy: 0.3623 - val_loss: 2.3962 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.3972 - accuracy: 0.4323 - val_loss: 2.6147 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.3133 - accuracy: 0.5165 - val_loss: 2.5796 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.2222 - accuracy: 0.5337 - val_loss: 3.0201 - val_accuracy: 0.2865 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0502 - accuracy: 0.5758 - val_loss: 3.2862 - val_accuracy: 0.2932 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.0047 - accuracy: 0.5916 - val_loss: 3.3712 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.9537 - accuracy: 0.6190 - val_loss: 3.5212 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 0.9133 - accuracy: 0.6251 - val_loss: 3.8179 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9439 - accuracy: 0.2000\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.200 total time=  19.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 62.9303 - accuracy: 0.1862 - val_loss: 1.8884 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.8627 - accuracy: 0.2217 - val_loss: 1.9014 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.7171 - accuracy: 0.2902 - val_loss: 1.9750 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.4854 - accuracy: 0.3962 - val_loss: 2.3157 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 1.2789 - accuracy: 0.5048 - val_loss: 2.4175 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 1.1646 - accuracy: 0.5520 - val_loss: 3.3268 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.9804 - accuracy: 0.6235 - val_loss: 3.9150 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.8163 - accuracy: 0.6981 - val_loss: 4.2864 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 0.7298 - accuracy: 0.7357 - val_loss: 4.5528 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 26ms/step - loss: 0.6697 - accuracy: 0.7651 - val_loss: 4.7301 - val_accuracy: 0.3770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 27ms/step - loss: 0.5627 - accuracy: 0.8087 - val_loss: 4.8498 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.9174 - accuracy: 0.1635\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=2;, score=0.163 total time=  19.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 28.1742 - accuracy: 0.1787 - val_loss: 1.8734 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8354 - accuracy: 0.2437 - val_loss: 1.8361 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6778 - accuracy: 0.3178 - val_loss: 1.8943 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5028 - accuracy: 0.3990 - val_loss: 1.9567 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2962 - accuracy: 0.5081 - val_loss: 2.9394 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0964 - accuracy: 0.6112 - val_loss: 3.2090 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9133 - accuracy: 0.6832 - val_loss: 2.8190 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7369 - accuracy: 0.7457 - val_loss: 3.2583 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6202 - accuracy: 0.7843 - val_loss: 3.5821 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5884 - accuracy: 0.7893 - val_loss: 3.5148 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5453 - accuracy: 0.8076 - val_loss: 3.6848 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5076 - accuracy: 0.8208 - val_loss: 3.8042 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.8769 - accuracy: 0.1998\n",
      "[CV 1/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.200 total time=  15.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 30.7067 - accuracy: 0.1639 - val_loss: 1.8865 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8361 - accuracy: 0.2334 - val_loss: 1.8991 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.7392 - accuracy: 0.2841 - val_loss: 2.0504 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6256 - accuracy: 0.3384 - val_loss: 2.0665 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5073 - accuracy: 0.3968 - val_loss: 2.0883 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4203 - accuracy: 0.4302 - val_loss: 2.5010 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2742 - accuracy: 0.4871 - val_loss: 2.5993 - val_accuracy: 0.2568 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2423 - accuracy: 0.4942 - val_loss: 2.6479 - val_accuracy: 0.2649 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2161 - accuracy: 0.5079 - val_loss: 2.8632 - val_accuracy: 0.2649 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1894 - accuracy: 0.5205 - val_loss: 2.8826 - val_accuracy: 0.2635 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1593 - accuracy: 0.5317 - val_loss: 2.9409 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9027 - accuracy: 0.1777\n",
      "[CV 2/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.178 total time=  14.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 2s 22ms/step - loss: 21.2619 - accuracy: 0.1674 - val_loss: 1.9142 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.8548 - accuracy: 0.2253 - val_loss: 1.8942 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7521 - accuracy: 0.2664 - val_loss: 1.9388 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.5935 - accuracy: 0.3597 - val_loss: 2.0960 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4499 - accuracy: 0.4094 - val_loss: 2.2541 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3053 - accuracy: 0.4693 - val_loss: 2.7970 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2239 - accuracy: 0.5074 - val_loss: 2.7599 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2244 - accuracy: 0.5094 - val_loss: 2.9768 - val_accuracy: 0.2824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0008 - accuracy: 0.5941 - val_loss: 3.5158 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9630 - accuracy: 0.6114 - val_loss: 3.4680 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9465 - accuracy: 0.6210 - val_loss: 3.5558 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9009 - accuracy: 0.6301 - val_loss: 3.5648 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.9138 - accuracy: 0.1990\n",
      "[CV 3/3] END activation=softmax, kernel_size=5, n_filter_1=64, n_filter_2=64, n_hidden=128, pool_size=3;, score=0.199 total time=  15.6s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 2s 15ms/step - loss: 39.3322 - accuracy: 0.1918 - val_loss: 1.8859 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 1.7222 - accuracy: 0.3474 - val_loss: 1.7206 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 1.3060 - accuracy: 0.5443 - val_loss: 1.4814 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.8604 - accuracy: 0.7033 - val_loss: 1.6061 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.6595 - accuracy: 0.7909 - val_loss: 1.4939 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.5078 - accuracy: 0.8285 - val_loss: 1.4341 - val_accuracy: 0.5865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.4076 - accuracy: 0.8620 - val_loss: 1.5825 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.3817 - accuracy: 0.8711 - val_loss: 1.6811 - val_accuracy: 0.5838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.3101 - accuracy: 0.8914 - val_loss: 1.5130 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.3059 - accuracy: 0.9117 - val_loss: 1.6247 - val_accuracy: 0.6122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.2426 - accuracy: 0.9076 - val_loss: 1.5318 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.2158 - accuracy: 0.9191 - val_loss: 1.6028 - val_accuracy: 0.6216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.1818 - accuracy: 0.9300 - val_loss: 1.6659 - val_accuracy: 0.6311 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.1814 - accuracy: 0.9330 - val_loss: 1.7107 - val_accuracy: 0.6324 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.1726 - accuracy: 0.9340 - val_loss: 1.7942 - val_accuracy: 0.6446 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.1459 - accuracy: 0.9398 - val_loss: 1.8004 - val_accuracy: 0.6378 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'softmax', 'kernel_size': 3, 'n_filter_1': 32, 'n_filter_2': 32, 'n_hidden': 64, 'pool_size': 2}\n",
      "Best Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_custom_cnn)\n",
    "param_grid = {\n",
    "    'n_filter_1': [32, 64],\n",
    "    'n_filter_2': [32, 64],\n",
    "    'kernel_size': [3, 5],\n",
    "    'pool_size': [2, 3],\n",
    "    'n_hidden': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax']\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Sequential()\n",
    "custom_model.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=target_size+(3,)))\n",
    "custom_model.add(MaxPooling2D(pool_size=3))\n",
    "custom_model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "custom_model.add(MaxPooling2D(pool_size=3))\n",
    "custom_model.add(Flatten())\n",
    "custom_model.add(Dense(128, activation=\"relu\"))\n",
    "custom_model.add(Dropout(0.3))\n",
    "custom_model.add(Dense(len(le.classes_), activation=\"softmax\"))\n",
    "\n",
    "custom_model.compile(optimizer=Adam(learning_rate=1e-03), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 38s 820ms/step - loss: 1.8529 - accuracy: 0.2897 - val_loss: 1.7439 - val_accuracy: 0.3287 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 36s 797ms/step - loss: 1.6660 - accuracy: 0.3489 - val_loss: 1.6500 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 37s 823ms/step - loss: 1.5450 - accuracy: 0.4095 - val_loss: 1.6042 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 37s 810ms/step - loss: 1.4312 - accuracy: 0.4708 - val_loss: 1.5488 - val_accuracy: 0.4708 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 36s 800ms/step - loss: 1.3883 - accuracy: 0.5014 - val_loss: 1.5142 - val_accuracy: 0.4791 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 36s 797ms/step - loss: 1.3038 - accuracy: 0.5348 - val_loss: 1.4417 - val_accuracy: 0.4652 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 38s 837ms/step - loss: 1.2667 - accuracy: 0.5411 - val_loss: 1.4149 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 37s 818ms/step - loss: 1.1677 - accuracy: 0.5787 - val_loss: 1.4619 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 36s 787ms/step - loss: 1.0906 - accuracy: 0.5947 - val_loss: 1.4536 - val_accuracy: 0.5042 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 35s 774ms/step - loss: 1.0468 - accuracy: 0.6170 - val_loss: 1.6066 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 35s 767ms/step - loss: 0.9836 - accuracy: 0.6330 - val_loss: 1.4568 - val_accuracy: 0.5181 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 35s 769ms/step - loss: 0.9072 - accuracy: 0.6741 - val_loss: 1.4350 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 35s 772ms/step - loss: 0.8360 - accuracy: 0.7047 - val_loss: 1.4143 - val_accuracy: 0.5237 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 36s 792ms/step - loss: 0.7742 - accuracy: 0.7166 - val_loss: 1.4366 - val_accuracy: 0.5265 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 36s 802ms/step - loss: 0.7543 - accuracy: 0.7298 - val_loss: 1.4623 - val_accuracy: 0.5348 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 36s 807ms/step - loss: 0.7275 - accuracy: 0.7423 - val_loss: 1.4781 - val_accuracy: 0.5320 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 36s 807ms/step - loss: 0.7207 - accuracy: 0.7458 - val_loss: 1.4750 - val_accuracy: 0.5376 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 37s 810ms/step - loss: 0.7458 - accuracy: 0.7284 - val_loss: 1.4335 - val_accuracy: 0.5404 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 36s 809ms/step - loss: 0.7144 - accuracy: 0.7500 - val_loss: 1.4392 - val_accuracy: 0.5404 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 37s 815ms/step - loss: 0.6887 - accuracy: 0.7611 - val_loss: 1.4456 - val_accuracy: 0.5460 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrx0lEQVR4nO3dd3gU9drG8e9ueoeEkgQChN4khl5EFKWLIiAKKKBYsKFi11dFj0fslQNYaCqiUkUBkd6lh96E0BMgQBISSJ/3j4FIKCGBJJPd3J/r2ovd2ZnZZxjC3pn5FZthGAYiIiIiTsJudQEiIiIiBUnhRkRERJyKwo2IiIg4FYUbERERcSoKNyIiIuJUFG5ERETEqSjciIiIiFNRuBERERGnonAjIiIiTkXhRkSuaNy4cdhsNmw2G4sWLbrkfcMwqF69OjabjVtuuaVAP9tmszF06NB8b7dv3z5sNhvjxo3L03off/zxtRUoIsWWwo2IXJWfnx+jR4++ZPnixYvZs2cPfn5+FlQlInJ5CjciclX33nsvU6ZMITExMcfy0aNH06JFCypVqmRRZSIil1K4EZGr6t27NwATJ07MXpaQkMCUKVN46KGHLrvNyZMneeKJJ6hQoQLu7u5UrVqV119/ndTU1BzrJSYm8sgjjxAUFISvry8dO3Zk165dl93n7t276dOnD+XKlcPDw4M6derwv//9r4CO8vIOHDjA/fffn+MzP/nkE7KysnKsN3LkSCIiIvD19cXPz4/atWvz2muvZb9/5swZXnjhBcLDw/H09CQwMJDGjRvn+DsVkYLhanUBIlL8+fv707NnT8aMGcNjjz0GmEHHbrdz77338vnnn+dYPyUlhVtvvZU9e/bw9ttv06BBA5YuXcqwYcOIiopi5syZgNlmp1u3bqxYsYI333yTJk2asHz5cjp16nRJDdu2baNly5ZUqlSJTz75hODgYObMmcPgwYOJi4vjrbfeKvDjPn78OC1btiQtLY3//Oc/VKlShT/++IMXXniBPXv2MGLECAB+/vlnnnjiCZ5++mk+/vhj7HY7//zzD9u2bcve15AhQ/jhhx949913iYyMJDk5mS1btnDixIkCr1ukxDNERK5g7NixBmCsWbPGWLhwoQEYW7ZsMQzDMJo0aWIMGDDAMAzDqFevntGmTZvs7UaNGmUAxq+//ppjfx988IEBGH/99ZdhGIYxe/ZsAzC++OKLHOv997//NQDjrbfeyl7WoUMHo2LFikZCQkKOdZ966inD09PTOHnypGEYhhEdHW0AxtixY3M9tvPrffTRR1dc55VXXjEAY9WqVTmWP/7444bNZjN27tyZXUOpUqVy/bz69esb3bp1y3UdESkYui0lInnSpk0bqlWrxpgxY9i8eTNr1qy54i2pBQsW4OPjQ8+ePXMsHzBgAADz588HYOHChQD07ds3x3p9+vTJ8TolJYX58+dz99134+3tTUZGRvajc+fOpKSk8PfffxfEYV5yHHXr1qVp06aXHIdhGCxYsACApk2bEh8fT+/evfntt9+Ii4u7ZF9NmzZl9uzZvPLKKyxatIizZ88WeL0iYlK4EZE8sdlsPPjgg/z444+MGjWKmjVr0rp168uue+LECYKDg7HZbDmWlytXDldX1+xbMSdOnMDV1ZWgoKAc6wUHB1+yv4yMDL766ivc3NxyPDp37gxw2UBxvU6cOEFISMgly0NDQ7PfB3jggQcYM2YM+/fvp0ePHpQrV45mzZoxd+7c7G2+/PJLXn75ZaZPn86tt95KYGAg3bp1Y/fu3QVet0hJp3AjInk2YMAA4uLiGDVqFA8++OAV1wsKCuLo0aMYhpFj+bFjx8jIyKBMmTLZ62VkZFzS7iQ2NjbH69KlS+Pi4sKAAQNYs2bNZR/nQ05BCgoKIiYm5pLlR44cAcg+DoAHH3yQFStWkJCQwMyZMzEMgzvuuIP9+/cD4OPjw9tvv82OHTuIjY1l5MiR/P3333Tt2rXA6xYp6RRuRCTPKlSowIsvvkjXrl3p37//Fde77bbbSEpKYvr06TmWf//999nvA9x6660ATJgwIcd6P/30U47X3t7e3HrrrWzYsIEGDRrQuHHjSx4XX/0pCLfddhvbtm1j/fr1lxyHzWbLrv9CPj4+dOrUiddff520tDS2bt16yTrly5dnwIAB9O7dm507d3LmzJkCr12kJFNvKRHJl/fff/+q6/Tr14///e9/9O/fn3379nHDDTewbNky3nvvPTp37sztt98OQPv27bn55pt56aWXSE5OpnHjxixfvpwffvjhkn1+8cUX3HTTTbRu3ZrHH3+cKlWqcPr0af755x9+//337PYv+bV582YmT558yfImTZrw3HPP8f3339OlSxfeeecdKleuzMyZMxkxYgSPP/44NWvWBOCRRx7By8uLVq1aERISQmxsLMOGDSMgIIAmTZoA0KxZM+644w4aNGhA6dKl2b59Oz/88AMtWrTA29v7mmoXkSuwuEGziBRjF/aWys3FvaUMwzBOnDhhDBo0yAgJCTFcXV2NypUrG6+++qqRkpKSY734+HjjoYceMkqVKmV4e3sb7dq1M3bs2HFJbynDMHs4PfTQQ0aFChUMNzc3o2zZskbLli2Nd999N8c65KO31JUe57ffv3+/0adPHyMoKMhwc3MzatWqZXz00UdGZmZm9r7Gjx9v3HrrrUb58uUNd3d3IzQ01OjVq5exadOm7HVeeeUVo3Hjxkbp0qUNDw8Po2rVqsZzzz1nxMXF5VqniOSfzTAuuikuIiIi4sDU5kZEREScisKNiIiIOBWFGxEREXEqCjciIiLiVBRuRERExKko3IiIiIhTKXGD+GVlZXHkyBH8/PwumfdGREREiifDMDh9+jShoaHY7blfmylx4ebIkSOEhYVZXYaIiIhcg4MHD1KxYsVc1ylx4cbPzw8w/3L8/f0trkZERETyIjExkbCwsOzv8dyUuHBz/laUv7+/wo2IiIiDyUuTEjUoFhEREaeicCMiIiJOReFGREREnEqJa3MjIiLOIysri7S0NKvLkALi7u5+1W7eeaFwIyIiDiktLY3o6GiysrKsLkUKiN1uJzw8HHd39+vaj8KNiIg4HMMwiImJwcXFhbCwsAL5bV+sdX6Q3ZiYGCpVqnRdA+0q3IiIiMPJyMjgzJkzhIaG4u3tbXU5UkDKli3LkSNHyMjIwM3N7Zr3o6grIiIOJzMzE+C6b19I8XL+fJ4/v9dK4UZERByW5gh0LgV1PhVuRERExKko3IiIiDioKlWq8Pnnn1tdRrGjBsUiIiJF6JZbbuHGG28skFCyZs0afHx8rr8oJ6MrNwUo4Uw6UQfjrS5DREQcmGEYZGRk5GndsmXLqrfYZSjcFJD1B07RfNh8nvhxHRmZGlBKREQuNWDAABYvXswXX3yBzWbDZrMxbtw4bDYbc+bMoXHjxnh4eLB06VL27NnDXXfdRfny5fH19aVJkybMmzcvx/4uvi1ls9n47rvvuPvuu/H29qZGjRrMmDGjiI/Sego3BaRuiD8+Hi4cSUjhz62xVpcjIlKiGIbBmbQMSx6GYeS5zi+++IIWLVrwyCOPEBMTQ0xMDGFhYQC89NJLDBs2jO3bt9OgQQOSkpLo3Lkz8+bNY8OGDXTo0IGuXbty4MCBXD/j7bffplevXmzatInOnTvTt29fTp48eV1/v45GbW4KiKebC32bVeaL+bsZvSyaOxqEWl2SiEiJcTY9k7pvzrHks7e90wFv97x9nQYEBODu7o63tzfBwcEA7NixA4B33nmHdu3aZa8bFBRERERE9ut3332XadOmMWPGDJ566qkrfsaAAQPo3bs3AO+99x5fffUVq1evpmPHjvk+NkelKzcF6P7mlXF3sbPhQDzrD5yyuhwREXEgjRs3zvE6OTmZl156ibp161KqVCl8fX3ZsWPHVa/cNGjQIPu5j48Pfn5+HDt2rFBqLq505aYAlfXz4M4bQ5m87hBjlkXTsE9pq0sSESkRvNxc2PZOB8s+uyBc3OvpxRdfZM6cOXz88cdUr14dLy8vevbsedVZ0C+etsBms5W4yUUVbgrYQ63CmbzuELO3xHI4/iwVSnlZXZKIiNOz2Wx5vjVkNXd39zxNL7B06VIGDBjA3XffDUBSUhL79u0r5Oqcg25LFbC6of60rBZEZpbB9yv2WV2OiIgUM1WqVGHVqlXs27ePuLi4K15VqV69OlOnTiUqKoqNGzfSp0+fEncF5lop3BSCh1qFAzBx9QGSU/M2VoGIiJQML7zwAi4uLtStW5eyZctesQ3NZ599RunSpWnZsiVdu3alQ4cONGzYsIirdUw2Iz992JxAYmIiAQEBJCQk4O/vXyifkZVlcNuni4mOS+adu+rRr0WVQvkcEZGSKiUlhejoaMLDw/H09LS6HCkguZ3X/Hx/68pNIbDbbTzYqgoAY5fvIyurROVHERERSyncFJIeDSvi7+lKdFwyC3eWrC54IiIiVlK4KSQ+Hq70bloJgNHLoi2uRkREpOSwNNwsWbKErl27Ehoais1mY/r06VfdZsKECURERODt7U1ISAgPPvggJ06cKPxir0G/llVwsdtYsecE22MSrS5HRESkRLA03CQnJxMREcHw4cPztP6yZcvo168fAwcOZOvWrUyaNIk1a9bw8MMPF3Kl16ZCKS861jeH1x6jqzciIiJFwtIRjzp16kSnTp3yvP7ff/9NlSpVGDx4MADh4eE89thjfPjhh4VV4nUbeFM4MzfF8FvUEV7qWJuyfh5WlyQiIuLUHKrNTcuWLTl06BCzZs3CMAyOHj3K5MmT6dKlyxW3SU1NJTExMcejKDWsVJobw0qRlpnFhFX7i/SzRURESiKHCzcTJkzg3nvvxd3dneDgYEqVKsVXX311xW2GDRtGQEBA9uP81PJFaeBN5qB+P/69n5T0qw+5LSIiItfOocLNtm3bGDx4MG+++Sbr1q3jzz//JDo6mkGDBl1xm1dffZWEhITsx8GDB4uwYlOn+sGEBngSl5TGjI1HivzzRUREShKHCjfDhg2jVatWvPjiizRo0IAOHTowYsQIxowZQ0xMzGW38fDwwN/fP8ejqLm62OnXsgpgNiwuYYNCi4hIAapSpQqff/559uur9Tbet28fNpuNqKio6/rcgtpPUXCocHPmzBns9pwlu7iYU80X98DQu0klvNxc2BF7mpV7imfXdRERcTwxMTH56pyTFwMGDKBbt245loWFhRETE0P9+vUL9LMKg6XhJikpiaioqOwUGB0dTVRUVPYkYq+++ir9+vXLXr9r165MnTqVkSNHsnfvXpYvX87gwYNp2rQpoaGhVhxCngV4u3FP44oAjFmubuEiIlIwgoOD8fAo/J64Li4uBAcH4+pqaUfrPLE03Kxdu5bIyEgiIyMBGDJkCJGRkbz55puAmUYvnC11wIABfPrppwwfPpz69etzzz33UKtWLaZOnWpJ/fk14Nytqfk7jhEdl2xtMSIiUuS+/vprKlSoQFZWVo7ld955J/3792fPnj3cddddlC9fHl9fX5o0acK8efNy3efFt6VWr15NZGQknp6eNG7cmA0bNuRYPzMzk4EDBxIeHo6Xlxe1atXiiy++yH5/6NChjB8/nt9++w2bzYbNZmPRokWXvS21ePFimjZtioeHByEhIbzyyitkZGRkv3/LLbcwePBgXnrpJQIDAwkODmbo0KH5/4vLJ0vj1y233JLr7aRx48Zdsuzpp5/m6aefLsSqCk/Vsr7cVrsc83ccY+zyaN65q/hf2hMRcQiGAelnrPlsN2+w2fK06j333MPgwYNZuHAht912GwCnTp1izpw5/P777yQlJdG5c2feffddPD09GT9+PF27dmXnzp1UqlTpqvtPTk7mjjvuoG3btvz4449ER0fzzDPP5FgnKyuLihUr8uuvv1KmTBlWrFjBo48+SkhICL169eKFF15g+/btJCYmMnbsWAACAwM5ciRnh5jDhw/TuXNnBgwYwPfff8+OHTt45JFH8PT0zBFgxo8fz5AhQ1i1ahUrV65kwIABtGrVinbt2uXp7+xaFP9rS05m4E3hzN9xjElrD/F8u1oEeLtZXZKIiONLPwPvWdQ84bUj4O6Tp1UDAwPp2LEjP/30U3a4mTRpEoGBgdx22224uLgQERGRvf67777LtGnTmDFjBk899dRV9z9hwgQyMzMZM2YM3t7e1KtXj0OHDvH4449nr+Pm5sbbb7+d/To8PJwVK1bw66+/0qtXL3x9ffHy8iI1NZXg4OArftaIESMICwtj+PDh2Gw2ateuzZEjR3j55Zd58803s9vINmjQgLfeeguAGjVqMHz4cObPn1+o4cahGhQ7gxbVgqgd7MfZ9Ex+XnPg6huIiIhT6du3L1OmTCE1NRUwA8l9992Hi4sLycnJvPTSS9StW5dSpUrh6+vLjh07cjTRyM327duz5188r0WLFpesN2rUKBo3bkzZsmXx9fXl22+/zfNnXPhZLVq0wHbBVatWrVqRlJTEoUOHspc1aNAgx3YhISEcO3YsX5+VX7pyU8RsNhsP3RTOS5M3MX7FPgbeFI6rizKmiMh1cfM2r6BY9dn50LVrV7Kyspg5cyZNmjRh6dKlfPrppwC8+OKLzJkzh48//pjq1avj5eVFz549SUtLy9O+89Jz+Ndff+W5557jk08+oUWLFvj5+fHRRx+xatWqfB2HYRg5gs2Fn3/hcje3nHcobDbbJW2OCprCjQXujAjlwz93cCQhhT+3xnJHg+Ld00tEpNiz2fJ8a8hqXl5edO/enQkTJvDPP/9Qs2ZNGjVqBMDSpUsZMGAAd999N2D2Kt63b1+e9123bl1++OEHzp49i5eXF2DOy3ihpUuX0rJlS5544onsZXv27Mmxjru7O5mZuY+oX7duXaZMmZIj5KxYsQI/Pz8qVKiQ55oLgy4ZWMDTzYW+zSoDMFqzhYuIlDh9+/Zl5syZjBkzhvvvvz97efXq1Zk6dSpRUVFs3LiRPn365OsqR58+fbDb7QwcOJBt27Yxa9YsPv744xzrVK9enbVr1zJnzhx27drFG2+8wZo1a3KsU6VKFTZt2sTOnTuJi4sjPT39ks964oknOHjwIE8//TQ7duzgt99+46233mLIkCGXjElX1BRuLHJ/88q4u9jZcCCe9QdOWV2OiIgUobZt2xIYGMjOnTvp06dP9vLPPvuM0qVL07JlS7p27UqHDh1o2LBhnvfr6+vL77//zrZt24iMjOT111/ngw8+yLHOoEGD6N69O/feey/NmjXjxIkTOa7iADzyyCPUqlUru13O8uXLL/msChUqMGvWLFavXk1ERASDBg1i4MCB/N///V8+/zYKns0o7kP7FrDExEQCAgJISEiwZCqGC70waSOT1x3ijgYhDO+T93+8IiIlXUpKCtHR0YSHh+Pp6Wl1OVJAcjuv+fn+1pWbgmQYkJX3Wb8famXOFj57SyyH488WVlUiIiIlisJNQclIg+lPwJ+vmCEnD+qG+tOyWhCZWQbfr9xXuPWJiIiUEAo3BeXAStj4E6z+BlYOz/Nm56/eTFx1gOTUjKusLSIiIlejcFNQqraBdv8xn//1f7B1Wp42a1u7HOFlfEhMyWDK+kNX30BERERypXBTkFo+DU0fNZ9PfQz2r7zqJna7jQdbVQFg7PJ9ZGWVqPbdIiLXpYT1iXF6BXU+FW4Kks0GHd+HWp0hMxV+7g1xu6+6WY+GFfH3dCU6LpmFOwt3SGoREWfg4uICkOeRe8UxnD+f58/vtdIIxQXN7gI9RsP4O+DwOvixBzw8D3zLXXETHw9XejetxNdL9jJ6WTS31SlfhAWLiDgeV1dXvL29OX78OG5ubpYPGifXLysri+PHj+Pt7Y2r6/XFE41zU1iSjsPo2+HUPghtCAP+yHVo8MPxZ7n5w4VkZhnMfqY1dUKsHYNHRKS4S0tLIzo6utDnKZKiY7fbCQ8Px93d/ZL38vP9rXBTmOL+MQPO2VNQsxPcN8G8snMFT/60npmbYrinUUU+uifiiuuJiIgpKytLt6aciLu7+xWvwinc5KLIRyg+8DeMv9Nsg9PkYej8sdk25zLWHzhF9xErcHexs/yVtpT18yj8+kRERByARiguTio1hx7fAjZY8x2s+PKKqzasVJobw0qRlpnFhFX7i65GERERJ6JwUxTq3gUd/ms+n/smbJlyxVUH3mQO6vfj3/tJSc/7VA4iIiJiUrgpKs2fgGaDzOfTBsH+FZddrVP9YEIDPIlLSuP3jUeKsEARERHnoHBTVGw26PAe1L4DMtNgYm84vuuS1Vxd7PRrWQWA0cuiNUCViIhIPincFCW7C3T/Fio2gZR4mNADTh+9ZLXeTSrh5ebCjtjTrNxzoujrFBERcWAKN0XN3Rt6/wyBVSH+APzUC9KSc6wS4O1Gz0YVARizPNqKKkVERByWwo0VfMpA38ngHQQxUTD5IcjMOSP4+fmm5u84RnRc8qX7EBERkctSuLFKUDXzCo6rJ+z6E2a/BBe0r6la1pfbapfDMGCsrt6IiIjkmcKNlcKaQo/vABusHQ3LP8/x9kPnuoVPWnuIhDPpRV+fiIiIA1K4sVqdruZM4gDzhsLmydlvtawWRO1gP86mZ/LzmgPW1CciIuJgFG6Kg+aDoPmT5vPpj8O+ZQDYbLbsqzfjV+wjI1OTw4mIiFyNwk1x0f5dqHOnOQbOz33g+E4A7owIpYyvO0cSUvhza6zFRYqIiBR/CjfFhd0O3b+BsGaQkgA/9oTTsXi6udC3WWXAHNRPREREcqdwU5y4ecF9EyGwGiScGwMnNYn7m1fG3cXOhgPxrD9wyuoqRUREijWFm+LGJwjunwzeZSBmI0x+kLLeLtx5YygAX83frSkZREREcqFwUxwFVoU+v4CrF+z+C2Y9z6Cbq+LuYmfhzuNMWX/Y6gpFRESKLYWb4qpiY+g5GrDBunFU3/Utz7WrCcDbM7ZyJP6stfWJiIgUUwo3xVntLtDpQ/P5/Ld5rPQ6IiuV4nRqBi9N3qTbUyIiIpehcFPcNXsUWjwFgP23JxjZKAZPNzvL/onjx1Ua2E9ERORiCjeOoN1/oG43yEonePZA5pf7klq2A7w3czv7T2hSTRERkQsp3DgCux3u/tq8gmN3o8KJFcz2eI03jVG8+/NCMrN0e0pEROQ8hRtH4eYJHf4LT62Gut2wk0Vv14V8fuwhNvzwCqTpCo6IiAgo3DiewKrQazw89BdxpRrgY0ulcfQoMr6IhA0/Qlam1RWKiIhYSuHGUVVqRtDgxYwo838cyCqLa/JR+O1J+LoN7FlodXUiIiKWUbhxYDa7nR79nqa7/QveTe9LqosvHN0MP3SDCffAsR1WlygiIlLkFG4cXHl/T97odiPfZXah1dlPiav3INhdzZGNR7aA35+FpGNWlykiIlJkFG6cwJ0RoXS+IZi4LF/6HupO2qCVUPsOMLJg3Vj4MhKWfAzpGtVYREScn8KNE7DZbPznrvqU8XVn59HTfLY+C+6bAANmQWgkpCXBgv/AV41g48+QlWV1ySIiIoVG4cZJBPl68N+7bwDg68V7WLf/FFRpBQ8vgO7fQUAYJB6GaY/Bt7dA9FJrCxYRESkkCjdOpEO9YLo3rECWAS9M2sjZtExzAMAG98BTa+H2oeDhDzEbYfwdMLE3HN9lddkiIiIFytJws2TJErp27UpoaCg2m43p06dfdZvU1FRef/11KleujIeHB9WqVWPMmDGFX6yDeKtrPYL9PYmOS+aDPy/oLeXmCTc9B4M3QJNHwOYCO2fBiOYw8wVIjrOuaBERkQJkabhJTk4mIiKC4cOH53mbXr16MX/+fEaPHs3OnTuZOHEitWvXLsQqHUuAlxsf9mwAwLgV+1ix56LQ4lMGunwMT/wNNTuBkQlrvjUbHS/7DDJSLaha5Aq2/wH/DTUHqBQRySObYRjFYmIim83GtGnT6Nat2xXX+fPPP7nvvvvYu3cvgYGB1/Q5iYmJBAQEkJCQgL+//zVWW/y9Pm0zE1YdoEIpL/58tjV+nm6XXzF6Ccx5HWI3ma/L1YO7R0JIRNEVK3I56SlmI/jEQ+BZCp6JAq/SVlclIhbJz/e3Q7W5mTFjBo0bN+bDDz+kQoUK1KxZkxdeeIGzZ6/cxTk1NZXExMQcj5Lgtc51CAv04nD8Wf47c/uVVwy/GR5dDN1GgXcZOLYVvm0Li96HzPSiK1jkYmu+NYMNQEo8LP3E0nJExHE4VLjZu3cvy5YtY8uWLUybNo3PP/+cyZMn8+STT15xm2HDhhEQEJD9CAsLK8KKrePj4crHPSOw2eDnNQdZuCOXgfzsdrixt3mrqs6dkJUBi4aZIefo1qIrWuS8s/H/hpn6Pc0/V30Np/ZbVpKIOA6HCjdZWVnYbDYmTJhA06ZN6dy5M59++injxo274tWbV199lYSEhOzHwYMHi7hq6zSrGsTAVuEAvDxlE/Fn0nLfwLcs9Poeeow2L//HbjLnqlr6CWRmFEHFIucs/wLOnoKytaH7N+YVxsw0WPCu1ZWJiANwqHATEhJChQoVCAgIyF5Wp04dDMPg0KFDl93Gw8MDf3//HI+S5IUOtahW1odjp1N5a0YersLYbHBDT3hiFdTqDFnpMP8dGNMeju8s/IJFEmPg75Hm89veArsLtPuP+Xrzr3AkyrLSRMQxOFS4adWqFUeOHCEpKSl72a5du7Db7VSsWNHCyoovTzcXPul1Iy52G79FHWHW5pi8behXHu77Ce7+GjwC4PA6GNUaln8JWZmFW7SUbIvfh4yzENYcanUyl4XeCDf0Mp/PfQOKRz8IESmmLA03SUlJREVFERUVBUB0dDRRUVEcOHAAMG8p9evXL3v9Pn36EBQUxIMPPsi2bdtYsmQJL774Ig899BBeXl5WHIJDuDGsFI+3qQbA/03fwvHTeezubbNBxH3w5N9QvR1kpppfLGM7wYk9hVixlFjHd8H6H8zn7d42/w2ed9sb4OJu9vDbPdea+kTEIVgabtauXUtkZCSRkZEADBkyhMjISN58800AYmJisoMOgK+vL3PnziU+Pp7GjRvTt29funbtypdffmlJ/Y5k8G01qB3sx8nkNF6ftpl8jQDgHwp9J8GdX4G7HxxcBSNbmbcONE+VFKQF75hjL9XqDJWa53yvVCVo9pj5fO6buoIoIldUbMa5KSolZZyby9l2JJG7/reM9EyDT3tF0L3hNdzKiz8IM56CvYvM15VbwV3/g8DwAq1VSqCDa2D07WCzw+MroFydS9c5ewq+uNHsGn7nV9Cw36XriIhTctpxbuT61A3159nbawLw1oytxCRceXygKyoVBg9Mhy6fgJsP7F9uXsVZ852u4si1MwyYN9R8HtHn8sEGzF58N79oPl/4HqQlF0l5IuJYFG5KmMdurkpEWClOp2Tw0uRN+bs9dZ7NBk0ehseXQ+WbID0ZZj4PP3SD+ANX3VzkEv/Mg/3LwMUDbn0193WbPmLeojodAytHFE19IuJQFG5KGFcXO5/cE4GHq52lu+P4afV1hJHAcOj/O3T8AFy9IHoxjGgJ68arN4vkXVYmzH3LfN7sUQi4yu1SVw+zizjA8s8h6XihlicijkfhpgSqXs6Xlzqak43+d+Z2Dpw4c+07s9uh+SAYtAzCmkHaafh9MEzoCQmHC6hicWqbJ5nTfngEwE1D8rZNve4QGglpSWbXcRGRCyjclFAPtqxCs/BAzqRl8sKkjWRlXeeVljLV4cHZ5mBrLh7mbYYRLSBqoq7iyJVlpMKC/5rPWz8H3nmcENdu/3dgv7VjIW534dQnIg5J4aaEstttfHxPBN7uLqzed5Ixy6MLYKcu0GowDFoKoQ0hNQGmD4KJveH00evfvzifNaMh4QD4hUDTx/K3bXhrqNnR7Dp+vjGyiAgKNyVaWKA3/9elLgAfztnJP8dOF8yOy9aCgXPhtjfB7ga7ZsOIZrDxZ81RJf9KSYAlH5nPb3kV3L3zv4/b3za7ju/4A/avLNj6RMRhKdyUcL2bhnFzzbKkZWTx/K8bycgsoO7cLq7Q+nl4bDEENzDHJ5n2GHx5Iyz9FJLjCuZzxHGt+ArOnoQyNeHGvte2j3K1IfIB87mmZRCRcxRuSjibzcaHPRrg7+nKxkMJfLXgn4L9gPL14JEF0PYN8AqEhIMw/234tC5MG2TOWSUlz+lYWPk/8/ltb5ph+Frd+hq4ecOhNbDtt4KpT0QcmsKNEBzgyX+61QfgqwW7WbPvZMF+gIsb3PwCDNkO3UaavVwyU2HjRPi2rfmImgjpKQX7uVJ8Lf4Q0s9AxSZQ+47r25dfMLR82nw+/23ISLv++kTEoSncCAB33ViB7pEVyDLg2Z+jSDiTXvAf4uYJN/aBRxfBwwugwX3mRIiH15kNjz+rC/PeNqd4EOcV9w+sG2c+v/2iyTGvVcunwaccnNwL68Ze//5ExKEp3Ei2d7rVp3KQN4fjz/JafifXzK+KjaD71/DcNvOWlX9FOHMCln0KXzSAn/ua81epDYXzWfAfs4dTjQ5QpVXB7NPDD255xXy++AOzsbKIlFgKN5LN18OVL++LxNVuY+bmGH5dWwRXUHzLmresntkI9/4I4W3AyDJ7v3x/F/yvKaz6BlISC78WKXyH18G26YANbn+rYPfdsD8E1TgXkj8v2H2LiENRuJEcIsJK8Xz7WgAMnbGNf44lFc0Hu7hCna7QfwY8sQqaPALuvhC3C2a/CJ/WgZkvwPGdRVOPFDzD+HeahYj7zMbmBcnFFdq9bT7/ewQkHCrY/YuIw1C4kUs8dnNVWlUP4mx6JoMnbiA1I7NoCyhXG7p8bDZA7vyx2VU4LQnWfGteyRnfFbb/rjFzHM2e+bBvqdnO6tbXCuczanWGSi0hI8WcNVxESiSFG7mE3W7j0143UtrbjW0xiXz4p0VXSzz9zRmgn1wN/X4ze9XY7BC9BH65H76IgCUfa+JER5CV9e8owk0fNWf1Lgw2G7Q/Ny1D1E8Qu7lwPkdEijWFG7ms8v6efNQzAoDRy6JZtPOYdcXYbFD1FrhvAjyzyRwc0DsIEg+ZjVM/qwtTH4WjW62rUXK3ZYoZNDz8zfNXmCo2hnp3AxfcBhOREkXhRq7o9rrl6d+iMgAvTNrI8dOpFlcElAozB317bhvc/TVUaAyZabDpF3O8nO1/WF2hXCwjzQyhAK2eyfvkmNfj/NQfe+bDngWF/3kiUqwo3EiuXu1ch9rBfsQlpfF8QcweXlDcPM1GqY/Mh0cWQrW2ZjuLX+43e1dJ8bFuLMTvB99gaP540XxmYFVo8rD5/K83zdtiIlJiKNxIrjzdXPiqdyQernaW7DpeMLOHF7QKDaHPJGj0IGCYvav+ekNfaMVB6mlzNGKAW14Gd5+i++w2L4FHABzdbF7ZE5ESQ+FGrqpGeT/euMOcPfyDP3ew5XAxHCDNxRXu+My8HQGw4kuY+jBkFINbaSXZiuFwJg6Cqv87wWVR8Q6E1s+Zzxe8C+lni/bzRcQyCjeSJ32bVaJ93fKkZxoMnriB5NRi2A3bZjMbq979jdneYssU+KG7OSO5FL2kY+bM33Bucky3oq+h2SBz9OvEQ7BqVNF/vohYQuFG8sRms/FBjwYE+3uyNy6Zt38vxj2TIu6F+yebPXP2L4MxHTVflRUWfwjpyVChEdS505oa3Lyg7f+Zz5d+CsknrKlDRIqUwo3kWWkfdz6790ZsNvh17SH+2HTE6pKurOot8OBs8AuF4zvgu9shZpPVVZUcF05gWVCTY16rBvdC+RsgNRGWfGRdHSJSZBRuJF9aVAviyVuqA/Dq1M0cPHnG4opyEVwfHp4H5epCUiyM7axuwUVlwbuQlQHVb4fw1tbWYrdD+3fM52u+M4OXiDg1hRvJt2dur0FkpVKcTsng2V+iyMgsxr2SAiqYV3CqtIa00zDhHnPkWik8R6LM9k7Y4PahFhdzTrW2UO02yEqH+e9YXY2IFDKFG8k3Nxc7X94XiZ+HK+v2n+LLBf9YXVLuvErB/VPghnvMqwnTH4fFH5kTOUrBOz/NQoNeEHyDpaXk0O4dwAZbp8GhtVZXIyKFyGYYJet/+MTERAICAkhISMDf39/qchzab1GHeebnKOw2+PnRFjQNL4KRZ69HVhYseAeWfWa+btgPunxmdiOXgrFnIfzQzeyt9vRaKF3F6opymv4ERE0wJ9d8cJa1bYGk4BgGnNoHsZvMtnWxm8zpPtKSzUblrp7g5m0+P//IXnbBe65eV1jnwmXn/nT3KZrRtiVbfr6/9b+6XLO7bqzAkl1xTFl/iGd/3sDsZ24mwNuC7r55Zbebt0n8K8Dsl2D993A6FnqOBQ9fq6tzfBdOjtnk4eIXbABufd28ZXZgBeycBbW7WF2R5FdmBpzYbYaYmI3ngswmSLnC+FupiYVXS1gzuOUVqHqrgnIxoys3cl2SUjO448ul7Dtxhk71gxnRtyE2R/gh3zETJg+EjLMQciP0nQS+5ayuyrFtmQKTHwJ3P3gmCnzKWF3R5c17G5Z9CkE14ImV1oy/I3mTngLHtv57NSZmozlBbkbKpeva3aBcHQiJMB/BDcwJdjPOmgM4nn9c/Pqyy86Yn3HZdc6YdWVeMEBopRZwy6sQfrNCTiHKz/e3wo1ct02H4ukxcgXpmQbv3X0DfZpVsrqkvDm0Fn7qBWdOQKnKZrucMjWsrsoxZaTB/5rCqWjz6kibl6yu6MpSEuDLSPO8d/kUmgy0uiIB87zEbr4gyGwyh3EwMi9d183HbM8V0uDfIFO2Nri6F129p2Nh2eewdsy/Qadyq3Mhx+Iegk5K4SYXCjeF4+vFexg2eweebnZ+f+omapT3s7qkvDmxB37sYX4pe5WG3j9DpeZWV1WwEg6Z3Z99g8EvGDz8Cv63y9XfwqwXwKccDN5Q/G/zrfravDXpU/ZcvQ7y79VZZGXCoTWwf7l5NSZmk/kzeDneQWZ4CWlw7s8bzYlR7cWkP0xijNmOb91YyEwzl1VpbYacKq2src3JKNzkQuGmcGRlGfQfu5qlu+OoHezH9Cdb4enmYnVZeZMcZ17BObwOXDygx7dQ9y6rq7p+Z0+ZvcJWf232EjvPzccMOX4h5/68wvO8TnKZmgRf3gjJx6HLJ//Oxl2cZaTBiGZm6GvzMtz6mtUVOb/0FIheDDv+gJ2zzX8vFwsIuyjINDDbyDnCrZ6Ew+btzvXf/xtywtuY/7ac7Rcmiyjc5ELhpvAcS0yh4xdLOZmcxoCWVRh6Zz2rS8q7tDMwZaDZyBQbdBwGzR+3uqprk5kB68fBgv/C2ZPmslKV4Gx8/hpXevhfJvxc9KdvsDlJ6cL/mr9NP7nacdqwbJ0Ok/qbvWGaP26Oah3WDFw9rK7MeZw9BbvnmoFm9zxzOo7zPAKg2q1QoeG5IBPhHL2PEg7B0k9g/Q/muEpgNji+9TUIa2ptbQ5O4SYXCjeFa8GOozw0zhxDZMyAxrStXd7iivIhKxNmvQhrR5uvWzwF7f5TfC5/58WehTDnNTi2zXxdphZ0fM8cKRjMrrGnY889Yi7684LnF34JXZUNMMxeZ/W7F/QRFR7DgHF3mPOPnefqBZVbmEEnvI35petI5784SDgEO2aZgWb/8pxXDf1CzR5qtbuY7VOKso1MUYs/AEs+NoceOP93UP12uOU1qNjI2toclMJNLhRuCt/QGVsZt2IfgT7u/PlMa8r5e1pdUt4ZBiz//N8uzXW7wd1fm2NhFGcn9sCc12HXbPO1V2nzP9HGD+b/SophQOppSDp6mQB00Z/ne62ENYMH/3S8IJB2xhzUL3ox7F1kHvOFvALNHjBVbzEfgeEWFFnMGQYc2272QNzxB8RE5Xy/bJ1/A01opGPcYipIp/adCzk//ds4ukZ7s01OhYaWluZoFG5yoXBT+FLSM7l7xAq2xyRyU/UyfP9QU+x2B/sPbdMkcyTjrHSzm+d9PxXPS+Zn483JIFd9bdZqc4Gmj5jtSAq7XsOAlHhIOg6lwsyBzRyZYZi9c/Yugr2LYd8yc8qOC5WqDFXb/Htlp7h2dy9sWZlwcLUZZnbMvKgxsM0Mu+cDTVA1y8osVk5GmyFn48R/Q07NjmbICb3R0tKuSWaGedvxzAnzcfbkv8/PnDRv7972ZoF+pMJNLhRuisY/x05zx1fLSEnP4tVOtXmsjQP+Bxe9BH7ua7ZTKVMTun5p/qddHK5OZGXC+vHmBJVnTpjLqt8OHd6DsrWsrc1ZZKbD4fXnws4iOLQ65y0WMLsjh7cx21RUbpH3RtiOKP2s+fewY6bZIPhM3L/vuXiY7WdqdzG/sDVm1JWd2GP+QrLpFzDOzctXq4s5GGBIA2tqOh9UcgSUcyHl/J8Xv3elQRPP8y0PL+wq0DIVbnKhcFN0Jq4+wKtTN+NqtzH1iZY0qFjK6pLy7+hWc7LNxMPma78QqNPV7E1VqQXYLegRtncx/PmqObgZmMGrw3tQo13R11KSpCbBgZX/hp2jW3K+b3czw+/5KzuhDR1/ao8zJ2H3X+YVmn/mmwPYnecZYAaZ2l3MSUmLe/f/4ibuH1jyIWye9G/IqX2HeSUnuP617TMzwwwdZ0+ZV1XPnrrgcfHrk/+Gl5T4az8Or9Lm7VvvoHOPQPPhWx5aPn3t+70MhZtcKNwUHcMweGLCemZviaVKkDd/DG6Nr4cD/mefeMQc1XbnrJy9jXzKmv8Z1b3LHNeisL/ITuyBuW+aXzRgfrnc8po5CJ2j9FByJknHzKt758NOwsGc73v4Q5WbzDY7VVpDubrF46pfbjIz4Mh6s2H6ngXmWDQXDqLnXyFng2D9u7t+x3fB4g/MEb4593Vc505o9azZ1u/iUHJJaDkfXOIh9SpXU67Gs9QFAeWCsJIjvFzwvmepIg3wCje5ULgpWgln0un0xRKOJKRwd2QFPurZAFeXYv4f/JVkpJpfYtt+My/NX/jbjlcg1O5sNkAOb1OwvUBSEsx79X+P/LddTZOB5m94xbEdUElkGOaYOeeDTvSSS38b9go0B3WrcrMZesrVKR6Na0/u/TfMRC+99AuyXL1/A01IRPGo2Rkd22GGnK3TyA4518rD3wweXqXOXVk5/7jo9fmw4hVovi7mVxoVbnKhcFP0Vkef5L5vVpJlQNWyPjzfrhad6gc7XiPjC2Wmm19g234zr6Scb/cC5vgdtTqZV3Sqtb32nlZZmbDhB7NdzfkBz6q1NW9Blatz/ccghScr05xCYM9C2LcUDvyd85YOgHeZc2GntXl1p0zNogkOZ+PNf7t7FsDehWZvngt5ljJvrVVra7YlKl258GuSfx3dZoac3X+ZYzBdLpR4XvT6wnU8A5z2iprCTS4Ubqwxed0h/jtzG6fOmINa1Q3x58UOtbilVlnHmGgzN5kZ5izT236D7b/n7E7s7mu2S6h7J1RvB+7eedtn9FKzXc3RzebroOrn2tW012/Ojuh84+R9S8+FnVXmRIwX8ilnXtE5fysrqHrBnOvMdHMetfNh5vC6f9t4ANhdzbZC1W6Fqm3NnjtWtCUTuQqFm1wo3FjndEo6o5dF893SaJJSzV4njSqX5sUOtWheNcji6grI+S6y236D7TP+bYgM5m9hNdqZ99Nrdrj8fEYno2HuG2ZIAvO3sDavmFMaOPOAZyVNRpoZMvYtg31LzH8zF8907RucM+wEVs1b2DEMs33W3gtuNV3cpb1MTfOqTLW25tUjza0lDkDhJhcKN9Y7lZzGqMV7GLdiH6kZ5m+QrWuU4YX2tYgIK2VtcQUpK8v8Atv+mxl24g/8+56Lh9l1u+6d5pUdmx2WnmtXk5lmvm78kNlg2MdJgp9cWUaqeXVl3zLzys7B1f/ONH2eX+gFYac1lA7/N+ycOWkORLhnAexZBAkHcm7rFWj24KrW1rxCE1CxKI5KpEAp3ORC4ab4OJqYwvAF/zBx9QEyssx/hu3rluf59rWoFexkv0kahjly67YZsG262YjzPLubOT7K+QaoVW+BDsOgfN2ir1OKh/QUs6fS+bBzaM2/kzGe518RKjUzr/Yd2UCORqh2N3OyxvNhJjii+PfUErkKhwk3S5Ys4aOPPmLdunXExMQwbdo0unXrlqdtly9fTps2bahfvz5RUVF5/kyFm+Ln4MkzfD5vN9M2HCLLMH8Z7XZjBZ69vQaVg5xwUDTDMMfP2T7DvKJzfIe5PLAadPjvuSs5alcjF0g/a17NyQ47a/+dlPG8snXMIFOtLVRu6dwDCkqJ5DDhZvbs2SxfvpyGDRvSo0ePPIebhIQEGjZsSPXq1Tl69KjCjZP459hpPp27i1mbYwFwtdvo1SSMp9tWJyTAwYf2z83xneYYKVVuVrsayZu0M3BwlRly/EPNUOMfanVVIoXKYcLNhWw2W57DzX333UeNGjVwcXFh+vTpCjdOZsvhBD7+ayeLdprdn91d7TzQvDJP3FKNIF8Pi6sTEREr5Of72+Fuwo4dO5Y9e/bw1ltvWV2KFJL6FQIY92BTfn2sBU2rBJKWkcXoZdHc/OFCPvlrJwln06++ExERKbEcKtzs3r2bV155hQkTJuDqmreRFFNTU0lMTMzxEMfQNDyQXx5rzviHmnJDhQCS0zL5asE/3PzhQkYu2sOZtIyr70REREochwk3mZmZ9OnTh7fffpuaNWvmebthw4YREBCQ/QgLCyvEKqWg2Ww22tQsy4ynWjHq/oZUL+dLwtl0PvhzBzd/uIjxK/aRmpF59R2JiEiJ4TBtbuLj4yldujQuLv+OnJmVlYVhGLi4uPDXX3/Rtm3bS7ZLTU0lNfXf8SISExMJCwtTmxsHlZll8FvUYT6bt4uDJ80RXiuU8uKZ22vQPbKC485bJSIiucpPm5viPUvWBfz9/dm8eXOOZSNGjGDBggVMnjyZ8PDwy27n4eGBh4caoToLF7uN7g0rckeDUH5de5Av5+/mcPxZXpq8iYmrDzD+oab4ezrnvCoiIpI3loabpKQk/vnnn+zX0dHRREVFERgYSKVKlXj11Vc5fPgw33//PXa7nfr16+fYvly5cnh6el6yXJyfu6ud+5tXpmejivywcj9fLdjNhgPxDBizmu8HNsPXw2Fyu4iIFDBLr+GvXbuWyMhIIiMjARgyZAiRkZG8+eabAMTExHDgwIHcdiElnKebC4/cXJWJjzYnwMuN9QfieWjcGjU2FhEpwYpNm5uionFunNemQ/H0/XYVp1MzaFU9iNH9m+DpptmNRUScgVOPcyNyJQ0qlmLcQ03xcXdh+T8neOyHdepJJSJSAinciFNpVLk0YwY0wcvNhcW7jvPkhA2knZt5XERESgaFG3E6zaoG8V3/xni42pm3/SjP/LyBjEwFHBGRkkLhRpxSq+pl+PqBRri72Jm9JZYhv24kM6tENS8TESmxFG7Ead1Sqxwj+jbE1W5jxsYjvDxlE1kKOCIiTk/hRpza7XXL81XvSFzsNiavO8Tr07dQwjoIioiUOAo34vQ63RDCp70isNtg4uoDDJ2xVQFHRMSJKdxIiXDXjRX4sGcENhuMX7mf92ZtV8AREXFSCjdSYvRsVJH37r4BgG+XRvPxXzsVcEREnJDCjZQovZtW4p276gHwv4V7+HL+P1fZQkREHI3CjZQ4/VpU4f+61AHgs3m7GLloj8UViYhIQVK4kRLp4dZVebFDLQA++HMH3y3da3FFIiJSUBRupMR68tbqPHNbDQDenbmdH1bus7YgEREpEAo3UqI9e3sNHr+lGgBv/LaVn1cfsLgiERG5Xgo3UqLZbDZe6lCLgTeFA/DqtM1MWXfI4qpEROR6KNxIiWez2fi/LnXo16IyhgEvTt7I7xuPWF2WiIhcI4UbEcyAM7RrPe5rEkaWAc/+EsWfW2KsLktERK6Bwo3IOXa7jffuvoHuDSuQmWXw9MQNzN9+1OqyREQknxRuRC5gt9v4qGcEXSNCSc80ePzH9SzeddzqskREJB+uKdwcPHiQQ4f+bXS5evVqnn32Wb755psCK0zEKi52G5/2iqBjvWDSMrN49Pu1rPgnzuqyREQkj64p3PTp04eFCxcCEBsbS7t27Vi9ejWvvfYa77zzToEWKGIFNxc7X/aO5PY65UjNyGLg+LVMXX+I9Mwsq0sTEZGruKZws2XLFpo2bQrAr7/+Sv369VmxYgU//fQT48aNK8j6RCzj7mrnf30bcnPNspxNz2TIrxtp8+FCvl2yl9Mp6VaXJyIiV3BN4SY9PR0PDw8A5s2bx5133glA7dq1iYlRDxNxHh6uLnzzQCOeb1eTMr7uHElI4b+zttNy2AL+O3MbR+LPWl2iiIhc5JrCTb169Rg1ahRLly5l7ty5dOzYEYAjR44QFBRUoAWKWM3TzYWnb6vBspfb8kGPG6hezpfTqRl8uzSa1h8uZPDEDWw+lGB1mSIico7NMAwjvxstWrSIu+++m8TERPr378+YMWMAeO2119ixYwdTp04t8EILSmJiIgEBASQkJODv7291OeKAsrIMFu86zrdL97Jiz4ns5c2rBvJI66rcWqscdrvNwgpFRJxPfr6/ryncAGRmZpKYmEjp0qWzl+3btw9vb2/KlSt3LbssEgo3UpC2HE7gu6V7+WNTDBlZ5o9StbI+PNy6KndHVsDTzcXiCkVEnEOhh5uzZ89iGAbe3t4A7N+/n2nTplGnTh06dOhwbVUXEYUbKQxH4s8yfsU+flp1gNOpGQAE+bjzQIvKPNC8MkG+HhZXKCLi2Ao93LRv357u3bszaNAg4uPjqV27Nm5ubsTFxfHpp5/y+OOPX3PxhU3hRgrT6ZR0fllzkLHL93H4XGNjD1c7PRpVZOBN4VQr62txhSIijik/39/X1KB4/fr1tG7dGoDJkydTvnx59u/fz/fff8+XX355LbsUcQp+nm483Loqi1+8ha96R9KgYgCpGVn8tOoAt32ymIfHr2XV3hNc491gERHJA9dr2ejMmTP4+fkB8Ndff9G9e3fsdjvNmzdn//79BVqgiCNydbHTNSKUOxqEsDr6JN8ujWb+jqPM224+GlQM4OHWVelcPxhXF82CIiJSkK7pf9Xq1aszffp0Dh48yJw5c2jfvj0Ax44d060ekQvYbDaaVQ3iu/6NmTekDX2aVcLD1c6mQwkMnriBNh8t4rule0k6105HRESu3zW1uZk8eTJ9+vQhMzOTtm3bMnfuXACGDRvGkiVLmD17doEXWlDU5kasdiIplR//PsD3K/dxIjkNAH9PV0YPaEKTKoEWVyciUjwVSVfw2NhYYmJiiIiIwG43LwCtXr0af39/ateufS27LBIKN1JcpKRnMm3DYb5dupe9x5MJ9HHntydbERbobXVpIiLFTpGEm/MOHTqEzWajQoUK17ObIqNwI8XN2bRM7vl6BVsOJ1KrvB9TnmiJr8c1NYcTEXFahd5bKisri3feeYeAgAAqV65MpUqVKFWqFP/5z3/IytKsySL54eXuwrf9GlPWz4OdR0/z7M8byMxSbyoRkWt1TeHm9ddfZ/jw4bz//vts2LCB9evX89577/HVV1/xxhtvFHSNIk4vJMCLbx5ohLurnXnbj/HRnJ1WlyQi4rCu6bZUaGgoo0aNyp4N/LzffvuNJ554gsOHDxdYgQVNt6WkOPst6jDP/BwFwCf3RNCjUUVrCxIRKSYK/bbUyZMnL9touHbt2pw8efJadikiwF03VuCpW6sD8OrUzazbf8riikREHM81hZuIiAiGDx9+yfLhw4fToEGD6y5KpCQb0q4mHeqVJy0zi8d+WJs9jYOIiOTNNd2WWrx4MV26dKFSpUq0aNECm83GihUrOHjwILNmzcqemqE40m0pcQTJqRn0HLWS7TGJ1AnxZ/KgFvioB5WIlGCFfluqTZs27Nq1i7vvvpv4+HhOnjxJ9+7d2bp1K2PHjr2mokXkXz4ernzXvzFlfN3ZHpPIkF+jyFIPKhGRPLnucW4utHHjRho2bEhmZmZB7bLA6cqNOJJ1+0/S+5tVpGVm8XTb6jzfvpbVJYmIWKLQr9yISNFoVDmQYd1vAOCrBf/wW1Tx7YkoIlJcKNyIFHM9GlXksTZVAXhx8iaiDsZbW5CISDGncCPiAF7qUJvbapcjLSOLR75fS0yCelCJiFxJvrpfdO/ePdf34+Pjr6cWEbkCF7uNL3pH0mPECnYePc2j36/j18da4OXuYnVpIiLFTr6u3AQEBOT6qFy5Mv369SusWkVKNN9zPagCfdzZfDiBFyZtpAD7A4iIOI0C7S2VX0uWLOGjjz5i3bp1xMTEMG3aNLp163bF9adOncrIkSOJiooiNTWVevXqMXToUDp06JDnz1RvKXF0q/ae4P7Rq0jPNHj29ho8e3tNq0sSESl0DtNbKjk5+YqjHV/OkiVLaNeuHbNmzWLdunXceuutdO3alQ0bNhRypSLFR7OqQbzbrT4An8/bzcxNMRZXJCJSvFh65eZCNpvtqlduLqdevXrce++9vPnmm3laX1duxFn8549tjF4WjaebnUmPteSGigFWlyQiUmgc5srN9crKyuL06dMEBgZecZ3U1FQSExNzPEScwaudatOmZllS0s0eVMcSU6wuSUSkWHDocPPJJ5+QnJxMr169rrjOsGHDcjR6DgsLK8IKRQqPq4udr/pEUq2sD7GJKTzywzpS0ovv6OAiIkXFYcPNxIkTGTp0KL/88gvlypW74nqvvvoqCQkJ2Y+DBw8WYZUihcvf043R/ZtQytuNjQfjeXnKJvWgEpESzyHDzS+//MLAgQP59ddfuf3223Nd18PDA39//xwPEWdSpYwPI/o2xNVu47eoI4xYtMfqkkRELOVw4WbixIkMGDCAn376iS5dulhdjkix0LJaGYbeWQ+Aj+bs5M8tsRZXJCJiHUvDTVJSElFRUURFRQEQHR1NVFQUBw4cAMxbShcOCjhx4kT69evHJ598QvPmzYmNjSU2NpaEhAQryhcpVu5vXpn+LSoD8NwvUWw9op8LESmZLA03a9euJTIyksjISACGDBlCZGRkdrfumJiY7KAD8PXXX5ORkcGTTz5JSEhI9uOZZ56xpH6R4uaNO+pyU/UynE3P5JHxazl+OtXqkkREilyxGeemqGicG3F2CWfS6TZiOdFxyTSsVIqJjzbHw1VzUImIYysx49yIyKUCvN34rn9j/D1dWX8gnlenblYPKhEpURRuRJxQtbK+/K9vQ1zsNqauP8zXS/ZaXZKISJFRuBFxUq1rlOWNLnUAeH/2DsYtj7a4IhGRoqFwI+LE+reswiOtwwEY+vs2vpy/W7eoRMTpKdyIODGbzcZrnevw7O01APh07i7+O3O7Ao6IODWFGxEnZ7PZePb2mrx5R10AvlsWzStTNpOZpYAjIs5J4UakhHjopnA+6tkAuw1+WXuQwRM3kJaRZXVZIiIFTuFGpAS5p3EYI/o2xM3FxszNMTzy/VrOpmkmcRFxLgo3IiVMx/ohjO7fBC83FxbvOk6/MatITEm3uiwRkQKjcCNSAt1csyw/PtwUP09X1uw7Re9v/iYuSVM1iIhzULgRKaEaVQ7k50ebU8bXna1HEuk1aiVH4s9aXZaIyHVTuBEpweqFBvDrYy0IDfBkb1wy94xayd7jSVaXJSJyXRRuREq4qmV9mfR4S6qW8eFw/Fl6fb2SbUcSrS5LROSaKdyICBVKefHroBbUDfEnLimN+75Zybr9J60uS0TkmijciAgAZXw9mPhocxpXLk1iSgb3f7eapbuPW12WiEi+KdyISLYALze+H9iU1jXKcDY9k4Hj1vLnlliryxIRyReFGxHJwdvdle/6N6bzDcGkZWbxxIR1TFp70OqyRETyTOFGRC7h4erCV70b0qtxRbIMeHHyJsYsi7a6LBGRPFG4EZHLcrHb+KBHAwbeFA7AO39s44t5uzWjuIgUewo3InJFNpuN/+tShyHtagLw2bxdvDtzuwKOiBRrCjcikiubzcbg22rwVte6AIxeFs3LUzaRmaWAIyLFk8KNiOTJg63C+fieCOw2+HXtIZ6euJ7UDM0oLiLFj8KNiORZz0YVGdG3Ee4udmZtjuWR79dxJi3D6rJERHJQuBGRfOlYP5gxA5rg5ebCkl3H6Td6NQln060uS0Qkm8KNiOTbTTXK8OPDzfD3dGXt/lN0/mIpk9cdUjscESkWFG5E5Jo0qlyaX87NKH44/iwvTNpIpy+WMHfbUfWmEhFL2YwS9r9QYmIiAQEBJCQk4O/vb3U5Ig4vJT2TcSv2MWLhPySmmO1vGlUuzcsda9M0PNDi6kTEWeTn+1vhRkQKRMKZdEYt2cPY5dGkpGcBcGutsrzUsTZ1QvSzJiLXR+EmFwo3IoXraGIKX87fzc9rDpKZZWCzwV0RoQxpV4tKQd5WlyciDkrhJhcKNyJFIzoumU/+2skfm2IAcHOx0adpJZ5qW4Oyfh4WVycijkbhJhcKNyJFa/OhBD6cs4Olu+MA8HZ34eGbwnnk5qr4ebpZXJ2IOAqFm1wo3IhYY8U/cXzw5w42HkoAoLS3G0/eWp37m1fG083F4upEpLhTuMmFwo2IdQzD4M8tsXz01072Hk8GoEIpL569vQbdG1bExW6zuEIRKa4UbnKhcCNivYzMLCavO8Tn83YTm5gCQI1yvrzQoRbt65bHZlPIEZGcFG5yoXAjUnykpGcyfsU+Rizakz2FQ2SlUrzcsTbNqwZZXJ2IFCcKN7lQuBEpfhLOpvP14j2MuWCMnFtqleXFDrWoFxpgcXUiUhwo3ORC4Uak+DqWmMIXF4yRA3BnRCivda5DcICnxdWJiJUUbnKhcCNS/F08Rk6Qjztf9o6kVfUyFlcmIlbJz/e3Js4UkWInvIwPw/s05I+nb6JOiD8nktO4f/Qqvpq/myzNPC4iV6FwIyLFVv0KAUx7oiX3NKqIYcAnc3cxcPwa4s+kWV2aiBRjCjciUqx5urnw0T0RfNijAR6udhbuPE6XL5ex6VC81aWJSDGlcCMiDqFXkzCmPtGSykHeHI4/S8+RK/nh7/2UsGaDIpIHCjci4jDqhQYw46mbaF+3PGmZWbwxfQvP/RLFmbQMq0sTkWJE4UZEHEqAlxtfP9CI1zrXxsVuY3rUEe4avpx/jiVZXZqIFBMKNyLicGw2G4/eXI2fHm5GWT8Pdh9L4q7hy/hj0xGrSxORYkDhRkQcVrOqQcwcfBPNqwaSnJbJUz9tYOiMraRlZFldmohYSOFGRBxaOT9PfhzYjMdvqQbAuBX7uPeblRyJP2txZSJiFUvDzZIlS+jatSuhoaHYbDamT59+1W0WL15Mo0aN8PT0pGrVqowaNarwCxWRYs3Vxc7LHWvzXb/G+Hu6suFAPF2+XMqSXcetLk1ELGBpuElOTiYiIoLhw4fnaf3o6Gg6d+5M69at2bBhA6+99hqDBw9mypQphVypiDiC2+uW54+nW1O/gj+nzqTTf+xqPp+3S6Mai5QwxWZuKZvNxrRp0+jWrdsV13n55ZeZMWMG27dvz142aNAgNm7cyMqVK/P0OZpbSsT5paRn8vbv25i4+gAAN9csy+f33kigj7vFlYnItXLauaVWrlxJ+/btcyzr0KEDa9euJT09/bLbpKamkpiYmOMhIs7N082FYd1v4JN7IvB0s7Nk13Hu+HIpGw6csro0ESkCDhVuYmNjKV++fI5l5cuXJyMjg7i4uMtuM2zYMAICArIfYWFhRVGqiBQDPRpVZPqTrQgv48ORhBR6fb2SccujNaqxiJNzqHAD5u2rC53/T+ri5ee9+uqrJCQkZD8OHjxY6DWKSPFRO9ifGU+1ovMNwaRnGgz9fRuDf44iOVWjGos4K4cKN8HBwcTGxuZYduzYMVxdXQkKCrrsNh4eHvj7++d4iEjJ4ufpxv/6NOSNO+riarfx+8Yj3Dl8GbuPnra6NBEpBA4Vblq0aMHcuXNzLPvrr79o3Lgxbm5uFlUlIo7AZrMx8KZwfn60OeX9PdhzPJk7hy/nt6jDVpcmIgXM0nCTlJREVFQUUVFRgNnVOyoqigMHzB4Or776Kv369ctef9CgQezfv58hQ4awfft2xowZw+jRo3nhhResKF9EHFDjKoHMHNyaVtWDOJueyTM/R/HFvN1qhyPiRCwNN2vXriUyMpLIyEgAhgwZQmRkJG+++SYAMTEx2UEHIDw8nFmzZrFo0SJuvPFG/vOf//Dll1/So0cPS+oXEcdUxteD7x9qxhPnRjX+bN4u3vljm8bDEXESxWacm6KicW5E5EJjl0fz9u/bAOjRsCIf9LgBVxeHumMvUiI47Tg3IiIF7cFW4XzaKwIXu40p6w/x+IT1pKRnWl2WiFwHhRsRKfG6N6zIqPsb4e5qZ+62ozw4dg1J6iou4rAUbkREgHZ1yzP+wab4eriycu8J+n77NyeT06wuS0SugcKNiMg5LaoF8dMjzSjt7cbGQwn0+nolMQlnrS5LRPJJ4UZE5AINKpZi0qAWhAR48s+xJHqOXEl0XLLVZYlIPijciIhcpHo5PyYNakF4GR8Ox5/lnlEr2XZEk+6KOAqFGxGRy6hY2ptfH2tB3RB/4pJSufeblazdd9LqskQkDxRuRESuoKyfBz8/1pwmVUpzOiWD+0evYuHOY1aXJSJXoXAjIpILf083vn+oGbfUKktKehaPjF/L7xuPWF2WiORC4UZE5Cq83F345oHG3BkRSkaWweCfNzBh1X6ryxKRK1C4ERHJA3dXO5/feyP3N6+EYcDr07bwv4X/aMJNkWJI4UZEJI/sdhv/uas+T91aHYCP5uzk/dk7FHBEihmFGxGRfLDZbLzQoRavd64DwNdL9vLKlM1kakZxkWJD4UZE5Bo8cnNVPuzRALsNfll7kKcnric1QxNuihQHCjciIteoV5MwRvRtiLuLnVmbY3l4/FqSNeGmiOUUbkRErkPH+iGMGdAEb3cXlu6O4/7Rq4g/owk3RaykcCMicp1uqlGGCQ83I8DLjQ0H4rn36785lphidVkiJZbCjYhIAYisVJpfH2tBOT8Pdh49Tc9RKzlw4ozVZYmUSAo3IiIFpFawH1Meb0mlQG8OnDxDz1Er2Bl72uqyREochRsRkQIUFujN5EEtqB3sx7HTqdwzagUr95ywuiyREkXhRkSkgJXz9+SXR1vQqHJpElMy6DdmFdM2HLK6LJESQ+FGRKQQBHi7MeHhZnS5IYT0TIPnftnIF/N2azRjkSKgcCMiUkg83Vz4qnckg9pUA+Czebt4YdIm0jKyLK5MxLkp3IiIFCK73cYrnWrz3t034GK3MWX9IfqPWU3C2XSrSxNxWgo3IiJFoE+zSozu3xgfdxdW7j1Bj5ErOHhSXcVFCoPCjYhIEbmlVjkmDWpJsL8n/xxL4u4Ry4k6GG91WSJOR+FGRKQI1Q31Z/qTragb4k9cUhr3fbOSOVtjrS5LxKko3IiIFLHgAE9+HdSCW2qVJSU9i0E/rmP0smiryxJxGgo3IiIW8PVw5bt+jenbrBKGAf/5YxtDZ2wlM0tdxUWul8KNiIhFXF3svNutPq91rg3AuBX7eOyHtZxJy7C4MhHHpnAjImIhm83GozdXY0Tfhni42pm3/ZhmFRe5Tgo3IiLFQOcbQvjpkeYE+riz+XACd4/QpJsi10rhRkSkmGhUuTTTnmhJ1TI+HI4/S8+RK1i2O87qskQcjsKNiEgxUjnIh6lPtKRplUBOp2YwYOxqfl1z0OqyRByKwo2ISDFTytudHx5uyl03hpKRZfDSlE18PGenJt0UySOFGxGRYsjD1YXP772RwW2rAzB84T8883MUqRmZFlcmUvwp3IiIFFM2m40h7WvxYc8GuNptzNh4hAe+W82p5DSrSxMp1hRuRESKuV6Nwxj/UFP8PFxZve8k3UeuYF9cstVliRRbCjciIg6gVfUyTHmiJRVKeREdl0z3kStYt/+U1WWJFEsKNyIiDqJmeT+mPdmSBhUDOJmcRu9v/+a3qMNWlyVS7CjciIg4kHJ+nvz8aHNur1OetIwsnvk5iv+bvpmUdDU0FjlP4UZExMF4u7vy9QONeOpWsyfVj38foIfa4YhkU7gREXFALnYbL3SoxfiHmhLo487WI4nc8dUyZm6Ksbo0Ecsp3IiIOLA2Ncsyc/BNNKlSmqTUDJ78aT1v/rZF4+FIiaZwIyLi4EICvJj4SHMev6UaAN+v3E+PkSvYf0K3qaRkUrgREXECri52Xu5Ym7EPNqG0txtbDidyx5fLmL1Zt6mk5LE83IwYMYLw8HA8PT1p1KgRS5cuzXX9CRMmEBERgbe3NyEhITz44IOcOHGiiKoVESnebq1VjpmDW9OocmlOp2bw+IT1DJ2xVbeppESxNNz88ssvPPvss7z++uts2LCB1q1b06lTJw4cOHDZ9ZctW0a/fv0YOHAgW7duZdKkSaxZs4aHH364iCsXESm+Qkt58fOjzXmsTVUAxq3Yxz2jVnLw5BmLKxMpGjbDwmlmmzVrRsOGDRk5cmT2sjp16tCtWzeGDRt2yfoff/wxI0eOZM+ePdnLvvrqKz788EMOHjyYp89MTEwkICCAhIQE/P39r/8gRESKsfnbj/L8pI3En0nHz9OVj3pG0LF+sNVlieRbfr6/Lbtyk5aWxrp162jfvn2O5e3bt2fFihWX3aZly5YcOnSIWbNmYRgGR48eZfLkyXTp0qUoShYRcTi31SnPzMGtaVipFKdTMhj04zre+X0baRlZVpcmUmgsCzdxcXFkZmZSvnz5HMvLly9PbGzsZbdp2bIlEyZM4N5778Xd3Z3g4GBKlSrFV199dcXPSU1NJTExMcdDRKQkqVDKi18ea8GjN5u3qcYsj+aer3WbSpyX5Q2KbTZbjteGYVyy7Lxt27YxePBg3nzzTdatW8eff/5JdHQ0gwYNuuL+hw0bRkBAQPYjLCysQOsXEXEEbi52Xutch+/6NSbAy42NB+Pp8uVS/tp6+V8mRRyZZW1u0tLS8Pb2ZtKkSdx9993Zy5955hmioqJYvHjxJds88MADpKSkMGnSpOxly5Yto3Xr1hw5coSQkJBLtklNTSU1NTX7dWJiImFhYWpzIyIl1qFTZ3jypw1sPBgPwMM3hfNSx9q4u1r++67IFTlEmxt3d3caNWrE3LlzcyyfO3cuLVu2vOw2Z86cwW7PWbKLiwtgXvG5HA8PD/z9/XM8RERKsoqlvZn0WAsevikcgO+WRdPr65UcOqXbVOIcLI3pQ4YM4bvvvmPMmDFs376d5557jgMHDmTfZnr11Vfp169f9vpdu3Zl6tSpjBw5kr1797J8+XIGDx5M06ZNCQ0NteowREQcjrurnf+7oy7fPNAIf09Xog7G0+XLZczfftTq0kSum6uVH37vvfdy4sQJ3nnnHWJiYqhfvz6zZs2icuXKAMTExOQY82bAgAGcPn2a4cOH8/zzz1OqVCnatm3LBx98YNUhiIg4tPb1gpkZ4s9TP61n46EEBo5fy6M3V+XFDrVwc9FtKnFMlo5zYwWNcyMicqm0jCyGzd7O2OX7AGhYqRTD+zQktJSXtYWJnJOf72+FGxERyfbnllhenLyR0ykZlPJ2444GITQND6JZeCDl/T2tLk9KMIWbXCjciIjk7sCJMzz503o2H07IsbxykDdNqgTSNDyQZuGBVAr0vuLQHSIFTeEmFwo3IiJXl5aRxYIdx1gVfYI1+06y7UgiWRd9W5T396BJFTPoNA0PokY5X+x2hR0pHAo3uVC4ERHJv8SUdNbtP8Xq6JOsiT7JxkPxpGfm/Poo5e1G48rnw04g9UL9cVWjZCkgCje5ULgREbl+KemZbDgQb4adfSdZt/8UZ9Mzc6zj4+5Cw8qlaXruVlZEWCk83VwsqlgcncJNLhRuREQKXnpmFlsOJ2SHndXRJ0lMycixjruLnYiwAJqeu43VqHJpfD0sHZFEHIjCTS4UbkRECl9WlsHOo6dZHX2S1efCzvHTqTnWcXOx0ap6GTrXD6Fd3fKU9nG3qFpxBAo3uVC4EREpeoZhsO/EGVZHn2B19ClWRZ/g0Kmz2e+72G20qBpEx/rBdKgXTFk/DwurleJI4SYXCjciIsXDP8dOM3tzLLO2xLI9JjF7uc0GTaoE0rl+MB3rhxAcUHLG1zmRlMqCHcf453gSbWqUpXnVIPVAO0fhJhcKNyIixc++uGT+3BrL7M0xbDyUc3ydyEql6Fw/hI71gwkL9LaowsJhGAZ7jiczb/tR5m07yroDp7jwW7liaS96NqpIz0YVqVjauY49vxRucqFwIyJSvB06dYY/t8Ty55ZY1u4/leO9GyoE0LF+MJ3qB1O1rK9FFV6fjMws1u0/ZQaa7ceIjkvO8f4NFQKoVtaH+duPcTrVbJRts0HLakHc0yiMjvWDS2SvM4WbXCjciIg4jqOJKczZGsvszbGsij6RYyDB2sF+dKofQqcbgqlRzrdYj5aclJrBkl3HmbftKAt2HiP+THr2e+4udlpUC+L2uuW5vU45QgLM+bzOpmUyZ2ssk9YdZPk/J7LX9/N0pWtEKL0ahxFRMaBYH3dBUrjJhcKNiIhjiktKZe62o8zeEsuKf+LIuCDpVCvrQ6dzt67qhfoXiy/8mISzzNt+jHnbjrJyzwnSMrOy3yvl7Ubb2uVoV6c8rWuWvWqX+IMnzzBl/SEmrT3E4fh/G2LXKOdLr8ZhdIus4PSNsBVucqFwIyLi+OLPpDFv+zFmb45h6e64HMGhUqA3neoH07hKIEG+7pTx8SDQ1x0fd5dCDT2GYbD1SOK5201H2XI4Mcf7VYK8aVe3PO3qBtOwUqlrGr05K8vg770n+HXtQWZviSU1wzxuV7uNW2uXo1fjMG6pVRY3JxwZWuEmFwo3IiLO5XRKOgt2HGP25lgW7TpGSnrWZdfzcLUT5ONOoK87QT4eBPm4E+TrTmCO5+6U8fUg0Mcd7zyEodSMTFbtPcncbUeZv/0oRxJSst+z2aBRpdLnbjeVp1pZnwINVwln0/lj0xEmrT1E1MH47OVlfN3p3rAi9zSqSI3yfgX2eVZTuMmFwo2IiPM6k5bBop3HmbM1lui4ZE4kpXEiOfWKgSc3Hq727KBzPviYIcgDb3cXVu09yeJdx0lK/XckZi83F1rXKMPtdcvTtnY5yvgWza2i3UdPM2ndIaauP0RcUlr28hvDSnFP44p0jQjF39OtSGopLAo3uVC4EREpec6kZZwLOmmcTE4lLimNk8lpnEhKPbcsjRPnlsUlpWbf7smLcn4e3FanPO3qlqNltTKW9mRKz8xi0c7j/Lr2IAt3HMtul+ThaqdT/WDuaRxGCwcdO0fhJhcKNyIikhvDMDiTlpkddM4Hn/PB6ERSGgln06kT4k+7uuW5oUJAsQwLx0+nMn3DYX5de5Ddx5Kyl1co5UWPhhXoUD+YuiHFo/F1Xijc5ELhRkREShLDMNh4KIFJaw8yY+MRTl8woWnF0l60rxtM+3rlaVy59DU1ci4qCje5ULgREZGSKiXdHDtn5qYYluw+nqMtUqCPO7fVLkf7esG0rmHt7bXLUbjJhcKNiIiIOUjgkt3H+WvrUebvOJpjYEEvNxfa1CxL+3pmw+hS3tbP2K5wkwuFGxERkZwyMrNYve8kf209ytxtR3MMFOhit9G8aiDt6wbTrm55Qkt5WVKjwk0uFG5ERESu7PxghH9tjeWvbUfZEXs6x/s3VAigQ73ytK9XtNNeKNzkQuFGREQk7/bFJTN321H+2mZOZHphaqgS5E2HemaD5Miw0oXaa0zhJhcKNyIiItfm+OlU5m8/yl/bjrLsomkvyvh60K5uedrXK0/LakF4uBZsg2SFm1wo3IiIiFy/pNQMFu88zl/bYlmw41iOLuZ+nq78/ept+FxlQtD8yM/3d8F9qoiIiJQYvh6udGkQQpcGIaRlZPH33hP8tS2Wv7YepVKgd4EGm/zSlRsREREpMFlZBifPpBX4vFr5+f4uvkMRioiIiMOx221FNmHoFWuw9NNFRERECpjCjYiIiDgVhRsRERFxKgo3IiIi4lQUbkRERMSpKNyIiIiIU1G4EREREaeicCMiIiJOReFGREREnIrCjYiIiDgVhRsRERFxKgo3IiIi4lQUbkRERMSpuFpdQFEzDAMwp04XERERx3D+e/v893huSly4OX36NABhYWEWVyIiIiL5dfr0aQICAnJdx2bkJQI5kaysLI4cOYKfnx82m61A952YmEhYWBgHDx7E39+/QPdd3JSkY4WSdbw6VudVko5Xx+p8DMPg9OnThIaGYrfn3qqmxF25sdvtVKxYsVA/w9/f36n/gV2oJB0rlKzj1bE6r5J0vDpW53K1KzbnqUGxiIiIOBWFGxEREXEqCjcFyMPDg7feegsPDw+rSyl0JelYoWQdr47VeZWk49WxlmwlrkGxiIiIODdduRERERGnonAjIiIiTkXhRkRERJyKwo2IiIg4FYWbfBoxYgTh4eF4enrSqFEjli5dmuv6ixcvplGjRnh6elK1alVGjRpVRJVeu2HDhtGkSRP8/PwoV64c3bp1Y+fOnblus2jRImw22yWPHTt2FFHV127o0KGX1B0cHJzrNo54XgGqVKly2fP05JNPXnZ9RzqvS5YsoWvXroSGhmKz2Zg+fXqO9w3DYOjQoYSGhuLl5cUtt9zC1q1br7rfKVOmULduXTw8PKhbty7Tpk0rpCPIn9yONz09nZdffpkbbrgBHx8fQkND6devH0eOHMl1n+PGjbvs+U5JSSnko8nd1c7tgAEDLqm5efPmV91vcTy3VzvWy50fm83GRx99dMV9FtfzWpgUbvLhl19+4dlnn+X1119nw4YNtG7dmk6dOnHgwIHLrh8dHU3nzp1p3bo1GzZs4LXXXmPw4MFMmTKliCvPn8WLF/Pkk0/y999/M3fuXDIyMmjfvj3JyclX3Xbnzp3ExMRkP2rUqFEEFV+/evXq5ah78+bNV1zXUc8rwJo1a3Ic59y5cwG45557ct3OEc5rcnIyERERDB8+/LLvf/jhh3z66acMHz6cNWvWEBwcTLt27bLnm7uclStXcu+99/LAAw+wceNGHnjgAXr16sWqVasK6zDyLLfjPXPmDOvXr+eNN95g/fr1TJ06lV27dnHnnXdedb/+/v45znVMTAyenp6FcQh5drVzC9CxY8ccNc+aNSvXfRbXc3u1Y7343IwZMwabzUaPHj1y3W9xPK+FypA8a9q0qTFo0KAcy2rXrm288sorl13/pZdeMmrXrp1j2WOPPWY0b9680GosDMeOHTMAY/HixVdcZ+HChQZgnDp1qugKKyBvvfWWERERkef1neW8GoZhPPPMM0a1atWMrKysy77vqOcVMKZNm5b9OisrywgODjbef//97GUpKSlGQECAMWrUqCvup1evXkbHjh1zLOvQoYNx3333FXjN1+Pi472c1atXG4Cxf//+K64zduxYIyAgoGCLK2CXO9b+/fsbd911V7724wjnNi/n9a677jLatm2b6zqOcF4Lmq7c5FFaWhrr1q2jffv2OZa3b9+eFStWXHablStXXrJ+hw4dWLt2Lenp6YVWa0FLSEgAIDAw8KrrRkZGEhISwm233cbChQsLu7QCs3v3bkJDQwkPD+e+++5j7969V1zXWc5rWloaP/74Iw899NBVJ5F11PN6XnR0NLGxsTnOm4eHB23atLnizy9c+Vzntk1xlZCQgM1mo1SpUrmul5SUROXKlalYsSJ33HEHGzZsKJoCr9OiRYsoV64cNWvW5JFHHuHYsWO5ru8M5/bo0aPMnDmTgQMHXnVdRz2v10rhJo/i4uLIzMykfPnyOZaXL1+e2NjYy24TGxt72fUzMjKIi4srtFoLkmEYDBkyhJtuuon69etfcb2QkBC++eYbpkyZwtSpU6lVqxa33XYbS5YsKcJqr02zZs34/vvvmTNnDt9++y2xsbG0bNmSEydOXHZ9ZzivANOnTyc+Pp4BAwZccR1HPq8XOv8zmp+f3/Pb5Xeb4iglJYVXXnmFPn365DqxYu3atRk3bhwzZsxg4sSJeHp60qpVK3bv3l2E1eZfp06dmDBhAgsWLOCTTz5hzZo1tG3bltTU1Ctu4wzndvz48fj5+dG9e/dc13PU83o9Stys4Nfr4t9wDcPI9bfey61/ueXF1VNPPcWmTZtYtmxZruvVqlWLWrVqZb9u0aIFBw8e5OOPP+bmm28u7DKvS6dOnbKf33DDDbRo0YJq1aoxfvx4hgwZctltHP28AowePZpOnToRGhp6xXUc+bxeTn5/fq91m+IkPT2d++67j6ysLEaMGJHrus2bN8/RELdVq1Y0bNiQr776ii+//LKwS71m9957b/bz+vXr07hxYypXrszMmTNz/eJ39HM7ZswY+vbte9W2M456Xq+HrtzkUZkyZXBxcbkk1R87duyS9H9ecHDwZdd3dXUlKCio0GotKE8//TQzZsxg4cKFVKxYMd/bN2/e3CF/M/Dx8eGGG264Yu2Ofl4B9u/fz7x583j44Yfzva0jntfzvd/y8/N7frv8blOcpKen06tXL6Kjo5k7d26uV20ux26306RJE4c73yEhIVSuXDnXuh393C5dupSdO3de08+wo57X/FC4ySN3d3caNWqU3bvkvLlz59KyZcvLbtOiRYtL1v/rr79o3Lgxbm5uhVbr9TIMg6eeeoqpU6eyYMECwsPDr2k/GzZsICQkpICrK3ypqals3779irU76nm90NixYylXrhxdunTJ97aOeF7Dw8MJDg7Ocd7S0tJYvHjxFX9+4crnOrdtiovzwWb37t3MmzfvmoK3YRhERUU53Pk+ceIEBw8ezLVuRz63YF55bdSoEREREfne1lHPa75Y1ZLZEf3888+Gm5ubMXr0aGPbtm3Gs88+a/j4+Bj79u0zDMMwXnnlFeOBBx7IXn/v3r2Gt7e38dxzzxnbtm0zRo8ebbi5uRmTJ0+26hDy5PHHHzcCAgKMRYsWGTExMdmPM2fOZK9z8bF+9tlnxrRp04xdu3YZW7ZsMV555RUDMKZMmWLFIeTL888/byxatMjYu3ev8ffffxt33HGH4efn53Tn9bzMzEyjUqVKxssvv3zJe458Xk+fPm1s2LDB2LBhgwEYn376qbFhw4bs3kHvv/++ERAQYEydOtXYvHmz0bt3byMkJMRITEzM3scDDzyQo/fj8uXLDRcXF+P99983tm/fbrz//vuGq6ur8ffffxf58V0st+NNT0837rzzTqNixYpGVFRUjp/j1NTU7H1cfLxDhw41/vzzT2PPnj3Ghg0bjAcffNBwdXU1Vq1aZcUhZsvtWE+fPm08//zzxooVK4zo6Ghj4cKFRosWLYwKFSo45Lm92r9jwzCMhIQEw9vb2xg5cuRl9+Eo57UwKdzk0//+9z+jcuXKhru7u9GwYcMc3aP79+9vtGnTJsf6ixYtMiIjIw13d3ejSpUqV/zHWJwAl32MHTs2e52Lj/WDDz4wqlWrZnh6ehqlS5c2brrpJmPmzJlFX/w1uPfee42QkBDDzc3NCA0NNbp3725s3bo1+31nOa/nzZkzxwCMnTt3XvKeI5/X893WL37079/fMAyzO/hbb71lBAcHGx4eHsbNN99sbN68Occ+2rRpk73+eZMmTTJq1apluLm5GbVr1y42wS63442Ojr7iz/HChQuz93Hx8T777LNGpUqVDHd3d6Ns2bJG+/btjRUrVhT9wV0kt2M9c+aM0b59e6Ns2bKGm5ubUalSJaN///7GgQMHcuzDUc7t1f4dG4ZhfP3114aXl5cRHx9/2X04ynktTDbDONcSUkRERMQJqM2NiIiIOBWFGxEREXEqCjciIiLiVBRuRERExKko3IiIiIhTUbgRERERp6JwIyIiIk5F4UZEBHMSxenTp1tdhogUAIUbEbHcgAEDsNlslzw6duxodWki4oBcrS5ARASgY8eOjB07NscyDw8Pi6oREUemKzciUix4eHgQHByc41G6dGnAvGU0cuRIOnXqhJeXF+Hh4UyaNCnH9ps3b6Zt27Z4eXkRFBTEo48+SlJSUo51xowZQ7169fDw8CAkJISnnnoqx/txcXHcfffdeHt7U6NGDWbMmFG4By0ihULhRkQcwhtvvEGPHj3YuHEj999/P71792b79u0AnDlzho4dO1K6dGnWrFnDpEmTmDdvXo7wMnLkSJ588kkeffRRNm/ezIwZM6hevXqOz3j77bfp1asXmzZtonPnzvTt25eTJ08W6XGKSAGweuZOEZH+/fsbLi4uho+PT47HO++8YxiGOVP9oEGDcmzTrFkz4/HHHzcMwzC++eYbo3Tp0kZSUlL2+zNnzjTsdrsRGxtrGIZhhIaGGq+//voVawCM//u//8t+nZSUZNhsNmP27NkFdpwiUjTU5kZEioVbb72VkSNH5lgWGBiY/bxFixY53mvRogVRUVEAbN++nYiICHx8fLLfb9WqFVlZWezcuRObzcaRI0e47bbbcq2hQYMG2c99fHzw8/Pj2LFj13pIImIRhRsRKRZ8fHwuuU10NTabDQDDMLKfX24dLy+vPO3Pzc3tkm2zsrLyVZOIWE9tbkTEIfz999+XvK5duzYAdevWJSoqiuTk5Oz3ly9fjt1up2bNmvj5+VGlShXmz59fpDWLiDV05UZEioXU1FRiY2NzLHN1daVMmTIATJo0icaNG3PTTTcxYcIEVq9ezejRowHo27cvb731Fv3792fo0KEcP36cp59+mgceeIDy5csDMHToUAYNGkS5cuXo1KkTp0+fZvny5Tz99NNFe6AiUugUbkSkWPjzzz8JCQnJsaxWrVrs2LEDMHsy/fzzzzzxxBMEBwczYcIE6tatC4C3tzdz5szhmWeeoUmTJnh7e9OjRw8+/fTT7H3179+flJQUPvvsM1544QXKlClDz549i+4ARaTI2AzDMKwuQkQkNzabjWnTptGtWzerSxERB6A2NyIiIuJUFG5ERETEqajNjYgUe7p7LiL5oSs3IiIi4lQUbkRERMSpKNyIiIiIU1G4EREREaeicCMiIiJOReFGREREnIrCjYiIiDgVhRsRERFxKgo3IiIi4lT+H8rgc0YLr/toAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = custom_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    ")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DOMINI~1\\AppData\\Local\\Temp/ipykernel_19888/2830820924.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy of {round(acc*100, 2)}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred = custom_model.predict(x_test)\n",
    "predictions = np.argmax(pred, axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), predictions)\n",
    "acc = accuracy_score(np.argmax(y_test, axis=1), predictions)\n",
    "print(f\"Accuracy of {round(acc*100, 2)}%\")\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg16_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 14s 75ms/step - loss: 2.9764 - accuracy: 0.3822 - val_loss: 0.5117 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4497 - accuracy: 0.5548 - val_loss: 0.3329 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2855 - accuracy: 0.6929 - val_loss: 0.5779 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1936 - accuracy: 0.7904 - val_loss: 0.3452 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1562 - accuracy: 0.8452 - val_loss: 0.3059 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1292 - accuracy: 0.8751 - val_loss: 0.3904 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0964 - accuracy: 0.9066 - val_loss: 0.4488 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0931 - accuracy: 0.9168 - val_loss: 0.3671 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0684 - accuracy: 0.9406 - val_loss: 0.3464 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0518 - accuracy: 0.9437 - val_loss: 0.4366 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0472 - accuracy: 0.9548 - val_loss: 0.4153 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0386 - accuracy: 0.9574 - val_loss: 0.4749 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0338 - accuracy: 0.9584 - val_loss: 0.4938 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0292 - accuracy: 0.9619 - val_loss: 0.5644 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0253 - accuracy: 0.9624 - val_loss: 0.5750 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.3173 - accuracy: 0.6846\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.685 total time=  58.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 68ms/step - loss: 2.5878 - accuracy: 0.3968 - val_loss: 0.8198 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.5344 - accuracy: 0.6758 - val_loss: 0.5224 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2640 - accuracy: 0.8341 - val_loss: 0.7305 - val_accuracy: 0.6122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1724 - accuracy: 0.8909 - val_loss: 0.7195 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0947 - accuracy: 0.9523 - val_loss: 0.6648 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0578 - accuracy: 0.9645 - val_loss: 0.6690 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0375 - accuracy: 0.9822 - val_loss: 0.7263 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.5599 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0032 - accuracy: 0.9975 - val_loss: 0.5605 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5819 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9743e-04 - accuracy: 0.9995 - val_loss: 0.5970 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9742e-04 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 0.6129 - accuracy: 0.5797\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.580 total time=  37.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 51ms/step - loss: 2.4298 - accuracy: 0.4307 - val_loss: 0.4848 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3835 - accuracy: 0.7291 - val_loss: 0.4648 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1875 - accuracy: 0.8600 - val_loss: 0.4000 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1199 - accuracy: 0.9148 - val_loss: 0.4442 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0841 - accuracy: 0.9533 - val_loss: 0.5349 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0569 - accuracy: 0.9650 - val_loss: 1.1006 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0540 - accuracy: 0.9746 - val_loss: 0.5860 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 0.7849 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.5579 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5792 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.5895 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.6020 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9985 - val_loss: 0.6410 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4566 - accuracy: 0.6843\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.684 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5774 - accuracy: 0.4853 - val_loss: 0.8557 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.3192 - accuracy: 0.8569 - val_loss: 0.4782 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0661 - accuracy: 0.9731 - val_loss: 0.5059 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.4417 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.4717 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9257e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4680e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9456e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9123e-04 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8807e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8503e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8165e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4332 - accuracy: 0.7657\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.766 total time=  40.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.7488 - accuracy: 0.4774 - val_loss: 0.6613 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3319 - accuracy: 0.8645 - val_loss: 0.5478 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.6365 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.5732 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5848 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5907 - val_accuracy: 0.7946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.5827 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4148e-04 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8363e-04 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5845e-04 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4107e-04 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5893 - accuracy: 0.7086\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.709 total time=  34.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.3638 - accuracy: 0.4957 - val_loss: 0.7382 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.4009 - accuracy: 0.8331 - val_loss: 0.5341 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1071 - accuracy: 0.9645 - val_loss: 0.5587 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0381 - accuracy: 0.9919 - val_loss: 0.5700 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0263 - accuracy: 0.9964 - val_loss: 0.5299 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0216 - accuracy: 0.9970 - val_loss: 0.5215 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.5423 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.5172 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4355e-04 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0898e-04 - accuracy: 0.9995 - val_loss: 0.5631 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3308e-04 - accuracy: 0.9995 - val_loss: 0.5319 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.2463e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4485e-04 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7284e-04 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4756e-04 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3672e-04 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2948e-04 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5845 - accuracy: 0.7411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.741 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.9415 - accuracy: 0.3832 - val_loss: 0.8438 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3802 - accuracy: 0.6518 - val_loss: 0.5365 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2643 - accuracy: 0.7660 - val_loss: 0.4064 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1598 - accuracy: 0.8528 - val_loss: 0.3616 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1097 - accuracy: 0.8964 - val_loss: 0.4235 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0721 - accuracy: 0.9381 - val_loss: 0.4723 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0562 - accuracy: 0.9624 - val_loss: 0.5237 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0438 - accuracy: 0.9701 - val_loss: 0.5103 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0280 - accuracy: 0.9812 - val_loss: 0.7329 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0126 - accuracy: 0.9883 - val_loss: 0.6460 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9944 - val_loss: 0.6566 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0029 - accuracy: 0.9944 - val_loss: 0.6780 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9954 - val_loss: 0.6878 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9964 - val_loss: 0.7060 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3995 - accuracy: 0.6237\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.624 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.8079 - accuracy: 0.3952 - val_loss: 0.6025 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4035 - accuracy: 0.6809 - val_loss: 0.4255 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2387 - accuracy: 0.8072 - val_loss: 0.4166 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1540 - accuracy: 0.8772 - val_loss: 0.4104 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0949 - accuracy: 0.9239 - val_loss: 0.4349 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0664 - accuracy: 0.9513 - val_loss: 0.4677 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0446 - accuracy: 0.9660 - val_loss: 0.6124 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0333 - accuracy: 0.9782 - val_loss: 0.6451 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0326 - accuracy: 0.9787 - val_loss: 0.5815 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0177 - accuracy: 0.9904 - val_loss: 0.5602 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0082 - accuracy: 0.9939 - val_loss: 0.5778 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0044 - accuracy: 0.9959 - val_loss: 0.6100 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 0.9970 - val_loss: 0.6239 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9970 - val_loss: 0.6656 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4273 - accuracy: 0.6721\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.672 total time=  41.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.7573 - accuracy: 0.3501 - val_loss: 0.5035 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3959 - accuracy: 0.5419 - val_loss: 0.3769 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2952 - accuracy: 0.6626 - val_loss: 0.4178 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2100 - accuracy: 0.7468 - val_loss: 0.3081 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1539 - accuracy: 0.8138 - val_loss: 0.2893 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1283 - accuracy: 0.8483 - val_loss: 0.3319 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1145 - accuracy: 0.8706 - val_loss: 0.3506 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0957 - accuracy: 0.8894 - val_loss: 0.3416 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0700 - accuracy: 0.9173 - val_loss: 0.4329 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0686 - accuracy: 0.9259 - val_loss: 0.3522 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0408 - accuracy: 0.9472 - val_loss: 0.3713 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0362 - accuracy: 0.9482 - val_loss: 0.4076 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0335 - accuracy: 0.9508 - val_loss: 0.4447 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0305 - accuracy: 0.9523 - val_loss: 0.5422 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0274 - accuracy: 0.9579 - val_loss: 0.5382 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3035 - accuracy: 0.6457\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.646 total time=  44.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.8071 - accuracy: 0.3467 - val_loss: 0.3542 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3467 - accuracy: 0.5528 - val_loss: 0.3123 - val_accuracy: 0.5865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2313 - accuracy: 0.7091 - val_loss: 0.2647 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1595 - accuracy: 0.7924 - val_loss: 0.2646 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1112 - accuracy: 0.8584 - val_loss: 0.2856 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0880 - accuracy: 0.8853 - val_loss: 0.2881 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0736 - accuracy: 0.9051 - val_loss: 0.3107 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0664 - accuracy: 0.9162 - val_loss: 0.3162 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0588 - accuracy: 0.9264 - val_loss: 0.3092 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0544 - accuracy: 0.9355 - val_loss: 0.3249 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0451 - accuracy: 0.9360 - val_loss: 0.3179 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0407 - accuracy: 0.9386 - val_loss: 0.3142 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0387 - accuracy: 0.9381 - val_loss: 0.3172 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0372 - accuracy: 0.9396 - val_loss: 0.3282 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2502 - accuracy: 0.6765\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.676 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0989 - accuracy: 0.3780 - val_loss: 0.3581 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2954 - accuracy: 0.6129 - val_loss: 0.3045 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1693 - accuracy: 0.7905 - val_loss: 0.3208 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0947 - accuracy: 0.8889 - val_loss: 0.3730 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0519 - accuracy: 0.9442 - val_loss: 0.3629 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9619 - val_loss: 0.3680 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9782 - val_loss: 0.3883 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0124 - accuracy: 0.9853 - val_loss: 0.3839 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9888 - val_loss: 0.3868 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0071 - accuracy: 0.9893 - val_loss: 0.3902 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0064 - accuracy: 0.9899 - val_loss: 0.3911 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0059 - accuracy: 0.9899 - val_loss: 0.3929 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3208 - accuracy: 0.5431\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.543 total time=  35.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4157 - accuracy: 0.4668 - val_loss: 0.5074 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1836 - accuracy: 0.8909 - val_loss: 0.3936 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0496 - accuracy: 0.9751 - val_loss: 0.4007 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0226 - accuracy: 0.9954 - val_loss: 0.4099 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.4481 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.9179e-04 - accuracy: 0.9995 - val_loss: 0.4003 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8791e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7264e-04 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6259e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5398e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4602e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4446 - accuracy: 0.7025\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.703 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 4.3191 - accuracy: 0.4284 - val_loss: 0.8100 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.6271 - accuracy: 0.7919 - val_loss: 0.8744 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3110 - accuracy: 0.9015 - val_loss: 0.8591 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1692 - accuracy: 0.9523 - val_loss: 0.8375 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1318 - accuracy: 0.9624 - val_loss: 1.9288 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1187 - accuracy: 0.9731 - val_loss: 1.0603 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0259 - accuracy: 0.9959 - val_loss: 0.9591 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.9719 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6421e-04 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9837e-04 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5081e-06 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.8971 - accuracy: 0.6450\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.645 total time=  33.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.4745 - accuracy: 0.4049 - val_loss: 1.3793 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.8121 - accuracy: 0.7113 - val_loss: 1.0284 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4534 - accuracy: 0.8366 - val_loss: 0.9269 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2035 - accuracy: 0.9234 - val_loss: 0.8512 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1744 - accuracy: 0.9417 - val_loss: 0.8444 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1133 - accuracy: 0.9711 - val_loss: 0.8286 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0791 - accuracy: 0.9822 - val_loss: 0.8968 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0620 - accuracy: 0.9843 - val_loss: 0.9936 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0553 - accuracy: 0.9909 - val_loss: 1.9342 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0629 - accuracy: 0.9858 - val_loss: 1.0482 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0319 - accuracy: 0.9949 - val_loss: 0.9946 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.9324 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.7618e-04 - accuracy: 0.9995 - val_loss: 0.9467 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.4473e-05 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2460e-06 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.1850e-06 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.8442 - accuracy: 0.7360\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.736 total time=  47.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.2237 - accuracy: 0.4373 - val_loss: 1.5213 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.6576 - accuracy: 0.7681 - val_loss: 1.1140 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2741 - accuracy: 0.9066 - val_loss: 1.2661 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1181 - accuracy: 0.9635 - val_loss: 1.0295 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1013 - accuracy: 0.9650 - val_loss: 0.9808 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0817 - accuracy: 0.9762 - val_loss: 0.8042 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0712 - accuracy: 0.9817 - val_loss: 0.9494 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 1.4364 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 1.6223 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9934 - val_loss: 1.3025 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 1.2481 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 1.0257 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.0534 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 1.0193 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.3936e-07 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4704e-07 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.9133 - accuracy: 0.7218\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.722 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3314 - accuracy: 0.5036 - val_loss: 0.8731 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3286 - accuracy: 0.9066 - val_loss: 0.7664 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0929 - accuracy: 0.9746 - val_loss: 0.8198 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 0.7577 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0155 - accuracy: 0.9990 - val_loss: 0.8244 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.8822 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.8568 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.8463 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8407 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7661e-05 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.2706e-05 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9895e-05 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7626 - accuracy: 0.7556\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.756 total time=  40.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.1270 - accuracy: 0.5099 - val_loss: 0.7594 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.3132 - accuracy: 0.9097 - val_loss: 0.8286 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0789 - accuracy: 0.9792 - val_loss: 0.7503 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0330 - accuracy: 0.9954 - val_loss: 0.7169 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.8355 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7224e-04 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.0825e-05 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.0329e-05 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9692e-05 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9033e-05 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8325e-05 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7672e-05 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7601 - accuracy: 0.7503\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.750 total time=  40.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 47ms/step - loss: 1.6035 - accuracy: 0.4683 - val_loss: 0.5344 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2926 - accuracy: 0.8767 - val_loss: 0.4614 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0916 - accuracy: 0.9685 - val_loss: 0.5033 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.4455 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.5226 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.4847 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4888 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4822 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4050e-04 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3560e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3190e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2865e-04 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2555e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4869 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.742 total time=  40.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.3014 - accuracy: 0.4147 - val_loss: 0.5475 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3627 - accuracy: 0.7574 - val_loss: 0.5873 - val_accuracy: 0.6135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2082 - accuracy: 0.8619 - val_loss: 0.4879 - val_accuracy: 0.6378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1010 - accuracy: 0.9340 - val_loss: 0.4811 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0707 - accuracy: 0.9533 - val_loss: 0.5820 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0526 - accuracy: 0.9721 - val_loss: 0.5019 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.7488 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.8146 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.8538 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 0.7247 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7704e-04 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.4745e-05 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7776e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4692 - accuracy: 0.7343\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.734 total time=  41.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.6217 - accuracy: 0.4216 - val_loss: 0.4631 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4084 - accuracy: 0.6535 - val_loss: 0.4124 - val_accuracy: 0.5486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2396 - accuracy: 0.7768 - val_loss: 0.3099 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1770 - accuracy: 0.8610 - val_loss: 0.5126 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1098 - accuracy: 0.9132 - val_loss: 0.4009 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0824 - accuracy: 0.9366 - val_loss: 0.3433 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0632 - accuracy: 0.9548 - val_loss: 0.4994 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0520 - accuracy: 0.9660 - val_loss: 0.5899 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0314 - accuracy: 0.9807 - val_loss: 0.5142 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0146 - accuracy: 0.9883 - val_loss: 0.5041 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9909 - val_loss: 0.5304 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9909 - val_loss: 0.5762 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0045 - accuracy: 0.9929 - val_loss: 0.6177 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3568 - accuracy: 0.6721\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.672 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.1392 - accuracy: 0.4282 - val_loss: 0.5408 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4031 - accuracy: 0.7159 - val_loss: 0.4347 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2579 - accuracy: 0.8234 - val_loss: 0.4055 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1501 - accuracy: 0.8970 - val_loss: 0.6148 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0992 - accuracy: 0.9417 - val_loss: 0.6491 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0927 - accuracy: 0.9493 - val_loss: 0.6719 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0528 - accuracy: 0.9726 - val_loss: 0.6957 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.9950 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0258 - accuracy: 0.9878 - val_loss: 0.6253 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0058 - accuracy: 0.9954 - val_loss: 0.6423 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.6530 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.6665 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.7002 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4837 - accuracy: 0.6335\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.634 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.7938 - accuracy: 0.5254 - val_loss: 0.7419 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1817 - accuracy: 0.9218 - val_loss: 0.6011 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.6295 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.6399 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.5780 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6051 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9833e-04 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0328e-04 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.5242e-05 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3100e-05 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4850e-05 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.8841e-05 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.4032e-05 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.0384e-05 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.0002e-05 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9650e-05 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.9235e-05 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.8869e-05 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5308 - accuracy: 0.7647\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.765 total time=  51.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 47ms/step - loss: 1.5541 - accuracy: 0.5028 - val_loss: 0.5422 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2079 - accuracy: 0.8914 - val_loss: 0.4999 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 0.4394 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.4424 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.4732 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.9329e-04 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7995e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8401e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7941e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7519e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7102e-04 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6666e-04 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5123 - accuracy: 0.7046\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.705 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.6050 - accuracy: 0.5373 - val_loss: 0.6132 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2344 - accuracy: 0.8955 - val_loss: 0.5443 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0655 - accuracy: 0.9706 - val_loss: 0.5879 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.5479 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.5383 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5445 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4451e-04 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2720e-04 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.2024e-04 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5095e-04 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.5027e-05 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.3483e-05 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.7922e-05 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4725e-05 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4371e-05 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.4035e-05 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3696e-05 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3348e-05 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.6309 - accuracy: 0.7543\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.754 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5912 - accuracy: 0.3716 - val_loss: 0.3416 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1771 - accuracy: 0.7761 - val_loss: 0.2943 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0677 - accuracy: 0.9305 - val_loss: 0.3486 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0243 - accuracy: 0.9817 - val_loss: 0.3904 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9959 - val_loss: 0.3921 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.3889 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.4744 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9460e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7860e-05 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0998e-06 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6614e-06 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1512e-07 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2962 - accuracy: 0.6217\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.622 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6312 - accuracy: 0.3927 - val_loss: 0.3693 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1929 - accuracy: 0.7504 - val_loss: 0.3237 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0846 - accuracy: 0.9137 - val_loss: 0.2868 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0352 - accuracy: 0.9716 - val_loss: 0.3480 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0178 - accuracy: 0.9883 - val_loss: 0.4371 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0091 - accuracy: 0.9954 - val_loss: 0.4133 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.4967 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.4637 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8650e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.1763e-05 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1903e-06 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4425e-06 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7591e-07 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2843 - accuracy: 0.6650\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.665 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5323 - accuracy: 0.3516 - val_loss: 0.3557 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2047 - accuracy: 0.7250 - val_loss: 0.3548 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0985 - accuracy: 0.8858 - val_loss: 0.3073 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0431 - accuracy: 0.9523 - val_loss: 0.2941 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0219 - accuracy: 0.9802 - val_loss: 0.3187 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0142 - accuracy: 0.9883 - val_loss: 0.3957 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0079 - accuracy: 0.9954 - val_loss: 0.4646 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0048 - accuracy: 0.9964 - val_loss: 0.4364 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.5391 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.5527e-04 - accuracy: 0.9990 - val_loss: 0.4774 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.3637e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.6820e-05 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6298e-05 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5391e-05 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3488 - accuracy: 0.6548\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.655 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.5326 - accuracy: 0.3579 - val_loss: 0.3255 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1938 - accuracy: 0.7371 - val_loss: 0.2784 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0889 - accuracy: 0.9036 - val_loss: 0.2742 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0373 - accuracy: 0.9716 - val_loss: 0.2855 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0161 - accuracy: 0.9914 - val_loss: 0.3221 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.3278 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3497 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9578e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5323e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.1728e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8457e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.5358e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2559 - accuracy: 0.6613\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.661 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6012 - accuracy: 0.3450 - val_loss: 0.3221 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2006 - accuracy: 0.7250 - val_loss: 0.2623 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0991 - accuracy: 0.8914 - val_loss: 0.2438 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0416 - accuracy: 0.9630 - val_loss: 0.2638 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0177 - accuracy: 0.9899 - val_loss: 0.2965 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.2974 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3313 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1973e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5494e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.0671e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.6517e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2612 - accuracy: 0.6579\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.658 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5693 - accuracy: 0.3577 - val_loss: 0.3279 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1987 - accuracy: 0.7265 - val_loss: 0.2862 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0857 - accuracy: 0.9016 - val_loss: 0.2682 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0380 - accuracy: 0.9685 - val_loss: 0.2898 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.3238 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.3327 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.3499 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3848 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3717 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3702 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3709 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2842 - accuracy: 0.6335\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.634 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6683 - accuracy: 0.3096 - val_loss: 0.3866 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2645 - accuracy: 0.6056 - val_loss: 0.3254 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1474 - accuracy: 0.8117 - val_loss: 0.3328 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0665 - accuracy: 0.9239 - val_loss: 0.3339 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0435 - accuracy: 0.9523 - val_loss: 0.4170 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0279 - accuracy: 0.9736 - val_loss: 0.4397 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0139 - accuracy: 0.9893 - val_loss: 0.5214 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0055 - accuracy: 0.9954 - val_loss: 0.4590 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 0.4802 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.4898 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 0.5144 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 6.8460e-04 - accuracy: 0.9990 - val_loss: 0.5466 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3116 - accuracy: 0.5801\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.580 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 54ms/step - loss: 0.7332 - accuracy: 0.3364 - val_loss: 0.4104 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2372 - accuracy: 0.6733 - val_loss: 0.2966 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1224 - accuracy: 0.8468 - val_loss: 0.3099 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0558 - accuracy: 0.9457 - val_loss: 0.4156 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0265 - accuracy: 0.9807 - val_loss: 0.3638 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0161 - accuracy: 0.9873 - val_loss: 0.3963 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0069 - accuracy: 0.9954 - val_loss: 0.4815 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4366 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5532e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.3832e-05 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7706e-06 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.9172e-06 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3276 - accuracy: 0.5635\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.563 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6519 - accuracy: 0.3374 - val_loss: 0.3776 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2560 - accuracy: 0.6464 - val_loss: 0.3319 - val_accuracy: 0.5365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1473 - accuracy: 0.8270 - val_loss: 0.3130 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0778 - accuracy: 0.9183 - val_loss: 0.3757 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0510 - accuracy: 0.9503 - val_loss: 0.4451 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0287 - accuracy: 0.9751 - val_loss: 0.3980 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0158 - accuracy: 0.9904 - val_loss: 0.5616 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0125 - accuracy: 0.9924 - val_loss: 0.4255 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 0.4103 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.4271 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6002e-04 - accuracy: 0.9990 - val_loss: 0.4594 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.9836e-04 - accuracy: 0.9995 - val_loss: 0.4930 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.3894e-04 - accuracy: 0.9995 - val_loss: 0.5223 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3413 - accuracy: 0.5939\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.594 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6824 - accuracy: 0.3142 - val_loss: 0.3622 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2508 - accuracy: 0.6162 - val_loss: 0.3189 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1335 - accuracy: 0.8294 - val_loss: 0.2935 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0656 - accuracy: 0.9315 - val_loss: 0.3124 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0357 - accuracy: 0.9614 - val_loss: 0.3335 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0200 - accuracy: 0.9802 - val_loss: 0.3666 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0117 - accuracy: 0.9909 - val_loss: 0.3913 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9929 - val_loss: 0.3927 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.3891 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.3923 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3960 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3990 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4013 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2982 - accuracy: 0.6187\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.619 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7074 - accuracy: 0.3394 - val_loss: 0.3600 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2362 - accuracy: 0.6479 - val_loss: 0.3371 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1338 - accuracy: 0.8229 - val_loss: 0.2947 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0680 - accuracy: 0.9305 - val_loss: 0.3090 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0355 - accuracy: 0.9630 - val_loss: 0.3045 - val_accuracy: 0.6243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0198 - accuracy: 0.9817 - val_loss: 0.3188 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0115 - accuracy: 0.9909 - val_loss: 0.3315 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0085 - accuracy: 0.9934 - val_loss: 0.3531 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0051 - accuracy: 0.9970 - val_loss: 0.3542 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.3554 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.3564 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3570 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.3585 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3122 - accuracy: 0.5949\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.595 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6408 - accuracy: 0.3222 - val_loss: 0.3530 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2556 - accuracy: 0.6251 - val_loss: 0.3054 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1550 - accuracy: 0.7854 - val_loss: 0.2876 - val_accuracy: 0.6189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0869 - accuracy: 0.8914 - val_loss: 0.3059 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0440 - accuracy: 0.9482 - val_loss: 0.3046 - val_accuracy: 0.6473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0312 - accuracy: 0.9655 - val_loss: 0.3114 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9777 - val_loss: 0.3105 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0171 - accuracy: 0.9827 - val_loss: 0.3488 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0130 - accuracy: 0.9868 - val_loss: 0.3368 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0096 - accuracy: 0.9883 - val_loss: 0.3376 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0084 - accuracy: 0.9893 - val_loss: 0.3396 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0076 - accuracy: 0.9904 - val_loss: 0.3416 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0071 - accuracy: 0.9909 - val_loss: 0.3414 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3327 - accuracy: 0.5411\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.541 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 54ms/step - loss: 0.7084 - accuracy: 0.3518 - val_loss: 0.3114 - val_accuracy: 0.5257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2052 - accuracy: 0.7152 - val_loss: 0.2650 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0905 - accuracy: 0.9122 - val_loss: 0.3544 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0390 - accuracy: 0.9695 - val_loss: 0.3904 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0182 - accuracy: 0.9893 - val_loss: 0.4623 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0102 - accuracy: 0.9934 - val_loss: 0.3642 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.4338 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.3821 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.3333e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.8591e-05 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.6077e-05 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 7.8291e-06 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2647 - accuracy: 0.6471\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.647 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7172 - accuracy: 0.4069 - val_loss: 0.3548 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1656 - accuracy: 0.8001 - val_loss: 0.2760 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0630 - accuracy: 0.9452 - val_loss: 0.2662 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0245 - accuracy: 0.9812 - val_loss: 0.4628 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0126 - accuracy: 0.9939 - val_loss: 0.4842 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.3809 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0167 - accuracy: 0.9934 - val_loss: 0.3935 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.5614 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4357 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6396e-05 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7819e-06 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5248e-07 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5985e-07 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2886 - accuracy: 0.6751\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.675 total time=  38.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7241 - accuracy: 0.3643 - val_loss: 0.3518 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2127 - accuracy: 0.7199 - val_loss: 0.2976 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1018 - accuracy: 0.8869 - val_loss: 0.3001 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0519 - accuracy: 0.9493 - val_loss: 0.3106 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0224 - accuracy: 0.9848 - val_loss: 0.3262 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0162 - accuracy: 0.9878 - val_loss: 0.4273 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.4012 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.3807 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3939 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6560e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4205e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6750e-05 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3226 - accuracy: 0.5766\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.577 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.7412 - accuracy: 0.3797 - val_loss: 0.3559 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1505 - accuracy: 0.8381 - val_loss: 0.3079 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0501 - accuracy: 0.9655 - val_loss: 0.3078 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.3152 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.3337 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3457 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.7027 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3029 - accuracy: 0.6785\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.678 total time=  37.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6376 - accuracy: 0.3998 - val_loss: 0.3138 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1378 - accuracy: 0.8554 - val_loss: 0.2639 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0430 - accuracy: 0.9736 - val_loss: 0.2681 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.2784 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.3009 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3072 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9439e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.6574e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.3943e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1420e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8878e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2817 - accuracy: 0.6386\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.639 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 52ms/step - loss: 0.6818 - accuracy: 0.3475 - val_loss: 0.3599 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1839 - accuracy: 0.7712 - val_loss: 0.2959 - val_accuracy: 0.6068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0776 - accuracy: 0.9325 - val_loss: 0.2925 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0289 - accuracy: 0.9822 - val_loss: 0.3168 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.3353 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0078 - accuracy: 0.9959 - val_loss: 0.3492 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3907 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0278e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4522e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0453e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.6833e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2871 - accuracy: 0.6660\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.666 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9095 - accuracy: 0.3518 - val_loss: 0.4124 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2188 - accuracy: 0.7447 - val_loss: 0.3505 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0983 - accuracy: 0.9046 - val_loss: 0.4379 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0435 - accuracy: 0.9716 - val_loss: 0.3952 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0193 - accuracy: 0.9883 - val_loss: 0.5144 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9893 - val_loss: 0.5076 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.5113 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.4887 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2058e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1825e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7225e-06 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0365e-07 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3290 - accuracy: 0.6308\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.631 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0583 - accuracy: 0.3607 - val_loss: 0.4124 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2048 - accuracy: 0.7768 - val_loss: 0.3421 - val_accuracy: 0.6135 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0800 - accuracy: 0.9330 - val_loss: 0.3723 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9741 - val_loss: 0.4555 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0238 - accuracy: 0.9858 - val_loss: 0.4508 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0183 - accuracy: 0.9904 - val_loss: 0.5046 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 0.5442 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.1153e-05 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.2601e-06 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7223e-07 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5719e-07 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3738 - accuracy: 0.5716\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.572 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9266 - accuracy: 0.3861 - val_loss: 0.4015 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1950 - accuracy: 0.7859 - val_loss: 0.4266 - val_accuracy: 0.5581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0761 - accuracy: 0.9274 - val_loss: 0.3961 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0367 - accuracy: 0.9741 - val_loss: 0.5998 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0184 - accuracy: 0.9878 - val_loss: 0.4880 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.4889 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.6072 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.6484 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 0.6029 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6197e-05 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7855e-06 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7762e-07 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4809e-07 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4173 - accuracy: 0.6467\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.647 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.9842 - accuracy: 0.3777 - val_loss: 0.4202 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1508 - accuracy: 0.8447 - val_loss: 0.3642 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0395 - accuracy: 0.9802 - val_loss: 0.3573 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.3834 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.8015e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.3814e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.2348e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.0889e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.9404e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7929e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3289 - accuracy: 0.6592\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.659 total time=  37.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 52ms/step - loss: 0.9614 - accuracy: 0.3978 - val_loss: 0.3904 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1534 - accuracy: 0.8407 - val_loss: 0.3514 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0419 - accuracy: 0.9721 - val_loss: 0.3591 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.3666 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.3856 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3872 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.4226 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7197e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0095e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4223e-04 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9907e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.6676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3637 - accuracy: 0.5909\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.591 total time=  34.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.8920 - accuracy: 0.4145 - val_loss: 0.3927 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1513 - accuracy: 0.8214 - val_loss: 0.3408 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0506 - accuracy: 0.9599 - val_loss: 0.3463 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0191 - accuracy: 0.9914 - val_loss: 0.3543 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.3613 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.3841 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4011 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.6730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.6743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9120e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.4355e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0646e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3728 - accuracy: 0.5716\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.572 total time=  34.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.3606 - accuracy: 0.3964 - val_loss: 0.7621 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4326 - accuracy: 0.6355 - val_loss: 0.4979 - val_accuracy: 0.5162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2675 - accuracy: 0.7624 - val_loss: 0.5832 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1858 - accuracy: 0.8508 - val_loss: 0.4869 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1214 - accuracy: 0.8832 - val_loss: 0.5020 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0681 - accuracy: 0.9365 - val_loss: 0.4249 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0566 - accuracy: 0.9574 - val_loss: 0.4387 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0439 - accuracy: 0.9685 - val_loss: 0.5492 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0226 - accuracy: 0.9838 - val_loss: 0.7640 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0233 - accuracy: 0.9853 - val_loss: 0.5360 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0232 - accuracy: 0.9822 - val_loss: 0.5354 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0130 - accuracy: 0.9929 - val_loss: 0.5256 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0079 - accuracy: 0.9934 - val_loss: 0.5246 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0056 - accuracy: 0.9944 - val_loss: 0.5460 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0045 - accuracy: 0.9949 - val_loss: 0.5361 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0040 - accuracy: 0.9949 - val_loss: 0.5559 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4636 - accuracy: 0.6744\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.674 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.0109 - accuracy: 0.4064 - val_loss: 0.9763 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4996 - accuracy: 0.6073 - val_loss: 0.4529 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2810 - accuracy: 0.7311 - val_loss: 0.3326 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1909 - accuracy: 0.8311 - val_loss: 0.3696 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1445 - accuracy: 0.8762 - val_loss: 0.5561 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0874 - accuracy: 0.9254 - val_loss: 0.4749 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0678 - accuracy: 0.9437 - val_loss: 0.5432 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0597 - accuracy: 0.9564 - val_loss: 0.4547 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0207 - accuracy: 0.9812 - val_loss: 0.4658 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0100 - accuracy: 0.9888 - val_loss: 0.4910 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0065 - accuracy: 0.9934 - val_loss: 0.5232 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0047 - accuracy: 0.9959 - val_loss: 0.5298 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0032 - accuracy: 0.9970 - val_loss: 0.5592 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3592 - accuracy: 0.6122\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.612 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.5093 - accuracy: 0.4059 - val_loss: 0.7780 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.5607 - accuracy: 0.7818 - val_loss: 0.6152 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2558 - accuracy: 0.9011 - val_loss: 0.7826 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1633 - accuracy: 0.9432 - val_loss: 0.7398 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1035 - accuracy: 0.9650 - val_loss: 1.1284 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1038 - accuracy: 0.9726 - val_loss: 1.1328 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0471 - accuracy: 0.9873 - val_loss: 1.1764 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.8881 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.8498 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7698e-05 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.7191e-06 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.6676 - accuracy: 0.7056\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.706 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 1.4504 - accuracy: 0.4645 - val_loss: 0.6451 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4010 - accuracy: 0.8076 - val_loss: 0.5035 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0933 - accuracy: 0.9609 - val_loss: 0.5679 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 0.5312 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.4796 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4614 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7283e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.8892e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.0893e-04 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.3969e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.9231e-04 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6126e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5755e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5407e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.5080e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.4716e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4471 - accuracy: 0.7404\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.740 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4482 - accuracy: 0.4434 - val_loss: 0.6995 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3714 - accuracy: 0.8174 - val_loss: 0.6022 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1285 - accuracy: 0.9366 - val_loss: 0.5659 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.5742 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.5279 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.6238 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.5949 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.5207 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5765 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5779 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5614 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6031 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4801e-04 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8969e-04 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7559e-04 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6716e-04 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5578 - accuracy: 0.7178\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.718 total time=  51.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.3481 - accuracy: 0.4505 - val_loss: 0.5155 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2743 - accuracy: 0.8143 - val_loss: 0.4301 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1158 - accuracy: 0.9422 - val_loss: 0.4237 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 0.4210 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.4455 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0091 - accuracy: 0.9959 - val_loss: 0.4337 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.4384 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4518 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.2821e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.2173e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.0237e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8490e-04 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6827e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4745 - accuracy: 0.7076\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.708 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5052 - accuracy: 0.3122 - val_loss: 0.4494 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4185 - accuracy: 0.4249 - val_loss: 0.4501 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3595 - accuracy: 0.5335 - val_loss: 0.3524 - val_accuracy: 0.5473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2525 - accuracy: 0.6675 - val_loss: 0.3468 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2028 - accuracy: 0.7421 - val_loss: 0.3482 - val_accuracy: 0.5554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1616 - accuracy: 0.7995 - val_loss: 0.2875 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1327 - accuracy: 0.8325 - val_loss: 0.4784 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1074 - accuracy: 0.8761 - val_loss: 0.3416 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0870 - accuracy: 0.8853 - val_loss: 0.3706 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0860 - accuracy: 0.9005 - val_loss: 0.4029 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0682 - accuracy: 0.9198 - val_loss: 0.6047 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0645 - accuracy: 0.9234 - val_loss: 0.3692 - val_accuracy: 0.7081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0467 - accuracy: 0.9355 - val_loss: 0.3909 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0413 - accuracy: 0.9376 - val_loss: 0.4571 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0352 - accuracy: 0.9365 - val_loss: 0.4879 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0306 - accuracy: 0.9426 - val_loss: 0.5505 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2763 - accuracy: 0.6663\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.666 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.9465 - accuracy: 0.3430 - val_loss: 0.4564 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3568 - accuracy: 0.5074 - val_loss: 0.3572 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2782 - accuracy: 0.6454 - val_loss: 0.2717 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2073 - accuracy: 0.7336 - val_loss: 0.3609 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1656 - accuracy: 0.7986 - val_loss: 0.3851 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1260 - accuracy: 0.8473 - val_loss: 0.3436 - val_accuracy: 0.6378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1063 - accuracy: 0.8727 - val_loss: 0.3055 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0881 - accuracy: 0.8990 - val_loss: 0.3155 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0574 - accuracy: 0.9214 - val_loss: 0.3610 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0454 - accuracy: 0.9300 - val_loss: 0.4199 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0391 - accuracy: 0.9351 - val_loss: 0.4047 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0325 - accuracy: 0.9452 - val_loss: 0.4344 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0304 - accuracy: 0.9482 - val_loss: 0.4481 - val_accuracy: 0.7027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3132 - accuracy: 0.5909\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.591 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.1287 - accuracy: 0.3866 - val_loss: 0.5558 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3793 - accuracy: 0.6601 - val_loss: 0.3378 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2138 - accuracy: 0.7910 - val_loss: 0.3458 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1474 - accuracy: 0.8625 - val_loss: 0.3531 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0901 - accuracy: 0.9209 - val_loss: 0.4949 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0638 - accuracy: 0.9447 - val_loss: 0.5572 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0444 - accuracy: 0.9609 - val_loss: 0.4555 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0224 - accuracy: 0.9782 - val_loss: 0.4478 - val_accuracy: 0.7189 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0143 - accuracy: 0.9822 - val_loss: 0.4630 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0095 - accuracy: 0.9863 - val_loss: 0.4779 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0066 - accuracy: 0.9883 - val_loss: 0.5347 - val_accuracy: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0051 - accuracy: 0.9909 - val_loss: 0.5701 - val_accuracy: 0.7324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3359 - accuracy: 0.5645\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.564 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.0020 - accuracy: 0.3995 - val_loss: 0.3197 - val_accuracy: 0.5473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2606 - accuracy: 0.7259 - val_loss: 0.3558 - val_accuracy: 0.5905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1323 - accuracy: 0.8802 - val_loss: 0.3092 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0552 - accuracy: 0.9645 - val_loss: 0.2853 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0250 - accuracy: 0.9878 - val_loss: 0.3223 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0116 - accuracy: 0.9939 - val_loss: 0.3164 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0101 - accuracy: 0.9939 - val_loss: 0.3272 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.3621 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.3431 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.3342 - val_accuracy: 0.7365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.3373 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.3418 - val_accuracy: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3443 - val_accuracy: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3448 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3124 - accuracy: 0.7099\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.710 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9641 - accuracy: 0.3856 - val_loss: 0.4213 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3060 - accuracy: 0.6890 - val_loss: 0.3506 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1588 - accuracy: 0.8493 - val_loss: 0.3356 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0587 - accuracy: 0.9472 - val_loss: 0.3197 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0347 - accuracy: 0.9685 - val_loss: 0.3346 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0177 - accuracy: 0.9893 - val_loss: 0.3523 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 0.3532 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.3454 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3653 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.3632 - val_accuracy: 0.7216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7673e-04 - accuracy: 0.9990 - val_loss: 0.3621 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0093e-04 - accuracy: 0.9990 - val_loss: 0.3617 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4074e-04 - accuracy: 0.9995 - val_loss: 0.3616 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9194e-04 - accuracy: 0.9995 - val_loss: 0.3621 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3329 - accuracy: 0.7005\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.701 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4795 - accuracy: 0.3912 - val_loss: 0.3625 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2608 - accuracy: 0.6717 - val_loss: 0.3114 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1492 - accuracy: 0.8031 - val_loss: 0.3307 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1003 - accuracy: 0.8874 - val_loss: 0.3462 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0662 - accuracy: 0.9274 - val_loss: 0.3240 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0444 - accuracy: 0.9589 - val_loss: 0.4600 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0346 - accuracy: 0.9721 - val_loss: 0.3497 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0205 - accuracy: 0.9792 - val_loss: 0.3672 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0169 - accuracy: 0.9822 - val_loss: 0.3796 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0147 - accuracy: 0.9843 - val_loss: 0.3869 - val_accuracy: 0.6824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0132 - accuracy: 0.9853 - val_loss: 0.3895 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9858 - val_loss: 0.3969 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2910 - accuracy: 0.6020\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.602 total time=  34.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 5.2696 - accuracy: 0.4294 - val_loss: 1.3597 - val_accuracy: 0.5554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.6548 - accuracy: 0.7650 - val_loss: 2.7674 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3201 - accuracy: 0.8782 - val_loss: 1.0405 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1591 - accuracy: 0.9411 - val_loss: 0.7267 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1205 - accuracy: 0.9650 - val_loss: 0.9011 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0740 - accuracy: 0.9858 - val_loss: 1.4502 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0723 - accuracy: 0.9807 - val_loss: 1.0621 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 1.3614 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0500 - accuracy: 0.9888 - val_loss: 1.1804 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.0501 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.2255e-04 - accuracy: 1.0000 - val_loss: 1.0354 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.6372e-07 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.8444e-07 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7176 - accuracy: 0.7546\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.755 total time=  41.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 3.3374 - accuracy: 0.4191 - val_loss: 0.8681 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.5299 - accuracy: 0.7565 - val_loss: 1.2700 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2641 - accuracy: 0.8818 - val_loss: 0.5009 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.6778 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0796 - accuracy: 0.9741 - val_loss: 0.5546 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0514 - accuracy: 0.9822 - val_loss: 0.7771 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 0.7361 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.6786 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.4906e-05 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1384e-06 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2814e-06 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.5976e-07 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.6275 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.689 total time=  38.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 6.1707 - accuracy: 0.4125 - val_loss: 1.9703 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0031 - accuracy: 0.7965 - val_loss: 1.3268 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.4322 - accuracy: 0.9092 - val_loss: 1.9202 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2761 - accuracy: 0.9482 - val_loss: 1.4354 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1750 - accuracy: 0.9625 - val_loss: 1.3822 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0952 - accuracy: 0.9792 - val_loss: 1.8461 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1373 - accuracy: 0.9756 - val_loss: 1.3084 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0630 - accuracy: 0.9878 - val_loss: 2.2918 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0580 - accuracy: 0.9904 - val_loss: 2.0443 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0571 - accuracy: 0.9924 - val_loss: 1.5984 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0360 - accuracy: 0.9954 - val_loss: 1.6251 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0555 - accuracy: 0.9939 - val_loss: 2.1397 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0156 - accuracy: 0.9985 - val_loss: 1.7015 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.8141e-04 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9331e-07 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6318e-08 - accuracy: 1.0000 - val_loss: 1.7184 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.2388e-09 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 1.4827 - accuracy: 0.7381\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.738 total time=  49.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.0718 - accuracy: 0.5122 - val_loss: 1.0350 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.3937 - accuracy: 0.8954 - val_loss: 0.9327 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1491 - accuracy: 0.9604 - val_loss: 0.9364 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0434 - accuracy: 0.9924 - val_loss: 0.9049 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 0.9572 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 0.8963 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.9095 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.9360 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 3.0391e-04 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7267e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.8490e-05 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6405e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6230e-05 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.6035e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5851e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5657e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7747 - accuracy: 0.7809\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.781 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.0733 - accuracy: 0.4769 - val_loss: 0.5660 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2889 - accuracy: 0.8640 - val_loss: 0.5230 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0677 - accuracy: 0.9726 - val_loss: 0.5576 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.4345 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.5094 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.2793e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.6701e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.7543e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4469e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2753e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2422e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2080e-04 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4978 - accuracy: 0.7553\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.755 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.9529 - accuracy: 0.4911 - val_loss: 0.6724 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2955 - accuracy: 0.8904 - val_loss: 0.6454 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 0.7928 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0415 - accuracy: 0.9914 - val_loss: 0.7201 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.6753 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.6703 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.1029e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5715e-04 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4520e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3630e-04 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2909e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.7208 - accuracy: 0.7107\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.711 total time=  35.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 49ms/step - loss: 2.9259 - accuracy: 0.4259 - val_loss: 0.7399 - val_accuracy: 0.5689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4302 - accuracy: 0.7670 - val_loss: 0.4609 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2391 - accuracy: 0.8746 - val_loss: 0.6332 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1357 - accuracy: 0.9355 - val_loss: 0.6232 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0801 - accuracy: 0.9655 - val_loss: 0.5527 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0660 - accuracy: 0.9751 - val_loss: 0.6990 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0346 - accuracy: 0.9873 - val_loss: 0.7668 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.6653 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6784 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4144e-04 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2592e-06 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.9260e-06 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4602 - accuracy: 0.7160\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.716 total time=  35.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.7922 - accuracy: 0.4485 - val_loss: 1.1641 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.4928 - accuracy: 0.7489 - val_loss: 0.7773 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2524 - accuracy: 0.8681 - val_loss: 0.6769 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1721 - accuracy: 0.9295 - val_loss: 0.6905 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1114 - accuracy: 0.9599 - val_loss: 0.8537 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0692 - accuracy: 0.9736 - val_loss: 0.8196 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0740 - accuracy: 0.9777 - val_loss: 1.0786 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.9423 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.7771 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3622e-04 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.8313e-06 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 8.4814e-07 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.6363e-07 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.7061 - accuracy: 0.6690\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.669 total time=  39.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.5986 - accuracy: 0.4536 - val_loss: 0.6191 - val_accuracy: 0.5716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3882 - accuracy: 0.7834 - val_loss: 0.4836 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2042 - accuracy: 0.8884 - val_loss: 0.6293 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1367 - accuracy: 0.9406 - val_loss: 0.7444 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0495 - accuracy: 0.9787 - val_loss: 0.5008 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0727 - accuracy: 0.9751 - val_loss: 0.7291 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0298 - accuracy: 0.9873 - val_loss: 0.7552 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 0.7028 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.7079 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3254e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.1207e-06 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.3141e-06 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.4762 - accuracy: 0.6995\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.699 total time=  36.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.8483 - accuracy: 0.5173 - val_loss: 0.7233 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2712 - accuracy: 0.8761 - val_loss: 0.7202 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0863 - accuracy: 0.9766 - val_loss: 0.6360 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.6663 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.6484 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5897 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.6294 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.7286 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.7185 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.6483 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.8083e-05 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.4221e-05 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.7651e-05 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.2951e-05 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5701 - accuracy: 0.7647\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.765 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.2567 - accuracy: 0.5008 - val_loss: 0.4984 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2645 - accuracy: 0.8782 - val_loss: 0.4442 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0946 - accuracy: 0.9645 - val_loss: 0.5158 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0263 - accuracy: 0.9888 - val_loss: 0.4422 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.5142 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.8179e-04 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.2621e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0482e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0318e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.0133e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.9641e-05 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.7853e-05 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4937 - accuracy: 0.7289\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.729 total time=  40.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 2.2978 - accuracy: 0.4850 - val_loss: 0.6831 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2528 - accuracy: 0.8894 - val_loss: 0.5879 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0497 - accuracy: 0.9797 - val_loss: 0.4508 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.4815 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.6129 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.4576 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 4.7820e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.9241e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.5055e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4743e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4387e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.4047e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3715e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4852 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.723 total time=  38.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5715 - accuracy: 0.3416 - val_loss: 0.3406 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2164 - accuracy: 0.7036 - val_loss: 0.3078 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1061 - accuracy: 0.8670 - val_loss: 0.2983 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0451 - accuracy: 0.9528 - val_loss: 0.3521 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0221 - accuracy: 0.9802 - val_loss: 0.4066 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0134 - accuracy: 0.9904 - val_loss: 0.4026 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0117 - accuracy: 0.9929 - val_loss: 0.5813 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0056 - accuracy: 0.9949 - val_loss: 0.5339 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.5831e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5986e-04 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.4072e-05 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.5593e-05 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.8073e-06 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3123 - accuracy: 0.6481\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.648 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5020 - accuracy: 0.3785 - val_loss: 0.3572 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1814 - accuracy: 0.7646 - val_loss: 0.2625 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0734 - accuracy: 0.9259 - val_loss: 0.2806 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0287 - accuracy: 0.9746 - val_loss: 0.3341 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9924 - val_loss: 0.3081 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.4174 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4277 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.4231 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.3666e-04 - accuracy: 0.9995 - val_loss: 0.4380 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.9262e-04 - accuracy: 0.9995 - val_loss: 0.4731 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7709e-04 - accuracy: 0.9995 - val_loss: 0.4912 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.1970e-05 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2723 - accuracy: 0.6071\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.607 total time=  35.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5543 - accuracy: 0.3841 - val_loss: 0.3443 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1953 - accuracy: 0.7311 - val_loss: 0.3201 - val_accuracy: 0.5932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0888 - accuracy: 0.9066 - val_loss: 0.2803 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0386 - accuracy: 0.9655 - val_loss: 0.3434 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0186 - accuracy: 0.9904 - val_loss: 0.3554 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0082 - accuracy: 0.9949 - val_loss: 0.3788 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.7459e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.6992e-05 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0976e-06 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1618e-06 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.4539e-07 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3126 - accuracy: 0.6619\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.662 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.5433 - accuracy: 0.3431 - val_loss: 0.3198 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2088 - accuracy: 0.7137 - val_loss: 0.2829 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0980 - accuracy: 0.8883 - val_loss: 0.2694 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0356 - accuracy: 0.9706 - val_loss: 0.2932 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0162 - accuracy: 0.9893 - val_loss: 0.3126 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0069 - accuracy: 0.9964 - val_loss: 0.3159 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 0.3438 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0149e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.3173e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9054e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2453 - accuracy: 0.6724\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.672 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6134 - accuracy: 0.3480 - val_loss: 0.3341 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2120 - accuracy: 0.7022 - val_loss: 0.2774 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0986 - accuracy: 0.8792 - val_loss: 0.2627 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0449 - accuracy: 0.9589 - val_loss: 0.2755 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0227 - accuracy: 0.9807 - val_loss: 0.3017 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0106 - accuracy: 0.9934 - val_loss: 0.3261 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0051 - accuracy: 0.9970 - val_loss: 0.3537 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.3520 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3556 - val_accuracy: 0.6959 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3586 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3626 - val_accuracy: 0.6973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3659 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3687 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2867 - accuracy: 0.6162\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.616 total time=  37.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.5622 - accuracy: 0.3252 - val_loss: 0.3415 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2283 - accuracy: 0.6692 - val_loss: 0.2988 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1184 - accuracy: 0.8508 - val_loss: 0.2862 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0590 - accuracy: 0.9366 - val_loss: 0.3004 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0331 - accuracy: 0.9645 - val_loss: 0.3171 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0180 - accuracy: 0.9822 - val_loss: 0.3351 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0112 - accuracy: 0.9899 - val_loss: 0.3324 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9944 - val_loss: 0.3577 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0035 - accuracy: 0.9964 - val_loss: 0.3551 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0029 - accuracy: 0.9975 - val_loss: 0.3564 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.3594 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 0.3628 - val_accuracy: 0.6743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.3655 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2854 - accuracy: 0.6162\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.616 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7218 - accuracy: 0.3360 - val_loss: 0.3723 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2635 - accuracy: 0.6096 - val_loss: 0.4361 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1498 - accuracy: 0.8086 - val_loss: 0.3229 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0864 - accuracy: 0.9096 - val_loss: 0.3640 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0431 - accuracy: 0.9533 - val_loss: 0.4237 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0268 - accuracy: 0.9782 - val_loss: 0.4148 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0170 - accuracy: 0.9898 - val_loss: 0.4596 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0090 - accuracy: 0.9949 - val_loss: 0.6020 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.5333 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 0.5516 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.9626e-04 - accuracy: 0.9995 - val_loss: 0.5738 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4043e-04 - accuracy: 0.9995 - val_loss: 0.5973 - val_accuracy: 0.7216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4721e-04 - accuracy: 0.9995 - val_loss: 0.6225 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3035 - accuracy: 0.6176\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.618 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6755 - accuracy: 0.3328 - val_loss: 0.3456 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2453 - accuracy: 0.6474 - val_loss: 0.3297 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1388 - accuracy: 0.8255 - val_loss: 0.3449 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0728 - accuracy: 0.9224 - val_loss: 0.3301 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0445 - accuracy: 0.9513 - val_loss: 0.3763 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0235 - accuracy: 0.9792 - val_loss: 0.4173 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0151 - accuracy: 0.9904 - val_loss: 0.5874 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0053 - accuracy: 0.9959 - val_loss: 0.4672 - val_accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.4654 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.3905e-04 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7263e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.7544e-05 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.3649 - accuracy: 0.5371\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.537 total time=  36.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 50ms/step - loss: 0.6872 - accuracy: 0.3272 - val_loss: 0.3755 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2647 - accuracy: 0.6129 - val_loss: 0.3153 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1511 - accuracy: 0.8011 - val_loss: 0.3113 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0930 - accuracy: 0.8767 - val_loss: 0.3388 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0570 - accuracy: 0.9376 - val_loss: 0.3787 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0370 - accuracy: 0.9650 - val_loss: 0.3354 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0226 - accuracy: 0.9782 - val_loss: 0.3699 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0158 - accuracy: 0.9863 - val_loss: 0.5126 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0070 - accuracy: 0.9949 - val_loss: 0.4355 - val_accuracy: 0.7297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0031 - accuracy: 0.9970 - val_loss: 0.4483 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0016 - accuracy: 0.9985 - val_loss: 0.4626 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8941e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.0701e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3575 - accuracy: 0.5858\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.586 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6603 - accuracy: 0.3396 - val_loss: 0.3633 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2301 - accuracy: 0.6665 - val_loss: 0.3199 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1157 - accuracy: 0.8543 - val_loss: 0.3076 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0556 - accuracy: 0.9411 - val_loss: 0.3300 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0281 - accuracy: 0.9756 - val_loss: 0.3324 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0149 - accuracy: 0.9883 - val_loss: 0.3508 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9924 - val_loss: 0.3774 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0062 - accuracy: 0.9964 - val_loss: 0.3895 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0035 - accuracy: 0.9970 - val_loss: 0.3866 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 0.3867 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.3880 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 0.3891 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.3906 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2883 - accuracy: 0.6095\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.610 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8326 - accuracy: 0.2988 - val_loss: 0.3757 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2678 - accuracy: 0.5860 - val_loss: 0.3288 - val_accuracy: 0.5351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1579 - accuracy: 0.7747 - val_loss: 0.2888 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0891 - accuracy: 0.8909 - val_loss: 0.2993 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0490 - accuracy: 0.9482 - val_loss: 0.3354 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0297 - accuracy: 0.9736 - val_loss: 0.3399 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0203 - accuracy: 0.9812 - val_loss: 0.4165 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0146 - accuracy: 0.9858 - val_loss: 0.3774 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0088 - accuracy: 0.9899 - val_loss: 0.3690 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0065 - accuracy: 0.9924 - val_loss: 0.3744 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0055 - accuracy: 0.9929 - val_loss: 0.3785 - val_accuracy: 0.6811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0049 - accuracy: 0.9959 - val_loss: 0.3830 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0045 - accuracy: 0.9959 - val_loss: 0.3871 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3018 - accuracy: 0.5716\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.572 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6971 - accuracy: 0.3577 - val_loss: 0.3450 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2395 - accuracy: 0.6560 - val_loss: 0.2931 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1448 - accuracy: 0.8092 - val_loss: 0.2801 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0877 - accuracy: 0.8940 - val_loss: 0.2855 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0514 - accuracy: 0.9406 - val_loss: 0.2842 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0315 - accuracy: 0.9701 - val_loss: 0.3170 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0204 - accuracy: 0.9807 - val_loss: 0.3484 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0179 - accuracy: 0.9843 - val_loss: 0.3524 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0102 - accuracy: 0.9888 - val_loss: 0.3499 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0072 - accuracy: 0.9909 - val_loss: 0.3505 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0060 - accuracy: 0.9939 - val_loss: 0.3509 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0054 - accuracy: 0.9939 - val_loss: 0.3529 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0050 - accuracy: 0.9939 - val_loss: 0.3548 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3220 - accuracy: 0.5685\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.569 total time=  38.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8463 - accuracy: 0.3655 - val_loss: 0.3523 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1827 - accuracy: 0.7711 - val_loss: 0.3037 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0646 - accuracy: 0.9508 - val_loss: 0.3019 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0257 - accuracy: 0.9832 - val_loss: 0.4387 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.3530 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0091 - accuracy: 0.9954 - val_loss: 0.4559 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5810 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.5094 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.5583e-05 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.2274e-06 - accuracy: 1.0000 - val_loss: 0.5215 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.0094e-06 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9313e-07 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0552e-07 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2810 - accuracy: 0.7008\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.701 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7062 - accuracy: 0.3998 - val_loss: 0.3413 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1773 - accuracy: 0.7834 - val_loss: 0.2626 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0623 - accuracy: 0.9452 - val_loss: 0.2408 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0198 - accuracy: 0.9853 - val_loss: 0.2995 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.3093 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.5592 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 0.5590 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.4252 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.1974e-05 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6037e-06 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3828e-06 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.5648e-07 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.2947e-07 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2627 - accuracy: 0.7066\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.707 total time=  38.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 4s 48ms/step - loss: 0.9309 - accuracy: 0.4064 - val_loss: 0.4022 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1779 - accuracy: 0.7839 - val_loss: 0.2437 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0675 - accuracy: 0.9386 - val_loss: 0.2961 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0220 - accuracy: 0.9893 - val_loss: 0.6430 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0112 - accuracy: 0.9929 - val_loss: 0.3566 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.4359 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0093 - accuracy: 0.9949 - val_loss: 0.3785 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3730 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.8676e-04 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2099e-05 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.0231e-06 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.2861e-07 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2760 - accuracy: 0.6660\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.666 total time=  36.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6579 - accuracy: 0.3711 - val_loss: 0.3311 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1672 - accuracy: 0.8010 - val_loss: 0.2876 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0597 - accuracy: 0.9487 - val_loss: 0.2825 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0209 - accuracy: 0.9909 - val_loss: 0.3147 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.3241 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.3351 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3553 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3637 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1926e-04 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.8026e-04 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.5402e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7068 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.2897e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2667 - accuracy: 0.6856\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.686 total time=  37.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6831 - accuracy: 0.4099 - val_loss: 0.3419 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1557 - accuracy: 0.8280 - val_loss: 0.2974 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0529 - accuracy: 0.9614 - val_loss: 0.2758 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0171 - accuracy: 0.9914 - val_loss: 0.3082 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.3149 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3554 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.8692e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.4147e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.1356e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 5.8964e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.7122 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6781e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3097 - accuracy: 0.6589\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.659 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.6805 - accuracy: 0.4064 - val_loss: 0.3333 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1500 - accuracy: 0.8316 - val_loss: 0.2780 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0556 - accuracy: 0.9543 - val_loss: 0.2776 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.2937 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.3214 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.2912e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.1635e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.9590e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.7573e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 6.5556e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.3540e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.7257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2899 - accuracy: 0.6457\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.646 total time=  37.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.1942 - accuracy: 0.3523 - val_loss: 0.4282 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2303 - accuracy: 0.7193 - val_loss: 0.3779 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1094 - accuracy: 0.8868 - val_loss: 0.4237 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0529 - accuracy: 0.9599 - val_loss: 0.3822 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0252 - accuracy: 0.9853 - val_loss: 0.4717 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0178 - accuracy: 0.9904 - val_loss: 0.5580 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.6507 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5423 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.5419 - val_accuracy: 0.7446 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.5539e-04 - accuracy: 0.9995 - val_loss: 0.5513 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6203e-06 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.3704e-06 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3653 - accuracy: 0.6288\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.629 total time=  35.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.9808 - accuracy: 0.3932 - val_loss: 0.3836 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1997 - accuracy: 0.7686 - val_loss: 0.3541 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0912 - accuracy: 0.9198 - val_loss: 0.3562 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0348 - accuracy: 0.9741 - val_loss: 0.4409 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0247 - accuracy: 0.9853 - val_loss: 0.4386 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.4843 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.6060 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.5964 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.0565e-05 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7831e-06 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1172e-06 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.4314e-07 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4024 - accuracy: 0.5736\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.574 total time=  36.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.0467 - accuracy: 0.4003 - val_loss: 0.4117 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1999 - accuracy: 0.7712 - val_loss: 0.3248 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0877 - accuracy: 0.9239 - val_loss: 0.3579 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0338 - accuracy: 0.9746 - val_loss: 0.3801 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0230 - accuracy: 0.9893 - val_loss: 0.4023 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0115 - accuracy: 0.9944 - val_loss: 0.4668 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.5247 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.4761 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1479e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.2305e-06 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.7378 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7094e-06 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5382e-07 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3863 - accuracy: 0.5807\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.581 total time=  35.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9260 - accuracy: 0.3518 - val_loss: 0.3706 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1992 - accuracy: 0.7492 - val_loss: 0.3224 - val_accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0840 - accuracy: 0.9086 - val_loss: 0.3055 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0370 - accuracy: 0.9695 - val_loss: 0.3253 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0141 - accuracy: 0.9919 - val_loss: 0.3508 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.3718 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.3798 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 0.4023 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.6703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.7388e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.6662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2864 - accuracy: 0.6511\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.651 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.9524 - accuracy: 0.3957 - val_loss: 0.3834 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1569 - accuracy: 0.8295 - val_loss: 0.3418 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0487 - accuracy: 0.9609 - val_loss: 0.3385 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.3412 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.3576 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3745 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3806 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3913 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.8060e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.6770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2830e-04 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.9296e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.6784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 7.5950e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.2733e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3652 - accuracy: 0.6335\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.634 total time=  37.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.0417 - accuracy: 0.4013 - val_loss: 0.3817 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1423 - accuracy: 0.8529 - val_loss: 0.3524 - val_accuracy: 0.6054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0394 - accuracy: 0.9812 - val_loss: 0.3277 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.3306 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.3455 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3589 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3783 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.6892 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.8281e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.6892 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 9.0089e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.4268e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 7.9518e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3655 - accuracy: 0.6223\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.622 total time=  38.1s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 1.4987 - accuracy: 0.5355 - val_loss: 0.4688 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.2065 - accuracy: 0.8877 - val_loss: 0.3825 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0579 - accuracy: 0.9723 - val_loss: 0.3778 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.3509 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.3572 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.3397 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 9.0943e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 4.5722e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.7973 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.9219e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.4178e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 2.0750e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.8446e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.8206e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7703e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 1.7427e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_vgg16_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inceptionv3_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 69ms/step - loss: 13.4405 - accuracy: 0.1624 - val_loss: 4.3928 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.2021 - accuracy: 0.1675 - val_loss: 0.6559 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7281 - accuracy: 0.1487 - val_loss: 0.6029 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5770 - accuracy: 0.1604 - val_loss: 0.5366 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5143 - accuracy: 0.1563 - val_loss: 0.4739 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4479 - accuracy: 0.1477 - val_loss: 0.4268 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4176 - accuracy: 0.1452 - val_loss: 0.4111 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4108 - accuracy: 0.1421 - val_loss: 0.4101 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1467 - val_loss: 0.4099 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4099 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4103 - accuracy: 0.1264 - val_loss: 0.4099 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1447 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1386 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1406 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1365 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1431 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1492 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1467 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1446 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 44ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  59.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 20.4652 - accuracy: 0.1938 - val_loss: 2.4708 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 4.3980 - accuracy: 0.1984 - val_loss: 3.4735 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9946 - accuracy: 0.1395 - val_loss: 0.6460 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6677 - accuracy: 0.1314 - val_loss: 0.5969 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5655 - accuracy: 0.1416 - val_loss: 0.5285 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4918 - accuracy: 0.1497 - val_loss: 0.4567 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4348 - accuracy: 0.1497 - val_loss: 0.4186 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4132 - accuracy: 0.1492 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1456 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1466 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1385 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1426 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1284 - val_loss: 0.4106 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1416 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 44ms/step - loss: 0.4104 - accuracy: 0.1401\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.140 total time=  55.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 19.5038 - accuracy: 0.1664 - val_loss: 4.0070 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.1712 - accuracy: 0.1654 - val_loss: 0.6649 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6726 - accuracy: 0.1451 - val_loss: 0.6337 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6039 - accuracy: 0.1471 - val_loss: 0.5636 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5185 - accuracy: 0.1471 - val_loss: 0.4732 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4434 - accuracy: 0.1471 - val_loss: 0.4200 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4135 - accuracy: 0.1471 - val_loss: 0.4102 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4104 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1461 - val_loss: 0.4103 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1390 - val_loss: 0.4103 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1471 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1446 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4105 - accuracy: 0.1340\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.134 total time=  49.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 8.0318 - accuracy: 0.1954 - val_loss: 2.7327 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.8625 - accuracy: 0.2868 - val_loss: 1.8162 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0907 - accuracy: 0.4223 - val_loss: 1.3089 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8423 - accuracy: 0.4888 - val_loss: 1.1846 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6800 - accuracy: 0.5503 - val_loss: 1.4124 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5356 - accuracy: 0.6208 - val_loss: 1.2080 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4805 - accuracy: 0.6665 - val_loss: 1.0854 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3161 - accuracy: 0.7543 - val_loss: 1.4796 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3171 - accuracy: 0.7599 - val_loss: 1.1061 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2853 - accuracy: 0.7959 - val_loss: 1.1647 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1612 - accuracy: 0.8853 - val_loss: 1.0114 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1525 - accuracy: 0.8964 - val_loss: 1.1048 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1715 - accuracy: 0.8939 - val_loss: 1.2443 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1207 - accuracy: 0.9360 - val_loss: 1.2413 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1102 - accuracy: 0.9371 - val_loss: 1.1009 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0759 - accuracy: 0.9624 - val_loss: 1.2887 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0260 - accuracy: 0.9964 - val_loss: 1.1295 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 41ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 1.1929 - accuracy: 0.4148\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.415 total time=  55.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 6.1779 - accuracy: 0.1913 - val_loss: 3.1543 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6468 - accuracy: 0.3567 - val_loss: 1.7231 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9017 - accuracy: 0.5297 - val_loss: 1.6806 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8330 - accuracy: 0.5652 - val_loss: 1.5950 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7710 - accuracy: 0.6043 - val_loss: 1.6409 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4171 - accuracy: 0.7610 - val_loss: 1.6627 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3463 - accuracy: 0.7930 - val_loss: 1.4302 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3503 - accuracy: 0.7889 - val_loss: 2.2420 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3960 - accuracy: 0.8067 - val_loss: 1.7107 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2421 - accuracy: 0.8564 - val_loss: 1.4666 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1263 - accuracy: 0.9168 - val_loss: 1.4198 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0727 - accuracy: 0.9569 - val_loss: 1.4433 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0441 - accuracy: 0.9807 - val_loss: 1.6087 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 1.3474 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0272 - accuracy: 0.9878 - val_loss: 1.3985 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0753 - accuracy: 0.9635 - val_loss: 1.4312 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 1.4543 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 1.4178 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.3909 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3826 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.4699 - accuracy: 0.4223\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.422 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 6.4899 - accuracy: 0.1887 - val_loss: 2.1131 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2944 - accuracy: 0.3156 - val_loss: 1.9956 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9007 - accuracy: 0.3907 - val_loss: 0.9838 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6458 - accuracy: 0.4105 - val_loss: 0.8878 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4493 - accuracy: 0.5145 - val_loss: 0.7985 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3478 - accuracy: 0.5764 - val_loss: 0.6874 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2887 - accuracy: 0.6337 - val_loss: 0.6239 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2353 - accuracy: 0.7047 - val_loss: 0.6672 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3051 - accuracy: 0.6474 - val_loss: 0.7668 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2462 - accuracy: 0.7169 - val_loss: 0.7796 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2046 - accuracy: 0.7549 - val_loss: 0.6782 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1534 - accuracy: 0.8321 - val_loss: 0.8472 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0877 - accuracy: 0.9274 - val_loss: 0.7080 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0669 - accuracy: 0.9635 - val_loss: 0.7065 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0605 - accuracy: 0.9716 - val_loss: 0.6958 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0575 - accuracy: 0.9751 - val_loss: 0.6962 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0528 - accuracy: 0.9787 - val_loss: 0.7090 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.6601 - accuracy: 0.2924\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.292 total time=  48.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 17.2006 - accuracy: 0.1619 - val_loss: 0.6906 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6873 - accuracy: 0.1431 - val_loss: 0.6250 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5903 - accuracy: 0.1426 - val_loss: 0.5375 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4835 - accuracy: 0.1426 - val_loss: 0.4345 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4183 - accuracy: 0.1401 - val_loss: 0.4101 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1467 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1391 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1431 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1386 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4104 - accuracy: 0.1345 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1360 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1320 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1437 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4143 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 18.1355 - accuracy: 0.1730 - val_loss: 5.1224 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 5.1707 - accuracy: 0.1852 - val_loss: 3.3311 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.3922 - accuracy: 0.1426 - val_loss: 2.4838 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.6304 - accuracy: 0.1568 - val_loss: 0.6164 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6461 - accuracy: 0.1624 - val_loss: 0.6621 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6285 - accuracy: 0.1421 - val_loss: 0.6109 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5725 - accuracy: 0.1497 - val_loss: 0.5257 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4940 - accuracy: 0.1537 - val_loss: 0.4422 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4229 - accuracy: 0.1426 - val_loss: 0.4115 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1431 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1431 - val_loss: 0.4109 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1451 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1350 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4109 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4108 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4105 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time=  57.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 18.0637 - accuracy: 0.1634 - val_loss: 11.2144 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.7477 - accuracy: 0.1786 - val_loss: 0.5790 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6320 - accuracy: 0.1497 - val_loss: 0.5761 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5612 - accuracy: 0.1512 - val_loss: 0.5479 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5078 - accuracy: 0.1441 - val_loss: 0.4663 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4389 - accuracy: 0.1497 - val_loss: 0.4878 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4140 - accuracy: 0.1441 - val_loss: 0.4107 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4134 - accuracy: 0.1476 - val_loss: 0.4103 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4096 - accuracy: 0.1613 - val_loss: 0.4138 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4092 - accuracy: 0.1466 - val_loss: 0.4127 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4080 - accuracy: 0.1532 - val_loss: 0.4124 - val_accuracy: 0.1162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1421 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1400 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4110 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4109 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4101 - accuracy: 0.1320\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.132 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 8.5435 - accuracy: 0.2086 - val_loss: 3.2417 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.6487 - accuracy: 0.3721 - val_loss: 3.1320 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6252 - accuracy: 0.4883 - val_loss: 2.3336 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.0266 - accuracy: 0.5670 - val_loss: 2.3361 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7729 - accuracy: 0.6162 - val_loss: 1.8028 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3880 - accuracy: 0.7599 - val_loss: 1.3428 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3594 - accuracy: 0.7604 - val_loss: 1.5205 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2553 - accuracy: 0.8330 - val_loss: 1.6697 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4109 - accuracy: 0.7706 - val_loss: 1.5858 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1811 - accuracy: 0.8756 - val_loss: 1.3134 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1761 - accuracy: 0.8822 - val_loss: 1.4410 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0559 - accuracy: 0.9690 - val_loss: 1.2448 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 1.2978 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 1.2977 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 1.3111 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 1.3147 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3400 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.3312 - accuracy: 0.4544\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.454 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.2204 - accuracy: 0.1892 - val_loss: 1.4952 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8755 - accuracy: 0.2907 - val_loss: 0.8835 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5160 - accuracy: 0.3491 - val_loss: 0.5294 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3646 - accuracy: 0.4181 - val_loss: 0.4664 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3071 - accuracy: 0.5195 - val_loss: 0.4934 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3003 - accuracy: 0.5485 - val_loss: 0.5820 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3642 - accuracy: 0.4871 - val_loss: 0.5531 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2819 - accuracy: 0.5718 - val_loss: 0.6201 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2756 - accuracy: 0.6058 - val_loss: 0.6459 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1795 - accuracy: 0.7514 - val_loss: 0.4755 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1446 - accuracy: 0.8163 - val_loss: 0.4766 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1344 - accuracy: 0.8290 - val_loss: 0.4834 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1267 - accuracy: 0.8427 - val_loss: 0.4770 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1176 - accuracy: 0.8686 - val_loss: 0.4874 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4819 - accuracy: 0.2843\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.284 total time=  40.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.3585 - accuracy: 0.1806 - val_loss: 1.6892 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9827 - accuracy: 0.2613 - val_loss: 0.8504 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5355 - accuracy: 0.2983 - val_loss: 0.6422 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4648 - accuracy: 0.3242 - val_loss: 0.6646 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3819 - accuracy: 0.4176 - val_loss: 0.6376 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4406 - accuracy: 0.4084 - val_loss: 0.6270 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3447 - accuracy: 0.4850 - val_loss: 0.5790 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3291 - accuracy: 0.5079 - val_loss: 0.6083 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2762 - accuracy: 0.6073 - val_loss: 0.5527 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2567 - accuracy: 0.6347 - val_loss: 0.5733 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2208 - accuracy: 0.6768 - val_loss: 0.6811 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2359 - accuracy: 0.6601 - val_loss: 0.7329 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2485 - accuracy: 0.6626 - val_loss: 0.6588 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2079 - accuracy: 0.7067 - val_loss: 0.7085 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1526 - accuracy: 0.7864 - val_loss: 0.6012 - val_accuracy: 0.3676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1140 - accuracy: 0.8473 - val_loss: 0.5855 - val_accuracy: 0.3554 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1038 - accuracy: 0.8671 - val_loss: 0.5946 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0976 - accuracy: 0.8777 - val_loss: 0.5876 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0930 - accuracy: 0.8848 - val_loss: 0.6112 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5926 - accuracy: 0.2934\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.293 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 30.7861 - accuracy: 0.2112 - val_loss: 13.8598 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 11.0466 - accuracy: 0.2340 - val_loss: 5.6718 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 6.1758 - accuracy: 0.2482 - val_loss: 1.8357 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 2.3377 - accuracy: 0.2543 - val_loss: 0.5765 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5629 - accuracy: 0.1817 - val_loss: 0.5925 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5066 - accuracy: 0.1482 - val_loss: 0.4960 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5089 - accuracy: 0.1462 - val_loss: 0.4739 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5077 - accuracy: 0.1584 - val_loss: 0.4938 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5397 - accuracy: 0.1543 - val_loss: 0.4824 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4704 - accuracy: 0.1538 - val_loss: 0.4708 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4448 - accuracy: 0.1421 - val_loss: 0.4312 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4185 - accuracy: 0.1381 - val_loss: 0.4160 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4113 - accuracy: 0.1376 - val_loss: 0.4132 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1411 - val_loss: 0.4126 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4125 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4125 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1396 - val_loss: 0.4124 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1457 - val_loss: 0.4123 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1416 - val_loss: 0.4122 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1426 - val_loss: 0.4123 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4107 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  57.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 31.2202 - accuracy: 0.1740 - val_loss: 12.2986 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 10.4508 - accuracy: 0.2308 - val_loss: 11.9248 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 8.3630 - accuracy: 0.2613 - val_loss: 5.8098 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 6.3318 - accuracy: 0.3049 - val_loss: 4.4131 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.2906 - accuracy: 0.3196 - val_loss: 5.7183 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.7690 - accuracy: 0.3623 - val_loss: 6.7894 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.4460 - accuracy: 0.3658 - val_loss: 4.3003 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.4537 - accuracy: 0.3856 - val_loss: 2.5938 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1016 - accuracy: 0.4110 - val_loss: 5.2158 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6631 - accuracy: 0.4465 - val_loss: 4.0617 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.4654 - accuracy: 0.4510 - val_loss: 1.3656 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2883 - accuracy: 0.4764 - val_loss: 1.9308 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0294 - accuracy: 0.5129 - val_loss: 1.3982 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9023 - accuracy: 0.5195 - val_loss: 1.0076 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8589 - accuracy: 0.5495 - val_loss: 1.7973 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7057 - accuracy: 0.5576 - val_loss: 0.8613 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5900 - accuracy: 0.6119 - val_loss: 1.6281 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6547 - accuracy: 0.5931 - val_loss: 1.3095 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5001 - accuracy: 0.6535 - val_loss: 1.4283 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4435 - accuracy: 0.6728 - val_loss: 0.8880 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.9228 - accuracy: 0.3563\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.356 total time=  58.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 30.4674 - accuracy: 0.1720 - val_loss: 26.5838 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 10.2923 - accuracy: 0.2106 - val_loss: 6.5623 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 6.0979 - accuracy: 0.2278 - val_loss: 5.5681 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.5613 - accuracy: 0.2511 - val_loss: 2.0403 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.5771 - accuracy: 0.3054 - val_loss: 3.5864 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0792 - accuracy: 0.3217 - val_loss: 4.2278 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.2619 - accuracy: 0.3623 - val_loss: 3.4552 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.0649 - accuracy: 0.3998 - val_loss: 2.8720 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7848 - accuracy: 0.3937 - val_loss: 2.4238 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4810 - accuracy: 0.6728 - val_loss: 0.9813 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2278 - accuracy: 0.7930 - val_loss: 0.8364 - val_accuracy: 0.3838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1791 - accuracy: 0.8295 - val_loss: 0.8073 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1432 - accuracy: 0.8650 - val_loss: 0.8568 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1244 - accuracy: 0.8798 - val_loss: 0.8652 - val_accuracy: 0.3635 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1055 - accuracy: 0.9016 - val_loss: 0.8129 - val_accuracy: 0.3851 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0913 - accuracy: 0.9183 - val_loss: 0.7648 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0801 - accuracy: 0.9310 - val_loss: 0.7853 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0707 - accuracy: 0.9452 - val_loss: 0.7823 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.0617 - accuracy: 0.9493 - val_loss: 0.7585 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0559 - accuracy: 0.9645 - val_loss: 0.7916 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.7968 - accuracy: 0.4000\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.400 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 16.6654 - accuracy: 0.1929 - val_loss: 3.9843 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.7062 - accuracy: 0.3934 - val_loss: 3.5728 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.7050 - accuracy: 0.5244 - val_loss: 4.2983 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.1576 - accuracy: 0.5335 - val_loss: 3.8836 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8155 - accuracy: 0.7437 - val_loss: 2.5991 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5692 - accuracy: 0.8112 - val_loss: 2.5305 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5095 - accuracy: 0.8340 - val_loss: 2.7368 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4044 - accuracy: 0.8777 - val_loss: 2.3522 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1695 - accuracy: 0.9416 - val_loss: 2.3285 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1595 - accuracy: 0.9497 - val_loss: 2.4558 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1543 - accuracy: 0.9569 - val_loss: 3.4131 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6640 - accuracy: 0.8350 - val_loss: 3.2159 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7185 - accuracy: 0.8132 - val_loss: 3.5690 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5677 - accuracy: 0.8533 - val_loss: 2.9516 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0922 - accuracy: 0.9741 - val_loss: 2.6093 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 2.5674 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 2.5637 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 2.5239 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 2.5247 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.4610 - accuracy: 0.4026\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.403 total time=  53.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 11.6500 - accuracy: 0.1979 - val_loss: 4.3321 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.2655 - accuracy: 0.4044 - val_loss: 3.0118 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 2.1560 - accuracy: 0.5292 - val_loss: 4.4610 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 2.4748 - accuracy: 0.5525 - val_loss: 5.9594 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7280 - accuracy: 0.6596 - val_loss: 3.1238 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.3245 - accuracy: 0.7296 - val_loss: 3.4050 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.8535 - accuracy: 0.8001 - val_loss: 3.5152 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3234 - accuracy: 0.9269 - val_loss: 2.7372 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1352 - accuracy: 0.9614 - val_loss: 2.5978 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0885 - accuracy: 0.9675 - val_loss: 2.5921 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0618 - accuracy: 0.9777 - val_loss: 2.5229 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0472 - accuracy: 0.9812 - val_loss: 2.4924 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0362 - accuracy: 0.9848 - val_loss: 2.4990 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0272 - accuracy: 0.9883 - val_loss: 2.4671 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0212 - accuracy: 0.9914 - val_loss: 2.5201 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 2.4469 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 2.4558 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 2.4493 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 2.4581 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 2.4653 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.7020 - accuracy: 0.4264\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.426 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 10.0294 - accuracy: 0.2116 - val_loss: 6.9680 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.5110 - accuracy: 0.3714 - val_loss: 5.8629 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.4403 - accuracy: 0.4409 - val_loss: 3.8353 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1795 - accuracy: 0.5840 - val_loss: 3.5316 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3239 - accuracy: 0.6961 - val_loss: 3.5271 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.2088 - accuracy: 0.7286 - val_loss: 3.5994 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0796 - accuracy: 0.7742 - val_loss: 3.4610 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.3118 - accuracy: 0.7423 - val_loss: 4.7077 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.1253 - accuracy: 0.8102 - val_loss: 4.2193 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7211 - accuracy: 0.8579 - val_loss: 4.1829 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4735 - accuracy: 0.9107 - val_loss: 3.1868 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2296 - accuracy: 0.9604 - val_loss: 3.4285 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2006 - accuracy: 0.9670 - val_loss: 3.3673 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5463 - accuracy: 0.9046 - val_loss: 3.7890 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2697 - accuracy: 0.9452 - val_loss: 4.0500 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1828 - accuracy: 0.9721 - val_loss: 4.2907 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0679 - accuracy: 0.9919 - val_loss: 3.2480 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 3.2193 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 3.2035 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 3.2096 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 3.3003 - accuracy: 0.4193\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.419 total time=  56.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 30.4345 - accuracy: 0.1959 - val_loss: 6.1782 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 7.2147 - accuracy: 0.2249 - val_loss: 3.0590 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.3483 - accuracy: 0.2076 - val_loss: 2.8989 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.8972 - accuracy: 0.1665 - val_loss: 0.4857 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5457 - accuracy: 0.1487 - val_loss: 0.5136 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5427 - accuracy: 0.1472 - val_loss: 0.5250 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5194 - accuracy: 0.1543 - val_loss: 0.5016 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4591 - accuracy: 0.1553 - val_loss: 0.4276 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4198 - accuracy: 0.1437 - val_loss: 0.4120 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4098 - accuracy: 0.1538 - val_loss: 0.4176 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4107 - accuracy: 0.1518 - val_loss: 0.4101 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4097 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1411 - val_loss: 0.4102 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4110 - accuracy: 0.1477 - val_loss: 0.4164 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4096 - accuracy: 0.1431 - val_loss: 0.4232 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4110 - accuracy: 0.1518 - val_loss: 0.4104 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4082 - accuracy: 0.1574 - val_loss: 0.4104 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4072 - accuracy: 0.1482 - val_loss: 0.4111 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4069 - accuracy: 0.1462 - val_loss: 0.4106 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4069 - accuracy: 0.1538 - val_loss: 0.4125 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4116 - accuracy: 0.1237\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.124 total time=  58.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 24.5403 - accuracy: 0.1568 - val_loss: 7.0129 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 6.9206 - accuracy: 0.2308 - val_loss: 8.3917 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.3963 - accuracy: 0.2359 - val_loss: 3.0724 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 2.5176 - accuracy: 0.2121 - val_loss: 0.7292 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5900 - accuracy: 0.1892 - val_loss: 0.6390 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5917 - accuracy: 0.1390 - val_loss: 0.5805 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5289 - accuracy: 0.1558 - val_loss: 0.4754 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4683 - accuracy: 0.1502 - val_loss: 0.4324 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4177 - accuracy: 0.1284 - val_loss: 0.4106 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4105 - accuracy: 0.1218 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1527 - val_loss: 0.4110 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1329 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1527 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1360 - val_loss: 0.4109 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4108 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1441 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1497 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4104 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 25.0345 - accuracy: 0.1740 - val_loss: 5.5797 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 7.5724 - accuracy: 0.2166 - val_loss: 3.6286 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 4.2008 - accuracy: 0.2197 - val_loss: 7.7200 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 1.3321 - accuracy: 0.1892 - val_loss: 0.5043 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5739 - accuracy: 0.1517 - val_loss: 0.7772 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6004 - accuracy: 0.1461 - val_loss: 0.5788 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5296 - accuracy: 0.1654 - val_loss: 0.4911 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4642 - accuracy: 0.1568 - val_loss: 0.4322 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4160 - accuracy: 0.1527 - val_loss: 0.4112 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4087 - accuracy: 0.1426 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4085 - accuracy: 0.1512 - val_loss: 0.4104 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4117 - accuracy: 0.1517 - val_loss: 0.4090 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4082 - accuracy: 0.1426 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4097 - accuracy: 0.1512 - val_loss: 0.4096 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4076 - accuracy: 0.1512 - val_loss: 0.4092 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4083 - accuracy: 0.1608 - val_loss: 0.4099 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4077 - accuracy: 0.1390 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1537 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1537 - val_loss: 0.4093 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4074 - accuracy: 0.1466 - val_loss: 0.4093 - val_accuracy: 0.1216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4089 - accuracy: 0.1381\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.138 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 12.2358 - accuracy: 0.2299 - val_loss: 5.4877 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.4010 - accuracy: 0.4020 - val_loss: 2.1043 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2666 - accuracy: 0.5345 - val_loss: 2.0751 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8301 - accuracy: 0.6325 - val_loss: 1.7621 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5784 - accuracy: 0.7254 - val_loss: 1.6545 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3857 - accuracy: 0.8096 - val_loss: 2.0687 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4020 - accuracy: 0.8041 - val_loss: 1.5695 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5114 - accuracy: 0.7569 - val_loss: 1.8777 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3080 - accuracy: 0.8396 - val_loss: 1.6459 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1448 - accuracy: 0.9264 - val_loss: 1.5532 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1188 - accuracy: 0.9421 - val_loss: 1.5551 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0648 - accuracy: 0.9675 - val_loss: 1.6197 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0365 - accuracy: 0.9827 - val_loss: 1.6094 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1355 - accuracy: 0.9421 - val_loss: 1.7719 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1312 - accuracy: 0.9325 - val_loss: 1.5490 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1186 - accuracy: 0.9457 - val_loss: 1.8421 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0928 - accuracy: 0.9569 - val_loss: 1.5104 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0848 - accuracy: 0.9614 - val_loss: 1.4996 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1588 - accuracy: 0.9325 - val_loss: 2.2203 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1428 - accuracy: 0.9360 - val_loss: 2.1321 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2241 - accuracy: 0.3854\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.385 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.3284 - accuracy: 0.2349 - val_loss: 4.3724 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.7743 - accuracy: 0.4343 - val_loss: 3.0289 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.7343 - accuracy: 0.5591 - val_loss: 3.2921 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2536 - accuracy: 0.6403 - val_loss: 2.7427 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.1536 - accuracy: 0.6895 - val_loss: 2.9811 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6841 - accuracy: 0.7905 - val_loss: 2.6905 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3889 - accuracy: 0.8620 - val_loss: 2.3675 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3112 - accuracy: 0.8894 - val_loss: 2.4264 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4303 - accuracy: 0.8772 - val_loss: 2.7984 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3363 - accuracy: 0.8940 - val_loss: 2.7226 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2430 - accuracy: 0.9214 - val_loss: 2.4335 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2092 - accuracy: 0.9330 - val_loss: 2.3827 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0263 - accuracy: 0.9949 - val_loss: 2.2394 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.2027 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2027 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2070 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1972 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2002 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1883 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1910 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.4811 - accuracy: 0.4376\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.438 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 13.7093 - accuracy: 0.2131 - val_loss: 7.2144 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.8249 - accuracy: 0.4485 - val_loss: 4.6031 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0839 - accuracy: 0.5246 - val_loss: 4.2715 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7288 - accuracy: 0.6758 - val_loss: 4.8056 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3928 - accuracy: 0.7144 - val_loss: 3.8549 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.1380 - accuracy: 0.7514 - val_loss: 4.1073 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4656 - accuracy: 0.8767 - val_loss: 3.1292 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3282 - accuracy: 0.9148 - val_loss: 3.2868 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4790 - accuracy: 0.8879 - val_loss: 4.1514 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3238 - accuracy: 0.9214 - val_loss: 3.7164 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2728 - accuracy: 0.9295 - val_loss: 3.8945 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1603 - accuracy: 0.9584 - val_loss: 3.2092 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0237 - accuracy: 0.9975 - val_loss: 3.0276 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 2.9231 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.9222 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 7.8452e-04 - accuracy: 1.0000 - val_loss: 2.9129 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.9023e-04 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.0658e-04 - accuracy: 1.0000 - val_loss: 2.9084 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 4.4961e-04 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.9858 - accuracy: 0.3929\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.393 total time=  56.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 2.6704 - accuracy: 0.1690 - val_loss: 0.8985 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6783 - accuracy: 0.1832 - val_loss: 0.5390 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5027 - accuracy: 0.2117 - val_loss: 0.5573 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4388 - accuracy: 0.2299 - val_loss: 0.4277 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4208 - accuracy: 0.2670 - val_loss: 0.4124 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3966 - accuracy: 0.3168 - val_loss: 0.4335 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3760 - accuracy: 0.3365 - val_loss: 0.4255 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3678 - accuracy: 0.3736 - val_loss: 0.4187 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3469 - accuracy: 0.3934 - val_loss: 0.4034 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3333 - accuracy: 0.4147 - val_loss: 0.4272 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3137 - accuracy: 0.4543 - val_loss: 0.4873 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3060 - accuracy: 0.4538 - val_loss: 0.4340 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2901 - accuracy: 0.5015 - val_loss: 0.5475 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2823 - accuracy: 0.5142 - val_loss: 0.5638 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2224 - accuracy: 0.6046 - val_loss: 0.4699 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2110 - accuracy: 0.6305 - val_loss: 0.4988 - val_accuracy: 0.3568 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2032 - accuracy: 0.6482 - val_loss: 0.5098 - val_accuracy: 0.3378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1980 - accuracy: 0.6599 - val_loss: 0.5141 - val_accuracy: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1936 - accuracy: 0.6660 - val_loss: 0.5322 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 0.4039 - accuracy: 0.2901\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.290 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.1196 - accuracy: 0.1659 - val_loss: 0.5038 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4928 - accuracy: 0.1989 - val_loss: 0.6972 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4690 - accuracy: 0.1877 - val_loss: 0.4295 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4369 - accuracy: 0.2298 - val_loss: 0.4379 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4204 - accuracy: 0.2334 - val_loss: 0.4670 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4152 - accuracy: 0.2603 - val_loss: 0.4224 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3972 - accuracy: 0.2775 - val_loss: 0.4231 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3894 - accuracy: 0.2958 - val_loss: 0.4214 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3862 - accuracy: 0.3130 - val_loss: 0.4253 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3744 - accuracy: 0.3354 - val_loss: 0.4905 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3674 - accuracy: 0.3663 - val_loss: 0.4140 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3548 - accuracy: 0.3749 - val_loss: 0.4186 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3523 - accuracy: 0.3831 - val_loss: 0.4658 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3463 - accuracy: 0.3998 - val_loss: 0.5148 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3337 - accuracy: 0.4313 - val_loss: 0.4805 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3325 - accuracy: 0.4287 - val_loss: 0.5031 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2868 - accuracy: 0.5053 - val_loss: 0.4444 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2650 - accuracy: 0.5566 - val_loss: 0.4523 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2579 - accuracy: 0.5718 - val_loss: 0.4690 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2513 - accuracy: 0.5870 - val_loss: 0.4638 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4634 - accuracy: 0.3127\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.313 total time=  56.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.1629 - accuracy: 0.1629 - val_loss: 0.5895 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4748 - accuracy: 0.1903 - val_loss: 0.4627 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4596 - accuracy: 0.2050 - val_loss: 0.4249 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4312 - accuracy: 0.2095 - val_loss: 0.4600 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4261 - accuracy: 0.2182 - val_loss: 0.4169 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4126 - accuracy: 0.2354 - val_loss: 0.4253 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4042 - accuracy: 0.2603 - val_loss: 0.4286 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3929 - accuracy: 0.2659 - val_loss: 0.4091 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3837 - accuracy: 0.2988 - val_loss: 0.4215 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3737 - accuracy: 0.3135 - val_loss: 0.4496 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.3676 - accuracy: 0.3384 - val_loss: 0.4383 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3602 - accuracy: 0.3496 - val_loss: 0.4508 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3490 - accuracy: 0.3648 - val_loss: 0.4698 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2920 - accuracy: 0.4663 - val_loss: 0.4391 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2801 - accuracy: 0.4815 - val_loss: 0.4477 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2734 - accuracy: 0.4926 - val_loss: 0.4393 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2668 - accuracy: 0.5094 - val_loss: 0.4791 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2617 - accuracy: 0.5256 - val_loss: 0.4689 - val_accuracy: 0.3041 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4160 - accuracy: 0.2193\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.219 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 1.0140 - accuracy: 0.1827 - val_loss: 0.4695 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4115 - accuracy: 0.2929 - val_loss: 0.4114 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3619 - accuracy: 0.4020 - val_loss: 0.4213 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3333 - accuracy: 0.4604 - val_loss: 0.4205 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2986 - accuracy: 0.5599 - val_loss: 0.3996 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2614 - accuracy: 0.6426 - val_loss: 0.4076 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2296 - accuracy: 0.6904 - val_loss: 0.4326 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2035 - accuracy: 0.7365 - val_loss: 0.4270 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1785 - accuracy: 0.7822 - val_loss: 0.4530 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1305 - accuracy: 0.8701 - val_loss: 0.4764 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0927 - accuracy: 0.9299 - val_loss: 0.4533 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0844 - accuracy: 0.9396 - val_loss: 0.4572 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0802 - accuracy: 0.9442 - val_loss: 0.4689 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0772 - accuracy: 0.9487 - val_loss: 0.4656 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0735 - accuracy: 0.9497 - val_loss: 0.4700 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4017 - accuracy: 0.3519\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.352 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.2885 - accuracy: 0.2035 - val_loss: 0.5341 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4220 - accuracy: 0.3338 - val_loss: 0.4814 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3503 - accuracy: 0.4531 - val_loss: 0.4128 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2943 - accuracy: 0.5647 - val_loss: 0.4183 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2591 - accuracy: 0.6251 - val_loss: 0.4179 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2332 - accuracy: 0.6859 - val_loss: 0.4760 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1950 - accuracy: 0.7742 - val_loss: 0.4572 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1549 - accuracy: 0.8331 - val_loss: 0.4807 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1124 - accuracy: 0.9173 - val_loss: 0.4592 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1018 - accuracy: 0.9422 - val_loss: 0.4641 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0962 - accuracy: 0.9488 - val_loss: 0.4636 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0924 - accuracy: 0.9533 - val_loss: 0.4667 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0880 - accuracy: 0.9579 - val_loss: 0.4759 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4150 - accuracy: 0.3381\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.338 total time=  38.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.1259 - accuracy: 0.1913 - val_loss: 0.4892 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4097 - accuracy: 0.3298 - val_loss: 0.4529 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3590 - accuracy: 0.4115 - val_loss: 0.4238 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3242 - accuracy: 0.4855 - val_loss: 0.4402 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2793 - accuracy: 0.5723 - val_loss: 0.4691 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2549 - accuracy: 0.6220 - val_loss: 0.4284 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2241 - accuracy: 0.6941 - val_loss: 0.4866 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2441 - accuracy: 0.6550 - val_loss: 0.5099 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1466 - accuracy: 0.8250 - val_loss: 0.4635 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1298 - accuracy: 0.8554 - val_loss: 0.4725 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1216 - accuracy: 0.8706 - val_loss: 0.4775 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1135 - accuracy: 0.8808 - val_loss: 0.4833 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1049 - accuracy: 0.8935 - val_loss: 0.4859 - val_accuracy: 0.3649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4224 - accuracy: 0.2802\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.280 total time=  38.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.1951 - accuracy: 0.1599 - val_loss: 0.6536 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5321 - accuracy: 0.1518 - val_loss: 0.4725 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4880 - accuracy: 0.1599 - val_loss: 0.6116 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4811 - accuracy: 0.1772 - val_loss: 0.4287 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4709 - accuracy: 0.1817 - val_loss: 0.4443 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4573 - accuracy: 0.1924 - val_loss: 0.4891 - val_accuracy: 0.1270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4546 - accuracy: 0.1858 - val_loss: 0.5313 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.1909 - val_loss: 0.4904 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4435 - accuracy: 0.2041 - val_loss: 0.4947 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3831 - accuracy: 0.2640 - val_loss: 0.4197 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3724 - accuracy: 0.2782 - val_loss: 0.4243 - val_accuracy: 0.2135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3692 - accuracy: 0.2777 - val_loss: 0.4253 - val_accuracy: 0.1946 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3654 - accuracy: 0.2883 - val_loss: 0.4222 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3642 - accuracy: 0.3036 - val_loss: 0.4295 - val_accuracy: 0.2095 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3612 - accuracy: 0.3066 - val_loss: 0.4315 - val_accuracy: 0.1959 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3571 - accuracy: 0.2959 - val_loss: 0.4289 - val_accuracy: 0.2149 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3554 - accuracy: 0.2995 - val_loss: 0.4284 - val_accuracy: 0.2216 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3550 - accuracy: 0.3015 - val_loss: 0.4298 - val_accuracy: 0.2230 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3545 - accuracy: 0.3086 - val_loss: 0.4302 - val_accuracy: 0.2284 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3542 - accuracy: 0.3239 - val_loss: 0.4309 - val_accuracy: 0.2203 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4188 - accuracy: 0.2160\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.216 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.2111 - accuracy: 0.1547 - val_loss: 0.6114 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5047 - accuracy: 0.1547 - val_loss: 0.4466 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4880 - accuracy: 0.1593 - val_loss: 0.4332 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4782 - accuracy: 0.1487 - val_loss: 0.4686 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4795 - accuracy: 0.1339 - val_loss: 0.4927 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4710 - accuracy: 0.1426 - val_loss: 0.4504 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4656 - accuracy: 0.1598 - val_loss: 0.5159 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4562 - accuracy: 0.1558 - val_loss: 0.4294 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.1745 - val_loss: 0.4415 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4477 - accuracy: 0.1821 - val_loss: 0.4306 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4434 - accuracy: 0.1847 - val_loss: 0.5109 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4387 - accuracy: 0.1857 - val_loss: 0.4904 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4311 - accuracy: 0.2014 - val_loss: 0.4302 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3898 - accuracy: 0.2197 - val_loss: 0.4328 - val_accuracy: 0.1635 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3852 - accuracy: 0.2232 - val_loss: 0.4309 - val_accuracy: 0.1595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3835 - accuracy: 0.2293 - val_loss: 0.4393 - val_accuracy: 0.1905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3812 - accuracy: 0.2278 - val_loss: 0.4429 - val_accuracy: 0.1865 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3795 - accuracy: 0.2329 - val_loss: 0.4331 - val_accuracy: 0.1932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4271 - accuracy: 0.1574\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.157 total time=  51.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.7337 - accuracy: 0.1481 - val_loss: 0.9824 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5376 - accuracy: 0.1451 - val_loss: 0.4836 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4857 - accuracy: 0.1588 - val_loss: 0.4853 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4762 - accuracy: 0.1948 - val_loss: 0.5045 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4586 - accuracy: 0.1781 - val_loss: 0.4650 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4590 - accuracy: 0.1852 - val_loss: 0.5240 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4527 - accuracy: 0.2045 - val_loss: 0.4536 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4453 - accuracy: 0.2045 - val_loss: 0.4175 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.2009 - val_loss: 0.5371 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4429 - accuracy: 0.2146 - val_loss: 0.5815 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4256 - accuracy: 0.2095 - val_loss: 0.4301 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3988 - accuracy: 0.2146 - val_loss: 0.4631 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3893 - accuracy: 0.2415 - val_loss: 0.4385 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3578 - accuracy: 0.2806 - val_loss: 0.4349 - val_accuracy: 0.2216 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3497 - accuracy: 0.2867 - val_loss: 0.4362 - val_accuracy: 0.2284 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3453 - accuracy: 0.3034 - val_loss: 0.4250 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3421 - accuracy: 0.3303 - val_loss: 0.4322 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3389 - accuracy: 0.3379 - val_loss: 0.4422 - val_accuracy: 0.2257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4115 - accuracy: 0.1919\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.192 total time=  51.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 55ms/step - loss: 1.4903 - accuracy: 0.1863 - val_loss: 0.4587 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4300 - accuracy: 0.2142 - val_loss: 0.4272 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3987 - accuracy: 0.2711 - val_loss: 0.4170 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3835 - accuracy: 0.3102 - val_loss: 0.4332 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3707 - accuracy: 0.3264 - val_loss: 0.4254 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3453 - accuracy: 0.3807 - val_loss: 0.4057 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3418 - accuracy: 0.4168 - val_loss: 0.4612 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3318 - accuracy: 0.4228 - val_loss: 0.4266 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3085 - accuracy: 0.4731 - val_loss: 0.4341 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2856 - accuracy: 0.5183 - val_loss: 0.4992 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2858 - accuracy: 0.5264 - val_loss: 0.4514 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2360 - accuracy: 0.6178 - val_loss: 0.4472 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2212 - accuracy: 0.6345 - val_loss: 0.4466 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2110 - accuracy: 0.6584 - val_loss: 0.4480 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2041 - accuracy: 0.6655 - val_loss: 0.4567 - val_accuracy: 0.3189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1993 - accuracy: 0.6772 - val_loss: 0.4639 - val_accuracy: 0.3446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4089 - accuracy: 0.2475\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.247 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.1481 - accuracy: 0.1953 - val_loss: 0.4981 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4405 - accuracy: 0.2547 - val_loss: 0.4646 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4029 - accuracy: 0.2927 - val_loss: 0.4259 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3623 - accuracy: 0.3846 - val_loss: 0.4358 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 41ms/step - loss: 0.3371 - accuracy: 0.4262 - val_loss: 0.4254 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3098 - accuracy: 0.4845 - val_loss: 0.4879 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2917 - accuracy: 0.5211 - val_loss: 0.4711 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2609 - accuracy: 0.5835 - val_loss: 0.4530 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2415 - accuracy: 0.6129 - val_loss: 0.4667 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2158 - accuracy: 0.6667 - val_loss: 0.4768 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1560 - accuracy: 0.7742 - val_loss: 0.4965 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1380 - accuracy: 0.8087 - val_loss: 0.4989 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1294 - accuracy: 0.8224 - val_loss: 0.5037 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1245 - accuracy: 0.8366 - val_loss: 0.5159 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1181 - accuracy: 0.8463 - val_loss: 0.5170 - val_accuracy: 0.3459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4551 - accuracy: 0.2640\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.264 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.7126 - accuracy: 0.1974 - val_loss: 0.6269 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4824 - accuracy: 0.2846 - val_loss: 0.4737 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3804 - accuracy: 0.3628 - val_loss: 0.4448 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3474 - accuracy: 0.4221 - val_loss: 0.4317 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3066 - accuracy: 0.5043 - val_loss: 0.4322 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2844 - accuracy: 0.5566 - val_loss: 0.4409 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2554 - accuracy: 0.6154 - val_loss: 0.4796 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2684 - accuracy: 0.5911 - val_loss: 0.4622 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2072 - accuracy: 0.7149 - val_loss: 0.5072 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1504 - accuracy: 0.8153 - val_loss: 0.4590 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1252 - accuracy: 0.8584 - val_loss: 0.4744 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1158 - accuracy: 0.8747 - val_loss: 0.4709 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1069 - accuracy: 0.8909 - val_loss: 0.4802 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1006 - accuracy: 0.9021 - val_loss: 0.4860 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 0.4286 - accuracy: 0.2832\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.283 total time=  41.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 3.9280 - accuracy: 0.1782 - val_loss: 1.4685 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.8309 - accuracy: 0.2188 - val_loss: 0.5589 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4804 - accuracy: 0.1802 - val_loss: 0.4924 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4456 - accuracy: 0.2020 - val_loss: 0.4204 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4251 - accuracy: 0.2467 - val_loss: 0.4222 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4060 - accuracy: 0.2680 - val_loss: 0.4138 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3908 - accuracy: 0.3142 - val_loss: 0.4406 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3710 - accuracy: 0.3371 - val_loss: 0.4330 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3567 - accuracy: 0.3761 - val_loss: 0.4235 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3406 - accuracy: 0.4086 - val_loss: 0.4197 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3265 - accuracy: 0.4284 - val_loss: 0.4848 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2673 - accuracy: 0.5335 - val_loss: 0.4205 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2472 - accuracy: 0.5675 - val_loss: 0.4268 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2387 - accuracy: 0.5817 - val_loss: 0.4356 - val_accuracy: 0.3514 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.2319 - accuracy: 0.5990 - val_loss: 0.4423 - val_accuracy: 0.3243 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2246 - accuracy: 0.6183 - val_loss: 0.4487 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4224 - accuracy: 0.2201\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.220 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.9701 - accuracy: 0.1725 - val_loss: 0.8546 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6217 - accuracy: 0.2314 - val_loss: 0.5064 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5098 - accuracy: 0.2237 - val_loss: 0.4891 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4621 - accuracy: 0.2740 - val_loss: 0.5335 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4135 - accuracy: 0.2998 - val_loss: 0.4256 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3870 - accuracy: 0.3196 - val_loss: 0.4489 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3576 - accuracy: 0.3688 - val_loss: 0.4085 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3513 - accuracy: 0.3927 - val_loss: 0.4325 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3200 - accuracy: 0.4394 - val_loss: 0.4970 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3197 - accuracy: 0.4729 - val_loss: 0.5139 - val_accuracy: 0.3135 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3051 - accuracy: 0.4815 - val_loss: 0.4513 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2794 - accuracy: 0.5312 - val_loss: 1.2311 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2409 - accuracy: 0.6281 - val_loss: 0.4807 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1937 - accuracy: 0.6844 - val_loss: 0.4860 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1823 - accuracy: 0.7108 - val_loss: 0.4982 - val_accuracy: 0.3730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1737 - accuracy: 0.7296 - val_loss: 0.5003 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1655 - accuracy: 0.7489 - val_loss: 0.5206 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.3987 - accuracy: 0.2863\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.286 total time=  49.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.7458 - accuracy: 0.1796 - val_loss: 0.8637 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.0811 - accuracy: 0.2085 - val_loss: 0.7104 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5582 - accuracy: 0.2491 - val_loss: 0.4991 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4380 - accuracy: 0.2709 - val_loss: 0.5064 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4147 - accuracy: 0.3090 - val_loss: 0.4700 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3857 - accuracy: 0.3486 - val_loss: 0.4397 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3693 - accuracy: 0.3917 - val_loss: 0.4944 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3401 - accuracy: 0.4708 - val_loss: 0.4381 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3221 - accuracy: 0.4967 - val_loss: 0.4372 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3073 - accuracy: 0.5622 - val_loss: 0.4115 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2716 - accuracy: 0.5921 - val_loss: 0.5737 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2602 - accuracy: 0.6159 - val_loss: 0.5038 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2336 - accuracy: 0.6651 - val_loss: 0.6874 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2227 - accuracy: 0.6880 - val_loss: 0.5120 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1993 - accuracy: 0.7144 - val_loss: 0.6192 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1168 - accuracy: 0.8453 - val_loss: 0.5236 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0956 - accuracy: 0.8782 - val_loss: 0.5820 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0861 - accuracy: 0.8950 - val_loss: 0.5984 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0774 - accuracy: 0.9056 - val_loss: 0.6510 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0707 - accuracy: 0.9117 - val_loss: 0.6853 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4212 - accuracy: 0.3381\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.338 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 2.4319 - accuracy: 0.2056 - val_loss: 1.0353 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7487 - accuracy: 0.3619 - val_loss: 0.8081 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4357 - accuracy: 0.5259 - val_loss: 0.7042 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3272 - accuracy: 0.6122 - val_loss: 0.5968 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2151 - accuracy: 0.7614 - val_loss: 0.5793 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1755 - accuracy: 0.8086 - val_loss: 0.5518 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1688 - accuracy: 0.8462 - val_loss: 0.5766 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1172 - accuracy: 0.8980 - val_loss: 0.6030 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0986 - accuracy: 0.9294 - val_loss: 0.5855 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0712 - accuracy: 0.9614 - val_loss: 0.6103 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.6559 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0278 - accuracy: 0.9964 - val_loss: 0.6138 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0245 - accuracy: 0.9980 - val_loss: 0.6144 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.6190 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.6217 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0216 - accuracy: 0.9975 - val_loss: 0.6232 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5677 - accuracy: 0.4026\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.403 total time=  45.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.9937 - accuracy: 0.2121 - val_loss: 0.7701 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5573 - accuracy: 0.3450 - val_loss: 0.6676 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4668 - accuracy: 0.4307 - val_loss: 0.5561 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3154 - accuracy: 0.5622 - val_loss: 0.4642 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2581 - accuracy: 0.6667 - val_loss: 0.4866 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2221 - accuracy: 0.7286 - val_loss: 0.4635 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1606 - accuracy: 0.8270 - val_loss: 0.4843 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1321 - accuracy: 0.8864 - val_loss: 0.5248 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1412 - accuracy: 0.8549 - val_loss: 0.5524 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1038 - accuracy: 0.9219 - val_loss: 0.5318 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0845 - accuracy: 0.9396 - val_loss: 0.6419 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0495 - accuracy: 0.9858 - val_loss: 0.5507 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0382 - accuracy: 0.9964 - val_loss: 0.5491 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0356 - accuracy: 0.9970 - val_loss: 0.5512 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0335 - accuracy: 0.9975 - val_loss: 0.5491 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0321 - accuracy: 0.9975 - val_loss: 0.5520 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4723 - accuracy: 0.3726\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.373 total time=  45.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.0999 - accuracy: 0.1984 - val_loss: 0.8615 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5090 - accuracy: 0.4033 - val_loss: 0.5852 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3506 - accuracy: 0.5424 - val_loss: 0.5493 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2814 - accuracy: 0.6494 - val_loss: 0.6210 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2127 - accuracy: 0.7605 - val_loss: 0.4826 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1412 - accuracy: 0.8600 - val_loss: 0.5455 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1217 - accuracy: 0.8985 - val_loss: 0.5584 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1037 - accuracy: 0.9158 - val_loss: 0.5270 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0880 - accuracy: 0.9427 - val_loss: 0.5933 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0600 - accuracy: 0.9721 - val_loss: 0.6323 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0335 - accuracy: 0.9959 - val_loss: 0.5729 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0274 - accuracy: 0.9995 - val_loss: 0.5718 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0257 - accuracy: 0.9995 - val_loss: 0.5729 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0246 - accuracy: 0.9995 - val_loss: 0.5736 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0236 - accuracy: 0.9995 - val_loss: 0.5750 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4798 - accuracy: 0.4000\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.400 total time=  43.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.8577 - accuracy: 0.1756 - val_loss: 0.9007 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6585 - accuracy: 0.1843 - val_loss: 0.5314 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5040 - accuracy: 0.1650 - val_loss: 0.5313 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4853 - accuracy: 0.2056 - val_loss: 0.4989 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4529 - accuracy: 0.2193 - val_loss: 0.5968 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4490 - accuracy: 0.2335 - val_loss: 0.5076 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4366 - accuracy: 0.2690 - val_loss: 0.4376 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4251 - accuracy: 0.2685 - val_loss: 0.4229 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4172 - accuracy: 0.2904 - val_loss: 0.4246 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4047 - accuracy: 0.3117 - val_loss: 0.4134 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3832 - accuracy: 0.3320 - val_loss: 0.5239 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3828 - accuracy: 0.3497 - val_loss: 0.5352 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3593 - accuracy: 0.3574 - val_loss: 0.5318 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3587 - accuracy: 0.3614 - val_loss: 0.4251 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3688 - accuracy: 0.3685 - val_loss: 0.7066 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3276 - accuracy: 0.4041 - val_loss: 0.4259 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2953 - accuracy: 0.4208 - val_loss: 0.4206 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2890 - accuracy: 0.4330 - val_loss: 0.4393 - val_accuracy: 0.2905 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2839 - accuracy: 0.4421 - val_loss: 0.4473 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2793 - accuracy: 0.4472 - val_loss: 0.4876 - val_accuracy: 0.3095 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4333 - accuracy: 0.2627\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.263 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 5.3714 - accuracy: 0.1613 - val_loss: 0.4402 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5520 - accuracy: 0.1613 - val_loss: 0.5429 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5128 - accuracy: 0.1847 - val_loss: 0.5380 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5055 - accuracy: 0.1781 - val_loss: 1.2150 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4796 - accuracy: 0.2121 - val_loss: 0.5072 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4528 - accuracy: 0.2232 - val_loss: 0.5344 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3856 - accuracy: 0.2511 - val_loss: 0.4250 - val_accuracy: 0.1784 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3713 - accuracy: 0.2735 - val_loss: 0.4320 - val_accuracy: 0.2027 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3660 - accuracy: 0.2709 - val_loss: 0.4364 - val_accuracy: 0.2189 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3617 - accuracy: 0.2750 - val_loss: 0.4319 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3562 - accuracy: 0.3019 - val_loss: 0.4335 - val_accuracy: 0.2176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3528 - accuracy: 0.3135 - val_loss: 0.4255 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3468 - accuracy: 0.3369 - val_loss: 0.4262 - val_accuracy: 0.2486 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3447 - accuracy: 0.3394 - val_loss: 0.4266 - val_accuracy: 0.2635 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3439 - accuracy: 0.3420 - val_loss: 0.4273 - val_accuracy: 0.2622 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3432 - accuracy: 0.3404 - val_loss: 0.4262 - val_accuracy: 0.2568 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3428 - accuracy: 0.3415 - val_loss: 0.4262 - val_accuracy: 0.2662 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4174 - accuracy: 0.1787\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.179 total time=  49.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.8968 - accuracy: 0.1771 - val_loss: 0.5418 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5486 - accuracy: 0.1984 - val_loss: 0.5334 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5023 - accuracy: 0.1568 - val_loss: 0.4642 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4962 - accuracy: 0.1776 - val_loss: 0.5748 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4620 - accuracy: 0.2024 - val_loss: 0.5289 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4623 - accuracy: 0.2055 - val_loss: 0.5706 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4453 - accuracy: 0.2354 - val_loss: 0.5131 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4362 - accuracy: 0.2405 - val_loss: 0.5055 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3750 - accuracy: 0.2887 - val_loss: 0.4330 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3586 - accuracy: 0.2943 - val_loss: 0.4433 - val_accuracy: 0.2270 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3534 - accuracy: 0.3176 - val_loss: 0.4336 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3487 - accuracy: 0.3267 - val_loss: 0.4388 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3443 - accuracy: 0.3262 - val_loss: 0.4391 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3408 - accuracy: 0.3338 - val_loss: 0.4506 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3335 - accuracy: 0.3546 - val_loss: 0.4448 - val_accuracy: 0.2432 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3323 - accuracy: 0.3567 - val_loss: 0.4440 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3317 - accuracy: 0.3577 - val_loss: 0.4450 - val_accuracy: 0.2405 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3311 - accuracy: 0.3602 - val_loss: 0.4454 - val_accuracy: 0.2432 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3307 - accuracy: 0.3607 - val_loss: 0.4466 - val_accuracy: 0.2446 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4024 - accuracy: 0.2447\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.245 total time=  54.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 2.8772 - accuracy: 0.2056 - val_loss: 0.9414 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6387 - accuracy: 0.3391 - val_loss: 0.5934 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3889 - accuracy: 0.4751 - val_loss: 0.6089 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3054 - accuracy: 0.5635 - val_loss: 0.5078 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2367 - accuracy: 0.6812 - val_loss: 0.4922 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1925 - accuracy: 0.7604 - val_loss: 0.5079 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1559 - accuracy: 0.8269 - val_loss: 0.5501 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1507 - accuracy: 0.8198 - val_loss: 0.5601 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1055 - accuracy: 0.9071 - val_loss: 0.5506 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0778 - accuracy: 0.9442 - val_loss: 0.5958 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0380 - accuracy: 0.9914 - val_loss: 0.5693 - val_accuracy: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 0.5699 - val_accuracy: 0.4203 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 0.5747 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0275 - accuracy: 0.9985 - val_loss: 0.5775 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: 0.5789 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5094 - accuracy: 0.3661\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.366 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.1773 - accuracy: 0.1994 - val_loss: 0.8431 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5209 - accuracy: 0.3734 - val_loss: 0.5924 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3520 - accuracy: 0.5003 - val_loss: 0.4886 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2763 - accuracy: 0.6210 - val_loss: 0.5076 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2099 - accuracy: 0.7316 - val_loss: 0.5144 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1780 - accuracy: 0.7950 - val_loss: 0.4914 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1327 - accuracy: 0.8737 - val_loss: 0.5258 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1027 - accuracy: 0.9295 - val_loss: 0.5549 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.5201 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0488 - accuracy: 0.9904 - val_loss: 0.5195 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0454 - accuracy: 0.9924 - val_loss: 0.5221 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0427 - accuracy: 0.9924 - val_loss: 0.5263 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 0.5318 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4986 - accuracy: 0.3421\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.342 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.7165 - accuracy: 0.1958 - val_loss: 0.8787 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5628 - accuracy: 0.3562 - val_loss: 0.5690 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3743 - accuracy: 0.4866 - val_loss: 0.5357 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3157 - accuracy: 0.5576 - val_loss: 0.5546 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2558 - accuracy: 0.6631 - val_loss: 0.5554 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2093 - accuracy: 0.7347 - val_loss: 0.5392 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1767 - accuracy: 0.7910 - val_loss: 0.6057 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1455 - accuracy: 0.8316 - val_loss: 0.6258 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0902 - accuracy: 0.9188 - val_loss: 0.5625 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0699 - accuracy: 0.9513 - val_loss: 0.5601 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0627 - accuracy: 0.9625 - val_loss: 0.5690 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0584 - accuracy: 0.9650 - val_loss: 0.5726 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0547 - accuracy: 0.9706 - val_loss: 0.5737 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5175 - accuracy: 0.3005\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.301 total time=  38.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 14.1344 - accuracy: 0.1513 - val_loss: 0.6804 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6840 - accuracy: 0.1447 - val_loss: 0.6326 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6032 - accuracy: 0.1426 - val_loss: 0.5656 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5237 - accuracy: 0.1396 - val_loss: 0.4809 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4515 - accuracy: 0.1355 - val_loss: 0.4267 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4173 - accuracy: 0.1320 - val_loss: 0.4110 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4107 - accuracy: 0.1396 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1376 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1472 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1381 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4099 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.125 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 17.6608 - accuracy: 0.1847 - val_loss: 6.3937 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.5635 - accuracy: 0.2146 - val_loss: 0.8941 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7695 - accuracy: 0.1720 - val_loss: 0.4677 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5167 - accuracy: 0.1431 - val_loss: 0.5113 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5418 - accuracy: 0.1360 - val_loss: 0.6475 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5145 - accuracy: 0.1502 - val_loss: 0.5027 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5243 - accuracy: 0.1370 - val_loss: 0.5209 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4855 - accuracy: 0.1390 - val_loss: 0.4625 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4541 - accuracy: 0.1360 - val_loss: 0.4358 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4236 - accuracy: 0.1390 - val_loss: 0.4140 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4115 - accuracy: 0.1395 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4102 - accuracy: 0.1385 - val_loss: 0.4104 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1476 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1375 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1446 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1497 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4107 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.130 total time=  56.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 26.5498 - accuracy: 0.1725 - val_loss: 9.1073 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.3760 - accuracy: 0.2045 - val_loss: 0.6584 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7078 - accuracy: 0.1720 - val_loss: 0.8546 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5582 - accuracy: 0.1451 - val_loss: 0.5800 - val_accuracy: 0.1176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5037 - accuracy: 0.1471 - val_loss: 0.5169 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4963 - accuracy: 0.1492 - val_loss: 0.4626 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4853 - accuracy: 0.1547 - val_loss: 0.4876 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4600 - accuracy: 0.1395 - val_loss: 0.4367 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4245 - accuracy: 0.1461 - val_loss: 0.4145 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4121 - accuracy: 0.1431 - val_loss: 0.4105 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1324 - val_loss: 0.4103 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4102 - accuracy: 0.1481 - val_loss: 0.4107 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1436 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1405 - val_loss: 0.4105 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1481 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1471 - val_loss: 0.4104 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1436 - val_loss: 0.4105 - val_accuracy: 0.1514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4102 - accuracy: 0.1350\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.135 total time=  57.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.4711 - accuracy: 0.2096 - val_loss: 2.6263 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.0647 - accuracy: 0.3782 - val_loss: 2.0029 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.2941 - accuracy: 0.4858 - val_loss: 2.2000 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.4866 - accuracy: 0.5325 - val_loss: 2.8848 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.1879 - accuracy: 0.5909 - val_loss: 1.7949 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5755 - accuracy: 0.7645 - val_loss: 1.9863 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5734 - accuracy: 0.7827 - val_loss: 2.3952 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5781 - accuracy: 0.7665 - val_loss: 2.0184 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4544 - accuracy: 0.8183 - val_loss: 1.6366 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3143 - accuracy: 0.8741 - val_loss: 2.2507 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2733 - accuracy: 0.8843 - val_loss: 1.9133 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1793 - accuracy: 0.9218 - val_loss: 1.7090 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1047 - accuracy: 0.9609 - val_loss: 1.8798 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0857 - accuracy: 0.9685 - val_loss: 1.9334 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 1.5805 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 1.5532 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 1.5454 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.5486 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.5554 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 1.5547 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.6208 - accuracy: 0.4473\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.447 total time=  55.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 5.8951 - accuracy: 0.2090 - val_loss: 4.0348 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1768 - accuracy: 0.4145 - val_loss: 2.2799 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.2512 - accuracy: 0.5464 - val_loss: 3.2353 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.2005 - accuracy: 0.5977 - val_loss: 2.1657 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7237 - accuracy: 0.7270 - val_loss: 3.0457 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5161 - accuracy: 0.8113 - val_loss: 2.0310 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3898 - accuracy: 0.8478 - val_loss: 1.9063 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4274 - accuracy: 0.8488 - val_loss: 1.9925 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2568 - accuracy: 0.9127 - val_loss: 1.9869 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2973 - accuracy: 0.8945 - val_loss: 2.1538 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1915 - accuracy: 0.9315 - val_loss: 1.8483 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1987 - accuracy: 0.9376 - val_loss: 2.3076 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1269 - accuracy: 0.9584 - val_loss: 2.1480 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2380 - accuracy: 0.9163 - val_loss: 2.3143 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2346 - accuracy: 0.9188 - val_loss: 2.5175 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1718 - accuracy: 0.9462 - val_loss: 2.3219 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 2.0419 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.0383 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2049 - accuracy: 0.4416\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.442 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 6.4073 - accuracy: 0.2207 - val_loss: 3.7078 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.5295 - accuracy: 0.4049 - val_loss: 2.7996 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.5783 - accuracy: 0.5408 - val_loss: 2.6127 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.0889 - accuracy: 0.6114 - val_loss: 2.7970 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8555 - accuracy: 0.6895 - val_loss: 2.4616 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5955 - accuracy: 0.7854 - val_loss: 2.0916 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.8246 - accuracy: 0.7154 - val_loss: 3.1124 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6579 - accuracy: 0.7752 - val_loss: 2.1522 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2603 - accuracy: 0.8955 - val_loss: 2.0813 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2126 - accuracy: 0.9178 - val_loss: 2.1243 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1797 - accuracy: 0.9269 - val_loss: 2.1336 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0897 - accuracy: 0.9680 - val_loss: 2.0460 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0820 - accuracy: 0.9741 - val_loss: 2.3433 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0524 - accuracy: 0.9792 - val_loss: 1.9967 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1188 - accuracy: 0.9650 - val_loss: 2.2020 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 2.6162 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1344 - accuracy: 0.9472 - val_loss: 2.3427 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3801 - accuracy: 0.8752 - val_loss: 2.4197 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2938 - accuracy: 0.8803 - val_loss: 2.7132 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0586 - accuracy: 0.9797 - val_loss: 2.2390 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.2352 - accuracy: 0.4132\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.413 total time=  56.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 20.4146 - accuracy: 0.1629 - val_loss: 3.3733 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1695 - accuracy: 0.1614 - val_loss: 0.6373 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6318 - accuracy: 0.1340 - val_loss: 0.5839 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5382 - accuracy: 0.1386 - val_loss: 0.4838 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4451 - accuracy: 0.1386 - val_loss: 0.4181 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4120 - accuracy: 0.1416 - val_loss: 0.4103 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1371 - val_loss: 0.4104 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1426 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1442 - val_loss: 0.4101 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1335 - val_loss: 0.4102 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1462 - val_loss: 0.4101 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1396 - val_loss: 0.4103 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1416 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 14.6735 - accuracy: 0.1715 - val_loss: 9.6263 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.8509 - accuracy: 0.2192 - val_loss: 2.8573 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5161 - accuracy: 0.1761 - val_loss: 0.4712 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6009 - accuracy: 0.1339 - val_loss: 0.6237 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5775 - accuracy: 0.1456 - val_loss: 0.5386 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4891 - accuracy: 0.1456 - val_loss: 0.4486 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4286 - accuracy: 0.1441 - val_loss: 0.4132 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4112 - accuracy: 0.1421 - val_loss: 0.4102 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1309 - val_loss: 0.4104 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1395 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4102 - accuracy: 0.1380 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1421 - val_loss: 0.4103 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4103 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1507 - val_loss: 0.4104 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1401\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.140 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 12.4767 - accuracy: 0.1537 - val_loss: 2.9720 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.3031 - accuracy: 0.1456 - val_loss: 0.6320 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5985 - accuracy: 0.1380 - val_loss: 0.5566 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5858 - accuracy: 0.1390 - val_loss: 0.5407 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4913 - accuracy: 0.1431 - val_loss: 0.4439 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4224 - accuracy: 0.1431 - val_loss: 0.4115 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4106 - accuracy: 0.1400 - val_loss: 0.4108 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1324 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4104 - accuracy: 0.1390 - val_loss: 0.4110 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1537 - val_loss: 0.4108 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1466 - val_loss: 0.4110 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4103 - accuracy: 0.1365 - val_loss: 0.4114 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4113 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4112 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4112 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1502 - val_loss: 0.4111 - val_accuracy: 0.1203 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4115 - accuracy: 0.1492\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.149 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 6.9470 - accuracy: 0.2071 - val_loss: 2.1093 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.7392 - accuracy: 0.3807 - val_loss: 2.3112 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0062 - accuracy: 0.5005 - val_loss: 1.2460 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.6873 - accuracy: 0.6203 - val_loss: 1.3416 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7168 - accuracy: 0.6000 - val_loss: 1.2632 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3680 - accuracy: 0.7497 - val_loss: 1.4993 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2373 - accuracy: 0.8335 - val_loss: 1.2510 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1928 - accuracy: 0.8675 - val_loss: 1.2763 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0686 - accuracy: 0.9594 - val_loss: 0.9830 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0311 - accuracy: 0.9868 - val_loss: 0.9688 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.9758 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.9693 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0184 - accuracy: 0.9970 - val_loss: 0.9558 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.9615 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.9620 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.9592 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0133 - accuracy: 0.9985 - val_loss: 0.9561 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.9540 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 0.9580 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0108 - accuracy: 0.9995 - val_loss: 0.9519 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.9813 - accuracy: 0.4412\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.441 total time=  56.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 7.0944 - accuracy: 0.2273 - val_loss: 2.8369 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1457 - accuracy: 0.3617 - val_loss: 2.3653 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.1052 - accuracy: 0.4795 - val_loss: 1.5621 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6671 - accuracy: 0.5936 - val_loss: 1.6285 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5400 - accuracy: 0.6484 - val_loss: 1.0753 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2523 - accuracy: 0.7783 - val_loss: 1.1284 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2193 - accuracy: 0.8260 - val_loss: 0.9986 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1334 - accuracy: 0.8884 - val_loss: 0.9531 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0779 - accuracy: 0.9396 - val_loss: 1.2052 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0896 - accuracy: 0.9310 - val_loss: 0.9600 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0432 - accuracy: 0.9731 - val_loss: 0.9011 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0698 - accuracy: 0.9518 - val_loss: 1.0592 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1694 - accuracy: 0.8874 - val_loss: 1.6110 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2405 - accuracy: 0.8610 - val_loss: 0.9722 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0919 - accuracy: 0.9361 - val_loss: 1.2713 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0762 - accuracy: 0.9508 - val_loss: 1.3841 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0237 - accuracy: 0.9853 - val_loss: 1.0787 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0647 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 1.2331 - accuracy: 0.4091\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.409 total time=  55.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 7.8776 - accuracy: 0.2268 - val_loss: 3.6499 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.3147 - accuracy: 0.3998 - val_loss: 2.6920 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7194 - accuracy: 0.4795 - val_loss: 1.7484 - val_accuracy: 0.3189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6448 - accuracy: 0.6631 - val_loss: 1.5250 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4144 - accuracy: 0.7641 - val_loss: 1.6353 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3099 - accuracy: 0.8280 - val_loss: 1.6674 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2505 - accuracy: 0.8782 - val_loss: 1.3317 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1857 - accuracy: 0.8970 - val_loss: 1.1878 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0969 - accuracy: 0.9508 - val_loss: 1.3762 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0920 - accuracy: 0.9508 - val_loss: 1.3273 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0534 - accuracy: 0.9782 - val_loss: 1.2723 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0647 - accuracy: 0.9691 - val_loss: 1.5113 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2069 - accuracy: 0.9117 - val_loss: 1.5179 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0350 - accuracy: 0.9919 - val_loss: 1.3934 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 1.3690 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 1.3386 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.2431 - accuracy: 0.3888\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.389 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 28.6497 - accuracy: 0.1741 - val_loss: 3.9325 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 5.5478 - accuracy: 0.2218 - val_loss: 5.5574 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 4.4783 - accuracy: 0.2457 - val_loss: 6.5111 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.1439 - accuracy: 0.2797 - val_loss: 6.5920 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.8019 - accuracy: 0.2959 - val_loss: 1.5073 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.2321 - accuracy: 0.3259 - val_loss: 2.0167 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.7697 - accuracy: 0.3477 - val_loss: 4.2191 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6896 - accuracy: 0.3624 - val_loss: 2.0757 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5481 - accuracy: 0.4020 - val_loss: 1.5219 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.4874 - accuracy: 0.3868 - val_loss: 1.7909 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3721 - accuracy: 0.6665 - val_loss: 0.7458 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2345 - accuracy: 0.7487 - val_loss: 0.6787 - val_accuracy: 0.3959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1897 - accuracy: 0.7954 - val_loss: 0.6613 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1638 - accuracy: 0.8264 - val_loss: 0.6726 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1450 - accuracy: 0.8386 - val_loss: 0.6598 - val_accuracy: 0.3797 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1306 - accuracy: 0.8680 - val_loss: 0.6347 - val_accuracy: 0.4041 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1183 - accuracy: 0.8883 - val_loss: 0.6401 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1100 - accuracy: 0.9010 - val_loss: 0.6251 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.0992 - accuracy: 0.9132 - val_loss: 0.6141 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0909 - accuracy: 0.9355 - val_loss: 0.6425 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.6781 - accuracy: 0.4097\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.410 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 35.7216 - accuracy: 0.1832 - val_loss: 14.4561 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 11.3851 - accuracy: 0.2111 - val_loss: 6.8734 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.7881 - accuracy: 0.1842 - val_loss: 0.6502 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6409 - accuracy: 0.1400 - val_loss: 0.5687 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5388 - accuracy: 0.1786 - val_loss: 0.5370 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4866 - accuracy: 0.1872 - val_loss: 0.5714 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4527 - accuracy: 0.1700 - val_loss: 0.4364 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4231 - accuracy: 0.1624 - val_loss: 0.4150 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4140 - accuracy: 0.1451 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4099 - accuracy: 0.1481 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4100 - accuracy: 0.1451 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4101 - accuracy: 0.1487 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4099 - accuracy: 0.1446 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4099 - accuracy: 0.1360 - val_loss: 0.4106 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4109 - accuracy: 0.1512 - val_loss: 0.4114 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4095 - accuracy: 0.1380 - val_loss: 0.4110 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4098 - accuracy: 0.1421 - val_loss: 0.4107 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4092 - accuracy: 0.1476 - val_loss: 0.4151 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.1416 - val_loss: 0.4118 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4092 - accuracy: 0.1537 - val_loss: 0.4121 - val_accuracy: 0.1392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4105 - accuracy: 0.1299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.130 total time=  57.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 22.5405 - accuracy: 0.1689 - val_loss: 4.3728 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 5.2667 - accuracy: 0.2004 - val_loss: 2.6919 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.0955 - accuracy: 0.2060 - val_loss: 1.4863 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.2252 - accuracy: 0.2324 - val_loss: 1.2586 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.5158 - accuracy: 0.2050 - val_loss: 3.4198 - val_accuracy: 0.1162 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.4037 - accuracy: 0.1613 - val_loss: 1.4896 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9776 - accuracy: 0.1547 - val_loss: 0.5914 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9468 - accuracy: 0.1497 - val_loss: 0.6058 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9536 - accuracy: 0.1624 - val_loss: 0.8986 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8021 - accuracy: 0.1786 - val_loss: 0.7125 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7671 - accuracy: 0.1750 - val_loss: 0.5274 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5120 - accuracy: 0.1481 - val_loss: 0.5662 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4813 - accuracy: 0.1421 - val_loss: 0.4652 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4743 - accuracy: 0.1461 - val_loss: 0.4607 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4703 - accuracy: 0.1466 - val_loss: 0.5466 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4761 - accuracy: 0.1471 - val_loss: 0.4415 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4648 - accuracy: 0.1629 - val_loss: 0.5059 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4694 - accuracy: 0.1588 - val_loss: 0.4994 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4662 - accuracy: 0.1532 - val_loss: 0.4322 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4599 - accuracy: 0.1563 - val_loss: 0.5179 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5189 - accuracy: 0.1360\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.136 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 13.3921 - accuracy: 0.2091 - val_loss: 3.8212 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.5938 - accuracy: 0.4518 - val_loss: 4.0626 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.8530 - accuracy: 0.4457 - val_loss: 3.4562 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.6709 - accuracy: 0.6157 - val_loss: 3.1669 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0882 - accuracy: 0.6959 - val_loss: 3.1295 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.7389 - accuracy: 0.7604 - val_loss: 2.8714 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7391 - accuracy: 0.7853 - val_loss: 3.0086 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6944 - accuracy: 0.7772 - val_loss: 2.6694 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3605 - accuracy: 0.8746 - val_loss: 2.6085 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2890 - accuracy: 0.9056 - val_loss: 2.8112 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2821 - accuracy: 0.9112 - val_loss: 2.5204 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1143 - accuracy: 0.9629 - val_loss: 2.3348 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2595 - accuracy: 0.9244 - val_loss: 2.8809 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3916 - accuracy: 0.8741 - val_loss: 2.7922 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2886 - accuracy: 0.9142 - val_loss: 3.5466 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1571 - accuracy: 0.9518 - val_loss: 3.1073 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1526 - accuracy: 0.9635 - val_loss: 3.3289 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0401 - accuracy: 0.9929 - val_loss: 2.7143 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 2.7090 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6770 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.8127 - accuracy: 0.4331\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.433 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 11.1005 - accuracy: 0.2263 - val_loss: 4.4037 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.2608 - accuracy: 0.4181 - val_loss: 4.3649 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 3.8105 - accuracy: 0.4526 - val_loss: 6.9307 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.8090 - accuracy: 0.5190 - val_loss: 3.7095 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3096 - accuracy: 0.6905 - val_loss: 3.1750 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.9252 - accuracy: 0.7377 - val_loss: 2.6868 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5803 - accuracy: 0.8498 - val_loss: 2.6464 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4091 - accuracy: 0.8762 - val_loss: 2.5871 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2832 - accuracy: 0.9163 - val_loss: 2.1209 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3907 - accuracy: 0.8950 - val_loss: 2.5424 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2321 - accuracy: 0.9335 - val_loss: 2.6708 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1915 - accuracy: 0.9594 - val_loss: 2.7108 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1931 - accuracy: 0.9462 - val_loss: 2.9814 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3708 - accuracy: 0.9097 - val_loss: 3.1440 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0723 - accuracy: 0.9833 - val_loss: 2.4138 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0205 - accuracy: 0.9975 - val_loss: 2.3688 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 2.2893 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.2962 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 2.2944 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 2.3646 - accuracy: 0.4081\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.408 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.8119 - accuracy: 0.2171 - val_loss: 6.6470 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.3960 - accuracy: 0.4536 - val_loss: 6.3389 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 3.0603 - accuracy: 0.5317 - val_loss: 4.3978 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.1081 - accuracy: 0.6332 - val_loss: 4.2131 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.3735 - accuracy: 0.7484 - val_loss: 5.0716 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 1.4001 - accuracy: 0.7666 - val_loss: 6.3311 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.8692 - accuracy: 0.8189 - val_loss: 5.3510 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.6745 - accuracy: 0.8747 - val_loss: 4.4537 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6443 - accuracy: 0.8879 - val_loss: 4.0825 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5080 - accuracy: 0.9082 - val_loss: 4.7022 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4266 - accuracy: 0.9229 - val_loss: 4.3093 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3270 - accuracy: 0.9462 - val_loss: 4.4176 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.5744 - accuracy: 0.8970 - val_loss: 4.5273 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2866 - accuracy: 0.9599 - val_loss: 4.6089 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0481 - accuracy: 0.9959 - val_loss: 4.1266 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 4.0471 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 4.0446 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 4.0687 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 6.5808e-04 - accuracy: 1.0000 - val_loss: 4.0776 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 4.2369e-04 - accuracy: 1.0000 - val_loss: 4.0651 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 4.1662 - accuracy: 0.3980\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.398 total time=  55.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 24.8186 - accuracy: 0.1629 - val_loss: 14.9081 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.4055 - accuracy: 0.1832 - val_loss: 1.1733 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6822 - accuracy: 0.1650 - val_loss: 0.5587 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5674 - accuracy: 0.1411 - val_loss: 0.6357 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5670 - accuracy: 0.1350 - val_loss: 0.5133 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4898 - accuracy: 0.1442 - val_loss: 0.4533 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4282 - accuracy: 0.1355 - val_loss: 0.4123 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4108 - accuracy: 0.1289 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1442 - val_loss: 0.4102 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1376 - val_loss: 0.4103 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4104 - accuracy: 0.1355 - val_loss: 0.4100 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1452 - val_loss: 0.4100 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1457 - val_loss: 0.4102 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1391 - val_loss: 0.4102 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1442 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1467 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1497 - val_loss: 0.4101 - val_accuracy: 0.1459 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1247\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.125 total time=  58.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 27.2532 - accuracy: 0.1903 - val_loss: 10.2750 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 8.8633 - accuracy: 0.2314 - val_loss: 4.1140 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 4.4198 - accuracy: 0.2420 - val_loss: 3.1748 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 3.2296 - accuracy: 0.2293 - val_loss: 1.3218 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.6952 - accuracy: 0.2040 - val_loss: 1.8543 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.7162 - accuracy: 0.2024 - val_loss: 0.8782 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.0185 - accuracy: 0.2121 - val_loss: 1.5229 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.6071 - accuracy: 0.1781 - val_loss: 0.5266 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5604 - accuracy: 0.1466 - val_loss: 0.6111 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5420 - accuracy: 0.1461 - val_loss: 0.5617 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5265 - accuracy: 0.1522 - val_loss: 0.5233 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4829 - accuracy: 0.1710 - val_loss: 0.4610 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4364 - accuracy: 0.1695 - val_loss: 0.4224 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4103 - accuracy: 0.1547 - val_loss: 0.4109 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4417 - accuracy: 0.1598 - val_loss: 0.4127 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4052 - accuracy: 0.1761 - val_loss: 0.4104 - val_accuracy: 0.1432 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4157 - accuracy: 0.1578 - val_loss: 0.4118 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4055 - accuracy: 0.1532 - val_loss: 0.4120 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4071 - accuracy: 0.1689 - val_loss: 0.4113 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4046 - accuracy: 0.1695 - val_loss: 0.4114 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 27ms/step - loss: 0.4095 - accuracy: 0.1360\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.136 total time=  57.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 30.4468 - accuracy: 0.1613 - val_loss: 24.6379 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 10.7907 - accuracy: 0.2177 - val_loss: 4.9079 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1955 - accuracy: 0.1608 - val_loss: 0.4895 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6263 - accuracy: 0.1461 - val_loss: 0.6419 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6018 - accuracy: 0.1350 - val_loss: 0.5702 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5297 - accuracy: 0.1370 - val_loss: 0.4917 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4563 - accuracy: 0.1334 - val_loss: 0.4255 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4152 - accuracy: 0.1481 - val_loss: 0.4102 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1497 - val_loss: 0.4108 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1375 - val_loss: 0.4105 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1324 - val_loss: 0.4105 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4104 - accuracy: 0.1334 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4103 - accuracy: 0.1350 - val_loss: 0.4108 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1456 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1380 - val_loss: 0.4107 - val_accuracy: 0.1311 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4101 - accuracy: 0.1441 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4101 - accuracy: 0.1380 - val_loss: 0.4106 - val_accuracy: 0.1189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.1442\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.144 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 14.0700 - accuracy: 0.2320 - val_loss: 4.2703 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.9231 - accuracy: 0.4076 - val_loss: 3.8542 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.6401 - accuracy: 0.5310 - val_loss: 2.1575 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9151 - accuracy: 0.6558 - val_loss: 2.1055 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.7325 - accuracy: 0.7041 - val_loss: 2.2086 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5539 - accuracy: 0.7426 - val_loss: 1.9900 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3727 - accuracy: 0.7944 - val_loss: 2.1352 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2633 - accuracy: 0.8650 - val_loss: 1.5768 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1126 - accuracy: 0.9421 - val_loss: 1.6851 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1448 - accuracy: 0.9299 - val_loss: 1.8290 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1150 - accuracy: 0.9437 - val_loss: 1.6276 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0749 - accuracy: 0.9675 - val_loss: 1.8764 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0835 - accuracy: 0.9665 - val_loss: 1.8866 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.5448 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 1.5503 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.5448 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5417 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5439 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.5657 - accuracy: 0.4473\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.447 total time=  56.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 57ms/step - loss: 12.0472 - accuracy: 0.2283 - val_loss: 5.0580 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.5151 - accuracy: 0.3876 - val_loss: 3.1006 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.5413 - accuracy: 0.5028 - val_loss: 2.3179 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.8306 - accuracy: 0.6388 - val_loss: 1.5001 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.6213 - accuracy: 0.7042 - val_loss: 1.4312 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3840 - accuracy: 0.7955 - val_loss: 2.0054 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3397 - accuracy: 0.8280 - val_loss: 2.0877 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2868 - accuracy: 0.8564 - val_loss: 1.7533 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2028 - accuracy: 0.9021 - val_loss: 1.6534 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1453 - accuracy: 0.9249 - val_loss: 1.4907 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0272 - accuracy: 0.9893 - val_loss: 1.3571 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 1.3433 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 1.3529 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.3318 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.3410 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 1.3353 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.4216 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 1.4853 - accuracy: 0.4142\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.414 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 11.6775 - accuracy: 0.2177 - val_loss: 4.7846 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 2.3696 - accuracy: 0.4145 - val_loss: 2.4710 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1242 - accuracy: 0.5860 - val_loss: 2.2643 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1197 - accuracy: 0.6271 - val_loss: 2.2530 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 1.1945 - accuracy: 0.6190 - val_loss: 2.1981 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4712 - accuracy: 0.7986 - val_loss: 2.1130 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3124 - accuracy: 0.8645 - val_loss: 1.6113 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2117 - accuracy: 0.9097 - val_loss: 1.5021 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1239 - accuracy: 0.9411 - val_loss: 1.6855 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0689 - accuracy: 0.9691 - val_loss: 1.5287 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.0746 - accuracy: 0.9696 - val_loss: 1.3881 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 1.4775 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0579 - accuracy: 0.9756 - val_loss: 1.8347 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0833 - accuracy: 0.9655 - val_loss: 1.7260 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1164 - accuracy: 0.9543 - val_loss: 1.8082 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1013 - accuracy: 0.9574 - val_loss: 2.1133 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 1.5663 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 1.5575 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.4311 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 1.7507 - accuracy: 0.4030\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.403 total time=  56.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.2606 - accuracy: 0.1782 - val_loss: 0.6286 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.6056 - accuracy: 0.1797 - val_loss: 0.4767 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4649 - accuracy: 0.1934 - val_loss: 0.5044 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4380 - accuracy: 0.2218 - val_loss: 0.5175 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4368 - accuracy: 0.2442 - val_loss: 0.4447 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4146 - accuracy: 0.2787 - val_loss: 0.4649 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4045 - accuracy: 0.2939 - val_loss: 0.5334 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3883 - accuracy: 0.3340 - val_loss: 0.4188 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3710 - accuracy: 0.3421 - val_loss: 0.4718 - val_accuracy: 0.2676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3581 - accuracy: 0.3746 - val_loss: 0.4553 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3435 - accuracy: 0.4046 - val_loss: 0.4734 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3366 - accuracy: 0.4142 - val_loss: 0.4381 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3276 - accuracy: 0.4472 - val_loss: 0.4954 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2654 - accuracy: 0.5406 - val_loss: 0.4229 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2454 - accuracy: 0.5782 - val_loss: 0.4464 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2381 - accuracy: 0.5858 - val_loss: 0.4549 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2320 - accuracy: 0.6010 - val_loss: 0.4507 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2257 - accuracy: 0.6112 - val_loss: 0.4668 - val_accuracy: 0.3405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4179 - accuracy: 0.2546\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.255 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.1249 - accuracy: 0.1583 - val_loss: 0.7482 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5997 - accuracy: 0.1999 - val_loss: 0.5453 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4663 - accuracy: 0.2050 - val_loss: 0.4548 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4354 - accuracy: 0.2496 - val_loss: 0.4616 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4276 - accuracy: 0.2329 - val_loss: 0.4241 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4154 - accuracy: 0.2440 - val_loss: 0.5242 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4002 - accuracy: 0.3019 - val_loss: 0.4544 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3992 - accuracy: 0.3176 - val_loss: 0.4359 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3745 - accuracy: 0.3430 - val_loss: 0.4712 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3615 - accuracy: 0.3719 - val_loss: 0.5409 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3095 - accuracy: 0.4581 - val_loss: 0.3985 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2872 - accuracy: 0.5028 - val_loss: 0.4016 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2801 - accuracy: 0.5200 - val_loss: 0.4072 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2729 - accuracy: 0.5342 - val_loss: 0.4137 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2673 - accuracy: 0.5449 - val_loss: 0.4174 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2599 - accuracy: 0.5647 - val_loss: 0.4207 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2505 - accuracy: 0.5926 - val_loss: 0.4249 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2492 - accuracy: 0.5977 - val_loss: 0.4257 - val_accuracy: 0.3176 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2483 - accuracy: 0.5941 - val_loss: 0.4273 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2474 - accuracy: 0.6002 - val_loss: 0.4275 - val_accuracy: 0.3230 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4214 - accuracy: 0.3208\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.321 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 2.5312 - accuracy: 0.1761 - val_loss: 0.5311 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4717 - accuracy: 0.1618 - val_loss: 0.4732 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4636 - accuracy: 0.1958 - val_loss: 0.5129 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4458 - accuracy: 0.2075 - val_loss: 0.4757 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4265 - accuracy: 0.2324 - val_loss: 0.4257 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4167 - accuracy: 0.2516 - val_loss: 0.5200 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4048 - accuracy: 0.2684 - val_loss: 0.4653 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3916 - accuracy: 0.3075 - val_loss: 0.4293 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3802 - accuracy: 0.3146 - val_loss: 0.4872 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3660 - accuracy: 0.3582 - val_loss: 0.4763 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3064 - accuracy: 0.4302 - val_loss: 0.3963 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2911 - accuracy: 0.4754 - val_loss: 0.4076 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2841 - accuracy: 0.4916 - val_loss: 0.4095 - val_accuracy: 0.3446 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2780 - accuracy: 0.4957 - val_loss: 0.4115 - val_accuracy: 0.3338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2722 - accuracy: 0.5180 - val_loss: 0.4164 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2666 - accuracy: 0.5297 - val_loss: 0.4214 - val_accuracy: 0.3419 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2581 - accuracy: 0.5413 - val_loss: 0.4226 - val_accuracy: 0.3392 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2569 - accuracy: 0.5429 - val_loss: 0.4249 - val_accuracy: 0.3419 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2563 - accuracy: 0.5474 - val_loss: 0.4240 - val_accuracy: 0.3405 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2556 - accuracy: 0.5530 - val_loss: 0.4270 - val_accuracy: 0.3378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4126 - accuracy: 0.3431\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.343 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 1.0688 - accuracy: 0.2041 - val_loss: 0.6785 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4537 - accuracy: 0.3426 - val_loss: 0.4453 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3323 - accuracy: 0.4970 - val_loss: 0.4346 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2947 - accuracy: 0.5472 - val_loss: 0.4381 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2424 - accuracy: 0.6655 - val_loss: 0.4251 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2141 - accuracy: 0.7269 - val_loss: 0.4245 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1757 - accuracy: 0.7975 - val_loss: 0.4602 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1376 - accuracy: 0.8726 - val_loss: 0.4623 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1052 - accuracy: 0.9193 - val_loss: 0.4862 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0931 - accuracy: 0.9365 - val_loss: 0.5358 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0820 - accuracy: 0.9386 - val_loss: 0.5514 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.5323 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0306 - accuracy: 0.9959 - val_loss: 0.5446 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0277 - accuracy: 0.9970 - val_loss: 0.5430 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0256 - accuracy: 0.9975 - val_loss: 0.5447 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.5557 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4143 - accuracy: 0.4158\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.416 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.0334 - accuracy: 0.1908 - val_loss: 0.4935 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4036 - accuracy: 0.3389 - val_loss: 0.4450 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3444 - accuracy: 0.4521 - val_loss: 0.4244 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3042 - accuracy: 0.5322 - val_loss: 0.4177 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2630 - accuracy: 0.6210 - val_loss: 0.4127 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2338 - accuracy: 0.6692 - val_loss: 0.4691 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2057 - accuracy: 0.7326 - val_loss: 0.4438 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1659 - accuracy: 0.8011 - val_loss: 0.5759 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1360 - accuracy: 0.8447 - val_loss: 0.5328 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1376 - accuracy: 0.8417 - val_loss: 0.5577 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0690 - accuracy: 0.9488 - val_loss: 0.5163 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0532 - accuracy: 0.9706 - val_loss: 0.5243 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0474 - accuracy: 0.9767 - val_loss: 0.5392 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0431 - accuracy: 0.9797 - val_loss: 0.5480 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0389 - accuracy: 0.9827 - val_loss: 0.5538 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4273 - accuracy: 0.3472\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.347 total time=  44.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.3323 - accuracy: 0.1837 - val_loss: 0.4747 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4289 - accuracy: 0.2481 - val_loss: 0.4245 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3968 - accuracy: 0.2796 - val_loss: 0.4390 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3752 - accuracy: 0.3364 - val_loss: 0.4201 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3538 - accuracy: 0.3886 - val_loss: 0.4141 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3360 - accuracy: 0.4353 - val_loss: 0.4279 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3105 - accuracy: 0.4947 - val_loss: 0.4368 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2891 - accuracy: 0.5408 - val_loss: 0.4365 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2693 - accuracy: 0.5835 - val_loss: 0.4498 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2423 - accuracy: 0.6256 - val_loss: 0.4828 - val_accuracy: 0.3068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1918 - accuracy: 0.7296 - val_loss: 0.4634 - val_accuracy: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1789 - accuracy: 0.7570 - val_loss: 0.4686 - val_accuracy: 0.3311 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1727 - accuracy: 0.7626 - val_loss: 0.4790 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1676 - accuracy: 0.7717 - val_loss: 0.4795 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1628 - accuracy: 0.7788 - val_loss: 0.4930 - val_accuracy: 0.3392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.3944 - accuracy: 0.2944\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.294 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.4886 - accuracy: 0.1645 - val_loss: 0.4709 - val_accuracy: 0.1203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5235 - accuracy: 0.1543 - val_loss: 0.5328 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4949 - accuracy: 0.1772 - val_loss: 0.4504 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.5051 - accuracy: 0.1558 - val_loss: 0.4758 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4787 - accuracy: 0.1868 - val_loss: 0.4610 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4613 - accuracy: 0.2086 - val_loss: 0.8147 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4633 - accuracy: 0.2320 - val_loss: 0.5287 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4408 - accuracy: 0.2305 - val_loss: 0.6464 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3813 - accuracy: 0.2858 - val_loss: 0.4348 - val_accuracy: 0.2608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3593 - accuracy: 0.3066 - val_loss: 0.4338 - val_accuracy: 0.2541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3538 - accuracy: 0.3178 - val_loss: 0.4527 - val_accuracy: 0.2635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3503 - accuracy: 0.3244 - val_loss: 0.4414 - val_accuracy: 0.2622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3457 - accuracy: 0.3208 - val_loss: 0.4455 - val_accuracy: 0.2595 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3415 - accuracy: 0.3411 - val_loss: 0.4454 - val_accuracy: 0.2581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3385 - accuracy: 0.3416 - val_loss: 0.4518 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3334 - accuracy: 0.3543 - val_loss: 0.4566 - val_accuracy: 0.2676 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3318 - accuracy: 0.3538 - val_loss: 0.4568 - val_accuracy: 0.2743 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3312 - accuracy: 0.3543 - val_loss: 0.4574 - val_accuracy: 0.2689 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3307 - accuracy: 0.3569 - val_loss: 0.4589 - val_accuracy: 0.2676 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3303 - accuracy: 0.3563 - val_loss: 0.4582 - val_accuracy: 0.2716 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4307 - accuracy: 0.2262\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.226 total time=  57.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 1.7889 - accuracy: 0.1507 - val_loss: 0.4934 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4992 - accuracy: 0.1608 - val_loss: 0.4469 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4871 - accuracy: 0.1755 - val_loss: 0.4398 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4678 - accuracy: 0.1928 - val_loss: 0.5521 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4615 - accuracy: 0.2045 - val_loss: 0.4805 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4530 - accuracy: 0.2156 - val_loss: 0.4796 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4718 - accuracy: 0.2344 - val_loss: 0.4288 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4322 - accuracy: 0.2552 - val_loss: 0.4845 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4321 - accuracy: 0.2527 - val_loss: 0.4937 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4202 - accuracy: 0.2790 - val_loss: 0.4480 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4109 - accuracy: 0.2704 - val_loss: 0.4335 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3944 - accuracy: 0.2938 - val_loss: 0.4310 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3493 - accuracy: 0.3415 - val_loss: 0.4283 - val_accuracy: 0.2770 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3289 - accuracy: 0.3749 - val_loss: 0.4412 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3214 - accuracy: 0.3947 - val_loss: 0.4514 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3138 - accuracy: 0.4089 - val_loss: 0.4429 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3086 - accuracy: 0.4130 - val_loss: 0.4453 - val_accuracy: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3032 - accuracy: 0.4262 - val_loss: 0.4616 - val_accuracy: 0.2757 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2968 - accuracy: 0.4297 - val_loss: 0.4607 - val_accuracy: 0.2892 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2958 - accuracy: 0.4282 - val_loss: 0.4601 - val_accuracy: 0.2824 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4323 - accuracy: 0.2772\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.277 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.0964 - accuracy: 0.1476 - val_loss: 0.5299 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5234 - accuracy: 0.1568 - val_loss: 0.5219 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4960 - accuracy: 0.1720 - val_loss: 0.5552 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4896 - accuracy: 0.1725 - val_loss: 0.5318 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4872 - accuracy: 0.1710 - val_loss: 0.5502 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4748 - accuracy: 0.1923 - val_loss: 0.5258 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4716 - accuracy: 0.2090 - val_loss: 0.5311 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4147 - accuracy: 0.1872 - val_loss: 0.4168 - val_accuracy: 0.1865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3863 - accuracy: 0.2374 - val_loss: 0.4152 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3812 - accuracy: 0.2456 - val_loss: 0.4184 - val_accuracy: 0.1905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3785 - accuracy: 0.2405 - val_loss: 0.4170 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3754 - accuracy: 0.2537 - val_loss: 0.4185 - val_accuracy: 0.1919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3719 - accuracy: 0.2623 - val_loss: 0.4221 - val_accuracy: 0.2216 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3683 - accuracy: 0.2740 - val_loss: 0.4195 - val_accuracy: 0.2284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3624 - accuracy: 0.2907 - val_loss: 0.4216 - val_accuracy: 0.2243 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3613 - accuracy: 0.2912 - val_loss: 0.4221 - val_accuracy: 0.2284 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3609 - accuracy: 0.2882 - val_loss: 0.4226 - val_accuracy: 0.2297 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3604 - accuracy: 0.2851 - val_loss: 0.4220 - val_accuracy: 0.2257 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3599 - accuracy: 0.2943 - val_loss: 0.4232 - val_accuracy: 0.2297 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4106 - accuracy: 0.2213\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.221 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 56ms/step - loss: 1.4320 - accuracy: 0.1822 - val_loss: 0.4698 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4267 - accuracy: 0.2244 - val_loss: 0.4419 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4006 - accuracy: 0.2655 - val_loss: 0.4238 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3727 - accuracy: 0.3259 - val_loss: 0.4220 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3545 - accuracy: 0.3660 - val_loss: 0.4399 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3466 - accuracy: 0.3949 - val_loss: 0.4326 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3202 - accuracy: 0.4442 - val_loss: 0.4374 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3126 - accuracy: 0.4701 - val_loss: 0.4932 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3008 - accuracy: 0.4924 - val_loss: 0.4683 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2438 - accuracy: 0.6076 - val_loss: 0.4511 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2266 - accuracy: 0.6386 - val_loss: 0.4555 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2195 - accuracy: 0.6619 - val_loss: 0.4610 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2114 - accuracy: 0.6777 - val_loss: 0.4577 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2064 - accuracy: 0.6944 - val_loss: 0.4690 - val_accuracy: 0.3203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4114 - accuracy: 0.2637\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.264 total time=  41.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.4099 - accuracy: 0.1857 - val_loss: 0.5539 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4427 - accuracy: 0.2943 - val_loss: 0.4660 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3643 - accuracy: 0.3962 - val_loss: 0.4422 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3340 - accuracy: 0.4779 - val_loss: 0.4598 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2968 - accuracy: 0.5403 - val_loss: 0.4395 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2660 - accuracy: 0.6043 - val_loss: 0.4917 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2465 - accuracy: 0.6281 - val_loss: 0.4725 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2009 - accuracy: 0.7108 - val_loss: 0.4894 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1615 - accuracy: 0.7864 - val_loss: 0.5526 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1340 - accuracy: 0.8346 - val_loss: 0.5558 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0765 - accuracy: 0.9198 - val_loss: 0.5160 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0617 - accuracy: 0.9498 - val_loss: 0.5236 - val_accuracy: 0.3932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0553 - accuracy: 0.9584 - val_loss: 0.5362 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0504 - accuracy: 0.9670 - val_loss: 0.5386 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0464 - accuracy: 0.9726 - val_loss: 0.5492 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4297 - accuracy: 0.3421\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.342 total time=  44.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.5846 - accuracy: 0.1796 - val_loss: 0.4522 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4183 - accuracy: 0.2227 - val_loss: 0.4289 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3999 - accuracy: 0.2638 - val_loss: 0.4138 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3777 - accuracy: 0.3105 - val_loss: 0.4090 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3549 - accuracy: 0.3617 - val_loss: 0.4130 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3449 - accuracy: 0.3825 - val_loss: 0.4441 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3328 - accuracy: 0.4054 - val_loss: 0.4483 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3177 - accuracy: 0.4404 - val_loss: 0.4316 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3036 - accuracy: 0.4789 - val_loss: 0.4663 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2506 - accuracy: 0.5967 - val_loss: 0.4403 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2310 - accuracy: 0.6393 - val_loss: 0.4370 - val_accuracy: 0.3284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2234 - accuracy: 0.6611 - val_loss: 0.4384 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2148 - accuracy: 0.6794 - val_loss: 0.4410 - val_accuracy: 0.3270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2079 - accuracy: 0.6966 - val_loss: 0.4572 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4102 - accuracy: 0.2548\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.255 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.6971 - accuracy: 0.1853 - val_loss: 0.8396 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.9643 - accuracy: 0.2152 - val_loss: 0.5119 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5381 - accuracy: 0.2416 - val_loss: 0.4365 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4262 - accuracy: 0.2431 - val_loss: 0.4809 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4066 - accuracy: 0.2878 - val_loss: 0.4711 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4016 - accuracy: 0.3330 - val_loss: 0.4896 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3747 - accuracy: 0.3832 - val_loss: 0.4925 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3492 - accuracy: 0.4208 - val_loss: 0.3955 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3325 - accuracy: 0.4467 - val_loss: 0.4812 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3076 - accuracy: 0.5107 - val_loss: 0.5118 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2989 - accuracy: 0.5244 - val_loss: 0.4329 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2785 - accuracy: 0.5716 - val_loss: 0.6529 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2587 - accuracy: 0.5959 - val_loss: 0.5408 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1902 - accuracy: 0.7294 - val_loss: 0.4580 - val_accuracy: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1541 - accuracy: 0.7731 - val_loss: 0.4889 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1433 - accuracy: 0.8000 - val_loss: 0.4838 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1329 - accuracy: 0.8168 - val_loss: 0.5056 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1237 - accuracy: 0.8289 - val_loss: 0.5292 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4034 - accuracy: 0.3164\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.316 total time=  52.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.5629 - accuracy: 0.1786 - val_loss: 0.7302 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.7266 - accuracy: 0.2354 - val_loss: 0.5037 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4941 - accuracy: 0.2648 - val_loss: 0.4291 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4316 - accuracy: 0.2943 - val_loss: 0.4387 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3875 - accuracy: 0.3506 - val_loss: 0.4764 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3701 - accuracy: 0.3790 - val_loss: 0.5066 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3533 - accuracy: 0.4262 - val_loss: 0.4105 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3276 - accuracy: 0.4749 - val_loss: 0.4626 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3092 - accuracy: 0.5124 - val_loss: 0.4150 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2880 - accuracy: 0.5520 - val_loss: 0.5520 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2688 - accuracy: 0.5997 - val_loss: 0.4474 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2469 - accuracy: 0.6210 - val_loss: 0.8762 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1779 - accuracy: 0.7610 - val_loss: 0.4698 - val_accuracy: 0.4014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1476 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1359 - accuracy: 0.8209 - val_loss: 0.4928 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1273 - accuracy: 0.8361 - val_loss: 0.5201 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1194 - accuracy: 0.8493 - val_loss: 0.5235 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4098 - accuracy: 0.3178\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.318 total time=  49.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 2.9937 - accuracy: 0.1776 - val_loss: 1.2039 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.6673 - accuracy: 0.2121 - val_loss: 0.4906 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4663 - accuracy: 0.2182 - val_loss: 0.5548 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4519 - accuracy: 0.2440 - val_loss: 0.4489 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4100 - accuracy: 0.2897 - val_loss: 0.4168 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4118 - accuracy: 0.3313 - val_loss: 0.4747 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3725 - accuracy: 0.3709 - val_loss: 0.4451 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3654 - accuracy: 0.4110 - val_loss: 0.4629 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3420 - accuracy: 0.4495 - val_loss: 0.4629 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3128 - accuracy: 0.4840 - val_loss: 0.5856 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2520 - accuracy: 0.5809 - val_loss: 0.4380 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2234 - accuracy: 0.6220 - val_loss: 0.4467 - val_accuracy: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.2121 - accuracy: 0.6464 - val_loss: 0.4336 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2039 - accuracy: 0.6621 - val_loss: 0.4501 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1967 - accuracy: 0.6717 - val_loss: 0.4418 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4058 - accuracy: 0.2873\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.287 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 1.9578 - accuracy: 0.1954 - val_loss: 0.6019 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4790 - accuracy: 0.3350 - val_loss: 0.5303 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3939 - accuracy: 0.4147 - val_loss: 0.4437 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3293 - accuracy: 0.5173 - val_loss: 0.4762 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2968 - accuracy: 0.5701 - val_loss: 0.4345 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2376 - accuracy: 0.6970 - val_loss: 0.4347 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2047 - accuracy: 0.7442 - val_loss: 0.4494 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1691 - accuracy: 0.8335 - val_loss: 0.4734 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1423 - accuracy: 0.8619 - val_loss: 0.5575 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1232 - accuracy: 0.8898 - val_loss: 0.4967 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0759 - accuracy: 0.9650 - val_loss: 0.4960 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0672 - accuracy: 0.9716 - val_loss: 0.5015 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0626 - accuracy: 0.9777 - val_loss: 0.5017 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0590 - accuracy: 0.9797 - val_loss: 0.5099 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.5103 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4352 - accuracy: 0.3651\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.365 total time=  43.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.6602 - accuracy: 0.2045 - val_loss: 0.5505 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4553 - accuracy: 0.3343 - val_loss: 0.4463 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3521 - accuracy: 0.4526 - val_loss: 0.4872 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2989 - accuracy: 0.5571 - val_loss: 0.4365 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2892 - accuracy: 0.5997 - val_loss: 0.4449 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2575 - accuracy: 0.6474 - val_loss: 0.4416 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2070 - accuracy: 0.7316 - val_loss: 0.4398 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1696 - accuracy: 0.8123 - val_loss: 0.4779 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1627 - accuracy: 0.8133 - val_loss: 0.5222 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1053 - accuracy: 0.9173 - val_loss: 0.4810 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0860 - accuracy: 0.9432 - val_loss: 0.4868 - val_accuracy: 0.4068 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0798 - accuracy: 0.9503 - val_loss: 0.4865 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0753 - accuracy: 0.9538 - val_loss: 0.4879 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0711 - accuracy: 0.9599 - val_loss: 0.4918 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4393 - accuracy: 0.3279\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.328 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 1.9757 - accuracy: 0.1943 - val_loss: 0.5718 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4935 - accuracy: 0.3064 - val_loss: 0.5354 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4047 - accuracy: 0.3856 - val_loss: 0.4368 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3338 - accuracy: 0.4906 - val_loss: 0.4371 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2960 - accuracy: 0.5637 - val_loss: 0.4487 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2679 - accuracy: 0.6200 - val_loss: 0.4416 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2444 - accuracy: 0.6692 - val_loss: 0.4725 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.2234 - accuracy: 0.7123 - val_loss: 0.4864 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1795 - accuracy: 0.8087 - val_loss: 0.4540 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1675 - accuracy: 0.8392 - val_loss: 0.4496 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1630 - accuracy: 0.8529 - val_loss: 0.4549 - val_accuracy: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1598 - accuracy: 0.8579 - val_loss: 0.4536 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1555 - accuracy: 0.8640 - val_loss: 0.4548 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4463 - accuracy: 0.2964\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.296 total time=  38.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 5.5645 - accuracy: 0.1909 - val_loss: 1.3732 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.5850 - accuracy: 0.1822 - val_loss: 0.5381 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5418 - accuracy: 0.1878 - val_loss: 0.7524 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4535 - accuracy: 0.1975 - val_loss: 0.5381 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.4554 - accuracy: 0.2091 - val_loss: 0.4723 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4703 - accuracy: 0.2147 - val_loss: 0.4989 - val_accuracy: 0.1770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4256 - accuracy: 0.2406 - val_loss: 0.4731 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4145 - accuracy: 0.2594 - val_loss: 0.5313 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4184 - accuracy: 0.2416 - val_loss: 0.4667 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4042 - accuracy: 0.2802 - val_loss: 0.5174 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3966 - accuracy: 0.2944 - val_loss: 0.4637 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.3862 - accuracy: 0.3305 - val_loss: 0.4594 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3897 - accuracy: 0.3137 - val_loss: 0.4666 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4003 - accuracy: 0.3234 - val_loss: 0.5166 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3826 - accuracy: 0.3198 - val_loss: 0.5693 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3688 - accuracy: 0.3396 - val_loss: 0.4455 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3584 - accuracy: 0.3584 - val_loss: 0.4735 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3633 - accuracy: 0.3629 - val_loss: 0.5000 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3518 - accuracy: 0.3883 - val_loss: 0.5074 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3473 - accuracy: 0.3858 - val_loss: 0.4870 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4851 - accuracy: 0.2434\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.243 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 5.5047 - accuracy: 0.1781 - val_loss: 0.8380 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5387 - accuracy: 0.1938 - val_loss: 0.4886 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4985 - accuracy: 0.1796 - val_loss: 0.8517 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4916 - accuracy: 0.1837 - val_loss: 0.4589 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4713 - accuracy: 0.2212 - val_loss: 0.5331 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4671 - accuracy: 0.2273 - val_loss: 0.5833 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4427 - accuracy: 0.2486 - val_loss: 0.4944 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4400 - accuracy: 0.2501 - val_loss: 0.4895 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4201 - accuracy: 0.2927 - val_loss: 0.4439 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4170 - accuracy: 0.2998 - val_loss: 0.4649 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4206 - accuracy: 0.3070 - val_loss: 0.4553 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3999 - accuracy: 0.3217 - val_loss: 0.4230 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3888 - accuracy: 0.3536 - val_loss: 0.4191 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3648 - accuracy: 0.3577 - val_loss: 0.4398 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3466 - accuracy: 0.3765 - val_loss: 0.4184 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3440 - accuracy: 0.4008 - val_loss: 0.5054 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3451 - accuracy: 0.3993 - val_loss: 0.4146 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3229 - accuracy: 0.4272 - val_loss: 0.4260 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3125 - accuracy: 0.4592 - val_loss: 0.4954 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3200 - accuracy: 0.4485 - val_loss: 0.4500 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4429 - accuracy: 0.3036\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.304 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 4.3415 - accuracy: 0.1583 - val_loss: 0.8523 - val_accuracy: 0.1270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.5785 - accuracy: 0.1700 - val_loss: 0.4992 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4893 - accuracy: 0.1684 - val_loss: 0.4935 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4776 - accuracy: 0.1603 - val_loss: 0.4584 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4608 - accuracy: 0.1958 - val_loss: 0.4425 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4577 - accuracy: 0.1857 - val_loss: 0.4955 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4458 - accuracy: 0.2065 - val_loss: 0.4845 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4473 - accuracy: 0.2146 - val_loss: 0.4281 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.4374 - accuracy: 0.2243 - val_loss: 0.4235 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4356 - accuracy: 0.2187 - val_loss: 2.5062 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4529 - accuracy: 0.2430 - val_loss: 0.4580 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4263 - accuracy: 0.2258 - val_loss: 0.4650 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4126 - accuracy: 0.2491 - val_loss: 0.4249 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4130 - accuracy: 0.2593 - val_loss: 0.5934 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3594 - accuracy: 0.2988 - val_loss: 0.4263 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3480 - accuracy: 0.3176 - val_loss: 0.4251 - val_accuracy: 0.2297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3429 - accuracy: 0.3349 - val_loss: 0.4469 - val_accuracy: 0.2608 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3385 - accuracy: 0.3369 - val_loss: 0.4638 - val_accuracy: 0.2622 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.3346 - accuracy: 0.3546 - val_loss: 0.4481 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4167 - accuracy: 0.1766\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.177 total time=  55.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 2.9778 - accuracy: 0.1726 - val_loss: 0.7099 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4958 - accuracy: 0.3234 - val_loss: 0.5356 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3876 - accuracy: 0.3807 - val_loss: 0.4493 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3467 - accuracy: 0.4569 - val_loss: 0.4886 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3084 - accuracy: 0.5208 - val_loss: 0.4698 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2761 - accuracy: 0.5827 - val_loss: 0.4635 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2342 - accuracy: 0.6619 - val_loss: 0.5100 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1890 - accuracy: 0.7442 - val_loss: 0.4881 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1269 - accuracy: 0.8635 - val_loss: 0.4748 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1135 - accuracy: 0.8904 - val_loss: 0.4793 - val_accuracy: 0.3716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1072 - accuracy: 0.9046 - val_loss: 0.4886 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1012 - accuracy: 0.9127 - val_loss: 0.4935 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0961 - accuracy: 0.9223 - val_loss: 0.4990 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 0.4487 - accuracy: 0.2941\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.294 total time=  38.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 57ms/step - loss: 3.1248 - accuracy: 0.1801 - val_loss: 0.6238 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4876 - accuracy: 0.3054 - val_loss: 0.4851 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3705 - accuracy: 0.4084 - val_loss: 0.4560 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3220 - accuracy: 0.4855 - val_loss: 0.4540 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.3127 - accuracy: 0.5271 - val_loss: 0.4684 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2721 - accuracy: 0.6022 - val_loss: 0.4650 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2157 - accuracy: 0.6981 - val_loss: 0.4757 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1929 - accuracy: 0.7316 - val_loss: 0.5109 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1534 - accuracy: 0.8016 - val_loss: 0.5529 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0939 - accuracy: 0.9183 - val_loss: 0.5244 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0769 - accuracy: 0.9447 - val_loss: 0.5325 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0696 - accuracy: 0.9579 - val_loss: 0.5351 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0646 - accuracy: 0.9619 - val_loss: 0.5541 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0597 - accuracy: 0.9670 - val_loss: 0.5550 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.4531 - accuracy: 0.3168\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.317 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 56ms/step - loss: 2.6750 - accuracy: 0.2050 - val_loss: 0.9608 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.5934 - accuracy: 0.3379 - val_loss: 0.6225 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.3962 - accuracy: 0.4541 - val_loss: 0.5209 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.3128 - accuracy: 0.5718 - val_loss: 0.5459 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.2680 - accuracy: 0.6408 - val_loss: 0.5191 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.2064 - accuracy: 0.7362 - val_loss: 0.5356 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.1826 - accuracy: 0.7813 - val_loss: 0.5586 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.1324 - accuracy: 0.8640 - val_loss: 0.5726 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0902 - accuracy: 0.9295 - val_loss: 0.5887 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0621 - accuracy: 0.9584 - val_loss: 0.6642 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 0.6271 - val_accuracy: 0.3757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.6417 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.6317 - val_accuracy: 0.4027 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: 0.6470 - val_accuracy: 0.3919 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.0193 - accuracy: 0.9990 - val_loss: 0.6490 - val_accuracy: 0.3986 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 28ms/step - loss: 0.5239 - accuracy: 0.3371\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.337 total time=  43.4s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 7s 51ms/step - loss: 5.9696 - accuracy: 0.2165 - val_loss: 1.2015 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 3s 38ms/step - loss: 0.7040 - accuracy: 0.2524 - val_loss: 0.4486 - val_accuracy: 0.1230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.4304 - accuracy: 0.1705 - val_loss: 0.4443 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.4106 - accuracy: 0.2138 - val_loss: 0.4383 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 38ms/step - loss: 0.4017 - accuracy: 0.2226 - val_loss: 0.4212 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3940 - accuracy: 0.2436 - val_loss: 0.4236 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.3949 - accuracy: 0.2473 - val_loss: 0.4562 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3836 - accuracy: 0.2832 - val_loss: 0.4445 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3853 - accuracy: 0.2960 - val_loss: 0.4406 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3748 - accuracy: 0.3129 - val_loss: 0.4660 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3379 - accuracy: 0.3863 - val_loss: 0.4373 - val_accuracy: 0.2514 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3251 - accuracy: 0.4090 - val_loss: 0.4345 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 3s 36ms/step - loss: 0.3179 - accuracy: 0.4273 - val_loss: 0.4498 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 3s 37ms/step - loss: 0.3077 - accuracy: 0.4428 - val_loss: 0.4547 - val_accuracy: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 38ms/step - loss: 0.3016 - accuracy: 0.4574 - val_loss: 0.4608 - val_accuracy: 0.2703 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'softmax', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_inceptionv3_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = resnet.ResNet50(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 64ms/step - loss: 1.7459 - accuracy: 0.3259 - val_loss: 0.6015 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4537 - accuracy: 0.5807 - val_loss: 0.5809 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2465 - accuracy: 0.7477 - val_loss: 0.6245 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1386 - accuracy: 0.8802 - val_loss: 0.2970 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0920 - accuracy: 0.9213 - val_loss: 0.4259 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0403 - accuracy: 0.9695 - val_loss: 0.3407 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0387 - accuracy: 0.9711 - val_loss: 0.3946 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0218 - accuracy: 0.9858 - val_loss: 0.4257 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0307 - accuracy: 0.9812 - val_loss: 0.4321 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.3930 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.3967 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4064 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.0493e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.5331e-04 - accuracy: 0.9995 - val_loss: 0.4382 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3249 - accuracy: 0.6927\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.693 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.8507 - accuracy: 0.3653 - val_loss: 0.6994 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.4326 - accuracy: 0.6794 - val_loss: 0.4296 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.2201 - accuracy: 0.8351 - val_loss: 0.3958 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0946 - accuracy: 0.9234 - val_loss: 0.6700 - val_accuracy: 0.5608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0758 - accuracy: 0.9472 - val_loss: 0.5041 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0456 - accuracy: 0.9756 - val_loss: 0.5593 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0320 - accuracy: 0.9838 - val_loss: 0.4386 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0285 - accuracy: 0.9838 - val_loss: 0.4384 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4355 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 8.4273e-04 - accuracy: 0.9995 - val_loss: 0.4457 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.6914e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0550e-05 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.3125e-06 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4334 - accuracy: 0.6609\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.661 total time=  42.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 60ms/step - loss: 1.5967 - accuracy: 0.3445 - val_loss: 0.5374 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3803 - accuracy: 0.5337 - val_loss: 0.3938 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2415 - accuracy: 0.7027 - val_loss: 0.2574 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1538 - accuracy: 0.8123 - val_loss: 0.2757 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1121 - accuracy: 0.8656 - val_loss: 0.3900 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0843 - accuracy: 0.8985 - val_loss: 0.2468 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0628 - accuracy: 0.9310 - val_loss: 0.2884 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0537 - accuracy: 0.9437 - val_loss: 0.3202 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0445 - accuracy: 0.9538 - val_loss: 0.4686 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0421 - accuracy: 0.9574 - val_loss: 0.3655 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0339 - accuracy: 0.9645 - val_loss: 0.5286 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0203 - accuracy: 0.9756 - val_loss: 0.3862 - val_accuracy: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0150 - accuracy: 0.9792 - val_loss: 0.4118 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9812 - val_loss: 0.4169 - val_accuracy: 0.7405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0109 - accuracy: 0.9817 - val_loss: 0.4383 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0097 - accuracy: 0.9833 - val_loss: 0.4437 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2879 - accuracy: 0.6751\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.675 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.9606 - accuracy: 0.4772 - val_loss: 0.3469 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.2203 - accuracy: 0.8431 - val_loss: 0.3492 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0618 - accuracy: 0.9635 - val_loss: 0.3147 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0201 - accuracy: 0.9964 - val_loss: 0.3178 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.3482 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.0614e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.6561e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.4199e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7047e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.1878e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8566e-04 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8085e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7658e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7278e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.6857e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.2939 - accuracy: 0.7880\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.788 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.8299 - accuracy: 0.4140 - val_loss: 0.3746 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2023 - accuracy: 0.7752 - val_loss: 0.2967 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0712 - accuracy: 0.9411 - val_loss: 0.2282 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0208 - accuracy: 0.9904 - val_loss: 0.2398 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.2401 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.2492 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0038 - accuracy: 0.9975 - val_loss: 0.2544 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2604 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2289 - accuracy: 0.7574\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.757 total time=  41.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.9632 - accuracy: 0.4749 - val_loss: 0.4217 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1732 - accuracy: 0.8843 - val_loss: 0.3556 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0502 - accuracy: 0.9787 - val_loss: 0.3232 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.3081 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.3298 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3488 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.5775e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.3212e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.1356e-04 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0267e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.9354e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.8504e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3525 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.742 total time=  44.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 59ms/step - loss: 2.0111 - accuracy: 0.3970 - val_loss: 0.4460 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.3220 - accuracy: 0.6624 - val_loss: 0.4851 - val_accuracy: 0.5405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1731 - accuracy: 0.8102 - val_loss: 0.4414 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0971 - accuracy: 0.9030 - val_loss: 0.6213 - val_accuracy: 0.5514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0619 - accuracy: 0.9487 - val_loss: 0.3425 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0583 - accuracy: 0.9553 - val_loss: 0.3976 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0341 - accuracy: 0.9751 - val_loss: 0.3663 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0222 - accuracy: 0.9853 - val_loss: 0.6876 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0364 - accuracy: 0.9797 - val_loss: 0.6371 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0248 - accuracy: 0.9873 - val_loss: 0.4324 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0046 - accuracy: 0.9959 - val_loss: 0.4329 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.4583 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0998e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4958e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.6245e-05 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3429 - accuracy: 0.7282\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.728 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 1.5904 - accuracy: 0.4023 - val_loss: 0.4797 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3253 - accuracy: 0.6996 - val_loss: 0.4045 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2222 - accuracy: 0.8346 - val_loss: 0.3578 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0668 - accuracy: 0.9406 - val_loss: 0.3282 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0611 - accuracy: 0.9564 - val_loss: 0.4776 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0416 - accuracy: 0.9772 - val_loss: 0.5801 - val_accuracy: 0.6932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0193 - accuracy: 0.9858 - val_loss: 0.4178 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0238 - accuracy: 0.9863 - val_loss: 0.3982 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0132 - accuracy: 0.9929 - val_loss: 0.6622 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0031 - accuracy: 0.9970 - val_loss: 0.4652 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4119e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5756e-05 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.1130e-06 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4353e-06 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3845 - accuracy: 0.6832\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.683 total time=  44.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 1.7195 - accuracy: 0.3724 - val_loss: 0.4845 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.3366 - accuracy: 0.6317 - val_loss: 0.3765 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1534 - accuracy: 0.8189 - val_loss: 0.3026 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1072 - accuracy: 0.8980 - val_loss: 0.2766 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0604 - accuracy: 0.9396 - val_loss: 0.3501 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0407 - accuracy: 0.9635 - val_loss: 0.3129 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0416 - accuracy: 0.9619 - val_loss: 0.3207 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0203 - accuracy: 0.9863 - val_loss: 0.5684 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0312 - accuracy: 0.9822 - val_loss: 0.4155 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0073 - accuracy: 0.9949 - val_loss: 0.3995 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0036 - accuracy: 0.9964 - val_loss: 0.4152 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0020 - accuracy: 0.9975 - val_loss: 0.4279 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 9.3799e-04 - accuracy: 0.9995 - val_loss: 0.4483 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 5.9275e-04 - accuracy: 0.9995 - val_loss: 0.4613 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3115 - accuracy: 0.6883\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.688 total time=  44.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 58ms/step - loss: 0.8631 - accuracy: 0.4853 - val_loss: 0.3880 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.1207 - accuracy: 0.9203 - val_loss: 0.3085 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.3115 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.2997 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 8.0372e-04 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6499e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8883e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4173e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0486e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.8203e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7958e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7712e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.7457e-04 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7177e-04 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3206 - accuracy: 0.7830\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.783 total time=  44.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 0.6596 - accuracy: 0.4881 - val_loss: 0.2816 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1576 - accuracy: 0.8453 - val_loss: 0.2357 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357 - accuracy: 0.9711 - val_loss: 0.2240 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.2426 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2488 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 6.3898e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.6054e-04 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.8613e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7824e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.7037e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6252e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5439e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2397 - accuracy: 0.7442\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.744 total time=  41.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.7625 - accuracy: 0.4845 - val_loss: 0.2545 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1449 - accuracy: 0.8787 - val_loss: 0.2741 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0406 - accuracy: 0.9827 - val_loss: 0.2674 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.2834 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.2818 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2912 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2910 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2893 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2888 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.2888 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2678 - accuracy: 0.6802\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.680 total time=  35.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 3.1893 - accuracy: 0.3503 - val_loss: 0.8999 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4438 - accuracy: 0.7086 - val_loss: 0.5254 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.1861 - accuracy: 0.8609 - val_loss: 0.3576 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1030 - accuracy: 0.9279 - val_loss: 0.7051 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0838 - accuracy: 0.9472 - val_loss: 0.4470 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0419 - accuracy: 0.9777 - val_loss: 0.4443 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0376 - accuracy: 0.9812 - val_loss: 0.4649 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0224 - accuracy: 0.9893 - val_loss: 0.4442 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.4092 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1434e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.1722e-05 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 5.5568e-06 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.5813e-06 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.3747 - accuracy: 0.7170\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.717 total time=  42.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.3756 - accuracy: 0.3770 - val_loss: 0.6834 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.5277 - accuracy: 0.7306 - val_loss: 1.6028 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.3327 - accuracy: 0.8559 - val_loss: 0.4362 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1269 - accuracy: 0.9269 - val_loss: 0.6483 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1054 - accuracy: 0.9482 - val_loss: 0.6286 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0623 - accuracy: 0.9706 - val_loss: 0.7754 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.6999 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.9840 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.6011 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.4334e-04 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.9658e-05 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 4.1994e-06 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 9.2524e-07 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4926 - accuracy: 0.6812\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.681 total time=  43.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 60ms/step - loss: 3.5015 - accuracy: 0.3820 - val_loss: 0.8105 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4432 - accuracy: 0.7078 - val_loss: 0.4694 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2544 - accuracy: 0.8427 - val_loss: 0.5552 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0796 - accuracy: 0.9554 - val_loss: 0.6653 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0677 - accuracy: 0.9640 - val_loss: 0.5489 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0291 - accuracy: 0.9822 - val_loss: 0.4485 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0323 - accuracy: 0.9833 - val_loss: 0.6390 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0273 - accuracy: 0.9853 - val_loss: 0.5000 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5359 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0167 - accuracy: 0.9919 - val_loss: 0.7039 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.5225 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.6315e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5665e-05 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.6277e-06 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.0049e-06 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 3.2897e-07 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.5055 - accuracy: 0.6761\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.676 total time=  51.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 58ms/step - loss: 1.2246 - accuracy: 0.4680 - val_loss: 0.3777 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1703 - accuracy: 0.9076 - val_loss: 0.4072 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0358 - accuracy: 0.9843 - val_loss: 0.4276 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.3717 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.2086e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.7932 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.6082e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.4325e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.0593e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7913e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.4277e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.3102e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2970e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2841e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.2568e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 0.3910 - accuracy: 0.7769\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.777 total time=  53.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 0.8311 - accuracy: 0.4795 - val_loss: 0.4126 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.2352 - accuracy: 0.8463 - val_loss: 0.3899 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0831 - accuracy: 0.9619 - val_loss: 0.3882 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0308 - accuracy: 0.9914 - val_loss: 0.3640 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.3614 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.4068 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3813 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4036 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 5.7594e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 4.5511e-04 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.6156e-04 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.0813e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.8874e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.7871e-04 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.7215e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.3920 - accuracy: 0.7492\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.749 total time=  47.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 59ms/step - loss: 1.7640 - accuracy: 0.4881 - val_loss: 0.5344 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1691 - accuracy: 0.9117 - val_loss: 0.4036 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 0.3603 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.3958 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 8.9763e-04 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 2.7494e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1852e-04 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1649e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.1459e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 1.1268e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.1078e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.4411 - accuracy: 0.7147\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.715 total time=  42.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 3.0155 - accuracy: 0.3802 - val_loss: 1.8955 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6131 - accuracy: 0.6787 - val_loss: 0.5046 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.2773 - accuracy: 0.8365 - val_loss: 0.5880 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.1547 - accuracy: 0.9142 - val_loss: 0.7656 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0763 - accuracy: 0.9548 - val_loss: 0.4716 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0521 - accuracy: 0.9736 - val_loss: 0.6463 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0425 - accuracy: 0.9832 - val_loss: 0.9515 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.5897 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0323 - accuracy: 0.9853 - val_loss: 0.6685 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0140 - accuracy: 0.9929 - val_loss: 0.9228 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.5550 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.6851e-04 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 8.7037e-06 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.4800e-06 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 2.9244e-07 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.4747 - accuracy: 0.7404\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.740 total time=  50.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.6503 - accuracy: 0.3688 - val_loss: 0.9860 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.4127 - accuracy: 0.6702 - val_loss: 0.3172 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.2051 - accuracy: 0.8402 - val_loss: 0.4782 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0943 - accuracy: 0.9224 - val_loss: 0.4500 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0570 - accuracy: 0.9604 - val_loss: 0.4847 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0403 - accuracy: 0.9746 - val_loss: 0.4300 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0325 - accuracy: 0.9751 - val_loss: 0.6598 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.4034 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.3875 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 9.0322e-04 - accuracy: 0.9995 - val_loss: 0.4240 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 4.6892e-04 - accuracy: 0.9995 - val_loss: 0.4311 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.7022e-04 - accuracy: 0.9995 - val_loss: 0.4385 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.3261 - accuracy: 0.6538\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.654 total time=  40.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 1.8896 - accuracy: 0.3815 - val_loss: 0.4360 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2945 - accuracy: 0.6494 - val_loss: 0.3656 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1843 - accuracy: 0.7971 - val_loss: 0.4644 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1019 - accuracy: 0.8950 - val_loss: 0.4877 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0638 - accuracy: 0.9366 - val_loss: 0.3467 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0516 - accuracy: 0.9533 - val_loss: 0.5165 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0521 - accuracy: 0.9584 - val_loss: 0.4776 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0155 - accuracy: 0.9888 - val_loss: 0.4648 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0190 - accuracy: 0.9863 - val_loss: 0.4493 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0228 - accuracy: 0.9853 - val_loss: 1.3234 - val_accuracy: 0.5878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0140 - accuracy: 0.9924 - val_loss: 0.6045 - val_accuracy: 0.7230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.5640 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5477 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.0700e-04 - accuracy: 0.9995 - val_loss: 0.5433 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.0641e-04 - accuracy: 0.9995 - val_loss: 0.5507 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.3770 - accuracy: 0.6944\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.694 total time=  52.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9682 - accuracy: 0.5452 - val_loss: 0.3994 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.1452 - accuracy: 0.9173 - val_loss: 0.3044 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.3463 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.3136 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.3366 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3415 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 6.2288e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.5215e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.3941e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.3261e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 1.2794e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.3196 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.767 total time=  40.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.2822 - accuracy: 0.4906 - val_loss: 0.4122 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1442 - accuracy: 0.8970 - val_loss: 0.3599 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0294 - accuracy: 0.9858 - val_loss: 0.3244 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.3028 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.1597e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5517e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.0898e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.7720e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.5435e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3857e-04 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3693e-04 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3516e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3347e-04 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.3166e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3388 - accuracy: 0.7665\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.766 total time=  51.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 0.9694 - accuracy: 0.5150 - val_loss: 0.3007 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1003 - accuracy: 0.9315 - val_loss: 0.3156 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0224 - accuracy: 0.9863 - val_loss: 0.2993 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.3027 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 8.7767e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.9061e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.9153e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 2.4015e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 2.0157e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.7383e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5553e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5345e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.5124e-04 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 1.4684e-04 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.3399 - accuracy: 0.7421\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.742 total time=  49.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.4602 - accuracy: 0.4239 - val_loss: 0.3152 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1717 - accuracy: 0.7797 - val_loss: 0.2602 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0657 - accuracy: 0.9284 - val_loss: 0.2684 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0327 - accuracy: 0.9726 - val_loss: 0.2315 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0226 - accuracy: 0.9807 - val_loss: 0.2700 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0113 - accuracy: 0.9929 - val_loss: 0.3046 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0145 - accuracy: 0.9888 - val_loss: 0.3162 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.4663e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0113 - accuracy: 0.9924 - val_loss: 0.3843 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 6.7424e-05 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6193e-05 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.8381e-06 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 9.9842e-07 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.8417e-07 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2391 - accuracy: 0.7525\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.753 total time=  48.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 0.4623 - accuracy: 0.3623 - val_loss: 0.3015 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1872 - accuracy: 0.7372 - val_loss: 0.2579 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0692 - accuracy: 0.9269 - val_loss: 0.2010 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0259 - accuracy: 0.9777 - val_loss: 0.2270 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0080 - accuracy: 0.9954 - val_loss: 0.2742 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0057 - accuracy: 0.9959 - val_loss: 0.2658 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0302 - accuracy: 0.9833 - val_loss: 0.3172 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0471e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3761e-05 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 5.9502e-06 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.3539e-07 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.6853e-07 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.2079 - accuracy: 0.7320\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.732 total time=  46.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 0.4338 - accuracy: 0.4181 - val_loss: 0.2803 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1679 - accuracy: 0.7864 - val_loss: 0.2216 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0621 - accuracy: 0.9330 - val_loss: 0.3017 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0223 - accuracy: 0.9812 - val_loss: 0.2843 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0085 - accuracy: 0.9944 - val_loss: 0.3496 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0291 - accuracy: 0.9833 - val_loss: 0.2846 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.7239e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 6.0435e-05 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.4537e-05 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.0113e-06 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.3549e-06 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.4422e-07 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2407 - accuracy: 0.6518\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.652 total time=  43.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3908 - accuracy: 0.4259 - val_loss: 0.2625 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1293 - accuracy: 0.8655 - val_loss: 0.1950 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.1906 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.2172 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 8.8907e-04 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 5.4408e-04 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.9134e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.2464e-04 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.1164e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.0296e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.9490e-04 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.8674e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2043 - accuracy: 0.7688\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.769 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.3564 - accuracy: 0.4713 - val_loss: 0.2384 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1080 - accuracy: 0.8869 - val_loss: 0.1885 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0228 - accuracy: 0.9893 - val_loss: 0.2022 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.2208 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 7.4398e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.9834e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.9482e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.8279e-04 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.7137e-04 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 3.5983e-04 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 3.4814e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 33ms/step - loss: 0.2089 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.720 total time=  42.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.3375 - accuracy: 0.4942 - val_loss: 0.2243 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0999 - accuracy: 0.9006 - val_loss: 0.1897 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1935 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 7.0969e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.8195e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.8360e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.7279e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6207e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.5138e-04 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.4066e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2129 - accuracy: 0.6944\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.694 total time=  44.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 70ms/step - loss: 0.4784 - accuracy: 0.3990 - val_loss: 0.3068 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.1900 - accuracy: 0.7213 - val_loss: 0.3159 - val_accuracy: 0.5838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0790 - accuracy: 0.9066 - val_loss: 0.2312 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0322 - accuracy: 0.9635 - val_loss: 0.2501 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0206 - accuracy: 0.9863 - val_loss: 0.2737 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0083 - accuracy: 0.9949 - val_loss: 0.3763 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0072 - accuracy: 0.9934 - val_loss: 0.3407 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0130 - accuracy: 0.9924 - val_loss: 0.3311 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3142 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.0879e-04 - accuracy: 0.9990 - val_loss: 0.3307 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 5.1923e-04 - accuracy: 0.9990 - val_loss: 0.3532 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.7933e-04 - accuracy: 0.9990 - val_loss: 0.3697 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.2297e-04 - accuracy: 0.9995 - val_loss: 0.3880 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2383 - accuracy: 0.7170\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.717 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4760 - accuracy: 0.3749 - val_loss: 0.3020 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1879 - accuracy: 0.7245 - val_loss: 0.2332 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0733 - accuracy: 0.9107 - val_loss: 0.3616 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0277 - accuracy: 0.9665 - val_loss: 0.2618 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0147 - accuracy: 0.9893 - val_loss: 0.2669 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.3204 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0169 - accuracy: 0.9934 - val_loss: 0.3893 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 7.3186e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.4829e-05 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.2192e-05 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.0642e-06 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0726e-06 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2593 - accuracy: 0.6284\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.628 total time=  44.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.4612 - accuracy: 0.3932 - val_loss: 0.3181 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1790 - accuracy: 0.7504 - val_loss: 0.2938 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0793 - accuracy: 0.9016 - val_loss: 0.3171 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0328 - accuracy: 0.9630 - val_loss: 0.2652 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0160 - accuracy: 0.9843 - val_loss: 0.3444 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0114 - accuracy: 0.9899 - val_loss: 0.3435 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0111 - accuracy: 0.9914 - val_loss: 0.3830 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0078 - accuracy: 0.9939 - val_loss: 0.3578 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0066 - accuracy: 0.9959 - val_loss: 0.3874 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.8103e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.2922e-05 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 6.1122e-06 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 1.4832e-06 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.6812e-07 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.2931 - accuracy: 0.6995\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.699 total time=  49.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.3981 - accuracy: 0.4264 - val_loss: 0.2706 - val_accuracy: 0.5959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1329 - accuracy: 0.8345 - val_loss: 0.2244 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0277 - accuracy: 0.9858 - val_loss: 0.2196 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.2295 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2547 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 6.2357e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 4.1283e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 3.0441e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 2.5225e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.4641e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 2.4038e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3428e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2814e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2196 - accuracy: 0.7465\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.746 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 0.3913 - accuracy: 0.4531 - val_loss: 0.2514 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1273 - accuracy: 0.8356 - val_loss: 0.2118 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0322 - accuracy: 0.9782 - val_loss: 0.2115 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.2233 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.2319 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2407 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.3755e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.9979e-04 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6389e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5467e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.4662e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3920e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.3202e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2419 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.720 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.4098 - accuracy: 0.4587 - val_loss: 0.2684 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1258 - accuracy: 0.8458 - val_loss: 0.2252 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0296 - accuracy: 0.9817 - val_loss: 0.2243 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.2513 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2555 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.8556e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.3862e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.7740e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.7012e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6301e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.5629e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4942e-04 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2411 - accuracy: 0.6904\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.690 total time=  49.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.5980 - accuracy: 0.4112 - val_loss: 0.3276 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1800 - accuracy: 0.7543 - val_loss: 0.2033 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0650 - accuracy: 0.9386 - val_loss: 0.1889 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0330 - accuracy: 0.9777 - val_loss: 0.1970 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0096 - accuracy: 0.9944 - val_loss: 0.2342 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9873 - val_loss: 0.2552 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.3114 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.3218e-05 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.7284e-06 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.4708e-06 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.4496e-07 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.7350e-07 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.1995 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.767 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 0.5521 - accuracy: 0.4419 - val_loss: 0.3342 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1719 - accuracy: 0.7854 - val_loss: 0.2233 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0642 - accuracy: 0.9335 - val_loss: 0.2009 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0428 - accuracy: 0.9680 - val_loss: 0.2487 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0193 - accuracy: 0.9873 - val_loss: 0.2475 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0066 - accuracy: 0.9964 - val_loss: 0.7150 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0115 - accuracy: 0.9944 - val_loss: 1.5044 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0427 - accuracy: 0.9782 - val_loss: 0.3110 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.3843e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.9892e-05 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 8.5165e-06 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.7455e-06 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.3437e-07 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 34ms/step - loss: 0.2102 - accuracy: 0.7543\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.754 total time=  47.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.5279 - accuracy: 0.4444 - val_loss: 0.2531 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1542 - accuracy: 0.8128 - val_loss: 0.2205 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0554 - accuracy: 0.9472 - val_loss: 0.2325 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0264 - accuracy: 0.9777 - val_loss: 0.2226 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0169 - accuracy: 0.9924 - val_loss: 0.2505 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0128 - accuracy: 0.9929 - val_loss: 0.2845 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 0.3462 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.5913e-05 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3442e-05 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.4355e-06 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.0366e-06 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.7176e-07 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2254 - accuracy: 0.6893\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.689 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 76ms/step - loss: 0.3697 - accuracy: 0.5168 - val_loss: 0.2463 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0858 - accuracy: 0.9310 - val_loss: 0.1967 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0161 - accuracy: 0.9975 - val_loss: 0.2146 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.1615e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.2903e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.0028e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.8497e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.7079e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.5675e-04 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.4281e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.1954 - accuracy: 0.7728\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.773 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.4082 - accuracy: 0.5190 - val_loss: 0.2297 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0737 - accuracy: 0.9503 - val_loss: 0.1931 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0141 - accuracy: 0.9985 - val_loss: 0.1979 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 7.8490e-04 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.3289e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.1573e-04 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 5.9923e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.8232e-04 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.6529e-04 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2056 - accuracy: 0.7371\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.737 total time=  44.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.4068 - accuracy: 0.4881 - val_loss: 0.2276 - val_accuracy: 0.6770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0866 - accuracy: 0.9259 - val_loss: 0.2022 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.2072 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 8.7355e-04 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.0165e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.8107e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.6769e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.5443e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.4104e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.2747e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2165 - accuracy: 0.7310\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.731 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7172 - accuracy: 0.3838 - val_loss: 0.2961 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.2016 - accuracy: 0.7365 - val_loss: 0.2076 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0752 - accuracy: 0.9162 - val_loss: 0.2562 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0252 - accuracy: 0.9792 - val_loss: 0.2753 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0246 - accuracy: 0.9832 - val_loss: 0.2690 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0136 - accuracy: 0.9914 - val_loss: 0.9392 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0201 - accuracy: 0.9873 - val_loss: 0.3529 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.4163e-04 - accuracy: 0.9990 - val_loss: 0.3386 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 5.3338e-05 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.1206e-05 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4907e-06 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 7.1085e-07 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2137 - accuracy: 0.7221\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.722 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6468 - accuracy: 0.4160 - val_loss: 0.3272 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1920 - accuracy: 0.7580 - val_loss: 0.3644 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0651 - accuracy: 0.9269 - val_loss: 0.2324 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0349 - accuracy: 0.9721 - val_loss: 0.5722 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0108 - accuracy: 0.9919 - val_loss: 0.3024 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0177 - accuracy: 0.9909 - val_loss: 0.3031 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3199 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0296 - accuracy: 0.9848 - val_loss: 0.3635 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.0136e-04 - accuracy: 0.9995 - val_loss: 0.3465 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.2085e-05 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.3418e-06 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.6040e-07 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.0898e-07 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2437 - accuracy: 0.7117\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.712 total time=  51.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6220 - accuracy: 0.3886 - val_loss: 0.2882 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.2027 - accuracy: 0.7291 - val_loss: 0.3728 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0778 - accuracy: 0.9041 - val_loss: 0.2839 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0275 - accuracy: 0.9751 - val_loss: 0.2452 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9888 - val_loss: 0.2910 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0122 - accuracy: 0.9934 - val_loss: 0.3674 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.5226e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0341 - accuracy: 0.9858 - val_loss: 0.5193 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.8596e-05 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.8486e-06 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 7.7336e-07 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.1490e-07 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 8.5409e-08 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2673 - accuracy: 0.7178\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  54.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.5055 - accuracy: 0.4381 - val_loss: 0.2604 - val_accuracy: 0.6027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1067 - accuracy: 0.8954 - val_loss: 0.2029 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0253 - accuracy: 0.9883 - val_loss: 0.2207 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.1003e-04 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.8797e-04 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.8507e-04 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7415e-04 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6358e-04 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.5256e-04 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.4175e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2078 - accuracy: 0.7211\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.721 total time=  45.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4511 - accuracy: 0.4718 - val_loss: 0.2395 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0943 - accuracy: 0.9097 - val_loss: 0.1955 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.2001 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.9795e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.2581e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.4338e-04 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3397e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.2494e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.1550e-04 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.0629e-04 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2197 - accuracy: 0.7025\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.703 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4480 - accuracy: 0.5013 - val_loss: 0.2495 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0871 - accuracy: 0.9168 - val_loss: 0.2240 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0164 - accuracy: 0.9914 - val_loss: 0.2205 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.9068e-04 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.9911e-04 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.3321e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3080e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7689e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6385e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5760e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5125e-04 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2399 - accuracy: 0.7239\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.724 total time=  50.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 1.9405 - accuracy: 0.3553 - val_loss: 0.6769 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4523 - accuracy: 0.6015 - val_loss: 0.4211 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2244 - accuracy: 0.7751 - val_loss: 0.4222 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1339 - accuracy: 0.8706 - val_loss: 0.6565 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0630 - accuracy: 0.9406 - val_loss: 0.4367 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0488 - accuracy: 0.9629 - val_loss: 0.4465 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0299 - accuracy: 0.9812 - val_loss: 0.4697 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0112 - accuracy: 0.9934 - val_loss: 0.3705 - val_accuracy: 0.7432 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0026 - accuracy: 0.9980 - val_loss: 0.3953 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.5431e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1501e-04 - accuracy: 0.9995 - val_loss: 0.4187 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0394e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5329e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.1720e-05 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.1265e-05 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.3054e-05 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.6734e-05 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 6.1242e-05 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.7703 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3974 - accuracy: 0.7373\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.737 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 2.7818 - accuracy: 0.3704 - val_loss: 1.1286 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.5190 - accuracy: 0.7159 - val_loss: 0.5771 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.2090 - accuracy: 0.8600 - val_loss: 0.4011 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.1278 - accuracy: 0.9249 - val_loss: 0.3896 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0740 - accuracy: 0.9564 - val_loss: 0.4423 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0662 - accuracy: 0.9670 - val_loss: 0.4424 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0389 - accuracy: 0.9822 - val_loss: 0.6519 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 0.5079 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.6406 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5027 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.8409e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.7914e-05 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.5620e-06 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.3479e-06 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4693 - accuracy: 0.7198\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.720 total time=  54.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 2.2279 - accuracy: 0.3800 - val_loss: 1.0416 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.5729 - accuracy: 0.6687 - val_loss: 0.5736 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2744 - accuracy: 0.8285 - val_loss: 0.6431 - val_accuracy: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1601 - accuracy: 0.9021 - val_loss: 0.5641 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1253 - accuracy: 0.9391 - val_loss: 0.8449 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0756 - accuracy: 0.9670 - val_loss: 0.5295 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0466 - accuracy: 0.9812 - val_loss: 0.6342 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0431 - accuracy: 0.9827 - val_loss: 0.7079 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0462 - accuracy: 0.9817 - val_loss: 0.7691 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.7026 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.6629 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.6156 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0868e-04 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0494e-05 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6560e-05 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.4588e-06 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.5556 - accuracy: 0.6964\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.696 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8593 - accuracy: 0.4777 - val_loss: 0.4386 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.2296 - accuracy: 0.8660 - val_loss: 0.3927 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0562 - accuracy: 0.9711 - val_loss: 0.3619 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.3584 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.3839 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3706 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.1085e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 5.7572e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.0383e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.9092e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.8161e-04 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7370e-04 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6626e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3697 - accuracy: 0.7495\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.749 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 0.6834 - accuracy: 0.4718 - val_loss: 0.3505 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1928 - accuracy: 0.7945 - val_loss: 0.2635 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0739 - accuracy: 0.9340 - val_loss: 0.2765 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0264 - accuracy: 0.9782 - val_loss: 0.2686 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9858 - val_loss: 0.2565 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0122 - accuracy: 0.9909 - val_loss: 0.2733 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0064 - accuracy: 0.9944 - val_loss: 0.2946 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0040 - accuracy: 0.9964 - val_loss: 0.2891 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0024 - accuracy: 0.9975 - val_loss: 0.3020 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.3040 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.3059 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.3060 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.3057 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.3050 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.3060 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2849 - accuracy: 0.7289\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.729 total time=  56.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8241 - accuracy: 0.5155 - val_loss: 0.4212 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1986 - accuracy: 0.8919 - val_loss: 0.4118 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0497 - accuracy: 0.9696 - val_loss: 0.3890 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.3711 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.4389 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 6.8950e-04 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.2278e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.8855e-04 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.5853e-04 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4089e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3931e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3735e-04 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3551e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3346e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.4314 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.723 total time=  53.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 1.8116 - accuracy: 0.3848 - val_loss: 0.3305 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.3526 - accuracy: 0.6462 - val_loss: 0.4027 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1826 - accuracy: 0.8081 - val_loss: 0.5504 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1108 - accuracy: 0.8949 - val_loss: 0.3539 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0762 - accuracy: 0.9310 - val_loss: 0.3224 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0384 - accuracy: 0.9690 - val_loss: 0.3896 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0286 - accuracy: 0.9761 - val_loss: 0.3931 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0602 - accuracy: 0.9660 - val_loss: 0.6729 - val_accuracy: 0.6243 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0148 - accuracy: 0.9873 - val_loss: 0.5604 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0163 - accuracy: 0.9883 - val_loss: 0.4608 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0068 - accuracy: 0.9949 - val_loss: 0.4584 - val_accuracy: 0.7473 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0045 - accuracy: 0.9959 - val_loss: 0.4868 - val_accuracy: 0.7527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0032 - accuracy: 0.9975 - val_loss: 0.4929 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0024 - accuracy: 0.9975 - val_loss: 0.5175 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0016 - accuracy: 0.9980 - val_loss: 0.5221 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3202 - accuracy: 0.7312\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.731 total time=  58.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 1.7202 - accuracy: 0.3760 - val_loss: 0.9867 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4033 - accuracy: 0.6271 - val_loss: 0.4980 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1967 - accuracy: 0.7965 - val_loss: 0.3438 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1185 - accuracy: 0.8864 - val_loss: 0.3364 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0703 - accuracy: 0.9340 - val_loss: 0.4431 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0326 - accuracy: 0.9716 - val_loss: 0.3129 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0231 - accuracy: 0.9797 - val_loss: 0.3827 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0163 - accuracy: 0.9904 - val_loss: 0.4898 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0155 - accuracy: 0.9893 - val_loss: 0.5612 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.4632 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0154 - accuracy: 0.9929 - val_loss: 0.5640 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.5162 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4882e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6182e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0066e-04 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.4571e-04 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3289 - accuracy: 0.7299\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.730 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.5376 - accuracy: 0.4044 - val_loss: 1.2600 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.3872 - accuracy: 0.6875 - val_loss: 0.6488 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1934 - accuracy: 0.8275 - val_loss: 0.3442 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1010 - accuracy: 0.9163 - val_loss: 0.5758 - val_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0638 - accuracy: 0.9523 - val_loss: 0.3560 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0438 - accuracy: 0.9741 - val_loss: 0.5304 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0306 - accuracy: 0.9772 - val_loss: 0.4137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0309 - accuracy: 0.9762 - val_loss: 0.4436 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0041 - accuracy: 0.9964 - val_loss: 0.4151 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.0290e-04 - accuracy: 0.9995 - val_loss: 0.4298 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.9162e-04 - accuracy: 0.9995 - val_loss: 0.4576 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.8677e-04 - accuracy: 0.9995 - val_loss: 0.4567 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.6418e-04 - accuracy: 0.9995 - val_loss: 0.4743 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.3718 - accuracy: 0.6924\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.692 total time=  51.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.6056 - accuracy: 0.3909 - val_loss: 0.3008 - val_accuracy: 0.5378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1930 - accuracy: 0.7503 - val_loss: 0.2465 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0859 - accuracy: 0.8964 - val_loss: 0.2530 - val_accuracy: 0.7041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0389 - accuracy: 0.9574 - val_loss: 0.2511 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0184 - accuracy: 0.9843 - val_loss: 0.2416 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0101 - accuracy: 0.9893 - val_loss: 0.2445 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0062 - accuracy: 0.9939 - val_loss: 0.2656 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 0.9959 - val_loss: 0.2750 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0025 - accuracy: 0.9964 - val_loss: 0.2676 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.2620 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.2287e-04 - accuracy: 0.9990 - val_loss: 0.2634 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.0127e-04 - accuracy: 0.9990 - val_loss: 0.2650 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 8.8093e-04 - accuracy: 0.9990 - val_loss: 0.2662 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.6046e-04 - accuracy: 0.9990 - val_loss: 0.2677 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 8.4128e-04 - accuracy: 0.9990 - val_loss: 0.2690 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 42ms/step - loss: 0.2544 - accuracy: 0.7465\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.746 total time=  57.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7788 - accuracy: 0.4384 - val_loss: 0.2841 - val_accuracy: 0.5878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1518 - accuracy: 0.8412 - val_loss: 0.2393 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0417 - accuracy: 0.9716 - val_loss: 0.2226 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.2367 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.2420 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2461 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 8.8605e-04 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.3536e-04 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.2475e-04 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.1394e-04 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.0442e-04 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.9441e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.8501e-04 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2518 - accuracy: 0.7371\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.737 total time=  51.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.8070 - accuracy: 0.4881 - val_loss: 0.3371 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1590 - accuracy: 0.8564 - val_loss: 0.3170 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0549 - accuracy: 0.9564 - val_loss: 0.3101 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0147 - accuracy: 0.9934 - val_loss: 0.2998 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.3103 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 9.3035e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.7739e-04 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1718e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.3923e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.0011e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.7237e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.5399e-04 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5196e-04 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.4781e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4568e-04 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.3500 - accuracy: 0.7452\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.745 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 3.3713 - accuracy: 0.3624 - val_loss: 0.7050 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6045 - accuracy: 0.7030 - val_loss: 0.5724 - val_accuracy: 0.6162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.3079 - accuracy: 0.8396 - val_loss: 0.7162 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1384 - accuracy: 0.9305 - val_loss: 0.5412 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1023 - accuracy: 0.9579 - val_loss: 0.6793 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0677 - accuracy: 0.9741 - val_loss: 0.5927 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0500 - accuracy: 0.9878 - val_loss: 0.6428 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.6107 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0414 - accuracy: 0.9822 - val_loss: 0.5813 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.5569 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3549e-04 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 7.5731e-05 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.9655e-06 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 5.6824e-07 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.5471 - accuracy: 0.7525\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.753 total time=  55.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 3.8396 - accuracy: 0.4023 - val_loss: 1.0716 - val_accuracy: 0.5527 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.8399 - accuracy: 0.7189 - val_loss: 0.6889 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.2794 - accuracy: 0.9006 - val_loss: 0.6034 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.1814 - accuracy: 0.9361 - val_loss: 0.5700 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1761 - accuracy: 0.9488 - val_loss: 0.6922 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0817 - accuracy: 0.9716 - val_loss: 0.7144 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0832 - accuracy: 0.9777 - val_loss: 1.0758 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.7356 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0329 - accuracy: 0.9873 - val_loss: 0.7682 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.6893 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.4280e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.3646e-05 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.4059e-06 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 8.3353e-07 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.6196 - accuracy: 0.7188\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.719 total time=  56.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 3.4062 - accuracy: 0.3912 - val_loss: 0.5478 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6296 - accuracy: 0.7103 - val_loss: 0.7612 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.2965 - accuracy: 0.8584 - val_loss: 0.4440 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1464 - accuracy: 0.9280 - val_loss: 0.4542 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0826 - accuracy: 0.9594 - val_loss: 0.7367 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0457 - accuracy: 0.9751 - val_loss: 0.6639 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0483 - accuracy: 0.9792 - val_loss: 0.5910 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 1.0921 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.6213 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 3.5695e-04 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 9.8373e-06 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.7288e-06 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 6.5684e-07 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.4884 - accuracy: 0.7066\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.707 total time=  52.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 1.0787 - accuracy: 0.4731 - val_loss: 0.4416 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1405 - accuracy: 0.9005 - val_loss: 0.2956 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0380 - accuracy: 0.9863 - val_loss: 0.2847 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.2774 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2757 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.9422e-04 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.7044e-04 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.9188e-04 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.3887e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.0248e-04 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9815e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9409e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.9002e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.8599e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3034 - accuracy: 0.7667\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.767 total time=  57.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 1.5164 - accuracy: 0.4810 - val_loss: 0.5557 - val_accuracy: 0.6568 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2236 - accuracy: 0.9077 - val_loss: 0.4673 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0718 - accuracy: 0.9777 - val_loss: 0.5828 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.5849 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.5093 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.8713e-04 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3180e-04 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0654e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 9.8663e-05 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 9.2513e-05 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.4877 - accuracy: 0.7472\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.747 total time=  45.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 1.0281 - accuracy: 0.5358 - val_loss: 0.4111 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1659 - accuracy: 0.9051 - val_loss: 0.4477 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 0.3842 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.5150 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.4478 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.4133 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 9.0845e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0494e-04 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.6132e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.4611e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.3793e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.4217 - accuracy: 0.7269\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.727 total time=  48.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 2.8220 - accuracy: 0.3954 - val_loss: 0.7620 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.4309 - accuracy: 0.6675 - val_loss: 0.5290 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1796 - accuracy: 0.8244 - val_loss: 0.4285 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0894 - accuracy: 0.9213 - val_loss: 0.2609 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0495 - accuracy: 0.9579 - val_loss: 0.4986 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0328 - accuracy: 0.9751 - val_loss: 0.5880 - val_accuracy: 0.6716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0275 - accuracy: 0.9822 - val_loss: 0.4004 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0217 - accuracy: 0.9868 - val_loss: 0.5516 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0221 - accuracy: 0.9873 - val_loss: 0.4786 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0039 - accuracy: 0.9959 - val_loss: 0.4641 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.3978e-04 - accuracy: 0.9995 - val_loss: 0.4716 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3565e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.9611e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.1648e-05 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2964 - accuracy: 0.7181\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  52.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.0198 - accuracy: 0.3825 - val_loss: 0.4865 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3463 - accuracy: 0.6753 - val_loss: 0.5215 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1946 - accuracy: 0.8153 - val_loss: 0.4010 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0997 - accuracy: 0.9173 - val_loss: 0.5263 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0781 - accuracy: 0.9442 - val_loss: 0.3774 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0622 - accuracy: 0.9619 - val_loss: 0.5922 - val_accuracy: 0.6784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0274 - accuracy: 0.9843 - val_loss: 0.6328 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9914 - val_loss: 0.5653 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0188 - accuracy: 0.9888 - val_loss: 0.5280 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0198 - accuracy: 0.9909 - val_loss: 0.7798 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5390 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.3997e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.1171e-06 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.4297e-06 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.6783e-07 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3625 - accuracy: 0.7178\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.718 total time=  58.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 2.9768 - accuracy: 0.3704 - val_loss: 2.5535 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.3859 - accuracy: 0.7139 - val_loss: 0.4071 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1723 - accuracy: 0.8498 - val_loss: 0.3505 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0929 - accuracy: 0.9315 - val_loss: 0.3317 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0775 - accuracy: 0.9518 - val_loss: 0.4942 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0359 - accuracy: 0.9827 - val_loss: 0.3665 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0295 - accuracy: 0.9817 - val_loss: 0.5791 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0359 - accuracy: 0.9817 - val_loss: 0.4552 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0213 - accuracy: 0.9878 - val_loss: 0.4909 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 0.4483 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.6928e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.8099e-05 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.1204e-06 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 4.0151e-06 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3928 - accuracy: 0.6802\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.680 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 74ms/step - loss: 1.0406 - accuracy: 0.4944 - val_loss: 0.4275 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1592 - accuracy: 0.9117 - val_loss: 0.3631 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: 0.4510 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.3583 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7691e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.7651e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.3831e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1971e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0779e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0642e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0489e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0355e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.0230e-04 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.3922 - accuracy: 0.7718\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.772 total time=  52.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.8751 - accuracy: 0.5058 - val_loss: 0.3140 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1183 - accuracy: 0.9203 - val_loss: 0.3338 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2886 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.3469 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.3031 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.7582e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.0415e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.6139e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.5827e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.5534e-04 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.4965e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.3239 - accuracy: 0.7350\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.735 total time=  49.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 1.2943 - accuracy: 0.5028 - val_loss: 0.3176 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1062 - accuracy: 0.9244 - val_loss: 0.3223 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.2964 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.2726 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.5761e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.4852e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7410e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3024e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.0549e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0217e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.9917e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.9624e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.9302e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2891 - accuracy: 0.7472\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.747 total time=  52.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3891 - accuracy: 0.4259 - val_loss: 0.2746 - val_accuracy: 0.5797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1594 - accuracy: 0.7909 - val_loss: 0.2041 - val_accuracy: 0.6919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0601 - accuracy: 0.9355 - val_loss: 0.1801 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0233 - accuracy: 0.9817 - val_loss: 0.2426 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0126 - accuracy: 0.9898 - val_loss: 0.2602 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0135 - accuracy: 0.9883 - val_loss: 0.2644 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.5197e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0132 - accuracy: 0.9909 - val_loss: 0.3024 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.4176e-04 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.7905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.1559e-05 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.3783e-06 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 9.0465e-07 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.7714e-07 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.1742 - accuracy: 0.7779\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.778 total time=  50.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.3681 - accuracy: 0.4282 - val_loss: 0.2381 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1515 - accuracy: 0.8077 - val_loss: 0.2590 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0603 - accuracy: 0.9366 - val_loss: 0.2077 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0170 - accuracy: 0.9833 - val_loss: 0.2177 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0180 - accuracy: 0.9868 - val_loss: 0.2629 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0184 - accuracy: 0.9883 - val_loss: 0.2511 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0084 - accuracy: 0.9944 - val_loss: 0.3014 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.2717 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 7.7509e-05 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.8770e-05 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.9407e-06 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3004e-06 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.7932 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4560e-07 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2365 - accuracy: 0.7381\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.738 total time=  50.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4058 - accuracy: 0.4282 - val_loss: 0.2627 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1620 - accuracy: 0.7727 - val_loss: 0.2505 - val_accuracy: 0.6527 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0667 - accuracy: 0.9274 - val_loss: 0.2706 - val_accuracy: 0.7095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0245 - accuracy: 0.9807 - val_loss: 0.2363 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0101 - accuracy: 0.9924 - val_loss: 0.2733 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0034 - accuracy: 0.9970 - val_loss: 0.2946 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0239 - accuracy: 0.9893 - val_loss: 0.3015 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.9046e-05 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.3512 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.7977e-05 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.9840e-06 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.0347e-06 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.7521e-07 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.4871e-07 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2506 - accuracy: 0.7228\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.723 total time=  53.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.3737 - accuracy: 0.4401 - val_loss: 0.2380 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1200 - accuracy: 0.8690 - val_loss: 0.2220 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0278 - accuracy: 0.9868 - val_loss: 0.2318 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2482 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.6482e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.1607e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.1227e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.0006e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.8857e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7731e-04 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.6600e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2164 - accuracy: 0.7008\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.701 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 0.3359 - accuracy: 0.4911 - val_loss: 0.2403 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1074 - accuracy: 0.8864 - val_loss: 0.1824 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.1981 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.2068 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.7083e-04 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.2315e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.1727e-04 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.0334e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.9111e-04 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.7898e-04 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.6673e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2099 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.689 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 0.3640 - accuracy: 0.4531 - val_loss: 0.2423 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.1231 - accuracy: 0.8564 - val_loss: 0.2057 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0302 - accuracy: 0.9817 - val_loss: 0.2012 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 6.8078e-04 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.5709e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.3447e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6952e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6244e-04 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5553e-04 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.4849e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2209 - accuracy: 0.7320\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.732 total time=  49.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4612 - accuracy: 0.3959 - val_loss: 0.3961 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.1834 - accuracy: 0.7442 - val_loss: 0.2555 - val_accuracy: 0.6595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0764 - accuracy: 0.9107 - val_loss: 0.2372 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0232 - accuracy: 0.9802 - val_loss: 0.3415 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0142 - accuracy: 0.9863 - val_loss: 0.2665 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 0.9959 - val_loss: 0.4597 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0140 - accuracy: 0.9909 - val_loss: 0.3829 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 6.8193e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.3857e-05 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.1771e-06 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.2060e-06 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6534e-07 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.4807e-07 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2319 - accuracy: 0.7221\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.722 total time=  50.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.5264 - accuracy: 0.3993 - val_loss: 0.3561 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1964 - accuracy: 0.7174 - val_loss: 0.2068 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0737 - accuracy: 0.9112 - val_loss: 0.2711 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0209 - accuracy: 0.9843 - val_loss: 0.5604 - val_accuracy: 0.5743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0162 - accuracy: 0.9883 - val_loss: 0.4216 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0068 - accuracy: 0.9934 - val_loss: 0.7184 - val_accuracy: 0.6189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 0.4429 - val_accuracy: 0.7203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 0.3447 - val_accuracy: 0.7514 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.8095e-04 - accuracy: 0.9995 - val_loss: 0.3590 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.0439e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.5328e-05 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.5450e-05 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.7635 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2284 - accuracy: 0.6893\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.689 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 0.4291 - accuracy: 0.3876 - val_loss: 0.2858 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1836 - accuracy: 0.7281 - val_loss: 0.2316 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0776 - accuracy: 0.9087 - val_loss: 0.2543 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0267 - accuracy: 0.9726 - val_loss: 0.2780 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0094 - accuracy: 0.9909 - val_loss: 0.2821 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 0.3114 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0089 - accuracy: 0.9934 - val_loss: 0.3405 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.3365 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2968e-04 - accuracy: 0.9995 - val_loss: 0.3539 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 7.3762e-05 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0062e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.8368e-06 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2540 - accuracy: 0.6579\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.658 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 65ms/step - loss: 0.3748 - accuracy: 0.4452 - val_loss: 0.2489 - val_accuracy: 0.6284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.1287 - accuracy: 0.8467 - val_loss: 0.2165 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0315 - accuracy: 0.9792 - val_loss: 0.2299 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.2460 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 6.3343e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 4.0075e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.1066e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.0147e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.9247e-04 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.8401e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.7540e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2354 - accuracy: 0.6633\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.663 total time=  44.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 66ms/step - loss: 0.3601 - accuracy: 0.4673 - val_loss: 0.2383 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1090 - accuracy: 0.8630 - val_loss: 0.2024 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0272 - accuracy: 0.9833 - val_loss: 0.2050 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.2217 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2356 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 9.5927e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.9630e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 4.3790e-04 - accuracy: 0.9995 - val_loss: 0.2555 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 3.5541e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.2893e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.1121e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.9756e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.2174 - accuracy: 0.6995\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.699 total time=  43.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 67ms/step - loss: 0.4434 - accuracy: 0.3871 - val_loss: 0.2798 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1844 - accuracy: 0.7504 - val_loss: 0.2220 - val_accuracy: 0.6662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0687 - accuracy: 0.9244 - val_loss: 0.2483 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0243 - accuracy: 0.9802 - val_loss: 0.2476 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0116 - accuracy: 0.9899 - val_loss: 0.2472 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0060 - accuracy: 0.9949 - val_loss: 0.2687 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0035 - accuracy: 0.9970 - val_loss: 0.2921 - val_accuracy: 0.7149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 0.2828 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.2807 - val_accuracy: 0.7149 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.2806 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.2805 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 0.2813 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2515 - accuracy: 0.6294\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.629 total time=  45.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 72ms/step - loss: 0.5747 - accuracy: 0.3980 - val_loss: 0.3022 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.1911 - accuracy: 0.7396 - val_loss: 0.2306 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0617 - accuracy: 0.9381 - val_loss: 0.3204 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0397 - accuracy: 0.9716 - val_loss: 0.2432 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0220 - accuracy: 0.9853 - val_loss: 0.2344 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0245 - accuracy: 0.9843 - val_loss: 0.2510 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 0.5200 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.3006 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 9.9434e-05 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.8945e-05 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.5329e-06 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.3207e-06 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2316 - accuracy: 0.6582\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.658 total time=  48.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 0.5501 - accuracy: 0.4135 - val_loss: 0.2509 - val_accuracy: 0.6108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.1987 - accuracy: 0.7367 - val_loss: 0.2653 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0906 - accuracy: 0.9107 - val_loss: 0.2362 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0321 - accuracy: 0.9756 - val_loss: 0.2968 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0197 - accuracy: 0.9878 - val_loss: 0.2686 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0262 - accuracy: 0.9878 - val_loss: 0.2785 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 0.3477 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0133 - accuracy: 0.9939 - val_loss: 0.3149 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.1510e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 4.2591e-05 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 8.0956e-06 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 2.0528e-06 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 5.9156e-07 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2364 - accuracy: 0.7015\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.702 total time=  52.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 72ms/step - loss: 0.5303 - accuracy: 0.4267 - val_loss: 0.2600 - val_accuracy: 0.6203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.1619 - accuracy: 0.7925 - val_loss: 0.2507 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0676 - accuracy: 0.9335 - val_loss: 0.3357 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0182 - accuracy: 0.9878 - val_loss: 0.3362 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0090 - accuracy: 0.9939 - val_loss: 0.4215 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0288 - accuracy: 0.9843 - val_loss: 0.2779 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0392 - accuracy: 0.9817 - val_loss: 0.3013 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 1.1895e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.7676 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.6918e-05 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.6776e-06 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 9.0461e-07 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2564 - accuracy: 0.6579\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.658 total time=  48.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.4145 - accuracy: 0.4492 - val_loss: 0.2555 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1083 - accuracy: 0.8934 - val_loss: 0.2170 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.2164 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 8.2522e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 5.4677e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 3.9807e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.2370e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.0631e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.9775e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 2.8912e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2036 - accuracy: 0.7789\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.779 total time=  50.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.3925 - accuracy: 0.4673 - val_loss: 0.2408 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1079 - accuracy: 0.8858 - val_loss: 0.1990 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0236 - accuracy: 0.9904 - val_loss: 0.1972 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.2125 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.7838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 6.9997e-04 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5950e-04 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.3811e-04 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.7866e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7134e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.6433e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5757e-04 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.5056e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 40ms/step - loss: 0.2159 - accuracy: 0.7563\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.756 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.3756 - accuracy: 0.5271 - val_loss: 0.2423 - val_accuracy: 0.6608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0744 - accuracy: 0.9335 - val_loss: 0.1915 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 0.2167 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2309 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.7559e-04 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 6.0797e-04 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.8477e-04 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.7187e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.5928e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.4653e-04 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.3366e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2041 - accuracy: 0.7188\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.719 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.5927 - accuracy: 0.3893 - val_loss: 0.3387 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.2050 - accuracy: 0.7183 - val_loss: 0.2866 - val_accuracy: 0.6541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0750 - accuracy: 0.9198 - val_loss: 0.2751 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.0412 - accuracy: 0.9660 - val_loss: 0.2409 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0119 - accuracy: 0.9919 - val_loss: 0.3166 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0125 - accuracy: 0.9934 - val_loss: 0.3184 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 0.0158 - accuracy: 0.9929 - val_loss: 0.3529 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0116 - accuracy: 0.9944 - val_loss: 0.3917 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3728 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.5355e-05 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.3945e-07 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 2.7788e-07 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.1277e-07 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2606 - accuracy: 0.7444\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.744 total time=  55.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.6743 - accuracy: 0.3891 - val_loss: 0.2946 - val_accuracy: 0.5338 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.1919 - accuracy: 0.7336 - val_loss: 0.2768 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0777 - accuracy: 0.9117 - val_loss: 0.3158 - val_accuracy: 0.6703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0281 - accuracy: 0.9731 - val_loss: 0.3756 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0119 - accuracy: 0.9924 - val_loss: 0.3366 - val_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0094 - accuracy: 0.9939 - val_loss: 0.3151 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.3131 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.0636e-04 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.9824e-05 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.4086e-06 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.6588e-07 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2939 - accuracy: 0.6254\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.625 total time=  47.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 71ms/step - loss: 0.7068 - accuracy: 0.4115 - val_loss: 0.3358 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.1801 - accuracy: 0.7697 - val_loss: 0.3840 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0720 - accuracy: 0.9264 - val_loss: 0.3247 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.0447 - accuracy: 0.9660 - val_loss: 0.2455 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9843 - val_loss: 0.2754 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0067 - accuracy: 0.9949 - val_loss: 0.2861 - val_accuracy: 0.7743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0250 - accuracy: 0.9873 - val_loss: 0.2934 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0273 - accuracy: 0.9893 - val_loss: 0.3858 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 8.8967e-04 - accuracy: 0.9995 - val_loss: 0.3593 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.1477e-05 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 4.4489e-06 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 57ms/step - loss: 1.0963e-06 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.7892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 3.1542e-07 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.7851 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 1.2160e-07 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2646 - accuracy: 0.7096\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.710 total time=  55.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 71ms/step - loss: 0.4014 - accuracy: 0.4807 - val_loss: 0.2516 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0948 - accuracy: 0.8980 - val_loss: 0.1990 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0223 - accuracy: 0.9873 - val_loss: 0.2211 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 9.9161e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5225e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 3.1932e-04 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.5909e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5241e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 2.4576e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.3914e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 2.3248e-04 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.7703 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 38ms/step - loss: 0.2019 - accuracy: 0.7282\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.728 total time=  46.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 70ms/step - loss: 0.4644 - accuracy: 0.4551 - val_loss: 0.2464 - val_accuracy: 0.6554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.0951 - accuracy: 0.9163 - val_loss: 0.2198 - val_accuracy: 0.7108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.2255 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.7662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 8.1083e-04 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.7749e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.6435e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 4.5060e-04 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.3890e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.2638e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.1397e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.7730 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 39ms/step - loss: 0.2371 - accuracy: 0.6863\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.686 total time=  46.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 77ms/step - loss: 0.4168 - accuracy: 0.5129 - val_loss: 0.2455 - val_accuracy: 0.6365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.0878 - accuracy: 0.9198 - val_loss: 0.2303 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.2366 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2528 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 9.2027e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 5.4966e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.3687e-04 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.2501e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 4.1339e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.0134e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 3.8942e-04 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 37ms/step - loss: 0.2521 - accuracy: 0.6832\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.683 total time=  46.5s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 7s 60ms/step - loss: 0.6478 - accuracy: 0.5504 - val_loss: 0.3686 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1041 - accuracy: 0.9344 - val_loss: 0.2548 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.2718 - val_accuracy: 0.8081 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.2362 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2394 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2545 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 8.0776e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 2.9130e-04 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.4626e-04 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1947e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.8324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 2.1628e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.8324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1358e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1057e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 2.0763e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.8338 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_resnet50_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xception_model(optimizer, init, n_hidden_1, n_hidden_2, activation):\n",
    "    base_model = xception.Xception(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_1, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(n_hidden_2, activation=\"relu\", kernel_initializer=init))\n",
    "    model.add(Dense(len(le.classes_), activation=activation, kernel_initializer=init))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 7s 80ms/step - loss: 5.5052 - accuracy: 0.1716 - val_loss: 0.5558 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.5941 - accuracy: 0.1523 - val_loss: 0.4440 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.4856 - accuracy: 0.1416 - val_loss: 0.5782 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4747 - accuracy: 0.1477 - val_loss: 0.4607 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 0.4579 - accuracy: 0.1629 - val_loss: 0.4575 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4623 - accuracy: 0.1467 - val_loss: 0.4341 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4630 - accuracy: 0.1386 - val_loss: 0.4465 - val_accuracy: 0.1149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4526 - accuracy: 0.1553 - val_loss: 0.4411 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4412 - accuracy: 0.1670 - val_loss: 0.4254 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.4174 - accuracy: 0.1898 - val_loss: 0.4061 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.4034 - accuracy: 0.1909 - val_loss: 0.4090 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.4019 - accuracy: 0.1827 - val_loss: 0.4029 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4053 - accuracy: 0.2051 - val_loss: 0.4048 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.3943 - accuracy: 0.2005 - val_loss: 0.4067 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3906 - accuracy: 0.2036 - val_loss: 0.4029 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3877 - accuracy: 0.2198 - val_loss: 0.4078 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.3877 - accuracy: 0.2112 - val_loss: 0.4169 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3805 - accuracy: 0.2162 - val_loss: 0.4194 - val_accuracy: 0.1932 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3784 - accuracy: 0.2157 - val_loss: 0.4325 - val_accuracy: 0.1959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3762 - accuracy: 0.2244 - val_loss: 0.4251 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 45ms/step - loss: 0.4131 - accuracy: 0.1846\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.185 total time= 1.3min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 5.9503 - accuracy: 0.1766 - val_loss: 0.5692 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5250 - accuracy: 0.1639 - val_loss: 0.4457 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4736 - accuracy: 0.1568 - val_loss: 0.5027 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4741 - accuracy: 0.1674 - val_loss: 0.4500 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4671 - accuracy: 0.1598 - val_loss: 0.5088 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4653 - accuracy: 0.1750 - val_loss: 0.4774 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4610 - accuracy: 0.1553 - val_loss: 0.4540 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4352 - accuracy: 0.1923 - val_loss: 0.4268 - val_accuracy: 0.1730 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4149 - accuracy: 0.1963 - val_loss: 0.4180 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4098 - accuracy: 0.1974 - val_loss: 0.4190 - val_accuracy: 0.1824 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4078 - accuracy: 0.1918 - val_loss: 0.4145 - val_accuracy: 0.1595 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4060 - accuracy: 0.1923 - val_loss: 0.4215 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4047 - accuracy: 0.1877 - val_loss: 0.4169 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4029 - accuracy: 0.1857 - val_loss: 0.4220 - val_accuracy: 0.1581 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4014 - accuracy: 0.1892 - val_loss: 0.4156 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3993 - accuracy: 0.1892 - val_loss: 0.4176 - val_accuracy: 0.1743 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3966 - accuracy: 0.1953 - val_loss: 0.4195 - val_accuracy: 0.1689 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3959 - accuracy: 0.1867 - val_loss: 0.4200 - val_accuracy: 0.1662 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3954 - accuracy: 0.1842 - val_loss: 0.4208 - val_accuracy: 0.1622 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3950 - accuracy: 0.1847 - val_loss: 0.4200 - val_accuracy: 0.1649 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 45ms/step - loss: 0.4262 - accuracy: 0.1553\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.155 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 5.1352 - accuracy: 0.1487 - val_loss: 1.5325 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5748 - accuracy: 0.1837 - val_loss: 0.9402 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7790 - accuracy: 0.1821 - val_loss: 0.4669 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4765 - accuracy: 0.1629 - val_loss: 0.6803 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4764 - accuracy: 0.1933 - val_loss: 0.5470 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4523 - accuracy: 0.2029 - val_loss: 0.4436 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4551 - accuracy: 0.2192 - val_loss: 0.4547 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4473 - accuracy: 0.2217 - val_loss: 0.5458 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4412 - accuracy: 0.2405 - val_loss: 0.4451 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4272 - accuracy: 0.2506 - val_loss: 0.4505 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4152 - accuracy: 0.2562 - val_loss: 0.5388 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3747 - accuracy: 0.2953 - val_loss: 0.4255 - val_accuracy: 0.2122 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3606 - accuracy: 0.3135 - val_loss: 0.4294 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3529 - accuracy: 0.3293 - val_loss: 0.4262 - val_accuracy: 0.2203 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3464 - accuracy: 0.3425 - val_loss: 0.4286 - val_accuracy: 0.2324 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3402 - accuracy: 0.3541 - val_loss: 0.4298 - val_accuracy: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3362 - accuracy: 0.3663 - val_loss: 0.4319 - val_accuracy: 0.2257 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3284 - accuracy: 0.3729 - val_loss: 0.4318 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3269 - accuracy: 0.3744 - val_loss: 0.4320 - val_accuracy: 0.2365 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3261 - accuracy: 0.3810 - val_loss: 0.4341 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4376 - accuracy: 0.2437\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.244 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.3497 - accuracy: 0.2051 - val_loss: 1.3589 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7989 - accuracy: 0.2421 - val_loss: 0.6050 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5106 - accuracy: 0.3076 - val_loss: 0.5616 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4061 - accuracy: 0.3817 - val_loss: 0.4710 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3814 - accuracy: 0.4452 - val_loss: 0.4874 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3720 - accuracy: 0.4574 - val_loss: 0.5427 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3291 - accuracy: 0.5147 - val_loss: 0.4607 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3164 - accuracy: 0.5416 - val_loss: 0.5047 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2950 - accuracy: 0.5792 - val_loss: 0.4668 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2467 - accuracy: 0.6487 - val_loss: 0.4643 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2052 - accuracy: 0.7274 - val_loss: 0.4677 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2004 - accuracy: 0.7376 - val_loss: 0.5423 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1571 - accuracy: 0.8137 - val_loss: 0.4930 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1303 - accuracy: 0.8690 - val_loss: 0.4931 - val_accuracy: 0.4351 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1212 - accuracy: 0.8782 - val_loss: 0.4803 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1139 - accuracy: 0.8954 - val_loss: 0.4834 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1088 - accuracy: 0.8990 - val_loss: 0.4849 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4513 - accuracy: 0.3347\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.335 total time=  57.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.3135 - accuracy: 0.2085 - val_loss: 1.3128 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8162 - accuracy: 0.3699 - val_loss: 0.7225 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5027 - accuracy: 0.4739 - val_loss: 0.5927 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3817 - accuracy: 0.5500 - val_loss: 0.5500 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3399 - accuracy: 0.5961 - val_loss: 0.5250 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2487 - accuracy: 0.7144 - val_loss: 0.5081 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2292 - accuracy: 0.7260 - val_loss: 0.5205 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2023 - accuracy: 0.7595 - val_loss: 0.5765 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1728 - accuracy: 0.8250 - val_loss: 0.6001 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1733 - accuracy: 0.8082 - val_loss: 0.6193 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1545 - accuracy: 0.8574 - val_loss: 0.6401 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0801 - accuracy: 0.9472 - val_loss: 0.5852 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0629 - accuracy: 0.9655 - val_loss: 0.5727 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0558 - accuracy: 0.9756 - val_loss: 0.5681 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0507 - accuracy: 0.9792 - val_loss: 0.5685 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.5734 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5296 - accuracy: 0.4213\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.421 total time=  54.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.9211 - accuracy: 0.2065 - val_loss: 1.1225 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7774 - accuracy: 0.2177 - val_loss: 0.5138 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4621 - accuracy: 0.2314 - val_loss: 0.4533 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4101 - accuracy: 0.3080 - val_loss: 0.4367 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3767 - accuracy: 0.3480 - val_loss: 0.4390 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3747 - accuracy: 0.3465 - val_loss: 0.4447 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3553 - accuracy: 0.3770 - val_loss: 0.4288 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3314 - accuracy: 0.4120 - val_loss: 0.4462 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3251 - accuracy: 0.4455 - val_loss: 0.4355 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3259 - accuracy: 0.4500 - val_loss: 0.4168 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2965 - accuracy: 0.4881 - val_loss: 0.4158 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2739 - accuracy: 0.5266 - val_loss: 0.4650 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2733 - accuracy: 0.5256 - val_loss: 0.4464 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2792 - accuracy: 0.5256 - val_loss: 0.4625 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2790 - accuracy: 0.5089 - val_loss: 0.4733 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2599 - accuracy: 0.5611 - val_loss: 0.4785 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2130 - accuracy: 0.6433 - val_loss: 0.4742 - val_accuracy: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2036 - accuracy: 0.6621 - val_loss: 0.4791 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1976 - accuracy: 0.6794 - val_loss: 0.4699 - val_accuracy: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1930 - accuracy: 0.6839 - val_loss: 0.4769 - val_accuracy: 0.3689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4980 - accuracy: 0.3411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.341 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 5.4990 - accuracy: 0.1736 - val_loss: 0.4952 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5581 - accuracy: 0.1569 - val_loss: 0.4752 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5155 - accuracy: 0.1680 - val_loss: 0.5636 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5031 - accuracy: 0.1487 - val_loss: 0.5532 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4864 - accuracy: 0.1685 - val_loss: 0.5137 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4436 - accuracy: 0.1711 - val_loss: 0.4320 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4166 - accuracy: 0.1538 - val_loss: 0.4116 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4097 - accuracy: 0.1543 - val_loss: 0.4094 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4099 - accuracy: 0.1497 - val_loss: 0.4091 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4084 - accuracy: 0.1584 - val_loss: 0.4089 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.1457 - val_loss: 0.4096 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4098 - accuracy: 0.1487 - val_loss: 0.4086 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.1442 - val_loss: 0.4091 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.1528 - val_loss: 0.4092 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4087 - accuracy: 0.1528 - val_loss: 0.4088 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4076 - accuracy: 0.1538 - val_loss: 0.4092 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4071 - accuracy: 0.1452 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4065 - accuracy: 0.1584 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4063 - accuracy: 0.1589 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4064 - accuracy: 0.1589 - val_loss: 0.4093 - val_accuracy: 0.1500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4087 - accuracy: 0.1298\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.130 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 6.8063 - accuracy: 0.1877 - val_loss: 0.6903 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.7548 - accuracy: 0.1862 - val_loss: 0.4629 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5444 - accuracy: 0.1466 - val_loss: 0.6246 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5122 - accuracy: 0.1644 - val_loss: 0.4629 - val_accuracy: 0.1392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5078 - accuracy: 0.1639 - val_loss: 0.4757 - val_accuracy: 0.1446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5114 - accuracy: 0.1801 - val_loss: 0.4614 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4965 - accuracy: 0.1745 - val_loss: 0.4497 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4391 - accuracy: 0.1649 - val_loss: 0.4384 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4160 - accuracy: 0.1583 - val_loss: 0.4152 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4174 - accuracy: 0.1593 - val_loss: 0.4193 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4106 - accuracy: 0.1573 - val_loss: 0.4177 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4164 - accuracy: 0.1598 - val_loss: 0.4150 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4048 - accuracy: 0.1598 - val_loss: 0.4164 - val_accuracy: 0.1419 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4103 - accuracy: 0.1583 - val_loss: 0.4146 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4137 - accuracy: 0.1547 - val_loss: 0.4169 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4098 - accuracy: 0.1684 - val_loss: 0.4164 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4045 - accuracy: 0.1593 - val_loss: 0.4186 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4041 - accuracy: 0.1553 - val_loss: 0.4219 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1583 - val_loss: 0.4198 - val_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4032 - accuracy: 0.1659 - val_loss: 0.4195 - val_accuracy: 0.1324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4163 - accuracy: 0.1462\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.146 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 5.6652 - accuracy: 0.2197 - val_loss: 0.6042 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6326 - accuracy: 0.1583 - val_loss: 0.4518 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5090 - accuracy: 0.1629 - val_loss: 0.4827 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5171 - accuracy: 0.1542 - val_loss: 0.5580 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4942 - accuracy: 0.1715 - val_loss: 0.5320 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4801 - accuracy: 0.1811 - val_loss: 0.4874 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4357 - accuracy: 0.1649 - val_loss: 0.4212 - val_accuracy: 0.1257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4143 - accuracy: 0.1654 - val_loss: 0.4156 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4045 - accuracy: 0.1684 - val_loss: 0.4069 - val_accuracy: 0.1338 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4136 - accuracy: 0.1634 - val_loss: 0.4397 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4063 - accuracy: 0.1512 - val_loss: 0.4279 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4039 - accuracy: 0.1583 - val_loss: 0.4147 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4016 - accuracy: 0.1618 - val_loss: 0.4220 - val_accuracy: 0.1311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4051 - accuracy: 0.1618 - val_loss: 0.4328 - val_accuracy: 0.1486 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4035 - accuracy: 0.1679 - val_loss: 0.4275 - val_accuracy: 0.1486 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4011 - accuracy: 0.1679 - val_loss: 0.4247 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4008 - accuracy: 0.1679 - val_loss: 0.4283 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4006 - accuracy: 0.1684 - val_loss: 0.4288 - val_accuracy: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4005 - accuracy: 0.1669 - val_loss: 0.4340 - val_accuracy: 0.1541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4623 - accuracy: 0.1431\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.143 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.6823 - accuracy: 0.2274 - val_loss: 1.8645 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.1079 - accuracy: 0.4127 - val_loss: 1.2851 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6537 - accuracy: 0.5345 - val_loss: 0.8910 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3921 - accuracy: 0.6523 - val_loss: 0.7582 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2432 - accuracy: 0.7457 - val_loss: 0.7268 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1851 - accuracy: 0.8213 - val_loss: 0.7496 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1213 - accuracy: 0.8843 - val_loss: 0.6641 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0876 - accuracy: 0.9299 - val_loss: 0.7061 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1460 - accuracy: 0.8766 - val_loss: 0.8367 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1648 - accuracy: 0.8690 - val_loss: 0.9564 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1882 - accuracy: 0.8604 - val_loss: 0.9399 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1190 - accuracy: 0.9025 - val_loss: 1.0109 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0371 - accuracy: 0.9787 - val_loss: 0.8296 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0157 - accuracy: 0.9934 - val_loss: 0.8150 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.8089 - val_accuracy: 0.5392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.8071 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.8080 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6637 - accuracy: 0.4787\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.479 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 3.4035 - accuracy: 0.2263 - val_loss: 1.3189 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9970 - accuracy: 0.3354 - val_loss: 0.9652 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5537 - accuracy: 0.3968 - val_loss: 0.6167 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4035 - accuracy: 0.4982 - val_loss: 0.5927 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3642 - accuracy: 0.5824 - val_loss: 0.6700 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3341 - accuracy: 0.6144 - val_loss: 0.6088 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2631 - accuracy: 0.6849 - val_loss: 0.5784 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2385 - accuracy: 0.7362 - val_loss: 0.5748 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1878 - accuracy: 0.7884 - val_loss: 0.5915 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1252 - accuracy: 0.8635 - val_loss: 0.6042 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1480 - accuracy: 0.8422 - val_loss: 0.8163 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2126 - accuracy: 0.7884 - val_loss: 0.8058 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1447 - accuracy: 0.8519 - val_loss: 0.6161 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0543 - accuracy: 0.9569 - val_loss: 0.6295 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0355 - accuracy: 0.9782 - val_loss: 0.6126 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0291 - accuracy: 0.9827 - val_loss: 0.6136 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0256 - accuracy: 0.9868 - val_loss: 0.6154 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0233 - accuracy: 0.9888 - val_loss: 0.6225 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5631 - accuracy: 0.4061\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.406 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.6407 - accuracy: 0.1684 - val_loss: 0.6456 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.5954 - accuracy: 0.1842 - val_loss: 0.5425 - val_accuracy: 0.1689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4918 - accuracy: 0.1837 - val_loss: 0.4822 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4364 - accuracy: 0.1994 - val_loss: 0.4534 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4144 - accuracy: 0.2080 - val_loss: 0.4399 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3955 - accuracy: 0.2613 - val_loss: 0.4336 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3842 - accuracy: 0.2790 - val_loss: 0.4250 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3638 - accuracy: 0.3455 - val_loss: 0.4427 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3686 - accuracy: 0.3420 - val_loss: 0.4336 - val_accuracy: 0.2770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3386 - accuracy: 0.3993 - val_loss: 0.4159 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3231 - accuracy: 0.4191 - val_loss: 0.4436 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3111 - accuracy: 0.4389 - val_loss: 0.4289 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2930 - accuracy: 0.4764 - val_loss: 0.3941 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2975 - accuracy: 0.4729 - val_loss: 0.4586 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2811 - accuracy: 0.4891 - val_loss: 0.4002 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2682 - accuracy: 0.5033 - val_loss: 0.4338 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2469 - accuracy: 0.5358 - val_loss: 0.4436 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2580 - accuracy: 0.5216 - val_loss: 0.4179 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2390 - accuracy: 0.5241 - val_loss: 0.4621 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2220 - accuracy: 0.5571 - val_loss: 0.4554 - val_accuracy: 0.3527 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4791 - accuracy: 0.3411\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.341 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 16.1676 - accuracy: 0.2020 - val_loss: 5.8794 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 5.1707 - accuracy: 0.3563 - val_loss: 4.3980 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.0889 - accuracy: 0.3614 - val_loss: 1.3912 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0022 - accuracy: 0.3995 - val_loss: 1.2224 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8284 - accuracy: 0.3782 - val_loss: 1.1166 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6800 - accuracy: 0.3635 - val_loss: 0.8185 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4762 - accuracy: 0.3924 - val_loss: 0.6522 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4098 - accuracy: 0.4152 - val_loss: 0.4341 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3962 - accuracy: 0.4345 - val_loss: 0.4915 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3795 - accuracy: 0.4685 - val_loss: 0.4607 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3532 - accuracy: 0.4909 - val_loss: 0.4792 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3179 - accuracy: 0.5528 - val_loss: 0.5369 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3123 - accuracy: 0.5706 - val_loss: 0.6678 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2305 - accuracy: 0.6543 - val_loss: 0.4757 - val_accuracy: 0.4284 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1942 - accuracy: 0.6883 - val_loss: 0.4882 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1767 - accuracy: 0.7223 - val_loss: 0.4910 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1648 - accuracy: 0.7315 - val_loss: 0.5123 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1554 - accuracy: 0.7457 - val_loss: 0.5193 - val_accuracy: 0.4473 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4425 - accuracy: 0.2677\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.268 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 11.9017 - accuracy: 0.2146 - val_loss: 3.0427 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.2012 - accuracy: 0.3151 - val_loss: 2.2465 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.6211 - accuracy: 0.3810 - val_loss: 1.3941 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.1560 - accuracy: 0.4206 - val_loss: 1.8720 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.9191 - accuracy: 0.4313 - val_loss: 1.7520 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7793 - accuracy: 0.4389 - val_loss: 0.9572 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6372 - accuracy: 0.4835 - val_loss: 0.8658 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5694 - accuracy: 0.5292 - val_loss: 0.8564 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5141 - accuracy: 0.5566 - val_loss: 0.7473 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4293 - accuracy: 0.6296 - val_loss: 0.9127 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4148 - accuracy: 0.6454 - val_loss: 1.1852 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3518 - accuracy: 0.6880 - val_loss: 1.0806 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2997 - accuracy: 0.7098 - val_loss: 1.9999 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3358 - accuracy: 0.7225 - val_loss: 0.7486 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1171 - accuracy: 0.8848 - val_loss: 0.6578 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0798 - accuracy: 0.9239 - val_loss: 0.6551 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0625 - accuracy: 0.9411 - val_loss: 0.6692 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0518 - accuracy: 0.9503 - val_loss: 0.6893 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0448 - accuracy: 0.9630 - val_loss: 0.7029 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0388 - accuracy: 0.9680 - val_loss: 0.7238 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6501 - accuracy: 0.5198\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.520 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 67ms/step - loss: 12.8045 - accuracy: 0.2060 - val_loss: 4.1157 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.5314 - accuracy: 0.3232 - val_loss: 3.5098 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.8632 - accuracy: 0.3907 - val_loss: 1.5372 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2347 - accuracy: 0.4099 - val_loss: 1.0130 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6756 - accuracy: 0.3952 - val_loss: 0.4947 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4720 - accuracy: 0.3247 - val_loss: 0.4759 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4171 - accuracy: 0.3683 - val_loss: 0.5281 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3976 - accuracy: 0.4120 - val_loss: 0.7712 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3718 - accuracy: 0.4287 - val_loss: 0.4598 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3453 - accuracy: 0.4389 - val_loss: 0.4851 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3449 - accuracy: 0.5155 - val_loss: 0.4535 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3185 - accuracy: 0.5449 - val_loss: 0.4871 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2946 - accuracy: 0.5708 - val_loss: 0.5308 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2678 - accuracy: 0.6032 - val_loss: 0.4656 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2574 - accuracy: 0.6190 - val_loss: 0.5245 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2441 - accuracy: 0.6535 - val_loss: 0.6632 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1679 - accuracy: 0.7473 - val_loss: 0.5338 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1414 - accuracy: 0.7778 - val_loss: 0.5471 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1305 - accuracy: 0.8006 - val_loss: 0.5598 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1224 - accuracy: 0.8102 - val_loss: 0.5872 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.5906 - accuracy: 0.4244\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.424 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.8600 - accuracy: 0.2538 - val_loss: 2.0417 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.4707 - accuracy: 0.4964 - val_loss: 2.2634 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0574 - accuracy: 0.6025 - val_loss: 1.6186 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.6084 - accuracy: 0.7518 - val_loss: 1.8510 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4340 - accuracy: 0.8112 - val_loss: 1.6404 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3753 - accuracy: 0.8594 - val_loss: 1.6452 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3024 - accuracy: 0.8919 - val_loss: 1.7159 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2188 - accuracy: 0.9127 - val_loss: 1.6316 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0555 - accuracy: 0.9873 - val_loss: 1.3458 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 1.3626 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 1.3423 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 1.3276 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 1.3254 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 1.3228 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.3243 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.3245 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 1.3216 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.3238 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.2094 - accuracy: 0.5497\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.550 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 5.9415 - accuracy: 0.2339 - val_loss: 2.0108 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.1935 - accuracy: 0.4531 - val_loss: 1.6824 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6947 - accuracy: 0.6058 - val_loss: 1.3327 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4625 - accuracy: 0.7215 - val_loss: 1.0725 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3814 - accuracy: 0.7859 - val_loss: 1.1545 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2525 - accuracy: 0.8447 - val_loss: 1.0405 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1443 - accuracy: 0.9097 - val_loss: 1.0849 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1291 - accuracy: 0.9224 - val_loss: 0.9856 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0737 - accuracy: 0.9665 - val_loss: 0.9476 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0612 - accuracy: 0.9701 - val_loss: 1.0374 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0503 - accuracy: 0.9777 - val_loss: 1.0567 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0700 - accuracy: 0.9589 - val_loss: 0.9429 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 1.0511 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.9877 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 1.0880 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1270 - accuracy: 0.9574 - val_loss: 1.5177 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1704 - accuracy: 0.9209 - val_loss: 1.3275 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 1.2893 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.2465 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 1.2421 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.2335 - accuracy: 0.5056\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.506 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 66ms/step - loss: 7.1412 - accuracy: 0.2572 - val_loss: 3.4562 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.1742 - accuracy: 0.5190 - val_loss: 2.2592 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.1864 - accuracy: 0.6398 - val_loss: 2.6801 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.7535 - accuracy: 0.7539 - val_loss: 2.4887 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.8697 - accuracy: 0.7418 - val_loss: 2.3548 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3721 - accuracy: 0.8711 - val_loss: 1.8297 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2275 - accuracy: 0.9112 - val_loss: 1.6885 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1557 - accuracy: 0.9406 - val_loss: 2.1141 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1304 - accuracy: 0.9493 - val_loss: 1.8272 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0761 - accuracy: 0.9741 - val_loss: 1.8069 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0725 - accuracy: 0.9746 - val_loss: 2.1625 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1018 - accuracy: 0.9716 - val_loss: 2.4308 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0449 - accuracy: 0.9899 - val_loss: 1.8441 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8455 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8477 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.9019 - accuracy: 0.4964\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.496 total time=  57.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 10.8204 - accuracy: 0.2127 - val_loss: 5.2057 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.8754 - accuracy: 0.2726 - val_loss: 1.1090 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9840 - accuracy: 0.2558 - val_loss: 0.8271 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5121 - accuracy: 0.2279 - val_loss: 0.4736 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4716 - accuracy: 0.2157 - val_loss: 0.4499 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4562 - accuracy: 0.2315 - val_loss: 0.4757 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4634 - accuracy: 0.2365 - val_loss: 0.4996 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4379 - accuracy: 0.2741 - val_loss: 0.4608 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4273 - accuracy: 0.3051 - val_loss: 0.4514 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3920 - accuracy: 0.3218 - val_loss: 0.4901 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3410 - accuracy: 0.3695 - val_loss: 0.4159 - val_accuracy: 0.2932 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3193 - accuracy: 0.3883 - val_loss: 0.4191 - val_accuracy: 0.3081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3083 - accuracy: 0.4046 - val_loss: 0.4305 - val_accuracy: 0.3216 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3010 - accuracy: 0.4157 - val_loss: 0.4336 - val_accuracy: 0.3176 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2941 - accuracy: 0.4442 - val_loss: 0.4323 - val_accuracy: 0.3162 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2847 - accuracy: 0.4624 - val_loss: 0.4564 - val_accuracy: 0.3324 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2754 - accuracy: 0.4660 - val_loss: 0.4428 - val_accuracy: 0.3162 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2726 - accuracy: 0.4751 - val_loss: 0.4424 - val_accuracy: 0.3189 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2712 - accuracy: 0.4802 - val_loss: 0.4426 - val_accuracy: 0.3257 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2701 - accuracy: 0.4853 - val_loss: 0.4440 - val_accuracy: 0.3243 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4385 - accuracy: 0.2982\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.298 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.6099 - accuracy: 0.2192 - val_loss: 4.2093 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.4111 - accuracy: 0.2522 - val_loss: 3.9088 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7599 - accuracy: 0.2197 - val_loss: 0.4722 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5016 - accuracy: 0.2009 - val_loss: 0.5086 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4831 - accuracy: 0.1948 - val_loss: 0.4900 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4778 - accuracy: 0.2466 - val_loss: 0.4966 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5144 - accuracy: 0.2222 - val_loss: 0.4833 - val_accuracy: 0.1838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4558 - accuracy: 0.2466 - val_loss: 0.4668 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4035 - accuracy: 0.2669 - val_loss: 0.4319 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3839 - accuracy: 0.2841 - val_loss: 0.4101 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3657 - accuracy: 0.3130 - val_loss: 0.4805 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3599 - accuracy: 0.3262 - val_loss: 0.4386 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3472 - accuracy: 0.3374 - val_loss: 0.4372 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3411 - accuracy: 0.3359 - val_loss: 0.4265 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3426 - accuracy: 0.3475 - val_loss: 0.4382 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3179 - accuracy: 0.3658 - val_loss: 0.4302 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3137 - accuracy: 0.3729 - val_loss: 0.4297 - val_accuracy: 0.3068 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3122 - accuracy: 0.3714 - val_loss: 0.4313 - val_accuracy: 0.3068 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3098 - accuracy: 0.3744 - val_loss: 0.4566 - val_accuracy: 0.3135 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3079 - accuracy: 0.3760 - val_loss: 0.4598 - val_accuracy: 0.3108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4208 - accuracy: 0.2051\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.205 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 69ms/step - loss: 10.6145 - accuracy: 0.2100 - val_loss: 1.8115 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.0065 - accuracy: 0.2694 - val_loss: 2.1775 - val_accuracy: 0.1568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6409 - accuracy: 0.2192 - val_loss: 0.5833 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5074 - accuracy: 0.1882 - val_loss: 0.5603 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4936 - accuracy: 0.1948 - val_loss: 0.4702 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4751 - accuracy: 0.2374 - val_loss: 0.4949 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4483 - accuracy: 0.2603 - val_loss: 0.4686 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4319 - accuracy: 0.2902 - val_loss: 0.4544 - val_accuracy: 0.2743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4235 - accuracy: 0.2719 - val_loss: 0.4334 - val_accuracy: 0.1797 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3938 - accuracy: 0.2588 - val_loss: 0.4811 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3870 - accuracy: 0.2846 - val_loss: 0.4304 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4015 - accuracy: 0.2892 - val_loss: 0.4218 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3722 - accuracy: 0.3044 - val_loss: 0.4355 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3563 - accuracy: 0.3212 - val_loss: 0.4493 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3709 - accuracy: 0.3506 - val_loss: 0.4664 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3365 - accuracy: 0.3577 - val_loss: 0.4460 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3361 - accuracy: 0.3612 - val_loss: 0.6358 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3260 - accuracy: 0.3993 - val_loss: 0.4774 - val_accuracy: 0.2635 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3020 - accuracy: 0.4084 - val_loss: 0.4909 - val_accuracy: 0.2662 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2950 - accuracy: 0.4115 - val_loss: 0.5018 - val_accuracy: 0.2662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5559 - accuracy: 0.2508\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.251 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.3747 - accuracy: 0.2274 - val_loss: 1.9726 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.2960 - accuracy: 0.4919 - val_loss: 1.5817 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7789 - accuracy: 0.6147 - val_loss: 1.3406 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.5329 - accuracy: 0.7218 - val_loss: 1.6418 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5286 - accuracy: 0.7239 - val_loss: 1.2553 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2385 - accuracy: 0.8553 - val_loss: 1.0790 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2135 - accuracy: 0.8655 - val_loss: 1.0127 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.9315 - val_loss: 1.1420 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1442 - accuracy: 0.9350 - val_loss: 1.2628 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1201 - accuracy: 0.9371 - val_loss: 1.2545 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1006 - accuracy: 0.9543 - val_loss: 1.4586 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0840 - accuracy: 0.9548 - val_loss: 1.2354 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 1.1063 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 1.0924 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 1.0879 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.0684 - accuracy: 0.4970\n",
      "[CV 1/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.497 total time=  56.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 61ms/step - loss: 5.9824 - accuracy: 0.2826 - val_loss: 3.0074 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6419 - accuracy: 0.4617 - val_loss: 1.6540 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7847 - accuracy: 0.6058 - val_loss: 1.3486 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4630 - accuracy: 0.6941 - val_loss: 1.0652 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3268 - accuracy: 0.7900 - val_loss: 1.0924 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2423 - accuracy: 0.8529 - val_loss: 1.1766 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1967 - accuracy: 0.8757 - val_loss: 1.0912 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1204 - accuracy: 0.9153 - val_loss: 1.0949 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0773 - accuracy: 0.9498 - val_loss: 1.1099 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 1.0016 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 1.0093 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 1.0061 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 1.0043 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 1.0078 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 1.0097 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.5135 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.9788 - accuracy: 0.5188\n",
      "[CV 2/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.519 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 7.5201 - accuracy: 0.2430 - val_loss: 2.6581 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.5065 - accuracy: 0.4987 - val_loss: 1.6695 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8421 - accuracy: 0.6367 - val_loss: 1.4283 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4758 - accuracy: 0.7468 - val_loss: 1.4070 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3420 - accuracy: 0.8138 - val_loss: 1.2610 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1676 - accuracy: 0.9097 - val_loss: 1.3455 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0884 - accuracy: 0.9482 - val_loss: 1.0706 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 1.1348 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1173 - accuracy: 0.9518 - val_loss: 1.3531 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0885 - accuracy: 0.9650 - val_loss: 1.3676 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1969 - accuracy: 0.9224 - val_loss: 1.6708 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1392 - accuracy: 0.9209 - val_loss: 1.4407 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 1.2830 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 1.2814 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2752 - val_accuracy: 0.5432 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.5459 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 1.1392 - accuracy: 0.4904\n",
      "[CV 3/3] END activation=sigmoid, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.490 total time=  57.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.0429 - accuracy: 0.2107 - val_loss: 0.4692 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4465 - accuracy: 0.3213 - val_loss: 0.4607 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4012 - accuracy: 0.3832 - val_loss: 0.4503 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3241 - accuracy: 0.5061 - val_loss: 0.4681 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2911 - accuracy: 0.5756 - val_loss: 0.4299 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2415 - accuracy: 0.6523 - val_loss: 0.4255 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2054 - accuracy: 0.7284 - val_loss: 0.4477 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1675 - accuracy: 0.7726 - val_loss: 0.4418 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1552 - accuracy: 0.8041 - val_loss: 0.4573 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1128 - accuracy: 0.8558 - val_loss: 0.6656 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1143 - accuracy: 0.8655 - val_loss: 0.8913 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0552 - accuracy: 0.9371 - val_loss: 0.5785 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0304 - accuracy: 0.9660 - val_loss: 0.6091 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0239 - accuracy: 0.9751 - val_loss: 0.6455 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0193 - accuracy: 0.9817 - val_loss: 0.6885 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0155 - accuracy: 0.9863 - val_loss: 0.7483 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4031 - accuracy: 0.4452\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.445 total time=  55.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.8678 - accuracy: 0.1852 - val_loss: 0.5140 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4354 - accuracy: 0.2648 - val_loss: 0.4307 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3874 - accuracy: 0.3440 - val_loss: 0.4029 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3475 - accuracy: 0.4236 - val_loss: 0.4172 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3113 - accuracy: 0.5221 - val_loss: 0.4125 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2848 - accuracy: 0.5764 - val_loss: 0.4502 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2421 - accuracy: 0.6367 - val_loss: 0.5032 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2135 - accuracy: 0.6890 - val_loss: 0.4599 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1501 - accuracy: 0.7854 - val_loss: 0.4313 - val_accuracy: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1257 - accuracy: 0.8260 - val_loss: 0.4452 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1152 - accuracy: 0.8427 - val_loss: 0.4490 - val_accuracy: 0.4446 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1060 - accuracy: 0.8574 - val_loss: 0.4571 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0985 - accuracy: 0.8691 - val_loss: 0.4822 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4087 - accuracy: 0.2954\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.295 total time=  45.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.2713 - accuracy: 0.1862 - val_loss: 0.4706 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4283 - accuracy: 0.3070 - val_loss: 0.4527 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3824 - accuracy: 0.3688 - val_loss: 0.4215 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3509 - accuracy: 0.4546 - val_loss: 0.4048 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3157 - accuracy: 0.5277 - val_loss: 0.3974 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2715 - accuracy: 0.5936 - val_loss: 0.4510 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2457 - accuracy: 0.6408 - val_loss: 0.4714 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2108 - accuracy: 0.6920 - val_loss: 0.5174 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1876 - accuracy: 0.7392 - val_loss: 0.5180 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1723 - accuracy: 0.7661 - val_loss: 0.5195 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1025 - accuracy: 0.8549 - val_loss: 0.4768 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0839 - accuracy: 0.8772 - val_loss: 0.4947 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0760 - accuracy: 0.8889 - val_loss: 0.5104 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0699 - accuracy: 0.9001 - val_loss: 0.5319 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0639 - accuracy: 0.9051 - val_loss: 0.5444 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4160 - accuracy: 0.3462\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.346 total time=  52.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.7033 - accuracy: 0.2157 - val_loss: 0.4179 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3887 - accuracy: 0.3127 - val_loss: 0.4074 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3489 - accuracy: 0.4091 - val_loss: 0.4008 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3145 - accuracy: 0.4731 - val_loss: 0.3864 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2775 - accuracy: 0.5584 - val_loss: 0.4240 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2403 - accuracy: 0.6416 - val_loss: 0.4316 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1941 - accuracy: 0.7178 - val_loss: 0.4266 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1639 - accuracy: 0.7635 - val_loss: 0.4676 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1399 - accuracy: 0.8152 - val_loss: 0.4835 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0907 - accuracy: 0.8843 - val_loss: 0.4614 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0759 - accuracy: 0.9091 - val_loss: 0.4635 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0698 - accuracy: 0.9157 - val_loss: 0.4758 - val_accuracy: 0.4541 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0639 - accuracy: 0.9264 - val_loss: 0.4785 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0595 - accuracy: 0.9310 - val_loss: 0.4822 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3749 - accuracy: 0.3793\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.379 total time=  47.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9310 - accuracy: 0.2232 - val_loss: 0.5465 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.4054 - val_loss: 0.4265 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3066 - accuracy: 0.5373 - val_loss: 0.4295 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2665 - accuracy: 0.6286 - val_loss: 0.3821 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1999 - accuracy: 0.7463 - val_loss: 0.4403 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1729 - accuracy: 0.7849 - val_loss: 0.4365 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1291 - accuracy: 0.8524 - val_loss: 0.4557 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0926 - accuracy: 0.9077 - val_loss: 0.4866 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0793 - accuracy: 0.9320 - val_loss: 0.4583 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.4599 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.4690 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: 0.4730 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0203 - accuracy: 0.9985 - val_loss: 0.4790 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0184 - accuracy: 0.9985 - val_loss: 0.4859 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3968 - accuracy: 0.4325\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.432 total time=  47.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 0.8404 - accuracy: 0.2253 - val_loss: 0.4767 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3783 - accuracy: 0.4165 - val_loss: 0.4379 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3062 - accuracy: 0.5353 - val_loss: 0.3769 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2252 - accuracy: 0.6976 - val_loss: 0.3807 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1760 - accuracy: 0.7884 - val_loss: 0.3800 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1479 - accuracy: 0.8331 - val_loss: 0.4310 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1093 - accuracy: 0.8935 - val_loss: 0.4453 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0795 - accuracy: 0.9356 - val_loss: 0.4949 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.4490 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 0.4499 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0273 - accuracy: 0.9964 - val_loss: 0.4558 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0248 - accuracy: 0.9959 - val_loss: 0.4634 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0227 - accuracy: 0.9975 - val_loss: 0.4705 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4019 - accuracy: 0.4020\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.402 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.3193 - accuracy: 0.1629 - val_loss: 0.4798 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4765 - accuracy: 0.2274 - val_loss: 0.4701 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4497 - accuracy: 0.2624 - val_loss: 0.4782 - val_accuracy: 0.2068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4104 - accuracy: 0.3289 - val_loss: 0.4690 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3835 - accuracy: 0.3904 - val_loss: 0.4700 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3614 - accuracy: 0.4345 - val_loss: 0.4975 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3259 - accuracy: 0.4929 - val_loss: 0.4382 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2942 - accuracy: 0.5330 - val_loss: 0.4555 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2794 - accuracy: 0.5787 - val_loss: 0.5091 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2614 - accuracy: 0.6102 - val_loss: 0.4564 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2289 - accuracy: 0.6584 - val_loss: 0.4816 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2083 - accuracy: 0.7086 - val_loss: 0.4931 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1460 - accuracy: 0.7766 - val_loss: 0.5095 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1302 - accuracy: 0.8010 - val_loss: 0.5254 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1208 - accuracy: 0.8107 - val_loss: 0.5442 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1142 - accuracy: 0.8198 - val_loss: 0.5795 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1086 - accuracy: 0.8249 - val_loss: 0.5816 - val_accuracy: 0.4230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4536 - accuracy: 0.2748\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.275 total time=  58.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.3856 - accuracy: 0.2090 - val_loss: 0.4332 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4659 - accuracy: 0.2659 - val_loss: 0.4360 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4201 - accuracy: 0.3044 - val_loss: 0.4357 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3907 - accuracy: 0.3719 - val_loss: 0.4152 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3576 - accuracy: 0.4277 - val_loss: 0.6280 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3452 - accuracy: 0.4515 - val_loss: 0.4414 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3014 - accuracy: 0.5175 - val_loss: 0.4208 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2902 - accuracy: 0.5388 - val_loss: 0.4180 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2776 - accuracy: 0.5784 - val_loss: 0.6176 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2122 - accuracy: 0.6565 - val_loss: 0.4416 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1805 - accuracy: 0.7047 - val_loss: 0.4630 - val_accuracy: 0.4095 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1689 - accuracy: 0.7179 - val_loss: 0.4676 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1609 - accuracy: 0.7372 - val_loss: 0.4812 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1520 - accuracy: 0.7549 - val_loss: 0.4905 - val_accuracy: 0.4419 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4325 - accuracy: 0.2883\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.288 total time=  48.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.1776 - accuracy: 0.1705 - val_loss: 0.6458 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4831 - accuracy: 0.2151 - val_loss: 0.4741 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4329 - accuracy: 0.2725 - val_loss: 0.5094 - val_accuracy: 0.2338 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4143 - accuracy: 0.3257 - val_loss: 0.4772 - val_accuracy: 0.2459 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3857 - accuracy: 0.3683 - val_loss: 0.4816 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3551 - accuracy: 0.4323 - val_loss: 0.5940 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3229 - accuracy: 0.4825 - val_loss: 0.6627 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2786 - accuracy: 0.5256 - val_loss: 0.4215 - val_accuracy: 0.3622 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2300 - accuracy: 0.6068 - val_loss: 0.4303 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2178 - accuracy: 0.6261 - val_loss: 0.4333 - val_accuracy: 0.3770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2072 - accuracy: 0.6494 - val_loss: 0.4503 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1977 - accuracy: 0.6657 - val_loss: 0.4519 - val_accuracy: 0.3892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1891 - accuracy: 0.6895 - val_loss: 0.4597 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1765 - accuracy: 0.7128 - val_loss: 0.4631 - val_accuracy: 0.3946 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1747 - accuracy: 0.7220 - val_loss: 0.4657 - val_accuracy: 0.3932 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1734 - accuracy: 0.7189 - val_loss: 0.4678 - val_accuracy: 0.3973 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1724 - accuracy: 0.7220 - val_loss: 0.4704 - val_accuracy: 0.3946 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1714 - accuracy: 0.7215 - val_loss: 0.4714 - val_accuracy: 0.3959 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4482 - accuracy: 0.3299\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.330 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 66ms/step - loss: 0.9025 - accuracy: 0.1919 - val_loss: 0.4529 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4290 - accuracy: 0.2553 - val_loss: 0.4204 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3841 - accuracy: 0.3259 - val_loss: 0.4364 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3535 - accuracy: 0.4157 - val_loss: 0.4014 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3258 - accuracy: 0.4711 - val_loss: 0.3975 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2792 - accuracy: 0.5599 - val_loss: 0.4062 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2450 - accuracy: 0.6269 - val_loss: 0.4397 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2173 - accuracy: 0.6736 - val_loss: 0.4817 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1972 - accuracy: 0.7213 - val_loss: 0.4363 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1780 - accuracy: 0.7457 - val_loss: 0.4802 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1354 - accuracy: 0.8157 - val_loss: 0.4623 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1135 - accuracy: 0.8386 - val_loss: 0.4731 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1049 - accuracy: 0.8497 - val_loss: 0.4781 - val_accuracy: 0.4405 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0982 - accuracy: 0.8584 - val_loss: 0.4795 - val_accuracy: 0.4486 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0931 - accuracy: 0.8726 - val_loss: 0.4854 - val_accuracy: 0.4514 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3984 - accuracy: 0.3174\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.317 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9646 - accuracy: 0.2040 - val_loss: 0.4468 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4044 - accuracy: 0.3146 - val_loss: 0.3981 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3596 - accuracy: 0.4135 - val_loss: 0.4044 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3132 - accuracy: 0.5028 - val_loss: 0.3817 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2698 - accuracy: 0.5830 - val_loss: 0.4022 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2217 - accuracy: 0.6814 - val_loss: 0.4184 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1866 - accuracy: 0.7311 - val_loss: 0.4332 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1669 - accuracy: 0.7727 - val_loss: 0.4670 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1372 - accuracy: 0.8082 - val_loss: 0.6012 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0950 - accuracy: 0.8858 - val_loss: 0.4508 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0661 - accuracy: 0.9310 - val_loss: 0.4467 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0600 - accuracy: 0.9346 - val_loss: 0.4522 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0552 - accuracy: 0.9422 - val_loss: 0.4584 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0514 - accuracy: 0.9482 - val_loss: 0.4654 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4009 - accuracy: 0.3584\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.358 total time=  47.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 0.9231 - accuracy: 0.1684 - val_loss: 0.4341 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4207 - accuracy: 0.2029 - val_loss: 0.4382 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3984 - accuracy: 0.2750 - val_loss: 0.4278 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3754 - accuracy: 0.3288 - val_loss: 0.4186 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3511 - accuracy: 0.3836 - val_loss: 0.4235 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3233 - accuracy: 0.4409 - val_loss: 0.4398 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3055 - accuracy: 0.4901 - val_loss: 0.4415 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2881 - accuracy: 0.5124 - val_loss: 0.4450 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2572 - accuracy: 0.5738 - val_loss: 0.4116 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2214 - accuracy: 0.6372 - val_loss: 0.4318 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1979 - accuracy: 0.6834 - val_loss: 0.4669 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1822 - accuracy: 0.7159 - val_loss: 0.4806 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1837 - accuracy: 0.7194 - val_loss: 0.6045 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1756 - accuracy: 0.7357 - val_loss: 0.4910 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1322 - accuracy: 0.8102 - val_loss: 0.4930 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1136 - accuracy: 0.8290 - val_loss: 0.4906 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1046 - accuracy: 0.8463 - val_loss: 0.5005 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0993 - accuracy: 0.8503 - val_loss: 0.5002 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0932 - accuracy: 0.8605 - val_loss: 0.5161 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4371 - accuracy: 0.3695\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.370 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.9326 - accuracy: 0.2056 - val_loss: 0.6462 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5670 - accuracy: 0.3071 - val_loss: 0.4608 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4045 - accuracy: 0.4447 - val_loss: 0.4301 - val_accuracy: 0.3459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3457 - accuracy: 0.5066 - val_loss: 0.4466 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2741 - accuracy: 0.6036 - val_loss: 0.4298 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2410 - accuracy: 0.6655 - val_loss: 0.5170 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1999 - accuracy: 0.7391 - val_loss: 0.4860 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1616 - accuracy: 0.7980 - val_loss: 0.5845 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1412 - accuracy: 0.8320 - val_loss: 0.4906 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1033 - accuracy: 0.8766 - val_loss: 0.6589 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0412 - accuracy: 0.9569 - val_loss: 0.5678 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0257 - accuracy: 0.9812 - val_loss: 0.6088 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0198 - accuracy: 0.9838 - val_loss: 0.6343 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0155 - accuracy: 0.9883 - val_loss: 0.6728 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0122 - accuracy: 0.9914 - val_loss: 0.7084 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3993 - accuracy: 0.4554\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.455 total time=  53.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.8246 - accuracy: 0.2222 - val_loss: 0.6217 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5194 - accuracy: 0.2897 - val_loss: 0.4815 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4136 - accuracy: 0.3709 - val_loss: 0.4212 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3656 - accuracy: 0.4713 - val_loss: 0.4348 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2991 - accuracy: 0.5596 - val_loss: 0.4106 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2561 - accuracy: 0.6352 - val_loss: 0.4694 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2167 - accuracy: 0.7057 - val_loss: 0.5981 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1834 - accuracy: 0.7681 - val_loss: 0.5098 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1508 - accuracy: 0.8108 - val_loss: 0.6310 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1294 - accuracy: 0.8407 - val_loss: 1.0169 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1013 - accuracy: 0.8935 - val_loss: 0.5232 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0445 - accuracy: 0.9554 - val_loss: 0.5535 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0350 - accuracy: 0.9680 - val_loss: 0.5841 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0283 - accuracy: 0.9751 - val_loss: 0.6091 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0234 - accuracy: 0.9807 - val_loss: 0.6413 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4173 - accuracy: 0.3695\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.370 total time=  52.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.6154 - accuracy: 0.2268 - val_loss: 0.7838 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4706 - accuracy: 0.2978 - val_loss: 0.4600 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3782 - accuracy: 0.4135 - val_loss: 0.4849 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3332 - accuracy: 0.4845 - val_loss: 0.4417 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2834 - accuracy: 0.5698 - val_loss: 0.4818 - val_accuracy: 0.3649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2524 - accuracy: 0.6438 - val_loss: 0.4149 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2124 - accuracy: 0.7007 - val_loss: 0.5114 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1715 - accuracy: 0.7580 - val_loss: 0.6691 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1429 - accuracy: 0.8097 - val_loss: 0.4357 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1258 - accuracy: 0.8397 - val_loss: 0.5717 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1003 - accuracy: 0.8721 - val_loss: 0.5777 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0404 - accuracy: 0.9599 - val_loss: 0.5900 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0296 - accuracy: 0.9721 - val_loss: 0.5926 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0239 - accuracy: 0.9782 - val_loss: 0.6091 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0201 - accuracy: 0.9807 - val_loss: 0.6429 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0169 - accuracy: 0.9843 - val_loss: 0.6890 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4232 - accuracy: 0.3980\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.398 total time=  56.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.2015 - accuracy: 0.2376 - val_loss: 0.5862 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4073 - accuracy: 0.4066 - val_loss: 0.4840 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2858 - accuracy: 0.5975 - val_loss: 0.4364 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2349 - accuracy: 0.6838 - val_loss: 0.4099 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1776 - accuracy: 0.7934 - val_loss: 0.4397 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1523 - accuracy: 0.8381 - val_loss: 0.4645 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1052 - accuracy: 0.9015 - val_loss: 0.4586 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0783 - accuracy: 0.9431 - val_loss: 0.4693 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0600 - accuracy: 0.9665 - val_loss: 0.5156 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 0.4817 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0246 - accuracy: 0.9985 - val_loss: 0.4929 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0219 - accuracy: 0.9985 - val_loss: 0.4967 - val_accuracy: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.5018 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0182 - accuracy: 0.9990 - val_loss: 0.5098 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3934 - accuracy: 0.4462\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.446 total time=  48.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.2355 - accuracy: 0.2344 - val_loss: 0.5575 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4081 - accuracy: 0.4592 - val_loss: 0.4961 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2874 - accuracy: 0.6088 - val_loss: 0.4138 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2261 - accuracy: 0.7118 - val_loss: 0.4388 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1695 - accuracy: 0.8077 - val_loss: 0.4339 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1273 - accuracy: 0.8828 - val_loss: 0.4979 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0974 - accuracy: 0.9137 - val_loss: 0.4712 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0627 - accuracy: 0.9594 - val_loss: 0.5233 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.4885 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0263 - accuracy: 0.9949 - val_loss: 0.4937 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0242 - accuracy: 0.9964 - val_loss: 0.4973 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.5047 - val_accuracy: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.5069 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4291 - accuracy: 0.4071\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.407 total time=  44.7s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.2395 - accuracy: 0.2374 - val_loss: 0.5830 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4260 - accuracy: 0.3902 - val_loss: 0.4481 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3176 - accuracy: 0.5282 - val_loss: 0.4410 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2490 - accuracy: 0.6494 - val_loss: 0.3982 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1899 - accuracy: 0.7570 - val_loss: 0.4116 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1506 - accuracy: 0.8305 - val_loss: 0.4074 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1119 - accuracy: 0.8848 - val_loss: 0.4412 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0853 - accuracy: 0.9290 - val_loss: 0.4777 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0813 - accuracy: 0.9356 - val_loss: 0.4682 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.4694 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.4787 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0230 - accuracy: 0.9959 - val_loss: 0.4850 - val_accuracy: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.4936 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9985 - val_loss: 0.4987 - val_accuracy: 0.5338 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3944 - accuracy: 0.3878\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.388 total time=  48.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 2.2252 - accuracy: 0.1954 - val_loss: 0.4525 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5102 - accuracy: 0.2355 - val_loss: 0.4593 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4390 - accuracy: 0.2893 - val_loss: 0.4476 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4075 - accuracy: 0.3381 - val_loss: 0.4355 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3815 - accuracy: 0.3944 - val_loss: 0.4991 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3697 - accuracy: 0.4462 - val_loss: 0.4459 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3229 - accuracy: 0.4949 - val_loss: 0.4311 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3009 - accuracy: 0.5269 - val_loss: 0.4743 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2850 - accuracy: 0.5655 - val_loss: 0.4166 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2526 - accuracy: 0.6102 - val_loss: 0.5497 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2633 - accuracy: 0.6178 - val_loss: 0.5051 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2201 - accuracy: 0.6726 - val_loss: 0.6993 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2101 - accuracy: 0.7076 - val_loss: 0.5486 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1864 - accuracy: 0.7157 - val_loss: 0.6184 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1312 - accuracy: 0.7924 - val_loss: 0.5425 - val_accuracy: 0.4459 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1133 - accuracy: 0.8152 - val_loss: 0.5609 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1026 - accuracy: 0.8345 - val_loss: 0.5851 - val_accuracy: 0.4622 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0954 - accuracy: 0.8421 - val_loss: 0.5894 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0888 - accuracy: 0.8614 - val_loss: 0.6188 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4045 - accuracy: 0.3834\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.383 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.0734 - accuracy: 0.2035 - val_loss: 0.5787 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4821 - accuracy: 0.2684 - val_loss: 0.4336 - val_accuracy: 0.2622 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4082 - accuracy: 0.3420 - val_loss: 0.4706 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3925 - accuracy: 0.3886 - val_loss: 0.4952 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3573 - accuracy: 0.4551 - val_loss: 0.3919 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3197 - accuracy: 0.5043 - val_loss: 0.4275 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2832 - accuracy: 0.5718 - val_loss: 0.5985 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2471 - accuracy: 0.6230 - val_loss: 0.6497 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2442 - accuracy: 0.6662 - val_loss: 0.4693 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2133 - accuracy: 0.6991 - val_loss: 0.4549 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1290 - accuracy: 0.8052 - val_loss: 0.4665 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1145 - accuracy: 0.8224 - val_loss: 0.4847 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1058 - accuracy: 0.8371 - val_loss: 0.5040 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0975 - accuracy: 0.8549 - val_loss: 0.5200 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0907 - accuracy: 0.8620 - val_loss: 0.5331 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.3259\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.326 total time=  52.4s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.4726 - accuracy: 0.1999 - val_loss: 0.5295 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4946 - accuracy: 0.2643 - val_loss: 0.4611 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4527 - accuracy: 0.2958 - val_loss: 0.4883 - val_accuracy: 0.2243 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3998 - accuracy: 0.3678 - val_loss: 0.4584 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3690 - accuracy: 0.4394 - val_loss: 0.4588 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3203 - accuracy: 0.5043 - val_loss: 0.6283 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2828 - accuracy: 0.5830 - val_loss: 0.4684 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2422 - accuracy: 0.6383 - val_loss: 0.5524 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2238 - accuracy: 0.6819 - val_loss: 0.5750 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1490 - accuracy: 0.7950 - val_loss: 0.4657 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1136 - accuracy: 0.8366 - val_loss: 0.4934 - val_accuracy: 0.4743 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1022 - accuracy: 0.8498 - val_loss: 0.4988 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0917 - accuracy: 0.8605 - val_loss: 0.5152 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0836 - accuracy: 0.8782 - val_loss: 0.5392 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4781 - accuracy: 0.2934\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.293 total time=  49.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.5127 - accuracy: 0.2036 - val_loss: 0.5828 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4514 - accuracy: 0.3853 - val_loss: 0.5196 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3508 - accuracy: 0.5147 - val_loss: 0.4934 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2758 - accuracy: 0.6426 - val_loss: 0.5075 - val_accuracy: 0.3595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2222 - accuracy: 0.7173 - val_loss: 0.4624 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1679 - accuracy: 0.8051 - val_loss: 0.4872 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1431 - accuracy: 0.8477 - val_loss: 0.5057 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1032 - accuracy: 0.9086 - val_loss: 0.5063 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1014 - accuracy: 0.9061 - val_loss: 0.5999 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0725 - accuracy: 0.9371 - val_loss: 0.6265 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0342 - accuracy: 0.9812 - val_loss: 0.5833 - val_accuracy: 0.4973 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.5806 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9959 - val_loss: 0.5902 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.5925 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.6010 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4419 - accuracy: 0.4168\n",
      "[CV 1/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.417 total time=  51.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.5962 - accuracy: 0.2349 - val_loss: 0.5666 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4325 - accuracy: 0.3653 - val_loss: 0.4262 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3295 - accuracy: 0.5084 - val_loss: 0.4535 - val_accuracy: 0.3797 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3145 - accuracy: 0.5622 - val_loss: 0.4016 - val_accuracy: 0.3811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2425 - accuracy: 0.6707 - val_loss: 0.4310 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1990 - accuracy: 0.7316 - val_loss: 0.4313 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1764 - accuracy: 0.7752 - val_loss: 0.4170 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1307 - accuracy: 0.8529 - val_loss: 0.4513 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1031 - accuracy: 0.8879 - val_loss: 0.4538 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0599 - accuracy: 0.9508 - val_loss: 0.4424 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0473 - accuracy: 0.9691 - val_loss: 0.4439 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0424 - accuracy: 0.9726 - val_loss: 0.4566 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0387 - accuracy: 0.9751 - val_loss: 0.4615 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0354 - accuracy: 0.9797 - val_loss: 0.4630 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4010 - accuracy: 0.3909\n",
      "[CV 2/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.391 total time=  47.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.6701 - accuracy: 0.2253 - val_loss: 0.7232 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4916 - accuracy: 0.3968 - val_loss: 0.5248 - val_accuracy: 0.3108 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3447 - accuracy: 0.5449 - val_loss: 0.5561 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2691 - accuracy: 0.6433 - val_loss: 0.5357 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2299 - accuracy: 0.7265 - val_loss: 0.4558 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1564 - accuracy: 0.8280 - val_loss: 0.4842 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1236 - accuracy: 0.8808 - val_loss: 0.5435 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0938 - accuracy: 0.9224 - val_loss: 0.5425 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1034 - accuracy: 0.9137 - val_loss: 0.5676 - val_accuracy: 0.5095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0589 - accuracy: 0.9619 - val_loss: 0.6511 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0324 - accuracy: 0.9833 - val_loss: 0.5566 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.5551 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 0.5592 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0154 - accuracy: 0.9990 - val_loss: 0.5622 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 0.5640 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4729 - accuracy: 0.4335\n",
      "[CV 3/3] END activation=sigmoid, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.434 total time=  51.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 10.0597 - accuracy: 0.1985 - val_loss: 5.8165 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 3.2921 - accuracy: 0.2675 - val_loss: 3.4235 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0706 - accuracy: 0.2548 - val_loss: 0.8960 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.9501 - accuracy: 0.2193 - val_loss: 0.5305 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5942 - accuracy: 0.1807 - val_loss: 0.4767 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4935 - accuracy: 0.1391 - val_loss: 0.4485 - val_accuracy: 0.1662 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4823 - accuracy: 0.1609 - val_loss: 0.4616 - val_accuracy: 0.1703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4744 - accuracy: 0.1868 - val_loss: 0.5462 - val_accuracy: 0.1730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4722 - accuracy: 0.1873 - val_loss: 0.4396 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4657 - accuracy: 0.2137 - val_loss: 0.4535 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4531 - accuracy: 0.1914 - val_loss: 0.4839 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4386 - accuracy: 0.2330 - val_loss: 0.4538 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4222 - accuracy: 0.2487 - val_loss: 0.4379 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4069 - accuracy: 0.2503 - val_loss: 0.4469 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3924 - accuracy: 0.2472 - val_loss: 0.4227 - val_accuracy: 0.2541 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3808 - accuracy: 0.2944 - val_loss: 0.3985 - val_accuracy: 0.2568 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3647 - accuracy: 0.3152 - val_loss: 0.4064 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3595 - accuracy: 0.3203 - val_loss: 0.4282 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3503 - accuracy: 0.3299 - val_loss: 0.3958 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3530 - accuracy: 0.3340 - val_loss: 0.4041 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3984 - accuracy: 0.2181\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.218 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 10.6362 - accuracy: 0.2171 - val_loss: 11.7141 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.7425 - accuracy: 0.2430 - val_loss: 0.5393 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4889 - accuracy: 0.1695 - val_loss: 0.4626 - val_accuracy: 0.1297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4845 - accuracy: 0.1603 - val_loss: 0.5218 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4705 - accuracy: 0.1771 - val_loss: 0.5078 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4629 - accuracy: 0.1639 - val_loss: 0.4593 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5043 - accuracy: 0.1847 - val_loss: 0.5189 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4484 - accuracy: 0.1872 - val_loss: 0.4671 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4492 - accuracy: 0.1938 - val_loss: 0.4616 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4317 - accuracy: 0.2227 - val_loss: 0.4668 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4190 - accuracy: 0.2248 - val_loss: 0.4734 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3812 - accuracy: 0.2912 - val_loss: 0.4484 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3739 - accuracy: 0.2948 - val_loss: 0.4483 - val_accuracy: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3687 - accuracy: 0.2983 - val_loss: 0.4481 - val_accuracy: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3625 - accuracy: 0.3044 - val_loss: 0.4561 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3577 - accuracy: 0.3090 - val_loss: 0.4515 - val_accuracy: 0.2446 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3524 - accuracy: 0.3019 - val_loss: 0.4525 - val_accuracy: 0.2473 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3492 - accuracy: 0.3161 - val_loss: 0.4616 - val_accuracy: 0.2270 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3465 - accuracy: 0.3130 - val_loss: 0.4598 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3405 - accuracy: 0.3161 - val_loss: 0.4604 - val_accuracy: 0.2378 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4500 - accuracy: 0.2152\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.215 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 9.0199 - accuracy: 0.2146 - val_loss: 2.8702 - val_accuracy: 0.2324 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.2904 - accuracy: 0.2912 - val_loss: 0.7251 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5577 - accuracy: 0.2227 - val_loss: 0.5339 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5000 - accuracy: 0.1938 - val_loss: 0.4904 - val_accuracy: 0.1473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4929 - accuracy: 0.1994 - val_loss: 0.5112 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4755 - accuracy: 0.2177 - val_loss: 0.4758 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4437 - accuracy: 0.2511 - val_loss: 0.5222 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4338 - accuracy: 0.2725 - val_loss: 0.4542 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4263 - accuracy: 0.2719 - val_loss: 0.4865 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4134 - accuracy: 0.2821 - val_loss: 0.4737 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3944 - accuracy: 0.3237 - val_loss: 0.5779 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3812 - accuracy: 0.3364 - val_loss: 0.5143 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3768 - accuracy: 0.3247 - val_loss: 0.4687 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3186 - accuracy: 0.4033 - val_loss: 0.4578 - val_accuracy: 0.2838 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3020 - accuracy: 0.4262 - val_loss: 0.4748 - val_accuracy: 0.2919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2933 - accuracy: 0.4592 - val_loss: 0.4718 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2874 - accuracy: 0.4556 - val_loss: 0.4789 - val_accuracy: 0.3014 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2814 - accuracy: 0.4683 - val_loss: 0.4908 - val_accuracy: 0.3149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4465 - accuracy: 0.2426\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.243 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.9431 - accuracy: 0.2391 - val_loss: 1.3224 - val_accuracy: 0.2797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9202 - accuracy: 0.4381 - val_loss: 1.2962 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6501 - accuracy: 0.5239 - val_loss: 0.8601 - val_accuracy: 0.3703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4092 - accuracy: 0.6492 - val_loss: 0.7221 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2562 - accuracy: 0.7954 - val_loss: 0.7577 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1782 - accuracy: 0.8447 - val_loss: 0.6899 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1071 - accuracy: 0.9208 - val_loss: 0.7446 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1050 - accuracy: 0.9239 - val_loss: 0.7094 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0678 - accuracy: 0.9533 - val_loss: 0.7219 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0483 - accuracy: 0.9761 - val_loss: 0.7609 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0520 - accuracy: 0.9746 - val_loss: 0.8069 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0264 - accuracy: 0.9898 - val_loss: 0.6943 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0162 - accuracy: 0.9985 - val_loss: 0.6950 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 0.6931 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 0.6971 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0139 - accuracy: 0.9990 - val_loss: 0.6969 - val_accuracy: 0.5311 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.6430 - accuracy: 0.4797\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.480 total time=  54.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 2.2970 - accuracy: 0.2303 - val_loss: 0.9432 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8849 - accuracy: 0.3952 - val_loss: 0.8404 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5455 - accuracy: 0.5246 - val_loss: 0.7580 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3992 - accuracy: 0.5951 - val_loss: 0.7485 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3213 - accuracy: 0.6900 - val_loss: 0.6150 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3231 - accuracy: 0.6743 - val_loss: 0.6977 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2016 - accuracy: 0.7849 - val_loss: 0.6528 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1652 - accuracy: 0.8371 - val_loss: 0.6859 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1141 - accuracy: 0.8767 - val_loss: 0.6773 - val_accuracy: 0.4784 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0984 - accuracy: 0.9061 - val_loss: 0.6953 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0531 - accuracy: 0.9589 - val_loss: 0.6553 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0408 - accuracy: 0.9731 - val_loss: 0.6582 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0376 - accuracy: 0.9772 - val_loss: 0.6532 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0347 - accuracy: 0.9802 - val_loss: 0.6514 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0327 - accuracy: 0.9848 - val_loss: 0.6566 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.6063 - accuracy: 0.4335\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.434 total time=  50.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.6544 - accuracy: 0.1695 - val_loss: 0.6999 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6816 - accuracy: 0.1563 - val_loss: 0.6531 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6197 - accuracy: 0.1481 - val_loss: 0.4888 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4560 - accuracy: 0.1578 - val_loss: 0.4497 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4542 - accuracy: 0.1598 - val_loss: 0.4619 - val_accuracy: 0.1365 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4356 - accuracy: 0.1801 - val_loss: 0.4630 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4273 - accuracy: 0.1740 - val_loss: 0.4482 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4253 - accuracy: 0.1710 - val_loss: 0.4437 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4238 - accuracy: 0.1715 - val_loss: 0.4246 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4176 - accuracy: 0.1700 - val_loss: 0.4242 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4188 - accuracy: 0.1842 - val_loss: 0.4198 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4151 - accuracy: 0.1781 - val_loss: 0.4276 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4161 - accuracy: 0.1913 - val_loss: 0.4205 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4137 - accuracy: 0.2171 - val_loss: 0.4453 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4203 - accuracy: 0.2385 - val_loss: 0.4206 - val_accuracy: 0.2311 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4042 - accuracy: 0.2770 - val_loss: 0.4402 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3933 - accuracy: 0.2993 - val_loss: 0.4213 - val_accuracy: 0.2243 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3822 - accuracy: 0.3034 - val_loss: 0.4245 - val_accuracy: 0.2054 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3792 - accuracy: 0.3125 - val_loss: 0.4295 - val_accuracy: 0.1919 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3776 - accuracy: 0.3237 - val_loss: 0.4240 - val_accuracy: 0.2135 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4290 - accuracy: 0.2122\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.212 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 4.7961 - accuracy: 0.1792 - val_loss: 0.5416 - val_accuracy: 0.1257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5964 - accuracy: 0.1508 - val_loss: 0.5253 - val_accuracy: 0.1243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5362 - accuracy: 0.1721 - val_loss: 0.4502 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5065 - accuracy: 0.1665 - val_loss: 0.5212 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4909 - accuracy: 0.1553 - val_loss: 0.4467 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4454 - accuracy: 0.1746 - val_loss: 0.4764 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4219 - accuracy: 0.1599 - val_loss: 0.4096 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4081 - accuracy: 0.1569 - val_loss: 0.4075 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.1579 - val_loss: 0.4077 - val_accuracy: 0.1378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4058 - accuracy: 0.1447 - val_loss: 0.4083 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4087 - accuracy: 0.1548 - val_loss: 0.4077 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4075 - accuracy: 0.1533 - val_loss: 0.4080 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4061 - accuracy: 0.1574 - val_loss: 0.4085 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1533 - val_loss: 0.4084 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4056 - accuracy: 0.1533 - val_loss: 0.4087 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4054 - accuracy: 0.1528 - val_loss: 0.4097 - val_accuracy: 0.1716 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4048 - accuracy: 0.1538 - val_loss: 0.4119 - val_accuracy: 0.1689 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4047 - accuracy: 0.1487 - val_loss: 0.4135 - val_accuracy: 0.1378 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4107 - accuracy: 0.1318\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.132 total time= 1.0min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 2.4554 - accuracy: 0.1740 - val_loss: 0.5744 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5478 - accuracy: 0.1542 - val_loss: 0.5549 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5145 - accuracy: 0.1720 - val_loss: 0.4512 - val_accuracy: 0.2108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4982 - accuracy: 0.1720 - val_loss: 0.4904 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4665 - accuracy: 0.1887 - val_loss: 0.4507 - val_accuracy: 0.1824 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4321 - accuracy: 0.1527 - val_loss: 0.4167 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4121 - accuracy: 0.1537 - val_loss: 0.4221 - val_accuracy: 0.1595 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4053 - accuracy: 0.1563 - val_loss: 0.4203 - val_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4056 - accuracy: 0.1679 - val_loss: 0.4323 - val_accuracy: 0.1541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4121 - accuracy: 0.1644 - val_loss: 0.4313 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4028 - accuracy: 0.1776 - val_loss: 0.4296 - val_accuracy: 0.1581 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3990 - accuracy: 0.1776 - val_loss: 0.4295 - val_accuracy: 0.1581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3980 - accuracy: 0.1816 - val_loss: 0.4361 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3971 - accuracy: 0.1842 - val_loss: 0.4400 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3966 - accuracy: 0.1842 - val_loss: 0.4435 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3960 - accuracy: 0.1852 - val_loss: 0.4457 - val_accuracy: 0.1608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4293 - accuracy: 0.1452\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.145 total time=  54.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 4.8071 - accuracy: 0.1837 - val_loss: 0.4874 - val_accuracy: 0.1743 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5810 - accuracy: 0.1832 - val_loss: 0.5046 - val_accuracy: 0.1959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5103 - accuracy: 0.1821 - val_loss: 0.4755 - val_accuracy: 0.1635 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4977 - accuracy: 0.1730 - val_loss: 0.4818 - val_accuracy: 0.2122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4631 - accuracy: 0.2090 - val_loss: 0.4772 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4476 - accuracy: 0.1969 - val_loss: 0.4481 - val_accuracy: 0.1459 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4203 - accuracy: 0.2136 - val_loss: 0.4190 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3997 - accuracy: 0.2268 - val_loss: 0.4263 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3922 - accuracy: 0.2192 - val_loss: 0.4329 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3825 - accuracy: 0.2456 - val_loss: 0.8398 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3827 - accuracy: 0.2582 - val_loss: 0.4607 - val_accuracy: 0.2014 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3849 - accuracy: 0.2638 - val_loss: 0.4215 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3649 - accuracy: 0.2572 - val_loss: 0.4368 - val_accuracy: 0.2324 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3574 - accuracy: 0.2745 - val_loss: 0.4527 - val_accuracy: 0.2405 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3543 - accuracy: 0.2867 - val_loss: 0.4609 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3517 - accuracy: 0.2958 - val_loss: 0.4657 - val_accuracy: 0.2230 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3493 - accuracy: 0.3009 - val_loss: 0.4920 - val_accuracy: 0.2351 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4245 - accuracy: 0.1898\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.190 total time=  58.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 2.6756 - accuracy: 0.2081 - val_loss: 1.5019 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8827 - accuracy: 0.3360 - val_loss: 0.7153 - val_accuracy: 0.3054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5041 - accuracy: 0.4249 - val_loss: 0.5799 - val_accuracy: 0.3216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4249 - accuracy: 0.4990 - val_loss: 0.5225 - val_accuracy: 0.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3615 - accuracy: 0.5091 - val_loss: 0.5378 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2816 - accuracy: 0.6157 - val_loss: 0.4882 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2551 - accuracy: 0.6523 - val_loss: 0.4995 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2165 - accuracy: 0.6939 - val_loss: 0.5023 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1907 - accuracy: 0.7558 - val_loss: 0.5504 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1664 - accuracy: 0.7756 - val_loss: 0.5961 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1377 - accuracy: 0.8127 - val_loss: 0.5358 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0878 - accuracy: 0.8888 - val_loss: 0.5493 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0714 - accuracy: 0.9046 - val_loss: 0.5434 - val_accuracy: 0.4676 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0630 - accuracy: 0.9254 - val_loss: 0.5435 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0585 - accuracy: 0.9294 - val_loss: 0.5473 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0553 - accuracy: 0.9360 - val_loss: 0.5603 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4809 - accuracy: 0.4047\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.405 total time=  54.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 60ms/step - loss: 4.3642 - accuracy: 0.2664 - val_loss: 1.6447 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0664 - accuracy: 0.5074 - val_loss: 1.3888 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6840 - accuracy: 0.6134 - val_loss: 0.9778 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.4919 - accuracy: 0.7128 - val_loss: 1.0265 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3013 - accuracy: 0.7976 - val_loss: 0.9671 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2387 - accuracy: 0.8498 - val_loss: 1.0511 - val_accuracy: 0.4311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1466 - accuracy: 0.9077 - val_loss: 1.0696 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1335 - accuracy: 0.9127 - val_loss: 1.0496 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1083 - accuracy: 0.9391 - val_loss: 0.9406 - val_accuracy: 0.5135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0617 - accuracy: 0.9655 - val_loss: 1.0275 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0825 - accuracy: 0.9523 - val_loss: 1.1474 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0472 - accuracy: 0.9746 - val_loss: 1.1394 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0356 - accuracy: 0.9827 - val_loss: 1.0729 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0664 - accuracy: 0.9635 - val_loss: 1.3178 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0197 - accuracy: 0.9909 - val_loss: 1.0740 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.9518 - accuracy: 0.4832\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.483 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 3.0215 - accuracy: 0.2136 - val_loss: 0.8739 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7591 - accuracy: 0.2841 - val_loss: 0.6529 - val_accuracy: 0.2730 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5155 - accuracy: 0.3004 - val_loss: 0.4578 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3951 - accuracy: 0.4115 - val_loss: 0.4726 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3617 - accuracy: 0.4318 - val_loss: 0.4617 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3081 - accuracy: 0.5200 - val_loss: 0.4580 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2948 - accuracy: 0.5449 - val_loss: 0.4479 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2655 - accuracy: 0.6083 - val_loss: 0.4481 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2274 - accuracy: 0.6672 - val_loss: 0.4799 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1984 - accuracy: 0.7215 - val_loss: 0.4910 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1895 - accuracy: 0.7397 - val_loss: 0.4754 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1983 - accuracy: 0.7347 - val_loss: 0.5104 - val_accuracy: 0.3973 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1475 - accuracy: 0.8001 - val_loss: 0.4930 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1200 - accuracy: 0.8356 - val_loss: 0.4863 - val_accuracy: 0.4568 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1117 - accuracy: 0.8519 - val_loss: 0.4998 - val_accuracy: 0.4595 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1041 - accuracy: 0.8666 - val_loss: 0.4994 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0996 - accuracy: 0.8706 - val_loss: 0.4977 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4443 - accuracy: 0.3503\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.350 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 64ms/step - loss: 16.3008 - accuracy: 0.2091 - val_loss: 6.9387 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 4.1344 - accuracy: 0.2873 - val_loss: 3.7083 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.8754 - accuracy: 0.2919 - val_loss: 1.5015 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1121 - accuracy: 0.2985 - val_loss: 1.1896 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6237 - accuracy: 0.2761 - val_loss: 0.7126 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5603 - accuracy: 0.2513 - val_loss: 0.5376 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4777 - accuracy: 0.2629 - val_loss: 0.7299 - val_accuracy: 0.1919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4457 - accuracy: 0.3051 - val_loss: 0.4680 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4310 - accuracy: 0.3137 - val_loss: 0.4195 - val_accuracy: 0.3122 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3979 - accuracy: 0.3690 - val_loss: 0.5456 - val_accuracy: 0.2824 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3690 - accuracy: 0.3812 - val_loss: 0.6157 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3658 - accuracy: 0.4076 - val_loss: 0.6232 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3697 - accuracy: 0.4269 - val_loss: 0.4161 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3223 - accuracy: 0.4772 - val_loss: 0.4528 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3141 - accuracy: 0.5086 - val_loss: 0.4074 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3011 - accuracy: 0.5102 - val_loss: 0.4090 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2915 - accuracy: 0.5325 - val_loss: 0.5079 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2818 - accuracy: 0.5503 - val_loss: 0.5376 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2893 - accuracy: 0.5695 - val_loss: 0.4610 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2675 - accuracy: 0.5924 - val_loss: 0.4430 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4157 - accuracy: 0.4178\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.418 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 68ms/step - loss: 12.3264 - accuracy: 0.2258 - val_loss: 9.4183 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5840 - accuracy: 0.3156 - val_loss: 1.7684 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6277 - accuracy: 0.3592 - val_loss: 1.9953 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1550 - accuracy: 0.3881 - val_loss: 1.0767 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.0018 - accuracy: 0.4302 - val_loss: 1.1689 - val_accuracy: 0.2932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.8577 - accuracy: 0.4500 - val_loss: 1.3589 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6962 - accuracy: 0.5104 - val_loss: 0.7851 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6057 - accuracy: 0.5317 - val_loss: 1.2678 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5150 - accuracy: 0.5652 - val_loss: 1.1714 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4488 - accuracy: 0.5972 - val_loss: 0.8724 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4356 - accuracy: 0.6413 - val_loss: 0.7654 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3849 - accuracy: 0.6657 - val_loss: 0.7294 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3362 - accuracy: 0.6870 - val_loss: 0.8033 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3125 - accuracy: 0.7174 - val_loss: 0.8465 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3298 - accuracy: 0.7412 - val_loss: 0.8387 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2384 - accuracy: 0.7686 - val_loss: 1.1566 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2306 - accuracy: 0.7889 - val_loss: 1.0689 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1135 - accuracy: 0.8787 - val_loss: 0.7647 - val_accuracy: 0.4851 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0563 - accuracy: 0.9386 - val_loss: 0.7713 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0447 - accuracy: 0.9619 - val_loss: 0.7773 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.7733 - accuracy: 0.4914\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.491 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.4303 - accuracy: 0.2121 - val_loss: 2.7728 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6942 - accuracy: 0.3009 - val_loss: 1.8511 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.5430 - accuracy: 0.3166 - val_loss: 1.1423 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.8848 - accuracy: 0.3902 - val_loss: 1.8346 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7930 - accuracy: 0.4348 - val_loss: 0.8140 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6432 - accuracy: 0.4515 - val_loss: 1.0543 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5439 - accuracy: 0.5348 - val_loss: 0.7910 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4646 - accuracy: 0.5637 - val_loss: 0.5889 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3604 - accuracy: 0.6256 - val_loss: 0.6966 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3314 - accuracy: 0.6479 - val_loss: 0.8401 - val_accuracy: 0.3770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3007 - accuracy: 0.6895 - val_loss: 0.4910 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2707 - accuracy: 0.7215 - val_loss: 0.4999 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2397 - accuracy: 0.7311 - val_loss: 0.6772 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2170 - accuracy: 0.7859 - val_loss: 0.5277 - val_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2064 - accuracy: 0.8042 - val_loss: 0.7883 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1751 - accuracy: 0.8321 - val_loss: 0.6238 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0622 - accuracy: 0.9432 - val_loss: 0.5357 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0501 - accuracy: 0.9625 - val_loss: 0.5817 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0433 - accuracy: 0.9660 - val_loss: 0.5485 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0380 - accuracy: 0.9751 - val_loss: 0.5789 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.6191 - accuracy: 0.4731\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.473 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 6.7286 - accuracy: 0.2467 - val_loss: 2.1646 - val_accuracy: 0.2257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.5378 - accuracy: 0.3914 - val_loss: 1.8009 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9709 - accuracy: 0.5513 - val_loss: 1.2120 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5657 - accuracy: 0.6741 - val_loss: 1.1775 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3890 - accuracy: 0.7558 - val_loss: 1.4453 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3810 - accuracy: 0.7995 - val_loss: 1.5860 - val_accuracy: 0.3541 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3211 - accuracy: 0.8198 - val_loss: 1.1809 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1406 - accuracy: 0.9254 - val_loss: 1.1085 - val_accuracy: 0.4676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1338 - accuracy: 0.9345 - val_loss: 1.0428 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1064 - accuracy: 0.9543 - val_loss: 1.1561 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0994 - accuracy: 0.9619 - val_loss: 1.2676 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0971 - accuracy: 0.9569 - val_loss: 1.2814 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0740 - accuracy: 0.9812 - val_loss: 1.2356 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0748 - accuracy: 0.9716 - val_loss: 1.2568 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 1.1444 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 1.1396 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 1.1414 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 1.1340 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 1.1378 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.9897 - accuracy: 0.4848\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.485 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.0997 - accuracy: 0.2445 - val_loss: 4.7656 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.2088 - accuracy: 0.4668 - val_loss: 2.1461 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.8336 - accuracy: 0.6616 - val_loss: 1.7626 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5194 - accuracy: 0.7433 - val_loss: 1.6808 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.3796 - accuracy: 0.7889 - val_loss: 1.9178 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2953 - accuracy: 0.8463 - val_loss: 1.4536 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1803 - accuracy: 0.9082 - val_loss: 1.7274 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1576 - accuracy: 0.9153 - val_loss: 1.5488 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1314 - accuracy: 0.9406 - val_loss: 1.6309 - val_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1702 - accuracy: 0.9214 - val_loss: 1.6783 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1473 - accuracy: 0.9417 - val_loss: 1.5920 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 1.4001 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 1.3874 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3754 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.5135 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.5108 - lr: 1.0000e-05\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 1.2778 - accuracy: 0.5076\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.508 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.0984 - accuracy: 0.2704 - val_loss: 2.9347 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 2.0989 - accuracy: 0.4394 - val_loss: 2.3632 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9700 - accuracy: 0.6372 - val_loss: 1.4591 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4942 - accuracy: 0.7610 - val_loss: 1.5753 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3559 - accuracy: 0.8067 - val_loss: 1.4308 - val_accuracy: 0.4797 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2638 - accuracy: 0.8691 - val_loss: 1.4862 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1446 - accuracy: 0.9269 - val_loss: 1.5721 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0883 - accuracy: 0.9579 - val_loss: 1.3057 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0534 - accuracy: 0.9767 - val_loss: 1.2541 - val_accuracy: 0.5135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0641 - accuracy: 0.9746 - val_loss: 1.4448 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 1.4330 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 1.4112 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0522 - accuracy: 0.9873 - val_loss: 1.6171 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 1.7047 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 1.3309 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3192 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 1.4510 - accuracy: 0.4995\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.499 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.0688 - accuracy: 0.1863 - val_loss: 6.7405 - val_accuracy: 0.1716 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.5562 - accuracy: 0.2381 - val_loss: 1.1755 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9845 - accuracy: 0.2264 - val_loss: 0.7389 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5696 - accuracy: 0.1898 - val_loss: 0.5176 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4995 - accuracy: 0.1858 - val_loss: 0.4668 - val_accuracy: 0.1649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5126 - accuracy: 0.1949 - val_loss: 0.4820 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4786 - accuracy: 0.2081 - val_loss: 0.5365 - val_accuracy: 0.1973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4701 - accuracy: 0.2223 - val_loss: 0.4585 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4464 - accuracy: 0.2213 - val_loss: 0.4709 - val_accuracy: 0.2135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4360 - accuracy: 0.2350 - val_loss: 0.4664 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4211 - accuracy: 0.2421 - val_loss: 0.4164 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4026 - accuracy: 0.2371 - val_loss: 0.4268 - val_accuracy: 0.1676 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3857 - accuracy: 0.2609 - val_loss: 0.4182 - val_accuracy: 0.2176 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3815 - accuracy: 0.2782 - val_loss: 0.4115 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3759 - accuracy: 0.2949 - val_loss: 0.4115 - val_accuracy: 0.2351 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3677 - accuracy: 0.3132 - val_loss: 0.4408 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3664 - accuracy: 0.3127 - val_loss: 0.4283 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3537 - accuracy: 0.3396 - val_loss: 0.5111 - val_accuracy: 0.2527 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4151 - accuracy: 0.3472 - val_loss: 0.4242 - val_accuracy: 0.1986 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3265 - accuracy: 0.3558 - val_loss: 0.4319 - val_accuracy: 0.2568 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4185 - accuracy: 0.2677\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.268 total time= 1.2min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 13.9954 - accuracy: 0.2131 - val_loss: 3.0591 - val_accuracy: 0.2851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.2401 - accuracy: 0.3090 - val_loss: 0.9560 - val_accuracy: 0.2095 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7502 - accuracy: 0.2308 - val_loss: 0.5149 - val_accuracy: 0.1554 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5030 - accuracy: 0.2171 - val_loss: 0.5077 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4801 - accuracy: 0.2374 - val_loss: 0.4599 - val_accuracy: 0.2284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4776 - accuracy: 0.2486 - val_loss: 0.5172 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4455 - accuracy: 0.2988 - val_loss: 0.4444 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4128 - accuracy: 0.3029 - val_loss: 0.4335 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3987 - accuracy: 0.3222 - val_loss: 0.3949 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3847 - accuracy: 0.3455 - val_loss: 0.4087 - val_accuracy: 0.2716 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3613 - accuracy: 0.3374 - val_loss: 0.4019 - val_accuracy: 0.2270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3515 - accuracy: 0.3450 - val_loss: 0.4842 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3413 - accuracy: 0.3785 - val_loss: 0.4174 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3624 - accuracy: 0.4074 - val_loss: 0.5214 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2893 - accuracy: 0.4566 - val_loss: 0.4527 - val_accuracy: 0.3351 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2742 - accuracy: 0.4617 - val_loss: 0.4518 - val_accuracy: 0.3432 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2670 - accuracy: 0.4713 - val_loss: 0.4615 - val_accuracy: 0.3486 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2624 - accuracy: 0.4810 - val_loss: 0.4754 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.2592 - accuracy: 0.4901 - val_loss: 0.4700 - val_accuracy: 0.3608 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4599 - accuracy: 0.2751\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.275 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 11.3090 - accuracy: 0.1938 - val_loss: 4.1237 - val_accuracy: 0.1811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 3.1433 - accuracy: 0.3029 - val_loss: 1.9857 - val_accuracy: 0.2919 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.8178 - accuracy: 0.3628 - val_loss: 1.3559 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1489 - accuracy: 0.3683 - val_loss: 1.2563 - val_accuracy: 0.2378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7567 - accuracy: 0.3902 - val_loss: 0.5928 - val_accuracy: 0.2662 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4759 - accuracy: 0.3765 - val_loss: 0.5045 - val_accuracy: 0.3014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4298 - accuracy: 0.4099 - val_loss: 0.5129 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4045 - accuracy: 0.4571 - val_loss: 0.5230 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3648 - accuracy: 0.5084 - val_loss: 0.4753 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3614 - accuracy: 0.5145 - val_loss: 0.5251 - val_accuracy: 0.3257 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3376 - accuracy: 0.5408 - val_loss: 0.7912 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3018 - accuracy: 0.5906 - val_loss: 0.5432 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3060 - accuracy: 0.6225 - val_loss: 0.4936 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2639 - accuracy: 0.6570 - val_loss: 0.5343 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1817 - accuracy: 0.7316 - val_loss: 0.5133 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1430 - accuracy: 0.7839 - val_loss: 0.5401 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1276 - accuracy: 0.8057 - val_loss: 0.5485 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1175 - accuracy: 0.8229 - val_loss: 0.5780 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.1097 - accuracy: 0.8311 - val_loss: 0.6081 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.5248 - accuracy: 0.3726\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.373 total time= 1.1min\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 7.2526 - accuracy: 0.2548 - val_loss: 2.4995 - val_accuracy: 0.2946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.6491 - accuracy: 0.4807 - val_loss: 1.6375 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7565 - accuracy: 0.6076 - val_loss: 1.3089 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4283 - accuracy: 0.7365 - val_loss: 1.1571 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3489 - accuracy: 0.7731 - val_loss: 1.0421 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2159 - accuracy: 0.8457 - val_loss: 0.9606 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1487 - accuracy: 0.8904 - val_loss: 0.9579 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1312 - accuracy: 0.9188 - val_loss: 1.1841 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0976 - accuracy: 0.9269 - val_loss: 1.2708 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0631 - accuracy: 0.9599 - val_loss: 1.0406 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0258 - accuracy: 0.9888 - val_loss: 1.0863 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0192 - accuracy: 0.9975 - val_loss: 1.0645 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 1.0319 - val_accuracy: 0.5284 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0345 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.8288 - accuracy: 0.4939\n",
      "[CV 1/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.494 total time=  57.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.7317 - accuracy: 0.2567 - val_loss: 1.5107 - val_accuracy: 0.2892 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.0757 - accuracy: 0.4110 - val_loss: 1.2117 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5273 - accuracy: 0.5302 - val_loss: 0.7017 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3895 - accuracy: 0.5530 - val_loss: 0.5481 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3193 - accuracy: 0.5890 - val_loss: 0.5504 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2585 - accuracy: 0.6728 - val_loss: 0.4708 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2063 - accuracy: 0.7321 - val_loss: 0.5330 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1626 - accuracy: 0.8102 - val_loss: 0.5368 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1595 - accuracy: 0.8341 - val_loss: 0.6050 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1550 - accuracy: 0.8194 - val_loss: 0.5804 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0943 - accuracy: 0.9001 - val_loss: 0.6271 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0506 - accuracy: 0.9543 - val_loss: 0.5681 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0372 - accuracy: 0.9665 - val_loss: 0.5677 - val_accuracy: 0.4662 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0346 - accuracy: 0.9696 - val_loss: 0.5597 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0301 - accuracy: 0.9767 - val_loss: 0.5669 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0278 - accuracy: 0.9792 - val_loss: 0.5765 - val_accuracy: 0.4716 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4896 - accuracy: 0.4213\n",
      "[CV 2/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.421 total time=  54.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 4.9616 - accuracy: 0.2461 - val_loss: 2.2350 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 1.2614 - accuracy: 0.4622 - val_loss: 1.2905 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.7221 - accuracy: 0.5606 - val_loss: 0.9237 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3526 - accuracy: 0.7057 - val_loss: 0.7974 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2003 - accuracy: 0.8077 - val_loss: 0.6290 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1214 - accuracy: 0.8879 - val_loss: 0.7586 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0923 - accuracy: 0.9254 - val_loss: 0.7402 - val_accuracy: 0.5122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0758 - accuracy: 0.9528 - val_loss: 0.7404 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0541 - accuracy: 0.9731 - val_loss: 0.6978 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0428 - accuracy: 0.9741 - val_loss: 0.7877 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.7296 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.7248 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.7237 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.5122 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.7086 - accuracy: 0.4558\n",
      "[CV 3/3] END activation=softmax, init=glorot_uniform, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.456 total time=  51.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.9562 - accuracy: 0.1924 - val_loss: 1.0761 - val_accuracy: 0.1851 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4575 - accuracy: 0.2772 - val_loss: 0.4428 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3904 - accuracy: 0.3452 - val_loss: 0.3923 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3546 - accuracy: 0.4228 - val_loss: 0.4019 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3088 - accuracy: 0.5168 - val_loss: 0.4220 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2824 - accuracy: 0.5614 - val_loss: 0.4093 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2420 - accuracy: 0.6431 - val_loss: 0.4202 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2085 - accuracy: 0.7051 - val_loss: 0.4238 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1295 - accuracy: 0.8208 - val_loss: 0.4147 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1097 - accuracy: 0.8553 - val_loss: 0.4327 - val_accuracy: 0.4757 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0978 - accuracy: 0.8736 - val_loss: 0.4408 - val_accuracy: 0.4649 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0897 - accuracy: 0.8843 - val_loss: 0.4444 - val_accuracy: 0.4824 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0826 - accuracy: 0.8939 - val_loss: 0.4574 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4055 - accuracy: 0.2972\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.297 total time=  46.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.3930 - accuracy: 0.1923 - val_loss: 0.4846 - val_accuracy: 0.2081 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4380 - accuracy: 0.2968 - val_loss: 0.4483 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3841 - accuracy: 0.3729 - val_loss: 0.4050 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3377 - accuracy: 0.4723 - val_loss: 0.4211 - val_accuracy: 0.3297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2957 - accuracy: 0.5378 - val_loss: 0.4169 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2611 - accuracy: 0.6124 - val_loss: 0.4871 - val_accuracy: 0.3743 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2372 - accuracy: 0.6474 - val_loss: 0.4465 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2012 - accuracy: 0.7194 - val_loss: 0.4843 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1297 - accuracy: 0.8204 - val_loss: 0.4406 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1070 - accuracy: 0.8519 - val_loss: 0.4470 - val_accuracy: 0.4959 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0964 - accuracy: 0.8656 - val_loss: 0.4571 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0869 - accuracy: 0.8828 - val_loss: 0.4851 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0788 - accuracy: 0.8929 - val_loss: 0.4943 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4133 - accuracy: 0.3157\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.316 total time=  46.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.1389 - accuracy: 0.1953 - val_loss: 0.4521 - val_accuracy: 0.2027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4414 - accuracy: 0.2664 - val_loss: 0.4617 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3899 - accuracy: 0.3501 - val_loss: 0.4241 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3501 - accuracy: 0.4338 - val_loss: 0.4072 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3146 - accuracy: 0.5079 - val_loss: 0.4534 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2827 - accuracy: 0.5865 - val_loss: 0.3989 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2495 - accuracy: 0.6494 - val_loss: 0.4131 - val_accuracy: 0.3959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2141 - accuracy: 0.7002 - val_loss: 0.5108 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1900 - accuracy: 0.7433 - val_loss: 0.5876 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1657 - accuracy: 0.7727 - val_loss: 0.5399 - val_accuracy: 0.4243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1435 - accuracy: 0.8031 - val_loss: 0.5371 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0800 - accuracy: 0.8864 - val_loss: 0.5063 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0662 - accuracy: 0.9041 - val_loss: 0.5368 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0582 - accuracy: 0.9168 - val_loss: 0.5479 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0522 - accuracy: 0.9229 - val_loss: 0.5825 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0476 - accuracy: 0.9325 - val_loss: 0.5928 - val_accuracy: 0.4689 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4103 - accuracy: 0.3909\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=rmsprop;, score=0.391 total time=  55.0s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.9177 - accuracy: 0.1980 - val_loss: 0.4396 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4005 - accuracy: 0.3305 - val_loss: 0.4009 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3427 - accuracy: 0.4477 - val_loss: 0.3960 - val_accuracy: 0.3608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2946 - accuracy: 0.5386 - val_loss: 0.4040 - val_accuracy: 0.3878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2637 - accuracy: 0.6066 - val_loss: 0.3826 - val_accuracy: 0.4216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2193 - accuracy: 0.6838 - val_loss: 0.3731 - val_accuracy: 0.4270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1865 - accuracy: 0.7442 - val_loss: 0.4130 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1611 - accuracy: 0.7883 - val_loss: 0.4290 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1403 - accuracy: 0.8213 - val_loss: 0.5313 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1390 - accuracy: 0.8213 - val_loss: 0.4718 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1109 - accuracy: 0.8629 - val_loss: 0.4981 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0665 - accuracy: 0.9249 - val_loss: 0.4537 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0548 - accuracy: 0.9376 - val_loss: 0.4592 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0500 - accuracy: 0.9447 - val_loss: 0.4655 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0463 - accuracy: 0.9497 - val_loss: 0.4650 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0432 - accuracy: 0.9543 - val_loss: 0.4733 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3841 - accuracy: 0.4249\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.425 total time=  54.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.8792 - accuracy: 0.2212 - val_loss: 0.4916 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4020 - accuracy: 0.3638 - val_loss: 0.4299 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3346 - accuracy: 0.4830 - val_loss: 0.4009 - val_accuracy: 0.3838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2736 - accuracy: 0.5961 - val_loss: 0.3947 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2202 - accuracy: 0.7007 - val_loss: 0.4170 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1713 - accuracy: 0.7747 - val_loss: 0.4408 - val_accuracy: 0.4568 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1301 - accuracy: 0.8442 - val_loss: 0.4684 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0966 - accuracy: 0.8929 - val_loss: 0.4745 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0700 - accuracy: 0.9254 - val_loss: 0.5264 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0358 - accuracy: 0.9756 - val_loss: 0.5067 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0285 - accuracy: 0.9822 - val_loss: 0.5165 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0247 - accuracy: 0.9868 - val_loss: 0.5238 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0221 - accuracy: 0.9909 - val_loss: 0.5337 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.5470 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4004 - accuracy: 0.3797\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.380 total time=  47.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 0.9308 - accuracy: 0.2207 - val_loss: 0.4652 - val_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3975 - accuracy: 0.3952 - val_loss: 0.4221 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3142 - accuracy: 0.5185 - val_loss: 0.3853 - val_accuracy: 0.4149 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2590 - accuracy: 0.6469 - val_loss: 0.4066 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2331 - accuracy: 0.6895 - val_loss: 0.4214 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1816 - accuracy: 0.7763 - val_loss: 0.4092 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1354 - accuracy: 0.8468 - val_loss: 0.4219 - val_accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1128 - accuracy: 0.8889 - val_loss: 0.4568 - val_accuracy: 0.4527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0636 - accuracy: 0.9564 - val_loss: 0.4147 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0505 - accuracy: 0.9711 - val_loss: 0.4185 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0463 - accuracy: 0.9751 - val_loss: 0.4239 - val_accuracy: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0424 - accuracy: 0.9782 - val_loss: 0.4299 - val_accuracy: 0.5270 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0393 - accuracy: 0.9792 - val_loss: 0.4351 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4005 - accuracy: 0.3482\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=64, optimizer=adam;, score=0.348 total time=  44.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 0.9974 - accuracy: 0.1817 - val_loss: 0.5140 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4630 - accuracy: 0.2076 - val_loss: 0.4774 - val_accuracy: 0.1946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4398 - accuracy: 0.2457 - val_loss: 0.4967 - val_accuracy: 0.2203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4207 - accuracy: 0.3030 - val_loss: 0.4597 - val_accuracy: 0.2757 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4012 - accuracy: 0.3558 - val_loss: 0.4882 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3661 - accuracy: 0.4310 - val_loss: 0.4950 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3453 - accuracy: 0.4721 - val_loss: 0.4249 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3178 - accuracy: 0.5234 - val_loss: 0.5614 - val_accuracy: 0.3392 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2853 - accuracy: 0.5614 - val_loss: 0.4912 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2770 - accuracy: 0.6091 - val_loss: 0.5243 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2502 - accuracy: 0.6223 - val_loss: 0.5238 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2286 - accuracy: 0.6721 - val_loss: 0.5437 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1740 - accuracy: 0.7147 - val_loss: 0.4905 - val_accuracy: 0.4270 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1489 - accuracy: 0.7513 - val_loss: 0.5074 - val_accuracy: 0.4324 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1376 - accuracy: 0.7640 - val_loss: 0.5095 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1293 - accuracy: 0.7817 - val_loss: 0.5403 - val_accuracy: 0.4338 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1242 - accuracy: 0.7888 - val_loss: 0.5499 - val_accuracy: 0.4392 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4146 - accuracy: 0.3195\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.319 total time=  58.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.1148 - accuracy: 0.1735 - val_loss: 0.4966 - val_accuracy: 0.1284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4708 - accuracy: 0.1989 - val_loss: 0.4685 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4432 - accuracy: 0.2699 - val_loss: 0.4058 - val_accuracy: 0.2838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4054 - accuracy: 0.3415 - val_loss: 0.4029 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3840 - accuracy: 0.3805 - val_loss: 0.4439 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3532 - accuracy: 0.4191 - val_loss: 0.4583 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3264 - accuracy: 0.4800 - val_loss: 0.5167 - val_accuracy: 0.2865 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3084 - accuracy: 0.5175 - val_loss: 0.4063 - val_accuracy: 0.3635 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2898 - accuracy: 0.5327 - val_loss: 0.4621 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2264 - accuracy: 0.6240 - val_loss: 0.4223 - val_accuracy: 0.3865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2076 - accuracy: 0.6438 - val_loss: 0.4222 - val_accuracy: 0.3946 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1972 - accuracy: 0.6646 - val_loss: 0.4267 - val_accuracy: 0.4149 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1888 - accuracy: 0.6763 - val_loss: 0.4316 - val_accuracy: 0.4122 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1819 - accuracy: 0.6875 - val_loss: 0.4330 - val_accuracy: 0.4189 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4214 - accuracy: 0.2914\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.291 total time=  49.2s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.5116 - accuracy: 0.1842 - val_loss: 0.4772 - val_accuracy: 0.1784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4609 - accuracy: 0.2131 - val_loss: 0.4937 - val_accuracy: 0.1905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4363 - accuracy: 0.2593 - val_loss: 0.4252 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4079 - accuracy: 0.3201 - val_loss: 0.4541 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3734 - accuracy: 0.3912 - val_loss: 0.4981 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3384 - accuracy: 0.4541 - val_loss: 0.4465 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3162 - accuracy: 0.5104 - val_loss: 0.4876 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2960 - accuracy: 0.5515 - val_loss: 0.4681 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2091 - accuracy: 0.6494 - val_loss: 0.4668 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1894 - accuracy: 0.6865 - val_loss: 0.4767 - val_accuracy: 0.4054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1774 - accuracy: 0.7057 - val_loss: 0.4978 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1688 - accuracy: 0.7179 - val_loss: 0.4940 - val_accuracy: 0.4162 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1602 - accuracy: 0.7311 - val_loss: 0.4939 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4267 - accuracy: 0.2650\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=rmsprop;, score=0.265 total time=  45.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.8589 - accuracy: 0.1904 - val_loss: 0.4509 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4337 - accuracy: 0.2437 - val_loss: 0.4244 - val_accuracy: 0.2189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3901 - accuracy: 0.3193 - val_loss: 0.4194 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3560 - accuracy: 0.3939 - val_loss: 0.4123 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3208 - accuracy: 0.4812 - val_loss: 0.3786 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2929 - accuracy: 0.5320 - val_loss: 0.3848 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2676 - accuracy: 0.5843 - val_loss: 0.4115 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2448 - accuracy: 0.6315 - val_loss: 0.3995 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2175 - accuracy: 0.6777 - val_loss: 0.4261 - val_accuracy: 0.3581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1880 - accuracy: 0.7284 - val_loss: 0.4280 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1429 - accuracy: 0.7985 - val_loss: 0.4338 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1258 - accuracy: 0.8178 - val_loss: 0.4354 - val_accuracy: 0.4216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1185 - accuracy: 0.8274 - val_loss: 0.4495 - val_accuracy: 0.4243 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1120 - accuracy: 0.8330 - val_loss: 0.4421 - val_accuracy: 0.4378 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1065 - accuracy: 0.8447 - val_loss: 0.4524 - val_accuracy: 0.4365 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3920 - accuracy: 0.3327\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.333 total time=  51.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.3386 - accuracy: 0.2171 - val_loss: 0.6290 - val_accuracy: 0.2446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4429 - accuracy: 0.3648 - val_loss: 0.4480 - val_accuracy: 0.3081 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3289 - accuracy: 0.5216 - val_loss: 0.4239 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2765 - accuracy: 0.5967 - val_loss: 0.4264 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2508 - accuracy: 0.6504 - val_loss: 0.4352 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1928 - accuracy: 0.7412 - val_loss: 0.4625 - val_accuracy: 0.4257 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1667 - accuracy: 0.8047 - val_loss: 0.4861 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.1435 - accuracy: 0.8168 - val_loss: 0.4837 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0819 - accuracy: 0.9209 - val_loss: 0.4599 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0676 - accuracy: 0.9411 - val_loss: 0.4604 - val_accuracy: 0.4770 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0604 - accuracy: 0.9528 - val_loss: 0.4672 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0558 - accuracy: 0.9609 - val_loss: 0.4669 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0517 - accuracy: 0.9640 - val_loss: 0.4729 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4438 - accuracy: 0.3756\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.376 total time=  44.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 0.9468 - accuracy: 0.1700 - val_loss: 0.4394 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.4276 - accuracy: 0.1892 - val_loss: 0.4399 - val_accuracy: 0.2054 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4095 - accuracy: 0.2501 - val_loss: 0.4206 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3762 - accuracy: 0.3232 - val_loss: 0.4232 - val_accuracy: 0.2297 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3489 - accuracy: 0.3810 - val_loss: 0.4067 - val_accuracy: 0.2986 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3355 - accuracy: 0.4328 - val_loss: 0.4625 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3133 - accuracy: 0.4830 - val_loss: 0.4127 - val_accuracy: 0.3027 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2729 - accuracy: 0.5581 - val_loss: 0.4290 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2669 - accuracy: 0.5632 - val_loss: 0.4569 - val_accuracy: 0.3176 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2711 - accuracy: 0.5713 - val_loss: 0.4693 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.2161 - accuracy: 0.6697 - val_loss: 0.4184 - val_accuracy: 0.3905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1881 - accuracy: 0.7169 - val_loss: 0.4170 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1767 - accuracy: 0.7362 - val_loss: 0.4167 - val_accuracy: 0.4135 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1673 - accuracy: 0.7534 - val_loss: 0.4252 - val_accuracy: 0.4108 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1603 - accuracy: 0.7595 - val_loss: 0.4241 - val_accuracy: 0.3973 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4202 - accuracy: 0.2721\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=64, n_hidden_2=128, optimizer=adam;, score=0.272 total time=  50.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 1.4700 - accuracy: 0.1873 - val_loss: 0.5629 - val_accuracy: 0.1878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.4871 - accuracy: 0.2782 - val_loss: 0.4211 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4043 - accuracy: 0.3914 - val_loss: 0.4503 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3448 - accuracy: 0.4670 - val_loss: 0.4159 - val_accuracy: 0.3311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2876 - accuracy: 0.5736 - val_loss: 0.4697 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.2614 - accuracy: 0.6249 - val_loss: 0.3906 - val_accuracy: 0.4392 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2150 - accuracy: 0.7091 - val_loss: 0.4349 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1819 - accuracy: 0.7640 - val_loss: 0.5132 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1575 - accuracy: 0.8030 - val_loss: 0.5679 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1322 - accuracy: 0.8452 - val_loss: 0.5645 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1120 - accuracy: 0.8635 - val_loss: 0.8196 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0428 - accuracy: 0.9589 - val_loss: 0.5906 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0286 - accuracy: 0.9741 - val_loss: 0.6143 - val_accuracy: 0.5095 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0229 - accuracy: 0.9812 - val_loss: 0.6316 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0180 - accuracy: 0.9868 - val_loss: 0.6914 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0148 - accuracy: 0.9878 - val_loss: 0.7127 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.3817 - accuracy: 0.4118\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.412 total time=  56.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 1.3149 - accuracy: 0.2212 - val_loss: 0.6311 - val_accuracy: 0.2473 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4623 - accuracy: 0.3125 - val_loss: 0.4256 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3875 - accuracy: 0.3856 - val_loss: 0.3893 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3293 - accuracy: 0.4881 - val_loss: 0.4872 - val_accuracy: 0.3284 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2872 - accuracy: 0.5748 - val_loss: 0.4331 - val_accuracy: 0.3892 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2472 - accuracy: 0.6413 - val_loss: 0.4005 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1987 - accuracy: 0.7270 - val_loss: 0.4978 - val_accuracy: 0.4284 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1852 - accuracy: 0.7681 - val_loss: 0.4928 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0963 - accuracy: 0.8904 - val_loss: 0.4666 - val_accuracy: 0.4838 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0770 - accuracy: 0.9127 - val_loss: 0.4810 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0667 - accuracy: 0.9264 - val_loss: 0.4961 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0588 - accuracy: 0.9381 - val_loss: 0.5152 - val_accuracy: 0.5014 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0504 - accuracy: 0.9533 - val_loss: 0.5429 - val_accuracy: 0.5027 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4039 - accuracy: 0.3340\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.334 total time=  46.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 1.7854 - accuracy: 0.2014 - val_loss: 0.5310 - val_accuracy: 0.2784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4735 - accuracy: 0.3019 - val_loss: 0.4217 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4001 - accuracy: 0.3912 - val_loss: 0.4008 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3516 - accuracy: 0.4688 - val_loss: 0.4513 - val_accuracy: 0.3230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2933 - accuracy: 0.5540 - val_loss: 0.4440 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2502 - accuracy: 0.6403 - val_loss: 0.5609 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2079 - accuracy: 0.7215 - val_loss: 0.4195 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1904 - accuracy: 0.7448 - val_loss: 0.4677 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1046 - accuracy: 0.8721 - val_loss: 0.4301 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0772 - accuracy: 0.9122 - val_loss: 0.4466 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0653 - accuracy: 0.9274 - val_loss: 0.4640 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0557 - accuracy: 0.9437 - val_loss: 0.4967 - val_accuracy: 0.5189 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0485 - accuracy: 0.9538 - val_loss: 0.5188 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4151 - accuracy: 0.3198\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=rmsprop;, score=0.320 total time=  46.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 61ms/step - loss: 1.3284 - accuracy: 0.2178 - val_loss: 0.6541 - val_accuracy: 0.2959 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4384 - accuracy: 0.4325 - val_loss: 0.4551 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3119 - accuracy: 0.5751 - val_loss: 0.4566 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2335 - accuracy: 0.7061 - val_loss: 0.4151 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1793 - accuracy: 0.7975 - val_loss: 0.4434 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1325 - accuracy: 0.8711 - val_loss: 0.4696 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0942 - accuracy: 0.9350 - val_loss: 0.4671 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0955 - accuracy: 0.9264 - val_loss: 0.5030 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0712 - accuracy: 0.9574 - val_loss: 0.5254 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0385 - accuracy: 0.9909 - val_loss: 0.4963 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0259 - accuracy: 0.9970 - val_loss: 0.4981 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 0.5008 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.5053 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0198 - accuracy: 0.9985 - val_loss: 0.5093 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4006 - accuracy: 0.4645\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.465 total time=  48.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.4306 - accuracy: 0.2603 - val_loss: 0.8863 - val_accuracy: 0.2405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4525 - accuracy: 0.4505 - val_loss: 0.4760 - val_accuracy: 0.3351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2904 - accuracy: 0.6038 - val_loss: 0.4472 - val_accuracy: 0.4027 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2023 - accuracy: 0.7509 - val_loss: 0.4327 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1529 - accuracy: 0.8427 - val_loss: 0.4798 - val_accuracy: 0.3932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1215 - accuracy: 0.8838 - val_loss: 0.4589 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0908 - accuracy: 0.9351 - val_loss: 0.5032 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0728 - accuracy: 0.9503 - val_loss: 0.5767 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0650 - accuracy: 0.9579 - val_loss: 0.5086 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.5087 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0224 - accuracy: 0.9970 - val_loss: 0.5107 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0200 - accuracy: 0.9980 - val_loss: 0.5172 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0182 - accuracy: 0.9995 - val_loss: 0.5229 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 0.5285 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4195 - accuracy: 0.4548\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.455 total time=  48.3s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 1.3174 - accuracy: 0.2141 - val_loss: 0.5482 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4380 - accuracy: 0.4084 - val_loss: 0.4325 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3159 - accuracy: 0.5576 - val_loss: 0.4485 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2404 - accuracy: 0.6646 - val_loss: 0.4072 - val_accuracy: 0.4230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1805 - accuracy: 0.7742 - val_loss: 0.4168 - val_accuracy: 0.4689 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1390 - accuracy: 0.8605 - val_loss: 0.4234 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1079 - accuracy: 0.9066 - val_loss: 0.4703 - val_accuracy: 0.4419 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0886 - accuracy: 0.9310 - val_loss: 0.4595 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0825 - accuracy: 0.9391 - val_loss: 0.4906 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 0.4801 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0301 - accuracy: 0.9934 - val_loss: 0.4758 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0259 - accuracy: 0.9964 - val_loss: 0.4815 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0237 - accuracy: 0.9970 - val_loss: 0.4837 - val_accuracy: 0.5230 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0218 - accuracy: 0.9970 - val_loss: 0.4869 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4408 - accuracy: 0.4142\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=64, optimizer=adam;, score=0.414 total time=  47.9s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 63ms/step - loss: 2.5718 - accuracy: 0.1878 - val_loss: 0.7332 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.5610 - accuracy: 0.2609 - val_loss: 0.4548 - val_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4490 - accuracy: 0.3107 - val_loss: 0.6866 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3988 - accuracy: 0.3832 - val_loss: 0.5234 - val_accuracy: 0.3162 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3510 - accuracy: 0.4706 - val_loss: 0.4188 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3068 - accuracy: 0.5665 - val_loss: 0.4369 - val_accuracy: 0.3824 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2675 - accuracy: 0.6081 - val_loss: 0.4452 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2339 - accuracy: 0.6701 - val_loss: 0.5750 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2134 - accuracy: 0.7239 - val_loss: 0.5070 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1800 - accuracy: 0.7579 - val_loss: 0.5608 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1022 - accuracy: 0.8543 - val_loss: 0.4727 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0791 - accuracy: 0.8888 - val_loss: 0.4957 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0695 - accuracy: 0.9005 - val_loss: 0.5083 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0621 - accuracy: 0.9157 - val_loss: 0.5320 - val_accuracy: 0.4986 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0555 - accuracy: 0.9254 - val_loss: 0.5557 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4270 - accuracy: 0.3692\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.369 total time=  53.1s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 63ms/step - loss: 2.5489 - accuracy: 0.2243 - val_loss: 0.9351 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5142 - accuracy: 0.2714 - val_loss: 0.4617 - val_accuracy: 0.2392 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.4281 - accuracy: 0.3176 - val_loss: 0.5260 - val_accuracy: 0.2608 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3928 - accuracy: 0.4170 - val_loss: 0.4637 - val_accuracy: 0.2878 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3349 - accuracy: 0.4926 - val_loss: 0.4355 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.3231 - accuracy: 0.5403 - val_loss: 0.4566 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2718 - accuracy: 0.6083 - val_loss: 0.4565 - val_accuracy: 0.3919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2425 - accuracy: 0.6545 - val_loss: 0.5005 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2161 - accuracy: 0.6991 - val_loss: 0.4998 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1845 - accuracy: 0.7549 - val_loss: 0.6107 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1127 - accuracy: 0.8442 - val_loss: 0.4925 - val_accuracy: 0.4797 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0885 - accuracy: 0.8803 - val_loss: 0.5073 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0788 - accuracy: 0.8929 - val_loss: 0.5203 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0708 - accuracy: 0.9087 - val_loss: 0.5463 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0644 - accuracy: 0.9168 - val_loss: 0.5559 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4725 - accuracy: 0.3289\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.329 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 64ms/step - loss: 2.7738 - accuracy: 0.1928 - val_loss: 0.7901 - val_accuracy: 0.1932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.5683 - accuracy: 0.2801 - val_loss: 0.5519 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4665 - accuracy: 0.3278 - val_loss: 0.4504 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.3919 - accuracy: 0.4028 - val_loss: 0.4215 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.3405 - accuracy: 0.5003 - val_loss: 0.4161 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2964 - accuracy: 0.5728 - val_loss: 0.4201 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2646 - accuracy: 0.6372 - val_loss: 0.5464 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.2292 - accuracy: 0.6849 - val_loss: 0.4725 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1995 - accuracy: 0.7078 - val_loss: 0.5129 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1650 - accuracy: 0.7884 - val_loss: 0.5056 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1034 - accuracy: 0.8625 - val_loss: 0.4851 - val_accuracy: 0.4784 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0782 - accuracy: 0.8924 - val_loss: 0.5211 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0686 - accuracy: 0.9036 - val_loss: 0.5178 - val_accuracy: 0.4811 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.0609 - accuracy: 0.9188 - val_loss: 0.5383 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0540 - accuracy: 0.9300 - val_loss: 0.5622 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4498 - accuracy: 0.3685\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=rmsprop;, score=0.369 total time=  53.5s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.5251 - accuracy: 0.2193 - val_loss: 0.7246 - val_accuracy: 0.2649 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5049 - accuracy: 0.3777 - val_loss: 0.5025 - val_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.3285 - accuracy: 0.5299 - val_loss: 0.5157 - val_accuracy: 0.3676 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2415 - accuracy: 0.6766 - val_loss: 0.4411 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1862 - accuracy: 0.7766 - val_loss: 0.4629 - val_accuracy: 0.4446 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.8558 - val_loss: 0.4851 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0913 - accuracy: 0.9325 - val_loss: 0.4901 - val_accuracy: 0.4770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0663 - accuracy: 0.9569 - val_loss: 0.5430 - val_accuracy: 0.4554 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0583 - accuracy: 0.9548 - val_loss: 0.5644 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0285 - accuracy: 0.9934 - val_loss: 0.5538 - val_accuracy: 0.4878 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 0.5559 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.5596 - val_accuracy: 0.4865 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.5662 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.5725 - val_accuracy: 0.4905 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 0.3996 - accuracy: 0.4320\n",
      "[CV 1/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.432 total time=  47.8s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 1.9432 - accuracy: 0.2486 - val_loss: 0.7832 - val_accuracy: 0.2811 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5377 - accuracy: 0.4211 - val_loss: 0.5269 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3237 - accuracy: 0.5677 - val_loss: 0.4693 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2392 - accuracy: 0.7144 - val_loss: 0.4877 - val_accuracy: 0.4041 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.1943 - accuracy: 0.7752 - val_loss: 0.4678 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.1554 - accuracy: 0.8366 - val_loss: 0.4514 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1077 - accuracy: 0.8924 - val_loss: 0.4938 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0752 - accuracy: 0.9427 - val_loss: 0.5210 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0495 - accuracy: 0.9772 - val_loss: 0.5553 - val_accuracy: 0.4757 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0328 - accuracy: 0.9868 - val_loss: 0.5519 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.6309 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 0.5910 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5954 - val_accuracy: 0.5054 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.5081 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.5068 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4666 - accuracy: 0.4437\n",
      "[CV 2/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.444 total time=  54.6s\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 62ms/step - loss: 1.5766 - accuracy: 0.2324 - val_loss: 0.6372 - val_accuracy: 0.2595 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4506 - accuracy: 0.3800 - val_loss: 0.4842 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.3510 - accuracy: 0.5013 - val_loss: 0.4813 - val_accuracy: 0.3405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.2914 - accuracy: 0.5921 - val_loss: 0.4442 - val_accuracy: 0.4068 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2345 - accuracy: 0.6859 - val_loss: 0.4469 - val_accuracy: 0.4351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.2128 - accuracy: 0.7362 - val_loss: 0.4573 - val_accuracy: 0.4473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1386 - accuracy: 0.8371 - val_loss: 0.4825 - val_accuracy: 0.4649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.1041 - accuracy: 0.8879 - val_loss: 0.4803 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0713 - accuracy: 0.9315 - val_loss: 0.4907 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0376 - accuracy: 0.9817 - val_loss: 0.4940 - val_accuracy: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0306 - accuracy: 0.9868 - val_loss: 0.4980 - val_accuracy: 0.5243 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.4997 - val_accuracy: 0.5216 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.5075 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.5106 - val_accuracy: 0.5203 - lr: 1.0000e-04\n",
      "31/31 [==============================] - 2s 35ms/step - loss: 0.4922 - accuracy: 0.3563\n",
      "[CV 3/3] END activation=softmax, init=normal, n_hidden_1=128, n_hidden_2=128, optimizer=adam;, score=0.356 total time=  48.2s\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 6s 56ms/step - loss: 6.1633 - accuracy: 0.2700 - val_loss: 4.4618 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.7228 - accuracy: 0.4533 - val_loss: 1.6559 - val_accuracy: 0.3986 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7875 - accuracy: 0.5907 - val_loss: 1.1847 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5867 - accuracy: 0.6644 - val_loss: 1.0168 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.3306 - accuracy: 0.7994 - val_loss: 1.0194 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.2066 - accuracy: 0.8572 - val_loss: 1.0069 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.1678 - accuracy: 0.8775 - val_loss: 0.9040 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1229 - accuracy: 0.9279 - val_loss: 0.9315 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0713 - accuracy: 0.9597 - val_loss: 0.9885 - val_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.0489 - accuracy: 0.9770 - val_loss: 0.9011 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0485 - accuracy: 0.9760 - val_loss: 0.9804 - val_accuracy: 0.5270 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0678 - accuracy: 0.9709 - val_loss: 1.0659 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1192 - accuracy: 0.9381 - val_loss: 1.0599 - val_accuracy: 0.5514 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0679 - accuracy: 0.9712 - val_loss: 1.1884 - val_accuracy: 0.5068 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.1189 - accuracy: 0.9476 - val_loss: 1.1364 - val_accuracy: 0.5392 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 1.0720 - val_accuracy: 0.5486 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 1.0506 - val_accuracy: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 1.0451 - val_accuracy: 0.5541 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.5527 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.5581 - lr: 1.0000e-04\n",
      "Best Parameters: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'}\n",
      "Best Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_xception_model)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'init': ['glorot_uniform', 'normal'],\n",
    "    'n_hidden_1': [64, 128],\n",
    "    'n_hidden_2': [64, 128],\n",
    "    'activation': ['sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning application"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.75  \n",
    "InceptionV3: {'activation': 'softmax', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.43  \n",
    "ResNet50: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 64, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.76  \n",
    "Xception: {'activation': 'sigmoid', 'init': 'glorot_uniform', 'n_hidden_1': 128, 'n_hidden_2': 64, 'optimizer': 'adam'} 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg_16 = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "model_inception_v3 = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "model_resnet_50 = resnet.ResNet50(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))\n",
    "model_xception = xception.Xception(weights=\"imagenet\", include_top=False, input_shape=target_size+(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'vgg_16': model_vgg_16,\n",
    "    'inception_v3': model_inception_v3,\n",
    "    'resnet_50': model_resnet_50,\n",
    "    'xception': model_xception\n",
    "}\n",
    "\n",
    "for key, value in model_dict.items():\n",
    "    for layer in value.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.2\n",
    "learning_rate = 1e-03\n",
    "epochs = 20\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model_dict.items():\n",
    "    model = Sequential()\n",
    "    model.add(value)\n",
    "    model.add(Flatten())\n",
    "    if key == \"vgg_16\" or key == \"xception\":\n",
    "        model.add(Dense(128, activation=\"relu\"))\n",
    "    else:\n",
    "        model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    if key == \"inception_v3\":\n",
    "        model.add(Dense(len(le.classes_), activation=\"softmax\"))\n",
    "    else:\n",
    "        model.add(Dense(len(le.classes_), activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model_dict[key] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head = model_vgg_16.output\n",
    "classification_head = Flatten()(classification_head)\n",
    "classification_head = Dense(128, activation=\"relu\")(classification_head)\n",
    "classification_head = BatchNormalization()(classification_head)\n",
    "classification_head = Dropout(dropout)(classification_head)\n",
    "classification_head = Dense(64, activation=\"relu\")(classification_head)\n",
    "classification_head = BatchNormalization()(classification_head)\n",
    "classification_head = Dropout(dropout)(classification_head)\n",
    "classification_head = Dense(len(le.classes_), activation=\"sigmoid\")(classification_head)\n",
    "\n",
    "xai_model = Model(inputs=model_vgg_16.input, outputs=classification_head)\n",
    "\n",
    "xai_model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93/93 [==============================] - 22s 191ms/step - loss: 1.5463 - accuracy: 0.4614 - val_loss: 2.3551 - val_accuracy: 0.3689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.9520 - accuracy: 0.6607 - val_loss: 2.0456 - val_accuracy: 0.3946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.6997 - accuracy: 0.7585 - val_loss: 0.9428 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.5717 - accuracy: 0.8109 - val_loss: 0.8924 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.4937 - accuracy: 0.8315 - val_loss: 0.8311 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.4347 - accuracy: 0.8586 - val_loss: 2.2493 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.3501 - accuracy: 0.8843 - val_loss: 1.0569 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.2875 - accuracy: 0.9070 - val_loss: 0.8571 - val_accuracy: 0.7486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.2944 - accuracy: 0.8965 - val_loss: 0.8062 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.2648 - accuracy: 0.9104 - val_loss: 1.0197 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.2269 - accuracy: 0.9256 - val_loss: 0.8960 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.1973 - accuracy: 0.9327 - val_loss: 1.0049 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.2169 - accuracy: 0.9249 - val_loss: 1.4140 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.2016 - accuracy: 0.9357 - val_loss: 1.1092 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1676 - accuracy: 0.9435 - val_loss: 0.8434 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.1460 - accuracy: 0.9550 - val_loss: 0.8092 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1247 - accuracy: 0.9614 - val_loss: 0.7994 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1210 - accuracy: 0.9638 - val_loss: 0.7970 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1196 - accuracy: 0.9628 - val_loss: 0.7840 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 17s 179ms/step - loss: 0.1146 - accuracy: 0.9618 - val_loss: 0.7905 - val_accuracy: 0.7986 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "xai_history = xai_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] --- Training of vgg_16\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 27s 192ms/step - loss: 1.5444 - accuracy: 0.4672 - val_loss: 1.7058 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.9500 - accuracy: 0.6587 - val_loss: 1.0892 - val_accuracy: 0.6189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 17s 179ms/step - loss: 0.7293 - accuracy: 0.7419 - val_loss: 0.8599 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.5914 - accuracy: 0.7879 - val_loss: 1.1716 - val_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.4692 - accuracy: 0.8478 - val_loss: 0.9578 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.4155 - accuracy: 0.8552 - val_loss: 0.8953 - val_accuracy: 0.7311 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.3441 - accuracy: 0.8904 - val_loss: 0.8961 - val_accuracy: 0.7378 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.3285 - accuracy: 0.8863 - val_loss: 0.7474 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.2782 - accuracy: 0.9087 - val_loss: 0.7730 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.2388 - accuracy: 0.9259 - val_loss: 0.8082 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.2333 - accuracy: 0.9188 - val_loss: 0.7789 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 16s 176ms/step - loss: 0.2130 - accuracy: 0.9290 - val_loss: 0.7559 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.2175 - accuracy: 0.9205 - val_loss: 0.8151 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.1666 - accuracy: 0.9432 - val_loss: 0.7383 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1461 - accuracy: 0.9526 - val_loss: 0.7209 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1282 - accuracy: 0.9591 - val_loss: 0.7114 - val_accuracy: 0.8081 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 17s 177ms/step - loss: 0.1189 - accuracy: 0.9618 - val_loss: 0.7000 - val_accuracy: 0.8122 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.1202 - accuracy: 0.9631 - val_loss: 0.7058 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 17s 178ms/step - loss: 0.1111 - accuracy: 0.9675 - val_loss: 0.6898 - val_accuracy: 0.8149 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 16s 177ms/step - loss: 0.1063 - accuracy: 0.9658 - val_loss: 0.7015 - val_accuracy: 0.8162 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_dict = {}\n",
    "\n",
    "for key, value in model_dict.items():\n",
    "\n",
    "    if key == 'inception_v3':\n",
    "        break\n",
    "\n",
    "    print(f\"[INFO] --- Training of {key}\")\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)\n",
    "\n",
    "    history = value.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "    )\n",
    "\n",
    "    history_dict[key] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History for vgg_16\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, history in history_dict.items():\n",
    "    print(f\"History for {key}\")\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # plot training and validation loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 79.22%\n",
      "Accuracy of 14.94%\n",
      "Accuracy of 14.18%\n",
      "Accuracy of 13.53%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in model_dict.items():\n",
    "    pred = value.predict(test_generator)\n",
    "    predictions = np.argmax(pred, axis=1)\n",
    "    cm = confusion_matrix(np.argmax(y_test, axis=1), predictions)\n",
    "    acc = accuracy_score(np.argmax(y_test, axis=1), predictions)\n",
    "    print(f\"Accuracy of {round(acc*100,2)}%\")\n",
    "    cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "    cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 79.44%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1d389533a88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = xai_model.predict(test_generator)\n",
    "predictions = np.argmax(pred, axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), predictions)\n",
    "acc = accuracy_score(np.argmax(y_test, axis=1), predictions)\n",
    "print(f\"Accuracy of {round(acc*100,2)}%\")\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce11b73888>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xai_methods import grad_cam\n",
    "\n",
    "scaled_heatmap = grad_cam(img=x_test[8][np.newaxis, :], model=xai_model, layer_name=\"block5_conv3\")\n",
    "\n",
    "plt.imshow(scaled_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce11c45748>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAD7YElEQVR4nOy9d6BcdZn///qcOr3c3nPTO6mGQIAIgiKICFbEXkD94aq4fnfRLa676nd3UdxVV8UFe4OviqKAtBACCRBagCSk5+b2Pvfe6XPO+fz+ODPnztzcNIoGyVvDnTn9nDmf5/OU9/M8QkrJKZzCKbx6ofylL+AUTuEU/rI4JQRO4RRe5TglBE7hFF7lOCUETuEUXuU4JQRO4RRe5TglBE7hFF7leNmEgBDiQiHELiHEXiHE379c5zmFUziFFwfxcvAEhBAqsBu4AOgCtgJXSCl3vOQnO4VTOIUXhZdLE1gD7JVS7pdS5oFfApe+TOc6hVM4hRcB7WU6bjPQWfa9Czj9SBurIig1EX9RJxTTfDqePY62tThsbfn3qRrUiV7B8V7ndJra8e5bfgxRdqzyz9McWwJCIrFxKOCQxZY5HPKAc9QzmaZJKBQiGo0SCoXQdf0Er/WVg87OTgYHB1FkFJXgND/LycXGzcueISll7dTlL5cQOCaEEFcBVwGoxGjS/r+jbVv27XDlRQCK9wsIJge4KBvqYso+ZdsIgZDFz9Ld1j2lUra9etg1uftMPaooEx7lL4HiXYcov0ZvE/dgrnmmlN3zNC+SPIIQ8BZLvIEvFUAikZPXICwEEind7xKBFA5SpMmTICs7STnPk3I6yMlxHJlG4pQ9D8e9fyGIRCIsXbqUs88+m9e+9rUsW7aMuro69yqKpmbl7/fXg3/7t3/jK1/5Cmb+DGJiPYhKASk57AX5i6Ij/4WO6Za/XEKgG2gt+95SXOZBSnkjcCOAqbQcUWQe6wUSQkw7TioH45GXi9LMVxQliMm14mgCR+JuL5WiwJCTx5t6fCjupUy51qmahUSI8n1EccAfTQMph1O2VXEfId1rBBQcQCClDwcHqeSwxARZ2UXW6SBlHyDpHCQvR4qzftmVCoGqSBRFY+bMdk4//XTOPfdc1q1bx+zZs1HVSiH5akBVVRVCCCQThwmAVxJeLiGwFZgrhJiJO/jfBbz7RA9yYjNI2axdIRhE5bHKJsnJ2bn8v+XnPMJnWTZIyzQKygb84Siq4BUT/JSZoiiAhJwqwKYMfHG4IHBvS/FuTiCL2zlIJAIFiYMtUhTEGGmnk6S9h7Szn6zTj80EEscTI0IIFEVBVVWisRhLFi9i/fr1vPa157Js2TKi0ejxCei/YtTV1aEoCg5Jyl6qlxxHd96XtNYXjpdFCEgpLSHENcCfABW4WUq5/cUfuOxzacaUU9YdydwtLhNS8XQBWRyIrkmglB2g/K/7eVrDQgDF2bVSIFCxb/kFlCkNxS/ls/7he8vSgC+XF9JBTv3lZfGevBO41yOR2GKMHAMkOcSEs4eMvZ+CM4xVPtsLgaqomJqGbujMmDGDM9aewWvPfS1rTz+dmTPbEUJ1Z75TmacAxONxFEXBcjJI4eAGxSp+3MO+ngjKH7P0tMTJ+aP0TUpRoY2e6MleNp+AlPIO4I4XfoSiej4F3hLJ5MCVk2uEPHwGKp+lFSErhrkonUdSJlGnqvSV5z3cZpdTrmXyxzjcXSgm9Q/vh5w68Kfe9eQsIybnateWx6HcryFxsMlTYJCM7GbCOUTS2U9GdlGQY4DtHVVRFDRNQ9d14lVVLFmyhLPPOouzzjqLpUuXEo1GUZRpTKK/8hn+eFFVVY2maWRII4UN6Iiy5zudb+h4xWdJACgqBIIG0VgAf9CHogrsQoHURJaxsQy5TAFHKkXzz5nWhD0W/mKOwaPBfcmO9aJNY+9P+3JOLlO87+UztjL5Y0lRVMlL66c8UFGu+lcetXzkigqH4tHuY/p1gkmRr0gJqEgUHAQIWRz+xbM7CraSoyCS5JRB0s4BUvZ+Uk4XOdmPTZqiiwohBJqmYxgGfr+f1tZWVq1axdlnn82a17yGWbNnYxjGUa73FMoRjUYwTZNxckgKCHwvwVGLTlyh4PMp1DeGqK2PYJgaUrjCQcEHjRFy2QJDAxP09yXIZWykVNxX+ATPeNIJgeOdZSo2E1Nt6Okcg5MRAEqDTAh3wJY534Sc9CEoFXurh5vmRR1hqqFQEXmYVlhN1TPK/xZRMl/QQDgIaaOgIAFbFG17mSCj9JCS+0ja+8k6fRTkWIVTT1FUTNPA5/NRVVXF/PnzOf300znzzDM57bTTqK6uflU69V4KhMMhQuEQ/X19SPKuH8bzy7wwyKImGwgaNM+IEq8OgHCwHYvShGMXZ33dFDS2VhOJh+jsGGBsNIt0lKIP6PhFwUknBI6Kog099faOeLtlzkFRISgmA4rlKrkQJadcSRgUdYfDpKviOR/FlEHsipVy06D8Ao/00xz5B5PCRuIgKWApE+ToJym7Sdp7yTj7yToJLHKA5R1LNwwCfj/hUJim5mZOW3YaZ6w9kzVrXsOsWTPx+/2TZz6l2r9gBIMBIpEIiINIct6zfKE+k9Jufr9BS2uUquoADiClK6QnjYuSLwDAIhjWmT2viUP7+xkaSBUFwZSJ8ig4+YXAFGfg5HIx6Rw8wiCalIeicrCK6bYpP0dpgJctLJoKMDlwPF5BxSAXFddcft6Kyz9CSNFdbiNFAYsMOZkgLw+RkodIFjrIyl5yMoH0Br1r2/v9IcLhELFYjNlz5rB69SrWrj2d05a6cXtNm/ypTzn2XhqYpo+qeBVCuELaRZn97/EkOPJ7PLk1ALqhUtsQJF7jp+gOdB1duJGeygO43iVH2ugGtM9qwLb7GRnKgCxpFce+j5NKCLiDa/rYfIUTrwSplNnp5dsKV0q6XsLJiJoo/SktUDz/Q/lRxOSBKmx9pbRnWUSifG93mawY2HLK9ZX2K5kwpf0d8uRFkgIT5GQvGaeTlNNJUnZjOcPYpMqCBwLTNAmHw8RiMRoaGli6dCmrV7+GlStXMHv2bMLh8PQPmVOz/0sFVdWIx+MIIYq/jyh7tyiLpBzpeZcLDFAUiMRMauuDbuhRyinO6kmvVuUxFaSUqAa0zqwmm+0nPZEv2+/oOKmEwEsJb3jJcsu8kq2nVLD4oHw4uzP64Q6+0p5QMhOmM05K0qboxJMlpl7J7JBFL366GL4bJe30kJIdZJwO0s4Alkwiy2x7VdUIBgPEYjGqqqqYN28ey5cvZ+XKlSxevJjGxsZTtv1fAHV1tQghcGR68mcvMwumFbhTtIKSVmiYGjU1QUzTwHFOlC4ukNLBH1BpaY2xb/cQtuUgpXNMR/tJIwSOODt5s/eU9dM5Az2SkCh+Lh/0xVhqkT03aUpUEo5d7QBPA/CIwKJSQymfx6def7nvYTL0aOOQp0CaPKPkZT8pp5u07CRNF3lnBJtc2RkkgUCAaCxKbU0NTU0tLFq0kGXLlrFs2TJmz55NKBQ64vM8hT8PqqtrXE3ASTLVNT8dp6LSJJz8IBQIhkwiMX9ReEzZ5ngg3ZBxVY2f4cEAw4MTx7XbSSMEThSHzb9lAmBydlemiokpOkHZ/F8WFZj0zB9+jArHX9mySoZiyQi0sJQ0eTFB3hkiI91Bn3F6yMt+8nIcB8u7GV3XiUQi1NXVU19fz7x5c1m4aAHLly1n/vwF1NfXIUSJpnxKpT8ZUFtb66rudqrMjpzOJJgOk7+hrinE4j50Xa1YL8Tx+nCKkQmpIoRDfUOExGgS2xLH9A2cvEJAlj1Tb1m5c6/0sN1BJ+Wko05UDPHSHsXBKSa/lR/e+ytF2VHLOATCVeNdblD5cSZ9Do6wcMhjyyQFMUJW9rm2vewmI/vJywQ2GZCTPPNQKERtbS2NjY3MmDGDhQsXsWTJEhYtWkhbWys+n7+oZcjiy/Dy0VNP4cRRW+uaA5ZMV/gDjhvF99z0aUSi/qLQKLFQYZIwOulKdv8rJ8fDlNfBkRCJ+QiGfYyN5Nz39pVgDkzF4Yp66ebLnSNT1wmUkpngUYLLVfVJ+/+wR1IyD2TpvJMzuhASRWpIObm/q3Q42Fg4ZLBkgpzsJyN7yMpe0vSQdYYoyIkyzzEYhkE8HqepqYnm5mbmz5/PwoULWbRoEbNnz6ampqZstq+8wFMOvZMPNTU1KIrAIlW0v0t+ppLArvQRlENQ9OArLi/A5zOKAmByvftXFDNAypeXsjrLJ8YypqoC0XiQsdEMRxMAcBILgWkhJod7aUYs1wem2RwqBnS5EJhiz3vmAEW/gUv6EGLSAHDdfJKCksRinBwj5Jx+MrKXnNNHXvaTYxSLjPdjCiEIBUM0NjbS2trK7NmzWbBgAfPnz2fOnLm0tDQTCARODfBXKKqqqtA0lYLMgrCAcsbl8ZkGqqYQCruU4CNp/kVaG46UOI5AKEpxhi+dpxISiMYCqKpA2hWXcRhOWiFw7EEhPIugNJyVytWUs/nK7X+l3HlYoSWUtgCQqFIBATYWeTGGxRA5hsk4/WSdHnKyj5wzSoEkkkLxOUt0Q6cqXkdrawuzZs1i/vz5zJ8/n7lz5zJjxgyqq6sr4van8MpFLBbD5/eTHM8UozlG2eRT+nt0rUDXVUJhH0cr2CJQsAoOidE0mUwef9BHNOZD1aYfJ1I6+PwqpqmRSVlMl3lawivsTZxWkffWVP4VHgW4VCegtLzcJ+AKkZLtXyyyoRRwZJqcSJJlgIzsIyt7yMsB8s4wFklsmXGderg/bCAQoKmpiTlzZjNvrjvoZ8+ZTXt7O42NjQQCQRTllEr/14ZwOEw4HGagfwgpCyiHMYNgqkYAFB1+7rujqgqKkNPsNwnHgeHBCXp7xshmbUxfGtqriFX5OTzHyz2OqoHpM1whcBScREJATOMMrPT4V3juBR7nXxRTKUuxfTejrjyy7w5wxWMBFh+SVAE3McMRWSzGyDkj5GQfGdntzvSMUnDGsGWqyNJz91UUlbqaOmbNms2CBe6gnzdvHu0zZtDc0kw8XlWRjHOKpffXiWAwSDQSATpxRA69aDIW/1/5LnuQFZ9z2Tw9XQmqaoKEIz40XanYTiBITmQZHBgnkyogUUkn8wwPjBOOGCjG9PwQIQSGqR7TlXxyCQGmuu6mzN5ycgb3timLBriflUmPqmcSuCU1FBQEGiVabl5MUGCErDNI2uklL3vJyyEKcpwCSRyZqbjCQCBAS0sLCxYsYOHChSxYsIBZs2bT0tJMbW0twWBw2tRbOB7z5hReiTAMg1i8CiFcB3FJA3Wm1QagPKGkFP6zCg5D/WmS43kiMZOq2iDhsA9VFYCDY0kSIynS6QIIgYKDg0ImlceybHSj3EFYdi5Bcd3R8YKFgBCiFfgxUF+8sxullP8lhPgi8FFgsLjp54u1BV7gidz/TOXkl10Hkzft8u5dbWCSpSeKBCGbAnkxQIF+ck4vadlPnl7yMoElUzhkkXJSdRKKQl1tLXPnzmXJkiUsXryYefPm0djYSH19PbFY7FTq7asciqIU8wfKWINljvrJYN/0cJ2FrmmQThXIZi0mxnNE436qqkOEwyaZTI6J8Tx2oWTVunUDHDmpYR6pnqOqHJtF+mI0AQv4rJTySSFEGHhCCHFPcd0NUsrrT/SAoqy+n7es3H4vqfxHg1RwixkJoIAt0xTkCFn6yDrdpOnFkqPYMokts4dV0A0EA8xsn8HixUtYtmw5ixYtoqWlhbq6OqqqqggGg6dm9VOoQE2tyxp0SBfzWRyY1jcwPVwr1w1FOw6kJmyymRTjiRzxqgCOLcmmbcqjYhJXAB2PA/1Y3JIXLASklL1Ab/HzhBBiJ26p8ZcQ0118eVjk8LiAFHksRskxQNrpIef0kJeDWEy4XH1ZgIoMPEFdfSNLFi9lxcrlnHbaEubNmUO8qoaa6hpC4b/ustmn8OLRUN/gUodl2p3Zy9Yd33ThTnUu4U0ihcS2HZITFtlMHiEULGtKQFyCYajFfBFxFEag/PMwBoUQ7cAK4FFgHXCNEOJ9wOO42sLosY7hDuMSC0otPr2ydL1S0m8xGcdV9xXAwhZJsgySd/rIOj3kZTcFRinIbJmKP/nThEIh5s6dy8qVK1m+fDmLlyyhsaGReDxOJBLG5/Odmu1P4bhRV1fnsgadcupwaYpy3zuH8intSO9WifsyyQ60CkUT10smKO3r4A/o6KpSzG6VlbWmSyawbRX5BEf2DbxoISCECAG/Bj4tpRwXQnwH+NfiHf0r8DXgQ9Ps5/Ud0IhNeu1FSRAUC4I6GojSQ9CLRTYK2CQp0EdWHiRr97qFM2USmyySfMUjUVSFxoYmli1bxpo1a1i+fDlz584lFosRDocJBALHqVqdwikcDpflKXBIuaYA5SnFokyBd79Pj7KkIVlm9k6zeckUCAYNFKWk8JcLj8kN8wX75Y0OCCF0XAHwMynlb9wbkP1l678P/GG6fcv7DviUFlny9Lsx/SLdF9XNiZAChyQWw+RkDzmni7wcoCDHsUnjkANpVTyCUCjE7NmzWb16NWvXruW0006joaHBG/SGYZwa9EfAVCdT6fvBgwdJJpMsXLgQVVVPPb8iamvdpj62TOEWcp3qra/UCuyyZdPhWBWdpZT4/DqBkF5W4Kb030ntWUqFfM6mxH49El5MdEAANwE7pZRfL1veWPQXAFwGPHcCR/U+SSwKDJOnh6zTQ0H2F/8lizN9adC7N6epKnV1dSw9bSlnnLmONWtew5zZc4jFYgQCAXw+36nZ/jhQ/vJlMhnS6TTxeJznn3+eX/7yl2SzWd7whjdw3nnn/QWv8uRCPB5H1zUKeVcICNTJYiKinJviztXH7zKcDu4xYlU+fL7KiazkIXOKJ7UsXCEgFI7GRnwxmsA64L3As0KIp4vLPg9cIYRYjnufB4Grj30o98akyFCQQ+SdTvKyl4wzgMWom3mHVeTjTz4+n8/HrFkzOf30tZx11tmsWL6MxqYmgsEgpmlWOPRODf7jx/PP7+KJJx7HcRxCoTCXXPImNm7cyNy5cwkGgzz00EOsXr2aaDT6l77UkwKxWJRAIMhIMoOUdjHKVdRLKxrVSM9lcEyf/hG0AceRBIIGNbWhIvW8PLfQ/VQSOoVCgXxuskDpkfBiogMPMf29nDAnwCbNsHMXeaeHvBzGkUmksEA6Fba9UARV8WqWLVvGWWedxRlnnMGCBQuoqnLZebquHzbbv1qYelJKMpkM/f391NfXEwgEjmu/VCrN7t27MU1XoFqWxT333Mv4+DjpdJpZs2YxMTHB8PAol176Fqqq4mzfvp1Dhw6xdOnSl/muXhkIhcIEg0EGGcYWOXRCxTFfyiapjGgpRYOg5O6exOEB8nL13nFA0wVNrWFC4ckU86kQSBShkE1msC2J2zvyyNd/UjAGLZlgzNqE2zLLpfWU7k3TNGbPns3pp5/OOeecw+rVq5kxY4Y30x/LNn21aABSSgYHB7n33nu5+OKLj0sI5PN57rvvfh555BFUVeU977kSIQT5fJ73vvc97N9/gO3btzM2No6iKEQibp39mpoaBgYG/gx39cpAIBAkFouB6MWRWSrKyMmi+u+9h1MrEZZw+HsqhENpTEhHomqSppYYVTUhhCI902L6IykkJzLF8OArop5A5Ywfi8VYuvQ01q8/h3POOcfrhqNp2mGD/tUyyI8FIQS6rnsaQTnS6TQdHR0IIWhra/MERHd3N93d3Vxwwfns2rWbzs4u/H4fsViUqqo4hUKBp59+GstyeRW27c5g4XCYZDL5573BkximaVBdVQXkPOqwLOYOlHgDlZ77shCinFx+eOcpN1wupUQ3FJpaotQ3BlH10tGO6FrEsSVjicxRNYASThIhIJg9ZyZrTz+d8173OtaefgYzZ85C01QURZnWofdqUfNPBJqmoWkqmUyGVCrF0NAQfr+f7du3c9ddd2GaJhdddBGrV69G0zRyuTzz5s1l6dIl5HI5UqlksTWZ7mVG2raNoqhF4ZImEnGrGJ8qajoJIQRxr0NxGjfCZU/WqKAoEEoDvowZezRHoZQCKW0CQY3m1hqqa3woWqnBbPleUyIRQjCRTJNKFQ475nQ4KYTA/PlzefjhzV6n2/IknCPN9Kc0gEqUnpuum6RSKfbs2cu2bdtYtWolg4ODrFu3jkwmw+DgIJlMpkiYmkNjYyObN2/h0UcfZdasWVRX11AoFNwwlM+H4zgYho5h6HR0HKK+vp7+/n5mzZr1l77lkwp1dXUA2DLrjUlRYQKUU4FKiyvVeVn2yQ0uOMSrTFpnVBGOmMhiXox78KkCoPL74MAoju2aJMcaKyeFEAiFwl6v9xJOzfRHRunZOI7DwYMdbN68hXnz5jFv3hx8Ph8jIwmklMTjVZimCcDcuXNpa5uB4zgEApMdiDZufJCDBw/S3NyMbdsEgwGSyST5fAGfz4dlFZDSYcGC+dxxx53s3rWH4eFR5syZ8xe595MVtXUuYSjPOKWWs5XUHVFGKS4P102mDSueIxEQkqqaIDNmVuEP6DjO1FSkaej0UkERKqlkluHBHIpS6lL0ivAJHD6z/7XO9NMJt/ICE0fb1rIs9u3bR3V1NTU1NUxMTPDrX/+Gvr4+Dh48SDQawe8P0NfXh6qqLFt2Gj6fj/Hxce65515WrVrFwoULUBQ3CWp0dJTh4WFe//oLUBSVhx56iFgshmUVePrpbZimyejoKMlkkrPPPpudO5/nyaee5JJL3uQRZE7BRU1NNQC2TIN0O0UjmMZ2L/tNyzQF13Rw4wUSiETCNLfG8fnVYg+C8uMcyR3oIIRGb88YhfyUUxwFJ40QeLVASklHxyEymQzt7e34/SYenaTYrKJ88CeTSTKZDLW1tdx2223cd999tLS0cM0119DV1YWiKHzqU3/Dgw9u8kJ9HR0dtLW10traSjAYYNGiRdx99z386le3sGbNGi688A3U1FSTz+eRUmIYBolEgrGxMfx+P/Pmzef22/9QjMAYJJNJIpEI11xzDel0murqqr9aIf1CUVdb71KHnfFiVEBxhYEoDftyt6A74CuWFD34UoLPp1HfGCQc1soc5seiGLnm4MjQBIP9SUDFbZN+bI36lBD4M0JKyWOPPcYf/nAHiUSCSy55E+ecczY+n69im0wmw/79+1m8eDEPPfQQ2WyWs88+m2eeeYa3vOUtPP300zz99NMANDc3U1dXS2NjA11dXbS0tDI6OkogEGB0dJR4PMYZZ5zB0qVL2br1CQ4ePMjw8DA1NdUEg0Fs2+Kuu+5ibGzcEwTr15+Dbds0Nzfz9NNPkc+700og4K8wJU5hEl4TEpnCVfc1StUEyg2DSn5fpcEgpURRBJG4n1i1iRSOWyhHTNUKpzuaIJeRdBwcxrYEk+nMx8axy46cwkuG8fFxnn32OZaddhqrV69mz+49pNNpwFX177rrLgYGBhgaGuLXv/41mUyWbDaH3x/g4MGD1Nc3cMEFF3DGGWewb99+MpkMhw518IMf/IgNGx4gn89jGDqBQIBCocC2bdtIJBI888wz9Pf309bWSjgcwnEmQ31z5syhp6eHpqZG3vSmN1FVVYXf7+fSSy9h9apVTIyPEwwG/5KP7RWBqqpqFFVgk0Ei3dL3opT1engugYtSxhDeuDZ8GtU1AbcJiWfPu+P5aNqXZTns39tLasLNGhQ4eHHKY+CUJnACOKxu/AmqxENDQ6iqyprTXwMIbr/9drLZLOCG3A4cOEA8Hqe2to6xsQl6e3uREvx+P4nEGIZhsm3bM+zcuYtsNovjwODgEMFgiNe+9rXMnTuXkZERZsxoY/78eTz33HPs3buXrq4uDh06hM/nx+8PEA5HADcT7ayz1rFkyWIikYiXVPX009vYuvVxLMsilU7T1tZ2Sv0/BmKxKMFAiPGsW3laSKPI2ZeT5rwolRQvhQ7lJKtQumXEQxGDcMSYppFpef/LUhcCt1BAoSA4uG+A0eFc8bjC21eeMgdeeti2TSKRIBwOe5736TBduSfLsohEwt5g0zTV21ZRFGbOnElXVxehUARVVdm/fz+2beHz+ZASduzYwZ49e6iurmb58mUEg0Ha29u5+uqrEMKlAKdSSXTdoL29nZ6eHvbv38/8+fM5eLCDRCLBa17zGhoa6r1r0nX9MCdfdXUVExMTJBIJLr74ImKx2CtWCEz3O0gpcRwHy7KKvAjtRd9fJBIhGAoyOpJAkgNCxTEqJklDpY7VYsp1SXew6rpKNBZA09UjRsdcv5GCm4vokM04HNw/yshg5gVnJZ0SAieIRCLBLbfcwiWXXEJra+sJ7dvW1kZTUxN+v5/9+w+gaTqmaXovYHt7Ow888AB1dcPMnTuX7u4eFEV4PoPq6mquvPJKGhsbUBRBV1c3Dzywkd279yClw9NPP83y5cuR0sYwDFauXMn+/ftpbm7mqqs+ipTSq51wNLS2tvKxj12NbduEQq/8cmpSSo/tqKoq2WyWRx99lDvuuIOFCxdy+eWXv+hkKL/fTywao5N+JFk3TCjcc5Yn+x4+M08KCX9AJxzxcezRbIPUGBst0HFwgFSyAMdIFz4aTgmBIkqzQ2mAHOnFV1UV27bJZDLTzjKlGcad6Ssfr9/v98516FCnV6i0tH9TUxP5fJ6urm5mz57NgQP7SSTGME0foVAI27aJx2PYtsWDD27m9NNPp66ujh//+Mf4/X5Wr15NQ0M9CxcuJBgM0tTUxPz5892sthMcyCeLA1BKWdHi+3juY+rvkkwmefrppykUCqxevZrnn3+ea6+9lp07d9Le3o5pmlxxxRUvStj5fD7i8Sog71KHp3SxRk5hCXqmgbtEUSAYMjD9OlLaHAlCCGxLoa93jJ6uMQp51/moiFJ94xO/h1elECh/SUovWTabo6urk9mzZx+1bLimaRiGycREkomJCaSUhMNhFEVBSsnQ0BDPPPMM1dU1nHba0mnptblcns7OThYsWFBhUoTDYaLRKAcOHGDp0iVMTIyzY8cOfD6ThoZ6fD6Tn//8FxiGTj6f57zzzuXiiy9iw4YNVFVVsX79OYRCIWpqarx7PNasf7JjZGSEvr4+Zs+efUTzq1x1llKSSCRIJpNexZ/vf//7/Mu//At+v59rrrmG2tpaxsbG+NCHPsT+/ftJJBIVguaFQAhBTU21O0idHEIpc/qVUodluRiA8rCfpquEIz5UIXDklDRiUTqQQjZToKtzlKGBJNIuhRbdjUp8k8Mf0NGv/ZX9hrwI2LaN4ziMjY0xMDBAX18//+///YZ8vpJvXVIlM5kMhUIBIQSm6WPPnj389Kc/59e//g2jowlv+/7+AR5+eAs7dz7vef6noquri3w+T0tLM7o+WbJcURRaWloYHOzH73dTe6V00HUN0zS54ILzGRoaYHh4iAsuOB9d12lpaea9730PF198EaFQyDvWC5n9T0Z897vf5QMf+AA9PT3Trs/n86RSKbq6uhgdHaW7u5uPf/zjXHzxxfzsZz9jcHCQ733ve8yZM4fW1lbuv/9+Ojo6CAaDvP71r+c//uM/ePe73/2SPKuamhoALJK4VGGl+L+iq07IomOvmGWIoNQ3wzBUAiETgYPbCbO8rrY7ijOZAh0HRxjsT+HYoiwEKLx/h5Huyv53JLwqNIGpKqWUkn379tHY2Mi2bdvo6DjE61//emzbJp/PYZqTA9NxHDo6Oti5cydtbW3MnDkTwzDYuXMn1dXVDA0l2bdvP9XVVcBkKMe2LS/7rhyO47B37z7q6+uJRMJI6bjEEvCy/Hw+H4ZhUF1dTWNjo9fbYMWKFbS0tKDrOlVVVS/3YzspkMvl6OnpIZlMer9jIpEA3Io+jzzyCM8++yx33nkn73//+3n66af5/e9/TyQS4atf/SpVVVWMj4/zsY99jGXLlpHNZunv7+fQoUN84hOf4KyzzuKqq67ita997YtOiio5WC2ZcoednOyrXSL9lA9bTx9QhNs30ChpAJNdqUtRAKsg6esZYXQ4g3SOVl34xPGiNQEhxEEhxLNCiKeFEI8Xl1UJIe4RQuwp/o2/+Et94bBtu+JFsiyLO++8k87OTqqqqqivr/fs9ZGRUfbv30dfX1/x+wi/+c1veOyxx/jjH//I2FiCUChEfX0D73jH25kzZzZDQ26fFSEE0WiU2bNn0djY6B2zHMlkit7eHurqapmYSNLR0UEul/PWNzQ0MGvWLPx+P9FolLe//e1urjquplBfX/+qEQDgPo9CocDY2BgHDx7k2Wef5b/+67/4+te/TiKR4Mc//jGf+cxnuPvuu+ns7OT2229n7dq1fO5zn6O/v59nn32WUCjEj370I+655x58Ph/r1q3jHe94B36/n/vuu4+f/exnnmB5sdcqhMBizCsfUnIKer0uZamTlvDme1VRCAZ0FPXwZCABSKkyMpxndKiAdOSU3oNH4yEcH14qTeBcKeVQ2fe/B+6TUv5fIcTfF7//3dEPUSJXlvtSDyNXvqCLy2az/OlPf2Lt2rXMnz8fTdPQdZ2xsTFWrlxJXV1d0dY32LJlM3v37qGqqpoPfOAD7N27D8PQufLKK/njH//IoUNdRKNRkskJwuEwkUiUsbFJm7KhoYGLL74ITdMwTd9h19Ld3c3IyCjbt+9g69atCAFXXHGFZ+8Gg0He+ta3emG59vZ2997/ClT7chypY47jOEjplsbq7u7Gsiwcx2F4eJibbrqJbdu2sXv3btLpNAsXLqSpqYlCocC5555Lc3MzXV1drF27loaGBlRVJZ1Oc/nll/OrX/2K7373u2zYsIFvfvObfOxjH+Pcc8/lF7/4BYODgyQSCaqrq1/UPZUyCS3p1lpwS4FP5g9WpA2UfVGEwDANBGpRYyinCgtyGZvEUAYrJ1FRcDzDf/rEoKkFYo+Fl8scuBR4bfHzj4AHOIYQ8Ab74REUjpUFdSyoqko+XyCdTuM4Dpqm4ff7SafTTExM8Kc/3c1ll12GYRjs23eARYuW8PTTT/H887sIBoOsXXsGpunD5wswNjZGdXU1uVwORVHw+UwGBnLYtu0Jl1gsdsQ+86lUCnBV2pqaatrbZ1RoDKqqVryMr6RsyiMN7ONBNptlYmKCvr4+DMOgv7+fb3/723R0dJBKpUgkEhw8eJA9e/ZwySWXcO+99/Lb3/6Ws846C4AvfvGLzJ8/H8dxuO2227jzzjtpa2ujtraWN7/5zTQ3N/PYY4/x4IMPcuutt3Lo0CFmzpyJaZpomlZB3X6hcB2RYDnFgitTH4OQUwSBO+k5Nown8himTiCkoGpQqk4EgonxFKlktsgzcIuGuvkJZQc6Zm7BkfFSCAEJ3C1cN+X3iqXE68sqDvfh9iusQHnfgba2Nrwc6lIoxVMFyjKoDsuhPj4YhoHf7yebzRczsiAYDJFOp7Ftm46Og1iWhWmaNDc3c/nll5HL5dm1azfvfOfbee657dx7770MDw97cf583s25N02TQiGPZVkVIcHpxoGUkpaWZt7whtcTj8eprq72NIBXct0EKSX9/f2k02lmzJhxXLa1ZVkMDw+Ty+Woqalh9+7d3HXXXTz88MOcdtpp9PT0sGXLFgzDwLZtJiYmqKmpob6+nhtuuIGrr76aZ599lte97nWAG6IzTRPTNFEUhfe///3MmjWLJUuWcPvtt6OqKueccw6PPPII0WiU4eFh7rrrLlpaWvjEJz7xkmRF1tTUoGoqdn4cBwu3Da7wsgfc91p4U1qpvoBjS7ch6USWeLWPWHUAf0BH0yFfcEiN57xQIKI8+Zhi49PSO1K+5vBktCPhpRACZ0kpu4UQdcA9Qojny1dKKaWYjGOUL/f6DqxatUqOjBTI5mwKeQdVc2OmAZ+GaRS7DItSPvWJDwp3xvaTTCYZG0swOJgnnU5jWQX8fj+qqpHP5wiFQh45ZubMdp588ikmJibYsOEB5syZ5ZbVmpjAMAwsy3X8+f2+okMxf1yzSX19PQ0NDeXP4YTv52SDZVn8/Oc/5+DBg1x//fXTCgEpJblcjrGxMUzTpKOjg1tvvZWhoSEuu+wyBgYG+PGPf+xRp59//nnmz5/P5Zdfzr/+67966rpbD8HNjNy8ebPnNO3t7WXlypW0trYyMTHBeeedx9atW9mxYwdPPfWUN+BnzZrFpZdeysqVK7nzzjtZvHgxl1566UvSWDYajRII+EnlMkjyKASLFN9SX+zKwKBAFse1azZkUg7ZTIrEaI54jZ9YlY983iadsqZpJSYq/hwLR3vPXrQQkFJ2F/8OCCF+C6wB+kv9B4QQjcBRq1Im0xZ33nuIiaRFJm+jKA4N9WGa6kxmzYxSW+3D0CXCazR6YhBCEAy6STiJRIKRkRF6e3tpa2spluTSSKczFbXzwuEI+Xyevr5+LMviggsu4PHHH+e553ag626Rh3w+783kpUy7Y13H8Sx7pcFxHB566CGee+45vvKVr3il3m3bxrZthoeHGRsbI5fLcf/997Nw4UIeeeQRvv/975NKpUgmk5xxxhkEAgHWrFlTrF2wk9mzZ/OGN7yBb33rW8XMxxqvCnLJJItEIiiKQn9/P4qicNFFF/HVr36VT3/60/T29vK5z32Oq666iomJCUzT5J3vfCcLFy5k0aJFnHfeed7v/1IgHA4TCoUZHx3DIYdGBFExU0/GBDztoFRGvxjxk1KQTubJZLKMjZooqiCbsYoh39JgniROFYv1H/GajkcbeLEdiIKAUmxIGgReD3wJ+D3wfuD/Fv/+7mjHSYzluW9TL1I4OFJBSjCNccIBWDA3xrLTGlg4N0o0VB5YOTFHYSAQpK+vj2QySV1dLe3tM7yaeoZRypkPc/BgB+A6a0ohqUIhz4EDB9i3bz+plNt00ufzUSgUiMVizJ8//6h5BH/tEELQ3NzMo48+SjKZJBgMkkgk2LBhAzU1NXR3d/Poo4+ybNkybr/9dtLpNM888wzLli0jEAiwa9cu2tra0HWd8847jze84Q384he/IJvNous64XCY4eFh2trayOfz7Nmzh/7+fjRNo76+Hk3T6O7uRgjBu9/9bp588kk6Ojo477zzuPTSS5k1axbNzW6v3Pb2dq9Y7UtdJzEQCBCNxujqHMCRORCKF6OfrAsk3DJhTPIF3GRB6W4vJEgVaStMjBXcdGJk2bs+9Z0/tib5cpcXqwd+WzyJBvxcSnmXEGIrcIsQ4sNAB/COox3EshzyjqDYOwVQyGRtslkYe3KYzt4MY2ONnLGqnkhIp5Q9dSLw+Uyqq6tZv/4c2tra6Onp4Y477sBxJH6/n4mJCSKRCENDQ4yMjNDZ2Ynf76O2thZVVfjjH/+I3++nvr4Wn8/HypUrCAaDBINBVq9e/arrXFxe4qy7u5twOOw59+rr6xkdHeV73/seixcvJh6Ps2nTJs8HMjExwdjYGG984xtpaWnhG9/4BqOjo4CrPei6TiQSob/f1cICgQDDw8NeqPQb3/iGJzja2tpobGz0ojPz58/ny1/+Mvv372fhwoXMmzcPwCuH9nKaXyVuB1hIMgg5aasL4ZRNX6XswtIsPtmoRAiBFA5ClvQF1eWSFG2ISfffpGnhjpxKcVBOUoajC4IXJQSklPuBZdMsHwZedyLHUoSsuJwStzpvSQ51ptmQ7UEB1q6uJxTUTzhgUGpF1traSizmhvgsy8ayLEKhIBMT47S3tzM0NMSdd97FwYMdrF69ing8xjnnnENHRwennXYa4XCYeDxGbW2NVwX51VZ5d2BggFgshqZpPPzww9x0000cOnQI27YZGRkBXEddKBRix44dLF68mEQiwe7du1FV1WNhmqbpOVpt20ZVVUZGRnAch9bWVu655x5uvfVWuru7iUajhEIhhBA89NBDAHz605+moaGB6667jmXL3NdQCMGyZcu871PxcppfiqJQV1MLSGyZLJ5LlBkAxbwBBFIKNN0mHA1gGBq5gsX4RIZ8tth8V5S/3mLK+z61SMnUZqTl9/gKTyUWApDuA+sbzLPh4V78Po01q2oxTtCOCwYD5PN5LMulBfv9fhzHIZfLeeprMBikoaG+GJ+fwcqVK1FVlVWrVrF48WJCodArnotfoj6XBNfxDoqhoSEOHTrE8PAwt956K+effz6XXXYZ3/rWt/j9739PNBrFcRxGRkYolStfunQpt9xyC/F4nFwux86dO6mrq/Ps+FQqha7rXojO7/czPj5OLpdjzZo1/P73v+e///u/kVISi8UIBl2n7Rvf+EbWrVvHG9/4RkzT5EMf+tBLZtcfLwqFAqOjoxQKBaqqqrx29h5XgAkvBOi6BYuagHTnbc1QaWgOUVXrR9NUCpbF6IhBX884mbSFUEoJRsVBPO3PVDnAX6h4O6mFgAcBFhY9/ZKHHxugodHPnBmxEzqEW0Pf8urq+Xy+Ipkk43mU4/E4b3rTxVRVVSOEm7orhMAwjJfEe/yXRiKR4O677yYYDHLOOedU5BpMRTabZcuWLWSzWc4991w2btzI9773PSYmJti6dSvPP/88a9asYdOmTZx77rmsXbuW66+/nuHhYcDVBBYuXEgikaC7u9sj8sTjcRobGwmFQuzcuZNAIOCZECX+f+mcb3jDGzhw4AAXXXQRTU1NtLa2oqoqbW1tvO997/PSsP8cplgpuqEoCr29vdx333088cQTJJNJZs+ezfnnn8+aNWtoamoCoMA4iFJ4EPDYg27+QE2tj7rmKJruIKWNogtq6gM4UtJ9KIFllbXfK5F/psz15TwBLztAFsOGJyARTiohMD0LQHprLNthf+cEW58coq46SCSouWtEuQ00PdzCHO4P6RbXNDnnnLOJRiNUV8exbbtYZNO1If8avPZT0dfXx2233UZNTY1n2pTgNhlRinkPNj/5yU/44Q9/SDqd5h//8R8ZHR3l/vvv53Wvex1nn302TzzxBDt27GBsbIx169Zx+eWX87Wvfc1rT6brOrNmzcI0TQYHBznrrLM8Vb+trY1Zs2Z5dOxQKMTChQtJJpMMDQ2h6zrNzc1ce+21pFIp5syZQyAQYHx8HL/fT09Pz5+1w3QqleKJJ55g8+bNZDIZ9u3bx6OPPkpvby+FQoFwOMyf/vQn3va2t5Eudn+y5DgKCnYFA9b9r2Hq1DUEUTXHZf8VfQeaBvEqPxNjOUaGUmV+r6kz/uR9V/JsS+tPjDZ00giBUhKNxEHxoqilTi7Si7OmMxZP7xhlzqwIq5bWFJ/TsV8Gvz/AqlUriUQixdlDY+XKFRVNTF8M4+2VgFAoxOzZs6mtdZ2bqVQKTdPYsGEDg4ODXHTRRVRXV9PZ2cl3vvMdhBD09PTw05/+lHe/+90AvPe97yWXy/Hggw/S19fndYiKx+OYpukJAUVRqK6u9ioczZ8/n87OTizLora2lvPOO4/NmzfT3d3NpZdeWiyHvpB8Pk9zczOKorBw4cKK6w8EAsyaNetl7YZc/g709vayefNmHnnkEbZs2cK+ffvI512OST6fLzZ7cennmzdv5uDBg552VWACpFKMEDjFYwuQkmDEJBA0caRV1qOwJCAUwlGT8dEMjg2OqBzoFSR6UfQyeGbDJJ24xMyRlc6FaXHSCAGYrKxaQjnLCkBIgXRgaDjD9p0jzJ8dJRw8PlXQ7/excuVKT4UshfnK8dc6+Euora3lTW96E5lMhk2bNrFlyxbOO+88br75Zmpraz32XWdnJ6qqct111/Hzn/+cbdu2eSp3aSA6jkMm43Ir+vr6CAQCRCIRTwgIIQiFQixevJiBgQHa2tpYsmQJO3fuJBgMsn79emKxGOPj4yxevJimpqZjNpc1TZOvfOUr1NXVeQ7Gl+M3y+fzPPHEE/z0pz/lwQcfpLu7m/Hx8YrCJqWCMLquewlO5enOadnNhLKdAPMqpmVFEYTDPhTFrRvgvd9usABVEQT8BrqukbPssvFQmhgrPeLl7cg8rViWLzv28zlphIDwCJCiLGgyTQhASPI52H8wTWd3ikXz44dvMw0URSEYDL4iGHpHu8YTeekdx3F71OfzbN26lc7OTnbv3k0ikWDWrFk89NBDdHV18dRTT/G+973PE4pz587ly1/+Ms888ww7duxgfHzc6wDd3d3NokWLANdv0NLSwmOPPcbWrVtJJpMVBToCgQDLli1jx44dzJgxg7lz5zI0NERTUxPBYJB169YhpTxup56iKJx55pkvq3M2l8vxhz/8ge985zs88cQTTExMFGtImMRiMRRFwbKsYkUoipOJic9Xz8TEBBMTE+QLebL00lW4hWb9ckIsAWwQtlsuLuDeb6lxacX8LgS6oWGYOtmMXTHcvcjCMZT9kyWB6ARRyr12o51OsTRTOcXCXVCKTcPgSI49ByaYMzOKaRx/KuUrabYvlTu788472bJlC3//939/zPLfpYy7vr4+hBBs3LiRUCjE3r17OXToEOBmMp533nnMnDmTe++9l2w2y+zZs71EptraWh599FF++tOfoigK6bRLkCrZ4/F4HF3XyWQynHHGGXz/+9/nE5/4BKOjowwODlIoFNB1HZ/Px0UXXcSKFStYuHAhhmEUexu6TtYT9ei/kHCs4zie2TNdavdUPPbYY3zve9/joYceKoaPQ4RCIc/77zgOqqoW24K5M7uqKgiheMVns5k8Y2NjJJ199Fm306pWY1LnbW8Y5TN6OQPQvQZVU9A0lXK3IlRm2MopguPFTG4nUbyrZLvIIgFCRUxzeQIQQpLO5jjUOUFiPHfYNq9kdHd3s2XLFiYmJvjbv/1b7r//fh588EFuvPHGaSsVleojlJDP53nwwQe57rrr2LJlCw8++CAPPfSQF7+Px+NkMhn8fj9nn+02PgkEArS0tHiDc2RkhF/96le87nWv49Of/rSXGxGNRunt7SUYDOLz+ejq6uLd7343oVCIbDbLZz7zGd71rnd5M7WqqjQ2NrJixQoCgQC6XllY9eVGPp/nN7/5DVdccQXXXnstXV1dR92+t7eX3/72t2zZssXzacRiMQKBgDfwpZSoquolLGmaVqwrabvl53SFSDhCfV01uiEYt59nyLkXW9gee1BRhKe7H+bQFsX3v8xXMMkFOHqFoMNxfNueJJqAxFFA8Zx8DsJ267BTYkuVQ4BtSwaGMvQNZqivOTmKYr4U+MY3vuGF437wgx9gGAbxeJyRkRHGx8epra318u1HR0f5+te/zuDgIFdddRVr165F0zRCoRD9/f3s2rWLkZERhoaGqKurIx6PU1VVhWW5oVK3MGkDO3fuZHh4GMuyUFWVZDLJyMgIoVCIRCKBbdskk0mi0SidnZ2YpukV6FyxYgW/+tWvUFWVpUuXomlahW3/l9C8SkVj9+3bx+c//3k6OjqIx+PMmzePz3zmM9PuY9s2Dz30EH/605+QUlJdXY3f7y/WDHQNdiEEhq5hmD50XceyCuRy2WJkBWzbwrEdhFrAHwhSBfT39zNkP4JfXUQ1K1Cwig5DUcyYdSglEjklQ1hKpFPkApbTBIQ3OopXXV5ctPTPXQ7uKRTKUo6PgJNECAhAxb14BV1zaG0zsHIqnT1J8Cq3lmSiRErB2LhF/0Aae34V6kmk07wYFAoF9u/fj2EYrF69mtNPP52JiQlvIG7evJmf/OQnXHPNNfzmN7/hf/7nfwCXA/DDH/6QcDhMXV0d1dXVXvGNEqmlqamJWCzmOfUymQy2bZNKpbj33ns588wzaWhoIBKJUF1dzc033wy4M+quXbtYuXIl0WgUVVX58Y9/TH19PYZhcPbZZwP8xanTpbJxX/3qV7nqqqvYv38/PT09vOc972HTpk088sgjHjNxKvbt28ftt9/Ovn37CIfDaJrmlSl3HAdVUdE0FZ/PRFFVr7BsKTpSEjyu01khXygQCPiIRasZTQwzUribqD4fVRrYBcWjFHtvdKknAQLHEtgFp2zeV5BlQ79iv2loweXOwHLH4ZFwUgwdISTCcUMoliXxmwZnndnG8qV1uJrTdDchSGVsevsypDOFadafXBgaGuJHP/oRDzzwwBELkIJboiqZdBOb/vu//5uZM2cSibgdg/r6+viP//gP7r//fkzT5NZbb2XhwoVcdtllPPXUU2zfvt3zXLe2trJv3z7AHRx79+5FVVXi8TiKopBMJtm7dy+2bdPU1MS9995LR0dHsax5nLe97W1YlsV5553Hv/3bv3HhhRdy/fXX86UvfQkhBEuXLvVSonVd/4sLgBIGBwe55ZZbOHDgACMjI7S2tvLxj3+c+fPnMzw87A3scmQyGTZs2MA999yDrusEg0Ev+lAa6KZhEPCZCCmRtkUuk8Eq5HFsG59poqoamqbjlhp3B2cuVyASi+HzmSSd3STkNhwnSDbloAjVdXHJkkYwWXLMKoBdcIr0Ivef8EqITf384jWtk0II6JqCII/EAWEhgKa6IC2NflRVmUYICBCSgm0xksgxkTz5hcChQ4f40Y9+xKZNm44qBOrr65FSMj4+zle/+lU+97nPeZWGHn/8cR5++GEuvPBCwK1a/I53vIN3vOMdZDIZdu3aBbh57bNmzaKrqwtVVZk5cyaJRMITEKqqMjo6yq5du6iqquLd7343lmWxYcMGTwB95jOf4c477+Tb3/421157LWvWrKG6utrjWZRU/pPN0ZpMJsnlcnz961+ntraW22+/ncbGRoaGhmhoaJjWGblt2zZ+9atfMTIy4mkBbi0/xYt0GLqGz9ARUuI4No50EEUtoBR5CgSC6Lrp5gWoilsyTJVEozEs8gxa95CTvUyM5d2kQcCrKywFilSQNmQzBQp5u5gqLPDqCMrSv3L1//DnP1UwvNxZhC8JDMMtmYRUEUKnUJAU8hYBn4aqKmA7h9+rAEc6JFN5VwjUv7CqQ38ulLz6JdUc3BlIVVV0Xfd+qNraWoQQJBIJCoUCBw4cIBAIYBgGv/71r0mlUlx++eVkMhlyuRzf/e53mZiYoFAo0N/f751r1qxZHj166dKlPPXUU+i6TjQaxe/309vby4EDB6itreXyyy9n4cKFLFiwwGNWhsNh1qxZUxGOO9kGvJSSVCrFc889x/e//30+/vGP88tf/pJCocBzzz1HoVCgra2Nu+++mwMHDnD11Vcfdg/d3d3ccsstPPzww/j9foKBAAiBFBLbcesh6KqKpiroqoI0VHKWg20V3NLgilvjIpcrkM/ncKR0Jy4pi04+ic9nYvpN0pmDjMmHCYxfSnrCIBjVcBWTyWFrFQqkxrPYdpEDIUrmr7tdeYzgePoMHg9OCiGgqgooGkKqCHQsJ0syY1EdC6D7VUTOmmZsC3AEqYxDMmUxNZHyZEMoFMIwDBKJBPl8njvuuIOvf/3rOI7Dv//7v7NixQo0TaOqqgohBMPDwzQ0NJBIJLzU2m3bthEOh2lsbMS23ZlicHCQtWvXctFFF3HRRRcBbkprc3Mzzc3NBINB5s2bR11dHY7jEIvFmDNnDrW1tVxwwQXMmjWLmTNnsnr1aoQQFYO+ZDufTNyK3t5ehBDU19fzrW99i1/84heMjo6yd+9eRkZGWLNmDT6fj7POOosLLrjAi5bU1NTw+te/vkII5HI5HnroIW655RaP3KSqGpZdoFTw0zR1gv4AQb+PgK5iqCDtHD6/D03RyBUK2MVAnupXyOYyFPJ591lKxTUrdIXqqir6evoZtp8kVjiTgW6D9lAMIeyiwHCf88R4gYlE3nWKVxDpS4O/jBXIZElSvKUlKGW7Hz3l9qQwB9xYqwQKIFIgC2QzBUxDRVMFztQ7BUrx1XTaZiKZf4lk4ssHv9/v1S3o6uriq1/9Klu2bGHjxo3893//t1fRKB6PAzA8PExjYyMTExM4jkMkEsFxHJLJJD/5yU+ora0lGo1y7rnncuutt3LaaadVhApjsRjt7e0YhsHChQu55JJLWLx4MXPmzOH666/ns5/9LBdeeCHz58/HMAxUVa1Q8csHy8mi9v/6179m3bp1rFu3jqeeeorR0VEeffRRTyg88sgjXHHFFcybNw+fz60FYds2XV1dtLe309jYWHG8vXv38tOf/pT+/n4ikTB+n49CIYdtWy4ZRUoUIfH5dEzDQNc0on4/rfEITZEIQUPHzV5xUJWi4l58ViVHYSms6Pf7CEf8ZJxuUs5+xoZsOg8kkJaKppgoUmN8xKK3I4OVnxyY5Y1KyrsNT36u9AtMH048+u/3gjUBIcR84Fdli2YB/wTEgI8Cg8Xln5dS3nG0YykKqKrE1ZJVLEtlfMLB1AV+U0yyKMrPjysG8nmHdNrCcSSq8ud5US3Loru7m76+PpYvXz5tVaFMJsPvfvc7fvGLX3DmmWdyxRVXEIvFGBwc5PHHH2dwcJBvf/vbPPnkkzQ2Nnq2ajQaxefz0dfXx5w5c7Asi2w2S1VVVbFjcYgf/vCHvO9972PZsmXcd999XHnllTz77LNcddVVLFy40BsUV155JUIIVqxYwemnnz7t4Ia/3Exfft7y6yqVAvvBD37Apk2b+MIXvkB1dTVf/OIXOXjwIFJKrr/+es455xyklNx8881s3LiRz3/+86TTaerq6ujr68NxHHRd5/TTTyccDlecY3x8nPvuu497770Xw9AxdI1CPosQCpqqFk0Agc8w8KkKurTxqTp14Qgxn04ym6NvLIVlW+SzOTdVWFB0ELpMzfLHKh0H0/QzIcZIyQ5q7HMY6EoynsgSCYfIF3KMJTIU8qAKUeQGOpUzu8cYxOMYTSENvyC8YCEgpdwFLAcQQqhAN/Bb4IPADVLK64/3WIoi0FQV6YBERQibTLqArkHAryNldvodBVjSJpu3sG2J+mfK9U8kEvzbv/0b27dv56677vJKZD/zzDM0NTWxePFiNm/ezDe+8Q0effRRNm/e7DU4yWazJJNJLMti9+7dvO9972Pp0qUeUScQCHhx/jPOOANws9gikQgLFizgyiuv5Atf+AK//vWvueqqq7jrrrv44x//yMyZMznvvPO8a6ypqeHKK6+sfFxHmA1eylleSsnY2Bj33HMPdXV1rF+//rj2K9UreOyxx/jJT35Ce3s79913H/39/SxevJjly5fT3d3N9ddfz/bt27n77ru951Nq615yqNbX13tNXfx+Px/60IcYGhqqyDU4dOgQv/vd77Btm0gkhqK6DD1VFWgqGIrAVHVChklQV/FrgpAuiJgq1UEDFZtUXieZ1/A5kkwhTyGfBxRUVcNxbGzbHZi6rpPPu0JA0SbI2gNINYsiTdLjNqmxccBlhyrFgrrlFPrKIJ9S9AY4FcsnS5acOF6qUfM6YJ+UsuOF7KwqCoahowowDQiF3OxBoQgCAXPaG3MzsorkCedIJsOxUQoDTTcbHmlZyRvc39/Pli1b2L17N9deey1veMMb+NjHPsbGjRvZtm0biUSCiy++mHg8ztNPP+1RWEvVdL761a9y1lln8fd///dec9NgMEg8Hqe/v98rp5VIJGhoaCCVSvH2t7+d6upqvv3tb7Nq1Sr+93//l6uvvpqbb76Z008/3bvOI836LzeklHR0dPCpT32KO++8s2J5+T/Hcdi+fTu33nore/bs4Q9/+APvec97+PSnP82WLVv4xS9+QXt7O1VVVTz55JM8/7xbxHrevHmEw2GGhoa84q69vb1eMY/R0VHq6uoYGRlhbGyMbDbLzTffzJvf/GYOHjwIuFratm3b2Lp1K4GAH7/PX2Sku6QgTSj4VJWgphFQVcKaRlRXCSugWllUWUBX3bA2lsvvVxRBwOfHb/rQNQ2BgqqoZREGBd3Q0HRJgTEkOQQSVbgzv6pMzvR4wcHJnoQlIr2XJFRMOiqFF0tdiA6PFwgvDHkkvFSOwXcBvyj7fo0Q4n3A48BnpZSjR9tZEYJ4lUbQEFRXmVTV+pk1K4quCQK+I1yiwH0AjptZ6JygCCy9jCXyyNRBUhIAU1XWUufhRx99lI6ODr70pS9xxRVXcOeddxIOh3n++ee59dZbkVKycOFCPve5z3HjjTdy6NAhamtryWQytLe38w//8A/8z//8D0888QQ/+clP+OhHP8qCBQvQNI2amhr6+/u9iEJfXx9VVVWMjo4SjUa54YYbyGazhMNhPvjBD/LBD37Qu77DHtOL5JWfKIQQRCIRL0OwdO5S5WFN09i0aRM33XQTW7duZdeuXXzyk5/0zJizzz6bdDpNZ2cn//mf/8k3vvENhoaGSCaT2LbNW97yFhzHIRgMemngfX19zJw5E3B5Ai0tLSQSCT72sY9x0003MTAwwNjYmHc9Q0NDbNy4kUKhQF1dLZrqpq0LAYamEjMNaoN+YgGTsGkQMnXCPh2frqOpIO0CGgK/quLHIW0VyFkOmukj59hYjo3jSGzLRqiTxCBVUVEVjYJMYIkchgwihEOp5DheQ5FSIdKKzAImuxeUfs9iVM3buvKTZFJYHE1HeNFCQAhhAG8Grisu+g7wr8Vr+Ffga8CHptnPaz7S0tLK2pX1hP0GdQ0+ovEAfkNDyDz+oArKkb2bpYEsT1AK9Pb2cu2117Jq1So+/elPezb51MG/Z88eNm/ezJlnnukVHMlkMuzfv59gMEh7ezt79uxhwYIFfOITn+A3v/kN27dvJxqNYhiGx77r7+/3+hWMjo6yYsUKbr31Vm655Rb++Z//mZGREU/LiMfj7Nmzp9h12C2L/sEPfpC3v/3thEIh3vWud1VcY/F5HvFeXw4tYKpgKacJm6ZJMBj0iohs376dr371q6TTaa655hqGhoa4++67yWazRCIRHn/8ceLxOD6fj7e//e1MTEzw/e9/H3DNmo6ODs9cOvPMM3nrW9/KunXriMVi/J//838YGBigqqrKKz2+YsUKpJRs2rSJ8fFx3va2t3m0YXCpvKWeBT6f6SZISQgYOjWBIE3xEE0xP3VBk7CuEtDczsIF2x2eeUcSNExm1Zq01YToT2bZ2zNEfzJNQUps7GJxUOmaCLqBoig40sHn8zGWTJKjH1PUIrCLk3TJyC8ZAmUNSyhT+8vrD1Q045msSDzJInTXybJ10+Gl0ATeCDwppewHKP0tXvD3gT9Mt9PU5iNrT29BEQ65rM3IcIHeTJq2Fp2AX6GUbzHtbZRexhN8z3fv3s0dd9zBnj17+NjHPkYoFMK2bXK5HM888wzj4+PMmzePiy66iIMHD7Js2TLuuOMO6uvraWlp4SMf+Qi33HILb37zm3nssceIRCKsXr2a7dvdbkWKohAKhSgU3AYnlmURDAZRFIXt27fzpS99yfPo+/1+LzQIcMYZZ9Da2kpLSwtbtmyhoaFh2ko6L9fgLq8yNN05ptMsHMfxwpYlZuL4+Dj9/f185zvf8fILVFXlwgsvpLm5mQsvvJBIJMKvfvUrRkdHvd6B4XCYQqFAMpmkqqqKiYkJqqurUVWVs88+m/e85z185Stf4b3vfS/BYJCuri7C4TCGYdDZ2ck111zDF77wBYLBIPX19cyaNYsVK1YArgDfuXOnVwDEtl0nnk83iAf8tNdV0xQLUB3SiRpGUQhILDtPXkocWyGXB6E6hE0Dvz9Ea1WUpliM7d39PNfdA5qO5ldIplLFZwKaZuA4El3TkSJNWh4iLJYAYrI7mZg0B9yBrEx6BYT7zREuZb40IkTFIC8raiomf6djaYMvhRC4gjJTQBSbjhS/XgY8dzwH6e9PsWv3IP29GXr60mg6XPmuBYT9PlQpPVvoMBRfuhN1Cg4MDOA4Djt37mTPnj2sWLGC2267jeuvv55EIsH5559PQ0MDHR0dLFy4kN27d/OHP/yBj3zkI4TDYc4880x++tOfMjw8jBDCC8+VGHU+n4/R0VF6enrIZDL4fD7q6+tRFDfldMmSJfz+978nk8nw0Y9+lJaWFi9Gf+2113qDLxqN/lnDc11dXdx8881ceOGFrFq16qjpvpZledrLPffcw4033siqVav48Ic/TCwWo7Ozk71797JlyxbWr19PTU0N+/fvZ9++fUSjUWKxGAsXLvQcpkIIxsbGvF4CJSGQTCZpbm5mxowZfOMb3+BnP/sZPT09vOENb6C5uZl0Ok0gEOCGG27g9NNPx+fz8aUvfWnaF398fJwnnniCQqGAqirF80LA1GiuitJSHSXmV/Hprp1uKAo+VaD7DHfmtRxyjlt3MmIaqIpKIl0gWB0m7DcwdY0nD/aQVKVLOpIUcwpcPoymaQjFJu10I1WbUsUsgTNFZZ9MIz6MLysm575KlLgF8vCdjoKXovnIBcDVZYv/QwixvHg1B6esmxZSwpNP9nL/pm7sgk3OUqiKm+RzDpGggaaqFA5z/BU9r5qC36cWE4iOToooR4ldl81m2bBhA8uWLWN4eJhHHnkEXdc566yzuP/++1m1ahW33HKLVw7rwx/+MIqiEAgEUBSF8fFxotEo2WyW8fFxz2k4Z84c7rvvPr785S8zNDTE+vXrmTFjBuFwGCkln//851mwYAHBYJD3vOc9FfX+Ss6klwPl8Wu1mAhTjj179vDd736XpqYmli1b5lJoy64lm3UbY5qmyXe+8x3Gx8d55zvfyUc/+lEGBgbYuHEjra2tNDU1sWPHDjo6OigUClx55ZU0NjbyhS98gYGBATRNY2JiAr/f7/UP1DSN8fFxjyE5NjbmZT36/X6uueYarrvuOgYHB7nyyitZt24d3/zmN5k5cyaapnH11Vcf9blJ6TaCfeyxx7zZsWBZmKpCbTRMU02ciN/Ep4EhJH4F/IrEpwgMoeDTVIQuySkaAdPAh0TRdDRNJ2NJdFUjXVvF4GiKfUNDBAMBUukkjm0DsqgJKai6Qj4/jBQFhNS9V3aqt3/SGCiz96WrIZScmN4EUXJslnwAh3f+OyJebN+BFFA9Zdl7T/g4QMFSSGUFQgGhChxHkM8UMP0Oqi4o5CoLjJSsH12HgF9hMjHs+IRAqQKu4zj88Y9/5JOf/KSXEHPJJZfw2c9+lre//e3ous63vvUtRkdH6e3t9Wa+SCTidS6aNWsWfX19/OY3v6Grq4uamhouuOAC+vv7+f3vf088HmfdunWsXLmSz3zmM8ybN485c+bwD//wD0e8vpdr9pdS8tRTT7Fnzx7OOOMMr/V5CTU1NWiaxtjYGFJK8vm8VzKstraWv/u7v6NQKHDDDTfw7//+75xzzjk88MADDA0N8cEPfpD77ruP22+/nSVLlpBOpz1fh6qqBINBr/aAYRiMj4+TL7LrXO59gNHRUfx+P4ZhMDIywuzZsz0n43vf+17a2tpIJpNccMEFBAKBw0KQR4uIWJbFgQMHeP75570EIaQg7A/QGK8iEgigCQVVSjQkqnDcQaspaBqYhgZCogkNn6riVyVCU9F8OhEMjPEcY0GT+Q1hcoUUXeMpsor7Lju2g64LFFWgahr5XAJHZlAwKNUgLKn2k+yAkpYAJfHgqf0Sl9UoixrHpCHgHq04H06XZTgVJwVtWCAJBjWXK1C8esu2SaVtgmEDw1DJZJ1pOEMuv8A0VBRxYuZAb28vLS0tLFiwgJ/97Gf09vZ6QuDSSy9l3rx56LrOtm3bOHToEK2trZx++ukVIULDMHj22WdpbW3FMAyuv/56wuEwH//4x1m/fj2RSIQZM2awaNEiLr74Ympraw8bdH9ulFp333PPPdTX1zNjxgxvXamSjqqqDA4OYts2GzZs4LrrrsOyLL73ve+xc+dOnn76af7u7/4OKSUtLS1s376d+vp6PvvZz9LX18eePXtYvny5169RCMHo6Chz5szx2rcHg0H27NmDpmmMjIxQX19PNBr1SpmV/CBLlizhm9/8JsuXL0fTNC644IIXfO+pVIqtW7cyPj7u+QMMTSMeCRGPhDB1BYENCihqMQlI0zEMDaOY4+HGBVUMVXG5BUIlaBhoegBTNUjmk3SNKixoqiGXzZHMajiqOyZt20YRKoZmkJUpLDLoxIsU5UkIiuOglGV0mHvwOHACc8hJIQQkEAy6Kr3laEjpkn/SWUlVrcDQDx/gJeeIz68SDGrTsgqPeD4p6evrIxKJcMEFF3DTTTfxwAMPsH79ehRF8Wa+qqoqYrEYN910E7Nnz/bU1lKprfr6eh5++GFaW1v58Ic/zI033siKFSu4/PLLCYfDrF+//rjJMn8uqKpKJBLBsixyucmqTJZl8dhjj7Fjxw5s22Z0dJRkMsk//uM/0tnZSaFQ4Prrr+eNb3wj9913H8899xyWZXl2/vDwMO9617vYv38/M2fOxDAMTzUPhUJe27BcLkddXR1jY2P89re/5b777mPhwoUsXLgQy7LIZNw+EN/85jeJx+NEo1Hmz5//ou+7RCR65JFHvCrBAD7TIBoMEDB1dAV0UdQCUDFUFU1RUCSoxUlGUxQ0oaBJia4IdMOHqvtc4WZCczRMpz+IwEeu0SGR7SCfKXi9LUG6RUbJYjGOoMUNT1YUCPE8hZQ3HC1PGRKVDCLXvJn6WZS6HR1deJwcQsCBYFBDVR0sSwHhVg5Kpiw0XcU0NaScpoyYgFBIJRo5scYguVyOkZERTNP0OPt//OMfeeMb3+hl2AGsWLGChx9+mAMHDnD//feTSCS4+eabUVWVaDTKxRdfTCqVYtGiRbzvfe/j0ksvJRqNviS97l8spiufXipFFgwGPeJSyTewe/duPv3pT3vZd2NjYzz77LPs3r2bz372s3R1dfHb3/6WD3zgA5imyaZNmzx6cn9/v1eg5J3vfCdnnHGG1+FJ0zTmzJnDbbfdxqOPPoqmaZx22mls27aN2tpaZs6cyaWXXsrq1at53ete53UJfqkrE0kpGR4eZseOHaiqiqZqCCDo9xMJBggYmssSFGAqoEkH4TggJ4t7KEJBFWAoCoaqogiXqq5pfoQqUCyLkKbSXhsnOzhCa02YnkSM8ewQOWkjFA0hHVQVHGFTkAlKTUtlRcy/dN+VHYwPgyhRg44wyI9TcTg5hICEUMD9EXLSAcXBkYKh4SyDQz4cZ+qL4N6dqgpiMZNI+MQ6AieTSdLpNBs3bmTDhg0UCgU2b97MyMgIVVVVXqbaJZdcwg9/+EM++9nPEgqFeP/73+8dIxqNctVVV3HZZZdRV1dHIBBg7ty5xfs5edKZbNv2bPLSwD548CCZTMajL6uqyqZNm+jt7eXss8/mmWeeYXR0lAMHDnjNQkZHR0kkEoTDYRYuXMi9997rzeotLS2Ypsl1113HypUreeKJJ6iqqvIIWW9605t48MEHGRwc5PLLL+eMM85g165dLFiwgH/8x39k3bp13sz8cuUzFAoFDh48SH9/P6bPRKgCVagETJOgz0BXBZpSmukFfk3BVAWKkChC9WZyXdcJaD5UReDgCgjUoj/OkeiqpKkmQFLmEcPjtNRE6ZlI0ZdMIR1ZDKEqgE2BsXJ/Pk7Zt8PpwiUO4dSug2XVhSiLmJdrBsfQBk4KIeBIUDU3acPNJAQbhz17RhnsHyeRyBUrtkzeiJRg6Co18QDBwIlVtRkbG2NiYgJN02hoaEDXdZ599lmeeuopampq6OvrA9x4/d/93d/x+9//nnnz5nHttdd63vSSM2u66r9/6Yw727bJZrOkUim6u7uxLIv58+dz33338aUvfYn9+/d7vQAty8I0TQ4dOkQwGOQrX/kK//mf/8mBAwe84ifXXXcdqqoyf/58IpEI5513Hv/1X//lEZvWrFmDpmnccMMNRKNRRkdH+cpXvkJ9fT2qqvL6178ex3EYHx/n/PPP92jTuVwO27anbfH2Uj/DfD7Pvn37vI5BmqohBJi6il9X0QSoQnpRCr/hMlhNTUFXNS8MrSoqmm4U6eq2W01Im6TrSmnhUxWaohEcSzKcytJUHWEslyNbLD2maioIB0uOeYQeynoFuMVEygVBeRZBeeBQlP2rLCrmBgoqtYsj4aQQArm8zYGOJHnpIEWp0opDf3+Ogb48eaFMW2s+6DeoqwmgT+MzOBpGR0fJZDK85S1v4eqrr2ZsbIy3ve1tbN68mcWLF3sxf03TuPbaa3n3u99NLBY7rpLVLxdKLdQOHDhAfX09VVVVh60bGRkp9ly0uf/++9m2bRsbN27E5/PxqU99iq1btzI2NsbcuXPp6upifHzcK3CSz+fx+XxEIhGam5t5+umnPY7AnDlzeMc73kFDQwMLFizgta99LTfccIMXJWlra+PCCy/k/vvvJxQK8Z73vIdFixbxN3/zN6xcuZLq6uqKZKZ8Pu/V8M9mj5Ac9hIjn89z4MABj9EohJsoFPGZRAwfulCRCCwpcNAQigGKq/6bml7MKlRRVR2hCIQU6EpxdhYa0i4gZcG1bS2JgSTqN6gP+6kNGhwyNbI5tziOIlSEIpEyXzHdlw/iUvNSUaTHI8orbJUGdslYUIrOxfIQeUlrOLYwPSmEwMREnk0PHySdk6CUZJuOhcvMmnqZUrqViaurdBobAiecQtzf349t25x//vmsXLmSVCrFO97xDubNm8fatWu9xJ0SY67UZPIvjc7OTj71qU/xyU9+kksuuQRwBUAmk+Hee+/l3nvvZeHChSxfvpwbb7yRxx9/nFAohK7rbNy4kYGBAdauXcub3/xmbrzxRi9EB241okwm4zn7Sg1a/X4/M2fOZMWKFfzoRz9ixYoVvOY1r6Gurg7LsohEIgSDQf71X/+VxYsXU1NTwzvf+U5qamoqzKdyqKrKwoULeeMb30hLS0tFdt/LhUKhQFdXl+cUlNLBpynEAiamoWGhMZa3sG2LiE9FNzRMqRJQwDRMDE1FATRFI5+30DUDTTOQhu6aPbYFTr6oj9sIaRE0FWpCfuJ+g7DfRyKfwWaShVnZO8Blx3tDWU5yAUozu/un6KHwHI3uHgKlGEw4QkXOkz1EmC849A8VkKpAFDnCAoEt8MgPUwizGIagpSlAfa1v+oMeBUII1q9fz+zZsxFCEA6H+drXvubRekvbvBw4Et//ePogJhIJHnjgAVasWMEZZ5xBTU0NjuOwa9cu/vEf/5F9+/bR3NzMJz7xCa+C0MUXX8yf/vQnDh06RD6fp66ujvb2diKRiNcGHNzahtlslr1791IoFLy8/DVr1vC73/2OrVu3MjQ0xEc+8hHmzp3LlVdeieM4xONxhBDMmzePf/7nfz4uW15RFM4++2zWrVv3Z+n2XOI7lHw9QghsyyEc9BHx+7AlJLJ5xtMZJjIZArpJriDQ6yKE/RpCVTF1ExyJqhhYdg4hVIQvhDQ1hGOh6ipCV1HygJBFDUIhZBrEggF8uo4gi+OUz9bF9vCUggFltYGLXOKKFGEpJkOGctJLMJlU5FKOK0yAo2QPlnBSCAEAIXSkLCCKD8bBAaGA1PD0paJUlBIiQZ2ZrRFCgdL64x+0K1as4Otf/7rX+LKU+eae4uVz6vX397N9+3ZmzZrlJQYdDY7jMDExwa5du5gzZ45XPfj//b//xznnnMPFF1/slcjq7u7mne98J08//TQbN24kHA7T0NDAeeedx7PPPksqlUJVVVKplFs91zQZGxvzhMD8+fPRdZ3vf//7DAwMkE6nsSyLT37yk6TTaSYmJrj88stZunQpAJ///Oe9xiUn+syEEH/WVu9SSiYmJhjo70dRVSyrgGPnifhiBAyD8VSaoVSaiXSWdCaHgkIqnQVsomY11UENGw2fqaOoKjJbQNoghIZiBCCfAbtQ9Ce4IUVdcVN7TVUjGvCjqyqOY1FK+Z207SeHsvd8KA77w0yF8lm+xCMQh+9X4SMo6QYnuWPQhYJwFFfdKdEop1IfpXuTmgrNDUFmtUdeUL+BqWWmyvFyaQC5XI7bbruNm266ib/5m7/hsssuqxACQogin91Na961axc7d+6kq6uL2267jXe9611eifBCoeBdZ6k4SSwW49xzz+XAgQMcOnSIpUuXksvlPAJQNpv1ugb39PRg23aFEFiyZAlLlizhnnvuYe7cuaxduxa/38+ZZ55JNBplYmKC008/3XOElvsk/hJ1C04Etm0zMDDAaCJBwDTx6xqWahPwa+iaYDybw7Ed4qZBla6RsQqkc0n2dPdQ69epDUcwVAiqOgiBouiAglMooAgFqRmuKeAoCAm6ULGxsJFoqkLAMDB0E8eRONhFtp8sMv4O5wxXRAUEXipyyRhwtQR3YAtJsbPxpLosAK+GgKgUHdPhpBECbrlxjhrblMWEjHBQY+GCKHW1vrIdTr6XrxyDg4PccccdJBIJ/H6/Z3ZkMhlM02TPnj08+OCDhMNh3vSmN3HvvffyzW9+EyEEhw4dYmxsjOuuu46GhgZmz57tVdUpNRIZGhriu9/9Ll1dXcyfP59AIEA2m/W84SMjI9TU1LBjxw5+8IMfsHv3burq6jzHXF1dHVdffTXt7e2cc8451NfXs2jRInRd58wzz/Tu42QKfx4vbNumt7eXbCZDrKaKgKFhqxq2AxPpLIZuMDMUocZQMFTIFgqMJDMkkll6RscYrq8lous40kERCobP7TPgSBusAoqhgvAj8haq7aDILJomyVu5Yuk8BV3XQJSSrorsV2kXk4HEpAAo5gBMhkqLywV4qr6cVPvLXX+ytFwUZ35x1OHk4aQRAq46pBxOhSqHBF0RtDWHWLwghmlMekJPdiQSCRKJBOvXr2fJkiV0dXWRSCTYsWMHZ599NjfccAO33XYbgUAAn8+H4zjs3buXj370o/T393PPPfewZMkS5s6dS6FQIBqNAnjJTJZlUV1dzfnnn8/s2bPp7Oxk69at5HI5L0163rx5bNu2jQcffJD29nbmzZvnRTyEEFxwwQWsWbOGWCx2RFPlZJzpj4WSJiCL5cDTmTS2qtCdy2PlbaqiMYLVKhF/kLqggWPZjAd8DASyWCiMpzPkQr5iONVAMwykIijkCygFG8U0QddwDHCEjqKm0BhFc3KAg1Jk7qmKCrKAO8hBSptyO37Ssp/0DbjxfmdSSIgyu79EqKJkJktv/IgyItERyUZFnDRCwMVUATCpLrmajaAqZrJqWR2NdSFXTXoZ3snjcdKdyH6l+vj5fJ7Ozk6eeuopHn74Yfbt28fAwACpVIrbbruNJUuWsH37dm6++Wbe+ta3AvDOd76Tjo4Ofve73zExMUFjYyNPPvkk2WzWa5TZ2tqKz+fjzDPPZOnSpRw4cIBgMEgul/PqEzqOw4IFC/jwhz/Mvn37WLFiBbNnz6a1tdW7Tl3XvUYnf02wHYehoSEQrsssk80jVIVgLITfULFyGcaSggNWmlwsQGM0TMSnoyBIFxysQo6CZWHLYsUfRcGWNslsjmR+lMzYONm8gyEU/KZGVDHwGwEMJ4tIZ1AVBSkdVE1F5ASOLLYcrzB3iwO6qO26M/xkWpCHcufglCDgZNThGCr1FJxkQgBKFy+FAKmgFB0gDhDwqSxfUs3ypVWYJ8gNeMFXIyUDAwPkcjl8Ph933nkn559/Ps3NzUfdL5lMepVzNE3jiSeeoKenh2eeeYaZM2fyyCOPsGPHDlatWsVTTz3lpRf/5Cc/4a677uItb3kL4JoLLS0tgNstuNSLoJRDbxgGK1asQFVVbrnlFu644w4ikQiXXHIJ1dXVmKbJ+vXraW9vZ+nSpZxxxhleh+E/p3PuLwnHthkeGQEJjrTRVJXqcIj5LQ1E/CZ2Nk+Vz0RKi86hMcbTeZqjcXyKhq3nkY5NwbaxHelSiZEU8ja9Y0kOjI3TO54kkS7g94dpqI7TFjOYGVQxVQ1N1VCUYsci3BJjlu0gcYqaQFkFYQ8CIWVFOkyJS+RyaKQ3PtxZ3xUyZSVFKPUycCfKo7MFTiIhUAxrlGcDCrfvqgBMTWXR/AhnnVlHVVTzNIOXC/39/Tz++OOsXr2ar33ta/h8PtavX8/XvvY1qqqqphUChUKBHTt28MQTT9DR0UEsFuPtb387zc3NFAoFHMdhxowZrF27lj179tDa2sqnP/1pj9Bz2mmnceaZZ3pddBRFoauryysgOjg4SGNjI+Pj4/ziF7/gQx/6EIFAgCVLlnDZZZfxy1/+ksbGRt7xjndw7rnnMmPGDBYvXkxtbS0rVqyoSIA6El6J6v6xYNs2wyPDgEQRAtMwiAcCxIJ+/JpCwbGxrRymphIwfdgFSedwgppIBNNUsKwCBcvCKfYicCybiUyaZL5AtmAhbItowE/vRJLesSRDNUGchirmRQW6pnp+PGk7KKoCefc3cGQWKW0UVCqJwqVZ3kXJX+Y6/DxeIZOfStGGKd+lmHQSvliegBDiZuBNwICUcklxWRVu34F23OIh75BSjgr3Lfov4CIgDXxASvnkMc6AS8AuyUNXFXJcNyqmoXHawjjnv7aZ1ib/UW/ohaDc2XXnnXfS0NBAd3c3//RP/8T//u//8thjj6EoCueddx6maRIKhdyCFIUChw4dYs+ePSxbtox0Os2NN97IXXfdxcTEBGeffTbnn38+ra2tXHjhhdx9991YlsXy5cu54447yGQyrFmzhm3btlEoFMhms14vQkVRvP4DpdJjfX19zJ07l1wux3e+8x0uueQS2tvbqamp4TOf+QxnnHEGVVVVrF27lurqambNmlXRgfeV6NR7KeA4DsNDwyAEmq4RME0CPrcKkJA2edtmLF/AJ6A5FqUqFiaZLTA8Pk4k6AdTJ18oIB3XNrcKBTK5LKYmaY0FaImYaIZJ10SWvf1jdA0ME1J1moJBdE1BRymaBBLbcVAU3e10RAawAL3CaheiUj8o5wq4lOKj2PgvYGgcrybwQ+BbwI/Llv09cJ+U8v8KIf6++P3vcGsOzi3+Ox238OjpHBXS9bRKlcn0R7chSW3Mx6IFNZy1tpaZbWGPqnmC1IDDkM/n2bFjB5FIhPb2doQQpFIpvvjFL7J69Wpe//rX8+yzz5JIJKiurmbv3r3Mnz+fL3zhC9TX13P33Xfz4IMP0tnZye7du7nyyiuZOXMmDz30EDU1NV6NvRL/ftasWbS1tXmls6uqqti7dy+O41BfX08mk6G3t5d0Oo2Ukvr6ekKhEL29vUQiEXRd5+DBg7zrXe/i9a9/Pbque01PNE1j7ty5tLe3V6TJTsVf4yx/LJSIQkNDQ6iqSsDw4dM0TENFFZBJ5+gaGWMi5xar7R5LsaitlbZYHE1CIp1BALZ0244jIJPLYVk2PgroioOiaOiKTbwuRFt1jOcOdTOUGKV7wk9bVCVsGpiaglAUNwysuLUIbPJIrLKZeipXoKQTlCgBk4lArlugMn1YlImLUgLR8XgHjksISCkfFEK0T1l8KfDa4ucfAQ/gCoFLgR9L92ofEULEptQdPAx+v0pbk5+R0RxC1VAUiaEJ2tuinLawivnz4tRVu00hZVG3erGmQH9/P3/zN3/DFVdcwUc/+lEvfTWTyQBU1LFvaGjgySefZHx8nNtvv5358+eTz+f5/ve/j2EYXmvrfD6Poii8733vo6+vjwceeMBLVdY0jUgkQjKZJJ/PE4/HSaVS5HI5lixZgqqqfO1rX2NkZIRoNOp57nt6evD5fLz1rW/lNa95DQ0NDXz9619HCEFNTY13PyUC0ClUQkrJRCrJ6OgIftNHzO9HReI3dQxFJWVLpAMhPUgyb3FoIo06nMav+an3+cghyRTcWoCmaaLqGjLrkoPI57AcB8sq4POZxE2dSFAh0N7E4/v76BpP0hoNEjR1gmWFbyb92XaZFX/4YJ0c/JWDubyq8LE8/8eDF+MTqC8b2H1AffFzM9BZtl1XcdkRhUB1zMe73jqf/oEUBcsVCrGIQUOtn1hEx2cWUzmByen/xQkBIQTPP/+8NxuD2y/wG9/4BqFQiEAggBCCgYEB6uvrmZiYYHR0lMcffxzLsliyZAmGYXDVVVexa9cu9u3bR09PD6ZpMnPmTIQQ5PN5TwgI4bYFz+fzFAoFamtryWazjI2NsXz5clasWMFdd91FLpfjPe95D21tbXz84x9n1qxZaJrGl7/8ZaLRKKqqsmjRohd1768mSCkZSyQYH58gZJjEDBXLcfBpKrqiUh0K4td1pNQ4NDLOcCbFcCpLz1iKiBokavjonpjA0UzMqjiKLKClNcayOQaGx0nnLXJSJRTwoWk6VeRp8KnMrYnQMZ5CUQQhU6XaNFGEm6pcqiKsYqCg4xr6okiOm8wSnKwxULLty/IIKIUPS9m1TvG45QVLp+oT0+MlcQxKKaU4jN53dJT3HWhra2PR3DBzZ4aQjkBRQNMkiuoWcphsylja+cVfcygU8jrZADzzzDMkEgl27drFxo0b+eIXv+jZ5E1NTV4lnkgkQiKRIBKJEAgEWLlyJZqmsWPHDo94k8vlCAQCAJ5mAW6T0BIvv/R5eHiYYDDIF7/4RW666Sbi8Tgf//jH8fv9fOQjH8EwDIQQzJgx41Wpzr9YOI7D6GiCTCZNTSiIT9fI2bZbNUjT3BZjeskbH8JxLHzhEP6ASTKfo94M0zM8xs8ffpyUqrO2vZWdnT08vGs3hYJFHsjaCopfZffAALMb6lg9p42GWICUY7sVinSbKlNDK2qxmhBYtoMpgigYRQe44zUYcyG8QV8yj93FlbN/mQFQNj1O18bs5REC/SU1XwjRCAwUl3cDrWXbtRSXVaC878Dq1aulpqpoKpUh0bL/vtQIBALE43FGR0fZt28f73znO3nf+97H8PAwd999N//yL/9CJBKhr6+PZcuWIaUknU5TU1PD8PCw10sgk8kQj8e9Cj2FQoGenh7i8TiWZZEq1p4vlfUqFAokEgkaGxtZu3Yt8XgcRVF4zWtew+zZs7325DDZofjV6tB7IZjK1ZBSkhgdRdoOPtNtdacpCrqq4lMUgrrCcC4Jlk2tT6WmtRrdH2Aik8UuWGTyeXRNIWD6uHPTI9z10BZmxIKEDBOp+xh3bAw0av0B4pEQqWSSjXu6aGxpo7G2DlNmkDKHoguPG6AZAsuysRjHEmk0GT0ybZgyctDkXRbXvHhTAF6cEPg98H7g/xb//q5s+TVCiF/iOgTHjuYPKGG6G3KJEK6a81KzgnRdp6qqikQiwV133cWePXtYv349Dz74IBMTE9i2TVVVldcT0J1RRqmurmb//v3ouo7jOJ5W4DgOgUAA0zT50Y9+RCgUoru7m3Q67QmB9vZ23vzmN9PU1MSiRYtYvny5x84TQniFTg97Nqc0gBOG4zh0dXXx+OOP88tf/sotAuMzCfpM7GzObSWuQDToBzvP0MgoUkgCpg+fCobfJK+qjGVTBEyF0xpChH21PNXZS1O0itTECCMFyUAyi6b5iPkkspBjTm2cUNDH/pFR7kylWdfeSLPjZzALUmiYusrylhrMbJrdXQNkZB9RYshSzJ8y298j/1AKGTBZfPRwlAcNK491dA/a8YYIf4HrBKwRQnQB/4w7+G8RQnwY6ADeUdz8Dtzw4F7cEOEHj+ccstSGxZMDJQWmGOJ6icdBybG2detWfv3rXzN37lyWL1/O888/79Xfq66uZmhoyOsJkEgkqK2tJZlMoqqqVxu/vt51h8TjcZYvX87//u//4vP5UFWViYkJ8vk8hmGwevVqlixZgt/vR9d1j/p7CieGI9VPTCWT7Nyxnc1bHuXhzZt57rln6e/vJ5VKIQRohoHP7wdVoCgCC4nP1KmpqyZqqBzsHyaRzhAtFhgZSaZJKQrt7TNYUF+LnU6yckYb9ZEwHfk03eOjjOXzdPf00z0aYXl7M6gWS3wxXlMTRXUKfPnnv6d1VjP5XB4biaoZXLhqBRcuns8nvvNH0rKLuFjoJRXhsQErzYJJZ+AkFXjye/ngOHH94HijA1ccYdXrptlWAv/fCVyDB+H9tzz+9/LNgo2NjXR3d9PR0cGHPvQhfD6fVxtvfHychoYGnn76aQzDQNM0hoaGqK6uJp/P4zhuX7mRkRH8fr8XGXj3u9+N4zjkcjm2b99OJpPxHI+maR7mwT+l6r9wONLhYMd+nnxiGxsf2MRjW7ewb+8+stks+Xwey3J7AoKCzzTIFCzydgGfoWLqOoFACEPVCBsO1U211IVDDI2lKEgYL1iM9mWYUFWWBoO01NSSTuiMFBJURaKk4uOEEmkCfp3B3BB6TZCnD/WhUI2JTZul4nfyaLZNd+8Is9vqsew8VsGht3uAVc1VhEMGueQIcpqeGaWiIqUmIuWjQYKXWTiZI1AaNQpIp9iyrMQpcI4qFE4axqCbIjn57c+BmpoaLzX3ySefJJ/Pe7P64OAgTU1NbNiwwWsdNjAwwOrVq73Ys2majI6O0trayvvf/37WrVvHvHnz+NSnPsWmTZt44okniMViR6XnnlL1TwxjY2Ns376dhx7axKaHHuLpp55lZHQIq1DAsqxii/rJZh4aQZdyq0qGRscYrwtRGwoCkkw2jxUKIoqc/7ARoDlexVguy86+YRQdYoZO1LLwC5ABg0xvFqkJwiEfNZEIQ2NZdBX6hvqZMXc+XYlxstkUyYIO0qExHuRtZ69l86EuhJT4NMGe3XupztcjFJfGXJ4M5F53ZZSglE/g8oaPHhYUU76VJtaXyzH4ikdtba03CJ944gnuuusuli1bBri9Cuvq6kgmk14r7J6eHqLRKIFAgKqqKq677jpmzJjBvHnz+Nu//VsAfve73/FP//RP9PT0MGvWLBYtWnQqfv8iYFkWnZ2dPProo2zYsIHNmzezf/9+LMvCsi0cu8xhJkBDwxB1BJUW4mIhAXUWPfY9JJytjI2l6RvNUBuJIR2bRCLBQUWhrq3JdRRqGgKHgnTQFI1IIEjA76NKN9BVFdNnkkxOULDySKeAIi3qQn7m1FSTy+c5ffYsnnv2OQ72DVMTCrOopYFFqTqWN8fYuGsvQdNHyNBpiofJS0kmlycsfJOEoJf0yR2/WfCqFgJ1dXUIIfjABz7Abbfdxg033MDPfvYzAoEA/f39zJ071/Pwn3XWWbS1tbF+/Xr++Mc/MmPGDK8AiKIoXtvxUgpuLBbjve99L+vWrTs1258gxsfH2blzBxs2PMCG+zfwzDPPMDI6gm3bOI4zxYRS0fATEI1ElLlE1IWElRmYNGA6IaRTICkOknCeJJdN0TkwwsLWBrdngAb9Y0l2D4wRndFCEBVVOECBgg0hX4iQ6v62GAamMKiORamOhFCtHBmrl7jp43VLFuMPmkSVLI1Rg1xaoyZg0hQL0BkLI1TIZC1i4QgNkQBNQYO8yJHNSXQlVFT9nammfQVKfsGK77Jy86MN+Je7NfkrFqWe9m984xtRFIUf/vCH/OlPfyIejzM8PMzll1/OP/zDPzBv3jz+53/+x2vgeaSqOqqqctFFF7Fq1Socx6GxsfFVk6n3YmBZFr29vTz62GNsuH8DmzdvYffu3WSzaa93QTkUDEwRJ6TMJqbMJyIWEqIJkxgSP9IppaG4xJy4WEqS50g4OxmZGGcklaQ2FMVxHArZLA9vf47u0WHOmr+E+mCQ7tEc/YlxhKYT9AeJhuLoehA0B7+uI1RoqK0lFj3EyNg4NX6doBQYjkVLlUnciLO8tYFMNkd1PEihYIOU6Fae7FiBlqaZPNg9gnB0fGptMRvweDE1gDg1A/HE8aoWAqU4fGdnJ1dffTWPP/44Y2Nj/OxnP2PmzJm0traycuVKb6BPVxi0HKXaeeU5+qe0gOmRTKbYvXs3mzZtYsP99/HEE4/TPzBAoWAdtq0CaEQIiAYi6hwi6jJCYj4mNRjSRMiS80sCVlmavgAcwsxkhvpuFHk3Y9ZGxjMZHKIoKIRNgVHw0b37ID/atQ/Tb2AYBrV1NQgkftMk4jcRioJQwKepZHMW1fEoS2a0sW3vAQrWBIWsSijoY0ZVCF9tnBnVQTbu7mRmqxsZUBSLuqBJWzxGXU2IZx8fQeDDpAYH27tamDLjS+FFDVw3nzJ5r2U+tEpewWFuRA5TLcrwqhYCVVVVvOUtb2HJkiWsXr2aLVu2HNZboFSddiqONLhfrYP+SGG7EhzHYXh4mCeeeIL77ruPjRs38fzzz5NMjk97PEXo+KghqLRRpSwipCwgwCwMGUV1VNyAmlOMKru59JXvfsmJpqAQImAvJiQOknDcHA8BKBpUB8LUNDahS4GTK6ADwqfTO5ZiKJkm7vfhMwHFRlE1NGAsmaExGmFmYyOahL7xYRQVon4/Sr6A32dgayqjqTxrY3E6BoeI+6LEdB+nNVQzmCnwbMcwPjETQ8S9CEYl5Xc60lAZC6D4tVzN97SCilewnDc4PV7VQqChoYGf/vSngPvy+v3+Y872p3B0lD+zUtefzZs3c++99/LII4/Q1dWFbduVOxVj4yp+AkozcbGQqFhISJmJn0ZUGSpS6G0kNrawUKRASLeTj0QeXl/CJduDVBAoqCKHkDYUG9k4SBwJhqYR9fuoDQQJ6z4sBZ7v7WZgbASfGSbq82Oohpv8o0LIb9AzmmB2fT1mwMeM5ibq40EUCVJXmRhPoCIYSObw+01MVTKRszitbSZ2cojG6jh/eG4vA4ksbfpidBnDIXt0Ok9F1GwaDRQxybM54nZHfpdf1UJg6qx9rO+nMAUlggvu4C8xKLdt28b999/Phg0b2LFjB2NjY5X7FR+rgomPGCGlmYiymKhYQlC0olOF4mhuF3ApgYJbPNej0AocIRHCrdEnygp1useXXtFNL4Iu3XCcqrgdiBzbwbJtsrk8lm0hHZt8PsdwJk1H3yCYBo2N1YQDYUSgCmkaYCeJmAY7O7tJOA4NtkALBgnpEiktRDCAYujYmQme2TPA3PZGbPIk8wVmhOMEgxqjsSC/3/YcKj6qWVZsOKJyxHZhU3hD5c++wv8/3Rifbr9p8KoWAqfwwlBy1jmOg2M77Nu/l00PP8zGDQ/w6JYtdHR0YDlTX2rXolVFkABNhJV2osp8wup8AjSiORFUqYC0ixayg8RGKhJ34LvLKktqKBXHn3zrS/uoxX1cq9uiyBxUBLYtyVg2GdMiVyhgOxYZYbF3sI++iSRtLU3UxWL4TAMRjiDjAZShNEHdID02xqM7dnH2osVUBSIIQ8PRHVRDx0mMM5TIMpzL8drmesaSo2RyDmGjQE1YZ1siwfMdvQTVJYTFDJBW0fNf4v6VUYWZpAGVW/aV9KFiTyLpagNe9eIpT+poOCUETuGYKB/0tm0zMjzMM888y6aHHuTBjRt59tntJMYSZXsI3FdLoKBiiggBpYWoMpeYmE+IdkxRhYKJdLTii2pjiylmgjeTlx936qey6xSl9FtAWEAOKQ0UUfQfyJxbXkzXkBLylk0mnydvFSjYbgmx/QOD9I8niUxEGBoaodEwcfJZVCWCVA1MM0hrvIanntnB/o4e1p91FouXzMQwgzjZFIPDGe59bjdnn74KTTiMJN3ORpaZRWup5bEnn6WQV2kxVqIRRQqLSefddBUFYOrQP3yr4x/w0+GUEDiFaSGlxLZtL4V63759PPLII2zcuJHHHtvKwYMHpuzhqt8KCqrwY4o4YTGbqLqYsDoTH80YThxVFr3bjlJUgIvd91605eW6CCUSIU0UCpRq8Uopir4Dt12YabhsPkc6ZPN5MgWLrOXQn0hyYGiUgWQaUCHv0BIJ0pAYxtQAIVFNk7b6OgxDY29XH3/83e945PEZtMxowbJSdHceZPWSRSyY0UA6NUzvaBKhQnVbHUnD4KGn96ASpIaVCKkiReHF3viLxikhcArApE1fKBSKdQ6GeOaZZ3nwwQfZtGkT27dvJ5VKTe4gXNtcIFCEhi4jBEUDMWUuYWUxQWUmPlmF6gTBKtbOR+LgFO35QtF39xJUjS46AV0xZIOwcKSNgo4QEiFVbKkjpN+tYu/YCKGDgLx0SObzjGUzDKfSFCxJOptjb38fQghm19fQOpHA1By0kAkGWNhEYiHOrl3OWYbOSCrHwMQ4AVHgzPPOoqmhCpnOkksKusfGaYtX4Q8KHt3fyTMHOgiLJQRpAZF7Ubd8rHl/siLR0SXsKSHwKoCk5DkW5RR1HMfxZvp0Os3BgwfZunUrDzzwAE8++QQdHYe85CcXAoGKQEUjgJ8GwmIGYW0eITGHgGhAxY9m+xCW4vaTxEEq9mT2m3RQZbFwhJBMBvVPUBWQ3n/KwmKStOghIZ8hwwgCnaDSSJSZ6LIagY5lWW6IMOhDCknetknl8wynU4xnU5imRsDnJ+/YjOVzdIwmaBiOkMznCWcCREwVISXJdJZglUlLdTXty2YgAiYkRsDJQD6NbcFoJoOGxty2ekbGJvjB/VtIpyTN+mo0wjgyVxnanP4mX3acEgKvKsjioM97rct2bH+Ohx/ezJZHHmHnjucZG0+UhfkEQqgoaAhMTKIElFbCyixiYh4B0YIh61GF7vWRREiksJGiFMMH3O4RgEAKpYy68sIZ85ORb/cYEhhjF/sLP2bc2YmFW+VJK4QIKW1UaWtI0lV0Tqqoxey7gmOTzudQhE3OdoiHw/j8AdLZPJlcns7BYerDIXbuP0QhneT1a5YTNHz0jowwng1Qlc4RHB8B20RICxQFJa+QsTIcSI7RWBVGOBY/e/RJbt38FD6lnmqxsshwKNUQkIffHBxFOLicgsnYDBUJSO6ulUc9RRt+FcNxHPL5fLGz8BgdHYd48qmn2LLlEZ588kkOdRwiny9XSxUUoaNJE01E8YkaQkorYXUuIWbiV+rQ7aj7kjml4ewgD3PqHZUKf1xrjgpRbNwlNVQKjIk97LG+y5jc5eZzCJdQZMsUCWcnY/k9CCGI+k10VUdIgRAuZz+bzyEdB9P00xQysBybVDpLOpkmrCsEFIfaqhApYaNKQSgeRwz0kkonyRfiBNJpBAWE7uaSWHmL0WSK0Yk8K+qi3LdjP9/4/aPks4KZ+nn4mQG47cgOfw5lvQUr1k3nNHxpNIVTQuAVjCOx9Eplz5LJJIODg+zatYvHH///2fvvWMu2PL8P+6yw8wk3h8ov9us009PsCSaHI3o4EoekxWDR0hCGKdmCZcI0bMMCDNP2H4YBGTKcAMIAbRIUSBkSJYukScoSh0OOOdOa6TQ9/V6/fjm/ehVvviftuNbyH2ufdOtWeFWve6pHswqn7jn77LPD2mv91i98f9/fd/nOd77N66+/xdHRIdZOJ61AopGE3qHHOqm8SFc+Q1c+R8ZVAtZQLkE5izOm9cIbfAju9w5Q5YRBOkUlBnxk/kNO7dtoHZDEMWEYYa1X/Zu6oTFuVs9BSo8C1VKAFdTGIZVgpZPSjRMwDSaJ2Lh0gQv9Llc3+sTO4Qwka+uIUNPp9TidDJlUE3plTBgKnDFYAafjIfunY7SAu+OC/8M//OfcOTpmXX2Fi+KXkI/tx39QZyybFZ/mDA8VAvcpPPJ/Av5VoALeB/77zrmTlpb8TeDt9uffcs795Ue+mj9oj9WccxRFwWAw4Pj4mJs3b/Lqq6/y3e9+l+9973t8/PHHS4SnAo0iQcqYyGUkYodMPkNXXCMT14jELlIkaDtVtQWWGq/Oe8iqcOqzrgHzKZvDuZpC7XHD/FP2mu8T6Yj+So8wCgGBMTVhGPjV2dSUpSEMA0xjfKhQa4S1NNZSNpbaOKIwIpERsqm50lvhQrdDLw7RQiN0Ar0VhLL0V1Y4mYwY1zWTskQGCisENZbj8YTjsmYsLX/z67/Dax/cpiOvclX9GyRuCyMaljEOv7ftUTSBv829hUf+GfBXnXONEOL/CPxVfM0BgPedc1/5LC/yv85tvtrDDDrSrvaj0Yjj4xMODw949913+d73vsd3v/s7vPnmWxwcHCw49QSSACkiNF1CsepXe/E8HXGFVOwSs4FyYRtPFwi7qJQ6EAYrFMu8jz+yXpibyS0QppETDtw3uFv/VxzZV5GyYWV1gzDxk7yu67bvfKq3DmJ0AFkcURuDkIJAKDSKUVlR1DV52VAWBq0gEQJlwVQ11moIHE5LrPbVhDpZh0BHDMqatKhxugYBw6pgWDbkwvGrv/sO/+jrPyAUq1xR/x3W3VfaSgOL+Ac3u8PzEoju3yOL+z38F09Ulfi8wiPOuV9b+Pgt4C889Cr+oD1Rc84yHhecHB9zcHjAjRs3eO3113nl5Zd59dVXuf7xx4zbakfQwnREghYpIX1isUMqLtMRV+mIK8Rik4AuAg1W+Hp5wrYFssXMae/ENINNIlos37RS9I/w5pkz7gqkCzjmZT6o/1/k7KF1SJp0iDOJMcZPfudmbDwOME2Nc5ZSwDivAIeUDi01VILKWk5Ox7iRJQb6kWbFRfSkxlqLkI6mzqGIIAxJooQ4jBmamqOyxCgvnHPjNaZBVfL1777OuGi4EvwS2/IXwLrWdzLnzTx3Ms9Q0FO7/7w8gLmAP3+fR2+fhU/gf4CvSThtzwghXgYGwP/WOfdfnfejs3UH/qDd26qq4vT0lL29Pe7eucNbb7/L66+/zg9efYV33n2Xvb39NgPNN0mAIiUUHWKxRiIukYmrZPIqibhEQB9N6BNv3HTg+DCdH0J+krUHA/AsuG7q328Dzz9SO8ABah4JEJZcHnG7+TpNcEw/7RFFISv9Lnk+wjYW01ictcxJh6aFPXxx0lFZYawjUKAkGGPJJyXWOUQApdTkeYkSB2AhiEK0kqhQQ9PgLEjnCLTCmophlSO0I0QiFASB5ObRgLsnQzJ5mSvyT6NdhBPmgV76T9cnn117IiEghPjf4Csq/kftptvAFefcoRDiDwH/UAjxRefcPfmiZ+sOPMl1/Di285x61lqGwyH7+/vcuXOHDz/8kDfffJPXX3+dN994k+s3blIWi6u9IpApig6BWCVlh0xcJhNXSMUFEjbQdBEErXo/zUOfOwVZWC0FkiiGKFHoUOGcpSod1cRiKtpy2D9iGYC/PnAYYci5wZ77BkfuFdZWV0jTmJVeFy0lZZETaoV0hsb5gh7WuqW+NtYxKWvKxhJISyMMjWnIq5qyanCiIQpCojBAnuaEYkhIhLSwth1CU9G4quUzbAikQ0gPhQoCTaAFQ1vzwZ1jqrrhkv5ZMnuZRpSfyfR/aE/dJ9r4oPbYQkAI8W/hHYZ/vGUYxjlXAmX7/neFEO8DLwLffdzz/H5vRVFweHjIzZs3uX79Ou+88w5vv/32rETa0dHR0v6SiICEUK4Qy01SdknkFRJxlYwtQlaRLmkz6wSIplVBpza8ONeTLCV0ViLWtiLSrkIFylderhrGpzUnBxXjU0Oraf8IBYE3T4zIOeBV7ppf49h8n0aMqKsN+jt9vvj5l3j9B68S6xDrwDaFL8HuQAhPRyZahKN1MKlq8qoiEiCdRQhHGCiKccGN0SlWKdbSLsoIRkmHg2GFRiCVI12pqYVg0lQ46eiHMSoICLUmC31qcz4xvPPJHUCyKr8AdloO/rNb68490hw88anaYwkBIcQvA/9L4F9yzk0Wtm8CR845I4R4Fl+Z+IPHOcfvh3beam+MYTgccOvWba5fv87777/PW2+9xdtvv80777zD7du3qapq4SgCLTJC0SUSq6TiMhkXSeUFEi4TsYYSKdKF3g7GzWx3J9q6d07gRIvRd4rl8pdexe+tR2xfzkg6CqRtzQyBjiVpNyXrh+xdLzg+yFufwA9ZCkzTlNtY/pH7Lh+b/4yBfZcwCtnub7HS7/Pn/9U/wa0bd6mKAmd9uXjTNF4DOMNH6FrhV1QNk6Kmo3xl4lhrNlKNFCmHDLhVTji1FWpygjhyhEKCzWhswY7rImLNoBqTphHdJGXK9xMGgklTsz/O+fj2HgErpOIZjGgWzC3JnEf43Nte+vb+Dr15xuT033LntdvE/c40b48SIjyv8MhfBSLgn7UDfBoK/AXgfy+EqPF3/Jedc0fnHvi/Rq0oCvb397l+/WM++OAD3n77Hd56+23ef+89rl+/zsnxMXYBpaeI0aJHJFdJxCYpl0nFJVKxTSy2CFhButa2x3mnHlNiPb8czAbdlIJmaZlYnBiWtBeyeSkj6Qof/18YM876bWlXceHZjMY0DA590suPgm9BIBmLD/i4+UeM+JArVy/x+ZdeYnd7i2tXLnPpwg7f+M1vUlc1jfVJQVIKjLGe6MN5I8hai5SAE9SNYVw2NIkhRBHrAKstvU7KtXSNi/WEPVdzPB7zxuk+B8MBX9rcpaz7VIElXQ2RqmKj2yELNAaBFmBdTW0dH5yMOB0XpPIaoVsHjPetCIs4U1LsweDANinqvDKfC4/SLX5e+PpR9Y5HiQ6cV3jkb91n378P/P1HPPfv2+ZX+yGffPIJ73/wAe++8w5vvfUW77//Hh9//DF37+yRFwVzUK1qVfwNH7MXF0jERVJxiYQtQnpIUhAKaRdUeeEH0yKybM40P9u0tH2BgA/nPOPuxnZM0pGzIyw3v+o7B2ECu1e6TEbHNOUP1yRw7XU7Ku7a32Tg3ucnfuLz/Il/5Y9z5fIFpBNc2Nnlt7/9LW7cvEFjTPubNpohWmegbSeSm+fkN8YwLiuMTRBKEuiAJi+YNDWXwg5Xuivsx4LrkzEf37pNfTpi7/CYTClEB1Y7hhXpJ75wDiUFSimqImdUWb73wW1GeUFHyjZLMEA4g3CyJUdZrCD0GbUnsDb+ADH4GO08Nb+qKvb29mbq/Ztvvsl77Up/69YtTk5PMM0cWiuJCWWfWGySiotkXCaVF0jZJXIraDJv29O684QF19r2j2n7nXcfaS+is6KQchoZuP+BnbNkK5KVzZSDG+PP5iLudy58YvJE3GTffpeNzR7/2p/5k3zhcy9xdHxIFIQUowmv/uAHTIocLRW1abDO4hweG6AkhoppZHO6alrrmBQ1pg11BtqbSIO65MCM2dExn49TrnZT/tBuSrQlEFpTqJpeFhApyJuSpsXvq7bKcNE4bucN79zYpyprxvI6N8Svsi1/hkhsIa1sL2VaTvx+BsG0vxf2EWf2nppLtH/d2V8/evsDIfCYzTnHcDjk448/5q233uKNN97g7bff5qOPPuLmzZvs7+/71X4mMBSBWCEWGyRit43ZXyQVWwRik9CttOG7AGbJIQYr2snppOen/3QV4B9wA36i9FYjguhRgT+evWZ1K+H4do617odmEkjnSUJHfEjhDvhjP/2zfOmlz2OqmuHglM7OBd7/4H1u37yFktITnljP3Z+mKVqFFFVJ1dSz8OD0vo21jMuKxoBxjkAKokCRFw23qhG9geLzCC4mKWGnT5ikVEpybE5IuxKjK44nBYWtiYlQzpDXDSeV41YJL7z4eY6GBe+8/x4fN/8ZI/kmO/qXWZc/CdaHOWdu/E/Vfa1W8zSFCH8/tkVH0llMvjWWO3fv8PZbb/GD117jjdff4L333+P27dvcvXuXwWBA08wps6WICMUqidyhIy6Tiauk4gKR2CB0fQIyBNoj9PxZsAvhu6mxIFyrzs/MgCe/T+scUaxJOgopz+axGYRQODdlwF0Ar1hIOpIoVeRD8xlcz3RQT7WQ6V17BN3QXieM4Stf+iJxkLB3MqSuLcPRiLffe5diMpmtirotArO7s4OpDXf397xZIKXvPzflMHKMipJRVbFiA7SSdGJNXtVMasMn1YRkJCmqyjv+bE0VGHTfIYMQhH9eZVkwkQFKKEpjOKwdhc74qS9/matXrvEbv/V1vvGt73DXfIOcY6TWrIqfaKE+0yjNshuQpb9n3X/nrfTzX872aJ2CXtGxDxUbfyAEHtCcc4zHY95//wN+8Nr3+cEPXueN19/kxo3r7O3tcXx8TJ7PbXuBJhQrxGKtjddfoyMuk7BNyApKdBDEyCmRxoJX6DwNf2rdz6xH8RnZAYBDEKWCIOYcAKDkeL+gyA3rGylhLJb20coRZpLJqUGos7/9tBcyV43FLPQocUJQy2OG1Ud0uhH93gq1sYzLAq0DJuOcG7du4azXmsIgAAsb6xtsb2xy584drLUEsk1ycg7rLDiwTpCXDYO8oG5SAFayiNpYqnLCUZHzfgk5lm3piHVI2A1IuxFI7/MJw4iyrBGiQitBXgsOmgBURBpGZNsdfuUv/Gtsb23x29/8NnfvvsFH/H1itUXCLu4cQpF7JuqZsOJyHKAVIrMIgN9jmu0xP4abax33aX8gBM40Ywy3bt3izTff5OWXX+YHP3iNd995l4OjfY6OjhkNRxjbzJ6NImyx+Luk8hk6PEvHXSRmjUB0kcQIAvxAnK52dsn8ns+v++DJxD1vnrB5NT5JFSpwC+FDgRSS4bHh9oc5VekwpeXic93lSxGOOAmA+okvaT6kW5JMYcjFXUZ8zKl5jYF9k0tZB600+WRCkecIIZiMRjRlBUIQRhFxECKl5MLODlmaIoVAK0UQBNi68Y7DBQ3cOkttDLW11Kahn6WEfYmoDXfrIbeKgnGTU8iaKxtrdLopUnpSlDiQWKcZlw2mqNBaMgn69C8/w82PPsLWliTJ2N7Z4Jd+4Y/wE1/8In/9b/0H7N35PjfFf8Ez6r+LtLrlF3w0U+xe3eCza38gBICTk5NZAs73vvc9Xn/9dfb39zk+PmY4HFIUBXNVVRDSIZIX6YiLdMVVMvEcsdgmpIt2CVIEbSgInHBYvGf4M/YHP1HzOfcaYXV7pdYjAq3g+G5ONbE4KxicluyYDKkVYgGvHgRqsUue4EI8dsGhmMg9juz3ODLfYeQ+pHIn1IyJolUCJcknY8bjCd1eBtbRyTLCIKDX7bWrc0i/2yWK49YxqIAaIbxZIwQ424bchMAJQVk3TOoKKVN2eh36KmIzTjkaF4yqmlNdUOoKqQzSQSglURIxntSUxuKEpZAB2YVrrFx6gevHh9y8sUcYRExOT+hFMdsvPs+//uf/PP/P/+Bvc6f6TVbVl1njp71QEudTjbulOD+cHTdTs/VBiv6jOgz/aykE6rrm5s2bfP/73+db3/oWr7zyCh9++CGDwYDBYMBkMjnDrpMS0fHOPPkMPfksibhE7NYJXIpo8fiziT+rJOPteTmbPItW3Y8ce3umOQ72csbjkl4/pNuPiLqSurSMTlu/hrBYK+8dQY7W2ebv8ckEm/d35OIWn5h/zL79BqU9xFKSZimXt67xpS9+AQHUlYfrGmPRYUi31yOLEy5sb3M6HKK0Zntzm9FkTGMMCGiaGiF0KwAWbqEtLz/Kc8ZVRGFAi4DNNGJNJ9h1bw40zrGRaF+YVAu0lhjnmJTVzLYXnU16F65Rm5qtzQ3G45qjw30wXdK0ixPwCz/3NW7dvsnf+4e/ym3zG/TkF1Aufoyeu9dEeNIh9ftOCJwXvgO/2r/19tt8+1vf5nd+5zu8+fqb7B3sMRgMyPOcul5kfRVoOiRinY58gZ58gY64RCJ20a6PFCHShUgn5g4Z4VpOPdF68W0rDOQc1PNZefafuPm+aUrHsDKMT8cchGPijkJLTV3N6au1Vgg1d1NOfz535j1ma0FMQlgambNnf5M985sU7oid7U2+8hNf4g//7M+y0utxdOLBVEVZYo3x1GBKsbqyymBtlQtb21gH/X6PThpzOjihaRpqY33pMB1immYB2OAw1jKcFKSBZDTJGOY1dexYCQMCHRBqhdIaKQO6SUAUWawoqJ3lMC+oaoEKAiyCdG0TFUTk4xFaKH7yS1/kO9/+JodHB5jGMBpLLl7J+HN/8k/w3e+9wu1PfsBIfkRffBFPzjLt7/nq7mYjy4saYGkP/51d2Gu+zS59ZunY57Xfd0Jg2uq64sYnN/ney6/wrW9+g9/93u/y4QcfMBgOmUwmVGXlJ23bN0Fb1z4Vl+iqq2S8RCIvEbNK6EIgAqt91Rs3VezbqXLGthdnyTOfmsk/bzMHkgNroCygLAxCtCjDduWMEk+Z1eYaz37fTFP0HvfehG19WpKhe5c9823inuFP/sKf5o/9ws/zuWefpdfpsLe3x+nxEUVZEeqAsiwIg5Ao6dDr9VhfW6Xf73Kaj1npduh3O3x8o/GgoMYQBGGb6zAFTM2nVV4bBpOKk1HBsJMzziq2opRQS+JAkyQpcZySZBFal1grORwPOS0rjFBI582iOOswGgwYVyXGGJ5/9hlsU/Brv/arBNLzB9y+FfH5l57jz/2ZP81f+7//HU7sq/Tl51v/3uIknTr7lj/f6zRcdPhN959HBdyZ3z2odvHvKyEwHA55++23+da3vsVv//Y3+P73X2V/f488n1CW5TzXHD8oArqkwlNp9eQLdMVzxGygSVE2BTObDzjOcYOLxbXwXt/+vevk77UJsNzmylIr1KZlwFt4qxWOTi9AyDNwNCeoi/nq9GnvarqaCSGpGXFgv8OEj/ilP/zz/IU/+2fYXltlc2UNrTXjJCWKYqy1TIocY/3ql6QJvdUVhsM+q/0eZVXR7XYJgoCmqtpIgCXQgQcNnrlKh6O2lrxuOM1zjic5+8Mxm2HGaqdHoiWR0sRJQhCHNLaktjBqLJPGUAEdoUjihKOjI6KuZw1cW1mh00n50ktf4M6NG7z1zg+QKqAsx5RlyU9/9Suk3b/L8ej7XFS/jKTHHM30oB5biAqcbU84rH5shMB5an7TNNy9e5eXX36Z3/qt3+Kb3/wm7733HoPBgKqqWnYZZlJVERDKDTriGVbFi3Tk8yTiAoFd9aw7TmLbohhOebXTGEfjJFKamc3/+7WJBXXZWkeUQm8tWpj/8ylfTR42cB/UvC/BITnmDY7s97hweY2f+eqXubi5RhZFaOF9N3EU0e/2uHuwB3iAU2MMnW6Xna1tiuEpF7Y20ErRWEEQhNRTWnEgigLyvGqjGgKs9Sulcxhnqa1lVNYcjQu6Qc5hWrKZORLpk65EW70oL0tGVcneuGBSGYQzrK6sgFZUeUljBxwOT7nwzDVsWdLr9fjZn/lZDvdusX90QJWPOTo8YufKNb76kz/Jt37rLQp3QEZ/aY0+f91vTaf2u/tF/M5GEO79//z2YyMEpq0oCt555x2+8Y1v8Bu/8Ru8/PLL3Llzh7IsW6fR4uAUBHToiB266nN0+QKZukriNgltF5zAOV81x9kGKy2dDcnaRkaSaaQSVGXN8KT2HvPCIaV42hb0z745BTRsX+oSxovDp/UlNIYyb54oOCAQFNxh3/42hbrDV7/6i7zwzPP0ux0wDaWpECrEGIOUkqoskUGABcqyREnJxsoqg94KW6trVI3BWM+BULfjIIkj4jhiPM4BhxS+FsJUNRYOsIKqceR1w6Cs2BuP2e6mREGMsxZdjSgqR95MOKpy9kYTmsJwsd+nF8Wc1DVSQq/TYZiPCYXE5Dkmiti5cImLO5cYDAeMRyNGoxGhkvzxP/rf4Bu/9QpD9zGZeG7e7c7NBYBYFAYPtumftD31QsBay8HhAa+88gq//uu/wTe/8Vu89dZbM3SenaaLtiNSoQnFOl15lb58ga74AhlXCEQP6WKk8WWwfLReAIbGVURpwMVrG6xseBy9E55rL+oE9FYj1rZ73Hj/gOGRQy55xn+fNSewzrK6G7O2FbPENoQvXjIeOqqiRRU++oHb/336jKPhyL3CkXmF5168xNd+4iv0u10a4zCNr/Lb72foMCDQirKqiKUE58iLgqaxbK9vMtq/iwB6acaksRwf7uNMRd0Yur0uYRiDPcZJT5lmp8lFeG4B67xQqxrDqCq5fXrKWhqhhKFrIibGYmxF7hqun5zgrONCv8tWJyGQkiIvuHuyx6goqOuacjhCaYkQEHa7PPe5l/jwkw8YHA8oygpT11y7ehkVGvLmBk7Pe8WdBfa0w8xTQwjmUad5BGruFDz7ef56GMz4qRMCUxLN9959j2/89m/z//vNX+e7v/M9Prn+CXVTL9n1vrWefC7QU8/RVy/SkS+QcBntUpRdzrRzM0+rH9zWSrprkmsvrBOlYGmwyLkTzIETlqjT8MxLK1x/Z8jJYY0UAAt8cT/2zcfrjTWsbgVcfGYFEdQLzkCPbhKi4uRu5aHOn0opmpsaAsWYG+zZb6KyCT/ztf8mL1y7RhiGNBZOB2MirTyZZxiiA01Z+dU/0Jq6aRBSkmUZ62urRFHEWhASFAV7twqa2qv/a/1VTodDmDEiSTw/QTs5rJ9KxlrysiYPK+42DoUmrwwraUwSC3TgGFUFWgZcXO2xEmniUKK1oKhKrt86ZGVlhVBK1je3iYLQm1ZKsbGz7SsbtxRuQgh2t7dZ21ghv32Ao1noI3dvh4qzvn030xLsuRP+zDN9BC3iqREC+/v7vPLKK/yLf/Ev+PrXv84bb7zBYDCYr/QLTREQih6JukJPfIEV+SKZuETIOtp2kI3EiQYj6la6tmWvYKGTBRhLdy3m2c+vEIb1LMR3Vsn1Z7foyHLpuR5VfcL41Ne6//3UnK1Z24659HwfHS6bVQBOWsqJY3hQAPKMY/TRmnABhooj97uc2Nf56hc/x8989aus9FfpdDpo4fkEpfRsPFmckCUpAphMJnR7Xcqy9PUETE3S6aBDTexgeDKgqWuclHSSlOcuXeaND98nSiNPCy4EsgUMCH/DOOcTj2pjKRpD6Qz50T6ndcFaJ2azG7PRTVjrdliNQrpJQCgFQaBxrkELy8nJIUVVsLW2QlWMObm7z9q1y6Ak/Y0NOp0e4cEhOF8PYmV1hY21dT68fYCh8NWZz3gGphGDmYaw0Ow9k/3J2uPWHfjfAf9DYL/d7X/tnPsv2+/+KvBv45fJ/6lz7p8+7BwffPABP/MzP8P169fnHmpYwEUIFAmR2KKnnqUvv0BHvEQqdohIkDZoQ6k+Sup53Zln5C2QbUybs4K4o7n2uQwdmlZFDbhXak41Ak/HHSSW3WdSPnx9BI2Ccyrv/Dg2a6GzGnDh2QwdOmahkYUmgbvXLU1t2go/n7I5/9+Y6xy677C6FfNzX/tprl68hBICa6BoCtI0Iks7KKWo64YwitFBwOHePmmaUhYFRZEzySeoMGRc5uz0VloqMYO1sLGySrfbIYtjIh2Ac14I4KeWRKCEf3l/oQHrkNqCbmhkgNMxcZqwvtJnPY4IlUFKS6i9iVLUJbFWdAPHjf0D4kBx4eIuQewntbOGuNPj0qUr3Lp9A5zDNpZ+t8fO1gbvvv4xthUC54YIHW2hlwV0gGv/iuWROp0yU4ExQxQ+Qgj3cesOAPzfnHP/58UNQogvAL8CfBG4APxzIcSLzrkHzpTj42OOj48XDuT/C1ghk9foy+foqRfIeJaINTQRWNVCQb1kdzPAhZmF9YQ7y48/7SCQgeDK53rEsZgRTkw77N5g31T98h+yfsDGTsTeJ+X0Us/93Y9Fc95GV4Fg60qXIBZesLl5/UCB16iH+4bDu+MFlfpR73i6r8CKnFP3KkPxPn/4pS/xh770BbptxSBjoawq0jggiiKUlJRNgzUNcRgxHA5Z39igbissOSwqjHBYToan2ACkligV8KUvvYgTjn6ng7QOJX29AKV8BCjQiigMCcMALT09mBKOfpLQi0M2ex02V/rsrnTppQFSGLR0aClQPvkAYyAWkt1+ynt7I46OBhRVTdBLEVrjcCgdcvHSFcJXfwdrG5/TEIRsba0C782KusxG2UK3Lk7gJWTgvY/wTG8vRwSe2CdwXt2BB7Q/C/wnLeHoh0KI94CfAb75KD+WIiZkjY56jr58ib54gZhLhHQ9LNd5aqZpmWvHVBD4Qev102na6JnYtr+bmSTdvZqQ9iW2Rf1NtYXz4/6LwkEipGNtJ+TkcEI1aTn7nkJA0KM1bxv3NyKybkvtfSYgIIBqJLn+3hHOTkO1j3583yygqNwxp/YHrG/FfO0nv8Lu5iahVmgpmUzGhIEmiRICrdoEII1SCqkVw3zCYDAkCAKEkozzEikremnE6ekJg9MRwik6nQ4rvR7D4ZCd7W3efveDtnSBREhJIGR7noAk8kIgkAqlFN04Y7ff5cJKh/VuymoSkWqFFJZQSEJ8MROEpbINQhqeXevwT8cfoTa2WO31CcIAncTINoMx6/aIdcCoqtE6xBnQUuEwWAz32O1uave3qv+9vsKZM3DOPTHFDy70uhALR77/+HwSn8D/RAjxl/BMwv+uc+4YuIgvRjJtN9pt97TFugOCgJ3gl+moF+lymZgdtEsRrp3conWBCME8Dcc7+LwMnTp8Fk9w7027VjB0VkLWt1Om+eXT5fz+43rhu1ZSh7FidSPj7vUJ85p8P4a6gBNIDf21BDUbDW3sRDgQmnJief/NA8rctbRdn/Yc4NODa4buA4Z8wBcvXeDq5ctoGaCDgKapKcsxQdDz49pYTMsX6JOdfHrx8ckxO9s7jIYjPvzwI3Z2tsmikKTTRewd0Ot06XZS+v2MOAiprJmNBeecrzyEIg1D0jAkjhSBlARSE4YBWRSwksWs9TLWeh0SJZDOerZhQEmFEJKGBts0BEpyaX2FWBg2NjbZ3Nz2JKfCRwgQjqyTksQJ43HFaDRCCijyAjALfqhZRz140i4NxGk0YarJnt1vMch4fyHwuDGuvw48B3wFX2vg//JpD+Cc+xvOua85576WiAtck3+RLfuH6ZirBCYCa7ALueafVRNSsns5RQX2MY/rVQkpBStrMUE0BXL8eGoCzkmSTBNn8szktigk1djx/hvHTEY+1ffx8x8Ujcs5dm8SdHNeevFz7Gxtt8Jd0iCwHsVD1VRez1M+EqCVJgojpJQcnRyTxDEvPPc8g+GQvCiQUpF1uvTW10h7GTtbG2xtrPHMlUtsrK+TJik4i7UGKRyRVmRRSBqHpEFAGgZ0oogs0MRakGhBIAFrMI3HQ8RaE+kAqQTG+XoGWkCsNJ04Zncl49LOFnHWQQYBTvh0ZXCEYUgcJdRVBc76bMd+Dz81m6n7j2kOihPTDIDFkCDzfbD3bFmEDS9+Bw83Bx5LCDjn7jrnjPO81H8Tr/ID3AQuL+x6qd32wCaQSCvBGYywNAKs+Gxqtcyv2Tt/VrdishWJFfYhXXP/q/WhMkGYOrK+biGqP4ZaAH6AZF1NEPpP0yaEphhLPnjziHwgfUj0SUweASUHDO077G5v8vzVZ5D46j9CeDVdKUWgvToSRRHhdDJZi9aaMAzJy5IoitjcWMc6X1YcITk4PCbpdEm7XZ679gyrvRWeuXSRTpx4wpF28igpCANNGgXESpKEkizU9JKIThSSaIVWEmscTVWhgDgI0FL5CTpzuPl70kIQKEmv1SDqqkBHyazOgMMLzyAIwDriOKSqKpIk9d+Lpl1Apmr9fHGaTeh2gi8LhmVFf54gOd3HmwqPsjg9lhAQQuwufPzzwGvt+38M/IoQIhJCPIOvO/Cdhx3PIWjElFrr7GvZUl+QfSx2gpuqRovltc50ZhBpNncihHJLx3y85j3JvZUQJR0/jsAh50AqSDvBAkOQ7zPTCD5+75h84FDCIoVoFeJP12+zJ+FKJnxMFdzi4sVttrfWMcaglEYrjW0sSijiKAYhmIxzD/1tF4PJeExd+lRiJeQscHTUsjtVdUNvZY21tU3WeuskYcJar0ev0yFLsxkkWklJqCVJEJAE2q/wgSYNQ7I4aqHiYJFIqZBCYI2hakpq23i7W86ZlqyEvCyIo5jtjVWaYoTSAVIqhJQ4a3DOopVGSk2gfDXnqqoXemjhgTAf47NRPuMWmPtXZmu+OBMRWAwtntEj7tcet+7AHxNCfKU98kfA/6i9iNeFEP9v4A18ebK/8rDIQHubM6ebD9+0/OzCe/zFOXt6QbyYJXXu1c9+5Sz01wOijjcxhLv/rx61SamJO6CjgLqwP4YeAYcOBWHcsvo4hRANQggObo8Znxjm0+0J7k4IjMs5te+TrDiuXrlMmiRYY2mamrqqOT05oTYNGxvrCKUwwjIpJxwfHXFycsLJ4JS6rpBSEqUJtm4wtuHgaMzxyRCpQAuJlpqVTuwLpqQpnTgmiiOEEDgrkFITBbHPEow0oZZEWhNHkk4aEocBQjiapsJYiXGC2tjW7+x9E9J6oYiSaAHjuuZkOMKpiMloQldqHMqPMeMYnR5SVLnXBpTCWsNoMmzX/ZKpibmw9s8c29NQ4FzRX0YFLjsKYTorFl3Z57nIF9tnWneg3f/fA/69hx13sU0DJPNPsn0tOkzuPwgfLAgcOIHS0N/wWgDuszA1/DGCSBGnmiovfyTFOD7L5hzoIEAF4dyxKiRVKTjcm+CsbJ2DT3omS8FdTt3bbK32uXL5MlEQYq2H7hpraayhMYa6LStuTY1qTYGqrpgUOTjnE4r6faq64uBwH+cU+4cHRFGIvHSRMAhYX+shAwUSkjgkDBVK+AktpfI2ehgQRwFKCEKlCJUk0pI0Ckm0jxhYa9prlB5FigDrEEqghCRSklhKTvKCxlpUENJd32hLntFGVhwSD01WQUAQhmTdDr1uD0dDyeF84p8JCbr2GTlxdkV/mJ9sWSA8rD01OuySF9MtbXhE/915O7Yy0kHS1aSdaQmuz6Y5QClBkmoWrbIfn+ZQIQjpEK5GiBohLaNBSTkRnyYOeN/mayJaBlynDq5z8cIu2+ub+OQt75ep64qmrr3nHQiUIo4SjHFo7QVUXTUEYUSv16Pb6TCpK6qyYjIZ8+FHHzIpcoqqwgBx1qHT7xPEAVJBN43RSvmJZR1RoIkDSaI1kZZoKYiVJlGKRCoirTz+HzCNpakb/2o8W5FSEucsgRRoKciLgkArsiQlWV2BlsoMHFU+BivIJyVSa6IwRiD58he/gAoaBs07LVbAnrHt/e+X7H+xHAicqf/3mR+L359F3S62p0YIADO04PnS6yGS4J6v245rbaTuaoAOHuE4j9za61SOMAGpxMNIXZ+6JoRgMqy49dGYo9uWciixpWR0XCJMWy7rieWAoCbn1L1L1tc8f+0ZkiCcUYV5iL3CGIMxTbveerVbCG+Xm8YSBBH9/ioXdnZJk5Q7e3s44yfkJzdvYKyhKAt0GBElCTqMkEFMFER0swwdBEwV40BJ0jAgVl4LUFIgpfOhQq0I2wKjwoEzZlbTUCzAjp0zKCFRSnM6KkiThDRJabQ3J5ACnGFydISViklZEUYx3W4fpQNeeOY5rlzbZWDfoxan3gHK1H+yOJCmoqG9hgeuinPt4Z7tT7sQOO/C73FrzKTZks6weIRzj+xw6ADSnl5Y2O7VGJYEj3vwUZd2FBBE0gNIflzadGEBbC04uVtz/e0h7792wvV3hoyO/HA8Hzj1qU6BE5ZS3GXEm6ys9rm0u4OwU2HPQp0GQVVWNM180lVl5YWDNSglWV1Z4cLOLkIIXnvjDYqiZHN9g8YYqsqHFRtrCMIQpEIoDU4S6ogoDP3KbgzGWpIobMuY+9XVOouxPlynlCQNApIoIgxDtNZ+8uN8roExXlApjdQRB6dDut0OaZohwtDfjQNbldTjCY2DUZ6TpOnsXi/s7PLVr/wElTugtPssViVatP3nCURntICFubE4W5YX0Hb7Qx7fUzdyxVTWTTHTrcNgOSxyr43khE8Tnd/w9IeOKFVEscLJ+2kZMz8MxcAyPLLY2j7Exm9hSkKgtEIFD3O/PJ3NL1q+2k9VOI72CsrCnHXUfKq22AuWmrG7ThPc4eKFXdZX15EyQEgfjjDW0uConaOoG6q6pihLirJkXOYILJN8QtDSia+ur4OAjz75mFu3b1PkNVVtaKwhjAOPv3MN0jnKsiQINetbm3SyEKUswjnK2hLqiG6cECoFTtI00DQO0zQYU2NMDbQh6+kUs14IYA2BFAQqonSO06LmyrPPE3T7CCV9JSQH+WCIUIHPdWgM3axHmsZoJUiikC+++AJO1OTugCns3U9aO3+dMQn89y1aoB3vbgkjYNthPzch/IO+/8N8eoTALMnnrAd0sblH/uQ3SZxTJGmA1medjctNIhgeNXz49jHvv3XI7U8KnJEzSXzuJbceBqU8Jv3HRgbMMBISqUEE4KQAIZFCLaicTygJnMC6hoF7jziTXLt0lTAMfQVm4Yt4IsSMQbhuaqqqBOHJY0aTMXXjzYRup8PmxgaRDinzgv29PfYP9rm7d5csTlBC4RpLVZY4/PNMspT+2grb29tsrKwSBhqco2waHIIsjknCwOM9raM2hqoVRHXT0NgaQ7OgKRgPElLaaxdRwMl4Qnd9i2eeewnd7yKdQ2oNrmJ8cEgQBBTjMUjJSr9PFEVMF6ednQ10CJU7WQBhLeoB99NuF/ThWcLdwvxxU61h4TgPeIxPjxCYrfoLt/gQh8Y5R2B5JgqEkCRZMCtLfe7AFoI6t9z48JRipHB1wN7NEYPD4iEd5CeKlKC0/LGRAb5MtiDpS7auxGxfSkh7DiE9O/Jn1QRQumNO3dv0+z0u7u6ipPITrGkIwzbv3vkVzFqDDgKCMKBpGqTUWCR5URBGAWEL2jk5OWE8GlM2NXf391BSUE5yJsMJrrEEUUqYxEgdkHV7bK+tsrOxRag9X6Kznl8ojWI6cUSo54xEVdNQ1g1lU1Nbg7XeHKkaQ1k3GAtShuggBqU4GFVcuPY5ti9cwwVeEAmgGg0oTocEQcjewQFah2ilqcuKuvI1Enq9LlGiMG7iNYzznlW7urtFB6Bb3qOlSPJ/xTSf4NHbUyIEllX9qWf1/vv6do9wmzpD3VwcSOUII+EjYOJ8qLBAcLJfUAy9aiwxYGD/9gTbyAdIUR/EFaKlHftxaU4Qp5KdKyk7VzJ2r3XYvZYRJ/NczCc8gY+miZqR+JBa3+HC7jYbayseeYfn91NtglAUhWg5rdkAddMwmUy8I04HGOP3FRKiMGTvYJ/GGZyEg+MDirLgZHBCUTU465A6BCmxAmQUsbnS58rFCyRx0oYKHY2DbprSzzKyKEQKaKylagyVMdTG0FiHdRLnfCjTITx8LdDIKOS4rKG/w+rmZcJeB2ssQgXQVBzfuk3U6RJ2U+7cucNKf5Vut0scRTjbproL2eazyPm4vccRtWwCn9UClrUGO9vmKzo92pN8SoTA9OaWVZh5LvXcQbK496IlNN2+5DBxDh06grCdoPfRKpxzDI4qpBMgDAiBEJrRacN40Dw0UiaEWBACD3cn/lCaA5ybgSbPgkrmqiIIaemva7Ke8vwLrqG7EtFdDRDSazdPjqj0/oAB7xOmhmuXL5PEEVJJmPaVEGilCXSAlBJnLU3j1fHhaIRSisZairJow4eCMI4YTcbe2y9gNB5zfHrMyeCUaso6JRTWWYSWOAGh0vQ6XZI4RkiBMZZRXhCHEd00oZdmhDrA4YFBTWNojKVuLNaKVnMCoQROStCa2sGtQcnW8y+xsXsRmcYEOkQqhcknlOOcbHOTxjn29g9Y29ig3+sRBJokjVBKcXI8oCwalEgWHuO9z20pi9C1e7nF0X+OoBAsf/O0RweAhUHnlrayKAi492aWPonpCtR2h3PoQCL0QoXfc85takdR2LY3xGzlN43j9KB6OGRePEx7+VG1s3bl+duVFsSZRuppb/jMwKwf+VDnE1+Hd5LWDBjZd+l0Uy5evNBONO8MnMWwhfBZd1Nt13nn3LjIkQ7KIqesK7RUWOPVcyEEURghnOeC2DvYJy9LysozDiFAKg22gaYmjGN6/R7ra2soramM5Wg0wQlJGkX0spRuknr4sgNjHc760SLAk40gWm1E4YRk73iM7W6Sra8Tr/QhTiAMqMsRR3fvkq1tECUp+fGI0/GE/uoaSnqOAdM0lEXFJzdv01QOLTLAl333r7MOwenTW9Rk7zV+oZ38gnu+e9AzfWqEwIPb/MbbBe+R9vYDXrW8+czMhbPNGIudFtNYEEZCwGhQYJpHmRa/lwLADx7bEmh614ovjiGcBCcXd0UH0gtHph4SbwSEsWdYflJtRjgQzpFzi0JdZ3NjnfXVVQLtw23gsMbMelpKidaBH4zGUhVlSxriKMuCpm7V/BaJlyYpcRRBG7sf5xMGowGjyYi8LEFJDz0uaqRUrG1t8+wz13ju2jWiIKQ2jruDnMPhmH4Ss5KErHcy+nFCqLUn9RRew5uGMpXS6CAiDGNOhwX7E8v65WfRSYeg30elGUjH5OSIk+MTsrU1pFAMT4dEYUKv0wU8n2FTW4qi4r0PPsRhMaKaTXzLNKR3jnOP6Qq/vPovpRPPHsKjP6+nSggsT/XFLWf3ukf+3Wcv4ZFfZ+7yHm2ijVvf6y8UVKWhqe797vz2e+kX8NPZYallTiGOaETRho/EdJnFAUJ6Z+b8d/476f2Fn0m5NIdlaD9ERjlXr1whS9Kl7wU+mUc4n8chpw47ZymLgjzPPVDIeAEQhSFpO0njOCaO4gUaOsHJyQlFUVDVFXVT43H+ASKICNMOF3Z3eOHZZ+gkHYwT7I9LXr5xB4NkNc1Y72RsZCmdKCLQGqF8Z0wLmwY6JIoynAu5fpqjNy/S37yAjBMIApQTuNGY0cExndV1n2Pg4PD4kO2tbda6PXSgcfgIjLOGQCsQJUP3BiX7zLQBB0tZhTMNYWH9b9GD8/3gcfNinyoh8PA2XeeWJ/LZW59q5g6HVA9HvyrlU1kXDzQ9k22Ep9d+wO+XeBF/T1q7njswDNl3v83H9u9y1/0GlThkfmNtIS6Ld0iJObZB4Dn+vJb+hMJMQCMmnLo3SNKIyxcvkoQxYRDhnMMY06Zfg20MpvHgGx+WswzzCQ5HEGhMYwi0JokTX34sjEii2KcZt32utaYoK8aTCXVZUYwm4EBGMTKMQWt63YxLO9t0Oz2cdYzLkm99eIvfub5PGGasxjGrScpKmpGFMYHSs9TmKIxI4hStY24fDRHru2w9/znilRVUHHoau7xgsHeXBsXK9kVcWTM6PmA0HnLtyjWyOAHpAUbWGCIl+G/90i/yuc9d49S8xoH7Jo2YzLQo3+Z2/9l/U0GwGFF7VB/A2faUCIFF/+ZUu5neWKsSzZxdC92yJAiWlKbZb8V9ioUsTlyphceDM+9Ev5PPPKuqh4dc7I88dWB+x36xr3GyZCQ+4lbzX3Cr+VU+Mf+Au/brNOKUqbPPCUfTWJpqbodPxUCZN5hmKiqeACWIpWCfsfyAjY1Vb4srn7gDjrqNw1tnvUNQOKSSrUfeMBiPkMrTfRV1SRAGKK3oZBlBoNGBL/0uhUQJ2abpSvYPDymLgtOjU89REEWgNVJpkqTD6uoaUkqsacDB7eMR/+TV93jt7iFRGNMNIzpxTBKGhCog0iFBEBInMWGScHcw4r2jU7pbl+lv76I7ia/dWJVMTk4ohaB/4SJBEJAPTrnxyXWCIGRjfY049RwDdV1R1SVaCL765S/xl37lV+itCI7Mtxi5t/EcAHbh2cyzAmfzYjp2W0ewnZm5i7Nj8dODCXSeEiEAjinj79ntZ6bmbHwub7/nnZh/eliTShDG6lxDwzuqHnyUFkTWTpsnANg8ZjNuwqH7HW7af8JN888Yi48Js4BK73Hb/DqH7mWsqPHU65q6dowHDab2YSQhLM7C+KTCmqlIeJw27SfL2N3A6SGXLlwkjRNvcpkG12YFehyARAeePahxXjswTcN4MiYMAqRzjMdjwigijEK6nYwwCDxkVyq00Cj8ah0GAbf27jIucu7cvg14J55UEqkVWkfEaeaTpXAtPkHw3t1D/sF3f8DXP7zBQWORKiBQymsCQYAII8ZW8dqtI373xgHhzmVWt7YJkthrPHnB5PiYoqzJNrbp9nrkJ4d88sknnAwn9PorPioS+OhDU1cIBVoHhEHIL/78z/PL/8ofpxK3OTbfpeakjYotVhw+27/zathzJ+LZfRY/z+fDee2pqTvg21lfgJh9cq2IWM4CdDx4uE4dJw8+q5CCJAsYHFX3rIIOsNZNHd7ntqlH+Uc7+WeGEUPxER81f4/c3cVQ0F1NePFzn+PmjRvcunGdO/brJOoiPV4AfGrs6XFF0lGsboZI6Tg5LBmeNN7zxFkn6cPb7Ik5b6eO3PsEoeDSzkXSKG61AGa2mXWW2hiPHnTG1wh0lrquySc5670VbGOpi4p+r08cR8RRRF6VbXTAOxmbppmFGPf39zkanvLh9ev81GhC1M1AeY4KoTVRFCEDhVDCY0aEpLSCH9w8YG844bmtda6u9klChWqFx6Q2HAxz9k5G/PzP/SzPPP85Vjc3kBLscMzxnX3GgyEbz3yONE1RVcXBrdvc2jsg6PS42O2htfZaQJEjcMhAUzYNQkl6nYw/86f+JC+/+irvv/UWA/E6K/JnF/p+cWlq9YKzlYqecNg9bt2B/xT4XLvLCnDinPtKy0r8JvB2+923nHN/+dEuZUoP7vxAacM/YkosIuYqvBCLM3JZYCwLBvFQ28hnZgm63YC9WWcuT+iHHAFraVfQH7UgAOcaTnmHgXgHIb29rWRMFEZsbm55Qo7Ra+yJ3yaSW4T0kRjKXHL3xoR82IAwjE4NZTHt88e9GH/3FSOG7h3SbszO1hZREM6BOpNJO359WLIxhjgM6aQZSikmRYExhjiMqeqGumroZxlR4IlBVFuKLAxDdOsX0C0l2XAw4Oad20gEhwcHXOhmfuxIiYzCWXgP5cutW+edbaUTfHKasze6y2vhATqY+kt8ncLawpdffI5nX3yB7e1NtJK4qmR0sM+t6zdY39oiThOkdRzsHXBr75DSSbqZpzvLJzmmLD1LhhA0dYMBtBNoKXnx2Wf4s3/6T/HXPv6bnJQvk/I8odicpVo7MV3I5g7BKYbmvKSi+dhw84fygPYo5sDfBn75zMH/DefcV5xzXwH+PvAPFr5+f/rdowsAmHlC2/dz5X7h3z04/nMV+KVmzL0VjO45s3VknbDltzurOTycXdcaizGfRdrt47XSHaMC2NhcJ05jqqrk5s2baK3Y2d5GBCV79psculew+OrKwjnKseHwTs7h7Yp85GmwhHgS54YApxiJPSbiJutra3R6CVr69FwdaJxt4bl1TWMMUikPGFIaHEyKHKU0QRAyqUomZdkKaq/7RGFEGidkaUaaJGil0VpjrdciTo9PGBcFb7zz1mxSCCFAq9Z+lkgZIoX2qcpTHj4hqa3juCzYG03YG+bsjyYcjUYkUcAf/Zmv8eKLzxNlCaJuGO7vc+vOJygdkqYpzWjIzQ8/5rW33+XupIAwpN/rUVY1o9xTpaVxTBwGAB7XUFZIBP0s5Rd//g/z1Z/6Ern9iJF7DUvl58PM9G2jAM77C+yiAHhCC/ShQsA593Xg6NxH7pfkfx34u49/CYvW/TzoYYXzr4W9poSMrtUWfA72g0IlzmMA3NR2skv7TmMuTjiq2rXOvbkJMu1ccV9IcHu+xuHMj14LAHBCANontmjF9vYuUZRxenLCaDCk319hbW2Ngtvctb/OyL0HgHAtcZh1ODs1gtzCgPp09zKdpBbBkOsQTLh88RKhDnz0RbSrq1BeaFrjnYONQUnZqsySw+MT70GXkrqlC2+ahiAKEUqipCJNE9bXV1lfXyPpJOjAawIOOB0MuLCzzVtvv8Pe7Zve1EAhlSJIEuIkxTnvpRctb6IULZGqtN6DLzVSKqwV9Psr/JGf/UN85UufY7XXRQtJMRpy++Z1qqJibWOdvDK8+e77fO8Hr3P36IjeyippmnJ0fMyH128yHI1pmhonQLWmwRTzIKxBO7i6u8sv/9IvEmY1Q/MWtTvywLfpCBcOK+wZF9+CtuoWvWeL43zxdX57UsfgHwXuOufeXdj2jBDiZSHEbwoh/ujjHvhevFTrF1hMMJpN2Pus9AKays6cXQvomNYm9HahbRw3bxx75tvZzJ8LAq0e0E2t49DaR3FBfsbNgXCaQHSxxjIZ5wRK0+l0sNZxcnJCXVdsbK6TdSNOzGvcdV+n4HgaLGRWVXRp8j+mMBMOK3NG9i2CUHBxdxeJQkkfblNKo8PAD2pjMHVNXVVYa4mjiDiKGQ5bok6lyPOcsihoTE0QhjTWMJlMAEcYBGRZQqeboQOvCQghGAwHdOIUC7z6/VcxwzG+CrWgt9Ln6uXLbU6Cv55ZZunsluWsbxrT0M1SXnzmGv0spS5ymrLg1q0bDIYTwrjL6aTg7Q+v8/YHHzOua3qrK9imYW9vj9t373o4c90gpPeDlKXnSex2MtI0RQcapSRxGPLTX/0pfvqnf5KJu86Ed3ELhUlmPv4lx3g7DNx5M8AtPcofJmz4L7KsBdwGrjjnfgr4XwD/sRCid94PhRD/jhDiu0KI7zZuuPDNg8MZi0HCs98stqk20NQLQuCei2iQwnF4u2BwVM46dzGtU2BRWtznknwIsaktzj6BLf1YzfeDAjJxBeUSxpMJeZ6jA02aJuRFwcnpKUEQsLG+gYoabxbwHRqZAx68Mr2XJ9dkBJUYMXLv0ut22VhdQ7QaSl3XNHVFHIYoqTB1g0BgrGlLjftyY2WRE0c+x6Aocso2byBNEnAQRx4nEEcR3W6XTtah3+/P8AdVVfH+Rx/xzLVrvPvuh9z+5AbUOU5AliR84YXnCbT2sOCW5lwI2WoEGtn2h22JR37+p7/G1770ZXppSj4ec+fObfaPjtBxl9PC8N71W3x06zb91TW2d3YoyopPbt7go48/RirprzeJfSjU+cUiCAICrTHWYCSEcYxUip31df7oz/0cQVowsG9Tc3r+k28xFkuDcgrDfoz22EJACKGB/zbwn86vw5XOucP2/e8C7wMvnvf7xeIjWnSnW1mUfFMswPl+gIXarG7aB2d0B+GFQF2d5xfwD308KLl7Y4Kw+lwtWEhQwf3x9A7PQ/fEAJvHbA5H6p6hJ16iqWvyIqduSuI0RQcBo9GI0WhEt9tlZXWdigPumF9nwAfY+2RVPuaFIJwk54BS7nFh9wL9bndWR8A5D/vV0idbNS1tl5KSsigw1npS0apEK4kUPtHHT0Y/6UOtiaOY9bU11tfW6Ha69Dpddra36Xa7s/P84I3XfapyEPD6++9RDYcI4YiShGtXLtPv93xUAtFmMgYz9dxBG7GAl55/np948QWSMKAsSwaDASeDIU6HHAwnXL+7z7As2djdpdPrcXJyymg8RgIXdnfppKknMg00WZp6s0cpmqoiz3Ossdg2rVoKQSdJ+ENf/hJf+vyLlO4uldtv7+l+T/7exXAp5ZjFeXH/9iSawC8Bbznnbkw3CCE2hfAM9kKIZ/F1Bz54lIMtxznd0sYZsGcm7c67qXtFhRUO20BV1ud0hKVpFLc+LmkKT3YulrAFfmWXUhDo+8cHrfXgmx99E62eIolElzX5NZyTFPmEsiix1pF1OjjnOD09pWka1tdWyDoRp/ZN7tpfo+LOmZDrkzWHYWLfR6iSSxcuoIQijRO09s67KNQEyq++Ze2fSSg1ZVFgrS85JqWnasvzCYOBXwmzNKWqKqqqIo4iT+oRhigp6fV6rK2tsb29jVIKay13D/Z47bUfcOXKJa5//Al7BwcI61CB5rnnnuXLX/yiT/tdiCIpFaB14I9hDBvr6/zLv/Av8cUXniMKNfuHB3x84zoHp6ec5iXHxYRRmbOxuYmSgju373jasjhho7/KpZ0LCOsjWVVRoJSkbpp5hMs5tFK+qpF1mLpBOcflnR3+yM99jSiuKN3hgner/bvk8Z/PhZnP5THaQ4VAW3fgm8DnhBA3hBD/dvvVr3CvQ/AXgFeFEK8Afw/4y865c52KZ5tXcfxkWqzBMnf2gWmtJIOvxmJnTsK5Q2ShLIM/lnPkI4NtBLbFX1t8h+3fGDE4Mt4hNPM1tK9WogolvTlw9nqnZ7CCppLcT0j8UFurwSsUa+InSLhA3VQ0pqauCsJQEycxRVVyOjhBacn6xhpBLNgz32TPfQvjRsxXlU/bpr3QtM+gYWDfRgeK3Z1trwJLSVn6QhtCKZwQxFECFuqqJoojnPQpwXlRec+39XUnhqMRYRCw2l+hk6RoJRHKowtN04BzbGxucenCRS5e2GFzbR3nPL33yz/4PpPJmH6nxw/eeo8yLxACOr0Ozz9zDak8r4EHS7k2v8T5cyvFl156kZ946QXSOCQfD9jfv8ukNIxqycQKJnlJlmaeH6CxbK6vst5b4XD/EB2GOJwHG0lJEIStz0hgnMM6gQWqumY8KWmMa3MTUnqdjBeeu0Z3NaC0x1iMH9MLCFdfpuwMTHjmNfC0ZHZhhjyMZuRRogN/0Tm365wLnHOXnHN/q93+bznn/h9n9v37zrkvtuHBrzrn/vNPNaaYetgXpF37mqVIttJumk01G7qLJq2Y/vERhMmkwTTGz208Achk4Ni/PWzFynySL1nGDlQgPbjkHHXfE88+HFH4w22+zxK2WZM/iWk8LHda1CNNM4IgYjzJGY3HpFlGv7+KUSNum1/jVLzlveVWffoqY9OH4gIcloYxI/ceK/0V1tdWPKgnipFatRNbEMcJURRhgaPTU2pniaII56AsSsBPjsFwQF4U9Ht91ldXfYhRe9Vda01V1TghWF9d4dL2DtcuXePSlWtEUYqzlpt37/DN736XK1evceOTW9z45BbCGrJOyuc//yK9XhfbpjQ7piusJxFdX1vl2SuXUDSMRqfcuHmD0+GEyimS7gqTsiRNUrpZhzCK2N7aZH1tlRufXKcovE8GIdo6iZIo9E5PYy1CKlSbj5DnBUXdkJcFroVQx3HK5sYmcRpiKHCtgJ0zBi1O57N+HLc0B9yZOXS/9tTAhudtXmzxwU7CMyv3ffYRAsq8oSqb1m4FW1tufXxKVQrAQCuZ741IOJTmXMLRGTTJOWzzCEWWfght8dlqMtbFTyFcQll6wE1ZljgLWdoFJxmNxtR1w0p/lSTtMHQfc9P+KiW3QNQ8njYzDQ4qRtyhkLfY2dkiS7wZgICyLCmrCqkEcRSSpAlSS46HpxwPTmisZTQZM5yMQECgA6qypKkqet0uSIXF0Vg/SUfjEcPJhChKiZQkEoqd9W12dy6w0ushhU9G+vbLv8utu7d57pln+f5rr1HlOaGEyxcvsLOx7glBkbMhZKwl0IqXnnuWL7/0ImkScnByyM29A0a1Jcy6NM6RJQlrq32CIGwTjEKf+uzsTEgVrYmTpilKa05PT6mbGoPzgCdAK4+fUEpR1SVlVRAEEVnaIY5D3FQInFnoztfZHmU+nN+eIiHQqjrTxCGf6sa9gmBBXWe+79zmd3O7qW11ZZkMvSNKoDm4PWF03DC9/SkI6awAAM9KJBYKUd5z1e7xFOnPtDkQTpBxhY64Sl01PlPPWqq6JgwDkjSmqmqGwxFCwvr6GlESsG9+hzviN6lFyaeODvg6WwgqHIIh74BsuLCzDU4SKI2WijhJsM4xGvt4eSdJ6XW6lGXJyfEJ1jpGkxGD0WDWz8Ya79HvpBjTtL9tGAwH7B/sc3x8RDdNiaMY6xzrKyvsbmxw6cJFojBECsFgMOLr3/htdrY3OT084t1334O6YXtjla995SdnSEPfhQ7TGDpZyqXtTZRpOD444PadPWoEa5tbNMagpeCFZ5/l2uUrrK6stKxSkk43Y8oTGIbhUhHVNEmIgoAoDH19hKLANoYojtBak6SpR0vmE6QQRDqgk0Y4ihY0tDzWzw63JZ/ZVD/+8csinLazU9G1833uKFzkD5zTj93vSK29BwxPKpxzjEc5d2/mvpwUzVL1WLt0DX6r1nPE4Hkpw1NV8ve2BFkrsFhnXXwFaxx1XQGOui6om4I0TbwKOikYj0fEkabfW0Gohhv1P+XUvYZ7LLSgBys5SgbuDXQUcOnCZeqyQStFt9tBSklRleRVgcERaU0nTsA6hqdDlJCUVcVgOGzNBs82HASaLMvaMJ4gy1KyrNPmaTh6aUKvv4YMNZ1OwnNXLvPM5cukcQp4QM4rr73K9199meefvcZbb73LZJIjBXTTDCEUHp7u/RBKK565dpUvfe5zrHU7DE5OGE8qVta2ofXyb21s0O92qMqCuq4QUhDHMVVVUJYFUgrGrcAKWlhzURYIIXzh1KZuzR9L3RYlNY3BGAiDmDDShGFAmqQ4Gpxrlnr77Gi/t1DJp1+QnhIh4B0dZmpiOj8lbfu/Dwd69Jh3ELaWcGun29kRFuymmaPRgRSMRzX5qeT2hzlVYT3SbpaDMDc/ltMwRcuJd+ZqnZfIwtnZNfyeKgNtbFMT0ZdfJmCDqqzaPoC6rMB6Rh4pJPmkpK4svaxHmmQU3OUj+/cY8wnzsqpuKuG4781NSTIRNAwZuI9Y6/fZWO1jbY2WCu1AOUtT1573zUAnS9neWCMJA04GJwgJW2vrM2EwyiccnxwThSFJElPbVlgbKIuCvYM9dBQSdzOfWBREWGNZ7a+wvb3F1vamRwNKyKuSf/obvwFCUDc1H39ykzTLuHr5AmkSe14DHNYa+t0Oz1+9SiAFn9y6ye3DY9L+CioMqOuGtZUVoijk6HTInb1DOmmX9d4KUaCIgwAL9Hp94igkDEOSKMQ2nu6sbAxBmBAFMUpKjIHK1jg8kKi2DVIHVJUhCmKyJMNRYanBzQuO+7boH1hwlYvzDOgfPmLws2uzhIiFtX3m1JhP0KlNNF+r298uLcT3DtzaWD7+YJ/hSbkQTVg4PYv4wzMOx/u0BWKb3+M2vQBJyhY9+SyNaWiaGoFrcfUVUeQnlWk88k5IwerqKlEUcWzf5Jb9NZw7aef+o9+UEI6CA0oO2dncIoliT9bZGIIgJEsSqrJkf2+PYbvaJ3FKlnUx1jGeTFjpr7KysooUgrKsGAyGdNr8gLpuvLPTGPb29zk8OCRNU9KsQxiGZGmGaSy9Xo/NjQ021ze8LwHAwUeffMK3vvtdLu5e4N133sVUNWsrK3Q7GdMxJATsbm1w5cI2WgmOhiOCrEucJpRlThBGGBwnJwMGgxFRGCCFt+t1oDk5PaUxhl6357VMKb0pFMdopRFCMRqNyCc5eV4wKXLiKPZO23GOaaznSZAKqQRplmBcjXXVPY96tlDOwoVuthA8zlr01AiB6aReVMmnfgE3XdGXnIbTTlgmZZwFT4Rb+OQ96HnumKJ73YKpca/99Cm6UroH5Bb8aJtAELk11uRXsFaRt4U4AKqqpmka0tRj7YuyoCgK4jhmZbWP0pbb5lc54NuzY3ku+we4lhe+GruPEXLiCUXDEGMtw9EQ6yydbof11VVAUNU1xjmyrMvu9gWkUOzvHzKaTAjCkDhNsdY7WnvdLlp7bIEUgkmRc+vOHmVds762TifLiMOQqiqp6gqlFVtbWzxz9Ro7m9toIZF4J+HvfP9lRpMJxhhu3rhJJ01JIs901NQNcRhz+eIuaaw5OD7CBTFh0kE4WOl1aWzDaDJhkhdes8JgbY21FpzkdDACIWdjyVpLEHpzYDQe0ZiGOEkIggBf9UCCdXSzLloFZJm/V9M0aCXJsggnSgz5rMLQYptTjS1tfaxx89QIgcW0nxlb8MxSX5j4s3/zhKFlFZ7Z9uXoiUOgljY+qMtmzhV3f/nqACTIwKvEv3dtfn2ShL77Mpm7StOYGeORc5ai8LHyLPN8f+PJmKquWuRdn0ZO+ND+YyZcx3ulW0HwkJ6yrmHIe2gtuXBhF1M3mKahKAukknSzDqv9FcIomkGbpYStzXU21tcYjcecnA6YTPK2DJhFK0WWpq1l58iLgqquOTg6JMs6pEmGc448zwGHDnzcf3N9nZ2tLZ65epX19XWk8NyF+4dHvPLaa2S9Pjdv3UJrRZzEGGOQAi7sbHJxe4vJeExpDGEcESURURJzOhgwOB3grPXFTJOYtdU14jj2ICelKNuaiknk6cPDMKCpG4bDIVprxpOxF7xViVCKOA4xTcNwMEBJiZTCa2xNjQoU3U6KVA2WcskQWGqL8nnqF3yM9lQIgbNr9uL2+eSfT/Alx+HCb+5JOXIsfF7IHjwjVDizFeZ9a6xhTm12bxBRKggCdQbRuHgB93s9sEM+/Wvai8IRscmq+LIvq92UM3PFmIayLAmjiCiOZ0U+nJX0V9aIk5SRfZ8b9v+LEwWIBWqrB9yHpWbQfEScRTNHoHNeyBwfn9A0hjiMWOn3QXhtwDpLGGl2d7fp9XozeHNRFIzGQ+I4JssymqaeAYNOTk85HQ7Z2tqh2+lg6po0jgl0QJqmFIVfpVdXVllfXePShYv0uj0Egqqo+P7rr7N/fIRpLMY0XNjdpTGGJI149tkrdNKMxoAKQvq9Luu9Ls45oiTj8sVLdOIErcDamrKYsiN5x2JlGrQOSNKU8Xjsy6oZ7xwEn6eQJAlhGFLVFUVZoaTA0aA06EB5KLWDJM7odvroQGJcxeJSd/4MuXf72XH2Y1F3YG6otwjBBSD/fOpOdXlvGDkxLf3lAbSLicfL4UXLdFVbWq8XgUjnICqmYSPc1O669yURhOE0gnCeWfEpBcDihT3ya15nUThBSMaK+DLKrlCWFdbOoxdlWWKaxlN16YCqrCjKHK0F/W4XpSS3zT9jn2/hRYBc7tdz7qUSJ4zFLdb7a2RRjHGWKAnIq4K9/T2UcGSdiLSTkEQRxhjysiBvawt0so7nGWwp0/PJmDSJicOIoCUo1UHIrb09wiDg4u42cRTR7/bRUmLqmiIvaKqG8XhEr9tha3OTy5eusrtzkV5vFSEkg+Ep1z/6CCUkk9GElW6GFI44DIgkVFWJ1CFJGJFEESqQdLs9NtY3SBMP9imrhiCMfJERaxmPRxwfHZCPx8Sxpxwb5t7f0lgLzj+TLI4JpUZai7AGS+2TpMoS6wxFPqGY5NimIdYB3TQjDAXOFTNNdOr8XkqHnz6Je4bvo461p0oIwOIKf6/cO2/1b2/0jF3vcDOK5rNa+v19AOecTQjqyjxQzVJSEMUSqc6aII+pm8F9Bc7DXmL2V5GpC3TltRY9uBxmmoaysk4GAiaTiSe9SFO/+pLzYfMPGIv30E559tv7RAkEktzdwohTLuzuEoUhQRAQRTEguX3nDofHR3RaFl/PrFOTTyYURUlV1T5XoCjAOaIwwFk7iwxM4/B5WXHnzh1WV1dneHxrTJuirNBtGDFJEqT0/AWrqytcunSZy5cv0+t1MU3D0fExeVVy9/CAW7duIIVgbaVPliQzMtQ4inHW80tEYYgEmqb2nARh6EuTS0GaJKytrpIXBeNJTpZlGNNg25CxEgIhpU8lFoK6rrHOEcUxcRwShSHWOIzxFZGn+RDgsQYqkBhxHhDtzFh//JEGPEVCoE3qAuaT1E0LLTKvsTad4IvbFgXEUk4BLJAtTMXG/bpsGopsu1V4r3ddW4w53953gJMQxBIVzLc93I5+WHsce2D+cjgit8kaX8YZ0WIG5q2qKsqyIElikiRpbesC5xyrq6vEccKQ93jf/McU4hjhEr8anXdLQjDgXaQ0XNjZBQdNVRMqj5wbjIZ8cvMWk/GEQCq0VLNCIlprrICqrhicnvrSYVISBAFZJ/Pkp6MRg/GI23du46ydpQ0rrZBSzHkK26aUIopjNre22dzYYHtriyuXrnDlylWSOGacT7i1vw9aocMQJSAJQ+I48Q7M9VX63S7OWJq6YTwaUeSTmSYVhgFaKZzx6eNVmwhVVjW9bhcJKKkIdIBt05ulEIzHExB+orsWYXkyGrf+L0EQec7EIIq8EA0jPNlSfd8x6xe0h4ykcxe95fbUCAHf5ir8zEcwcxJOJ+kywHdREEzRe9NOm+3dOviWtIX7dM6Sd0JAUzua+l6ugNkvBegIwlguDMZPo/rfrx+e7KVdQsZzaNb8CrTAiS6EB+M0TU2nk6G19gSfeY6QgrV+Hy01d823uS7+c4wacX62ocDic9/DMGB9fa2V444oithY36RqDO988D7Xb93EOo9VCJRG4Nl9ojiZEaAURUFd1V4IZF2sdRjnyKuSm7du0ut50s7GNG0JckNR1TQtoUjcmhpKStI0oZt1WOmvcPHiBV763ItcvHCBuqk5ONgnz3Nu37lLGAZsb27S6/VI0tSbIVFElmVeVW8MaRzTNI2HBlvriU+jmED74ihHp8eEYUQSJ2ANSngexE6nMyu/jhAY21CbhqKqkEpTlhVKBbMqzT7hSCCVIoxCdKCwNCy6x38Y7akRArNpvYACPGsSuOU9F6brcpAQ2jX9zMRfPpe75/2ZnXz4qLE+72D5q7b5iaEDSDuRP787ez33Ewdnvn3wzo/cpgnGQkAsNkjYxRiPuZ/llrQaV57nCCHotPHysixp6oYojen3VxDCcbP+JxzxSovDEAuX6tez2g0Ymuusrq6z0u9QlRVlO5n73R6dTpfT4ZDrN29R2YaVfo9epwPWUVU1Svs4+2g8Jp9m+mUdgkD79OGy4uDwkKqq6Ha7BEGIQGLt3BSQ0psC1YxPoaGuagSCMAzodXu88PzzfPELX5zF8euqAudYW1vjwu4OvW6PtdU1b94FIWmSkiQJ6+trrPT7KOU1lCiOoU0D9o5BxdHRMU1jvGBqTZTxeNyWUgMtJWEYYZxp4dweJWidhxZLpWZCuMhzTFMTBLotcrvAm3FmnC8PkzPa4CNoANP29AiBNv0RWEqSmAmGWdmlBbMAsZBdODuQ/+X8v+kXs/NMbeg57+DytJ6TeYO1hnLsPbTnCxWHkwKlBULIdgp6F6S/ds5JQDxv9Z6f/cmaP4YDAnqkXMQ6hzUNzhn8oPKiwg+8ic8tSFKMcRRFhbHQ7Xr6q9od8kHz9xiLmwtXLzwhiZPk3KYQh+xsrZNEKVJrHGDqGmcatjfXsULy4Ucfs3/3DgYfftOBbpl3QuLIFyoVwldRisIQBFS2wVjH6dExWbcDWtJYKGtHknhBYuqSTpb4CSN86vhoNKIqCsqm9gLDGLRQXL10ld2dXbIso65y1lcTnn/mKv3eCmniS5xZ48jLgiIf00siBJZJntM0FiUVEknVND6zVGsmeUFZ1kipSZKU0hqPD1ASHUYgPdy4sTVFVWOMAycYTwqwElqUZFlVmKpGCX+9cz/OXDuevmYa7hM4AxfbUyEE3ML/n+53y3bw0vq75KDzOdZzbPzZyXdWcjpmpZ2sYDT0k8dDNJmbIMLgcOTDhsP9MdYZWHDkzDQDt3Rl5y/6S06+T90V5zYtEhK5g7BBixlwC6FMv09RFjRNRafTIQgCqqqiyHNAsLKyQhgGDMzr3LD/iEoN2z6swPkeGbs7CFlx6eIFXGMJAoXSirKuaJyh2+txcXeXvCh44+23+eTGDcIoZGNjgzgM21XZ1w7I0gTV+gSaqmIymXBweAgIsqxDHKeURQF4cwM8AUld11RV1TolQ69at+Qg1nkm6KPjI0bDoecREHB6ekQoKp67epGsk5F1OpS5xykIaIVCQFlWnI5HFHWFNT5SZFuS1DAIqPKSsij9yq0Udd1QFgVVnnuNQXuuRCUVWZzgSwZYxvmEMApbDWh6XodQclaQ9DMbCA9pj0IqclkI8S+EEG8IIV4XQvzP2u1rQoh/JoR4t/272m4XQoi/JoR4TwjxqhDiq49yIYsKz+LGee5QKyqWEITziT+r5rrAD+gnvo+dz02FOaJw+fyLRseiZqCYjBrPGSDM7LupHGhKw+GdkmJikTNH5vnK/1zvmPo6ztvrs7L8HFJEpFwksH2a1mu9qMn4KjyOST4GHN1u17P+lJ7FR2vtVWENt+p/wZ77Oo2weP4AhROWofsQqQQr/TUPEqq9it9Yw8npKVVVsbu1xc7uLscnp3z40XVu3rqNcZZ+r0egAzpZl93tbaIoRGntUXV2bp6EcYzWIRJBmsQEUjKZjGisJS9rqroiiiNf8bcVAMb4giZCgHFmhtwbDYctF2HOeHjE8PSAJA5xzlE3Pt08jiKy1EcZHB4HELZcgXHkbX9rLXVV4awlLwviJCGJY5RWVHVNmqTgDE1RMC4rpPBZlRJLXngkZ16VrRD2QjDNMlSgsc7fh1sqaDOdCO7MELnXhvw0GYTwaJpAA/y7zrkvAD8H/BUhxBeA/xXw6865F4Bfbz8D/Ek8rdgLwL8D/PWHneCsRnOWJ23+1ZmVfynfYO40PDPd2v3PfHbn2VR2wePqnYFCOoqyJp9wpugJmEZyclBxsl9ModvcT6VffFSWKY+dfy3hwD8zIQDCCWKxRSwu0BiDteYcj7LDNA15MSGOY9I0BRxVVWGMIUm6dLsdjJjwSfUPGfBe24cCIyqG9j2SLKTbzcA1OGN86E4qhIW6qtCB5uKFC2zt7JIXnojz9q1b1FVFt5Oxutr31YGEIknTGdGo1po4jhBT/j/j0RzGmPbZaMLIg54cUNf1jGxUSkmWJoShbmniPFjHWA8UqusKhCJJWqJSa5FCkKYJWZrQNA2Ndb4mIoIkCFFB4FN1nOdGdM55YhTbkCQpQRBgrKVoapAS6yxJGINSVHVD1RgqUzEcDbDOU6njfEFVHQS+FmPLTWFmJkHLWnUPEO3syGo/PQZs8FGYhW47577Xvh/iKwxdBP4s8Hfa3f4O8Ofa938W+A+db98CVoQQuw88B2cV+vP+nb8f57w7f+uCNsFZzcMtvFsUKF51M41hdFoDan4O55iMavZvF74O4UwgiaW7uv/r3k/3v+cHHeX+ZwOIRJ9U+NDdNHox1aSmPAzOOcqW2TfLMqIo8mptWdCYijCIieOYEZ9ws/lPKOUhAknjRoztDdZW10mikLouaYzxAKW6AWupyorhaISUkt2tHba2NomiCOMcdVlTFSXDwSlFXhBHiS8oojWdrEOaZjTW+ihC5JGBSkmiyOfpyzavoWk8gYpSqs0K9AQhxnqBEIQ+l7+TZd7pqAOGwxFGhFy++iyr/RXiyCMU+/0+URyhtCKvSwaDIc44AqUJowgd+tDf1HG5d7jPMJ8Qhpqm8VpJg+czNG2hkDTrYJxjMBoyLgqqpvGeGdE6G6MIqRVFWVCVJXVV++hN3SDaLM3F8XD+CLjf3FocTee3T1WLsC0z9lPAt4Ft59zt9qs7wHb7/iLwycLPbrTbbvOgJhzOGawQrWRqKw86cK6tJyfAiBad5xxqSYY5zqL8xTnf2NkqP0cQOg8KOJtqMPulcJLBccHGxenA81V9D+5MyMc1Qsq2CMjsh/fe3nmfFkyC83/18IcsF3ax55iQioyUXYSJMcYSaOknv/X+jDma0DGZjOn1FN1uj7pqKMuKuvb0a3EcY5qG/fp3yNQ/5xq/QunuUIsTdraugrXklUFHAq3bOHrrCzFNg7OGNIlJ4xAhBGEcUzuDqhtM45Nt4tSDiTppRhBGnA6H1NbQiROEEx5CLAzGWXQhiTqBL8duQStvvxdlQW2aVghYwjCkqWuU8iAlJRVxnDAZl2ysbrKzuYGpStI4bOnBk/a62wIhUlDWDa4oiJ0nCHUC4jAC21AUE4SQJEFAXhTYxhIFnlQkCRMqYwisdyRmScqNvQFhFHkHaBQS6pbl2toZ3NpYS1GUNLVDEs7G50NHy/20gIe4Fh7ZMSiE6OBLjv3PnXODMyf/1HrsYt0BT3b5adqyir8oGe+Veu13rcNtubTTWQ3hfiu1X/WLceOfhXWcHBQcHxTT+/9UIZml63roGv/gQzz4Fw5cRCQuELgVPxmn1yjwA7p1duE8Km4yGRNo5dGE7b1p7Sm50yQB5bhV/xon4lUm3AJh2FrfRAmJkB66HEUxnV6XpJMRxR6QFE9Xcul5AgVQlZW308cTHD4S43n4BHmek48nKOE5HYxrcEIQhL6aL8BgOGCS+9qGRVFiW/ox6xxFUVCVFcJapPAIPGN83r1ps/+uXL5MJ0t9HkMQkEQxSkicdTTG+BXDOpQUaCGQzhEqTZakKCWp6pqqLgmUAudm6EzXAoSqqvKl04UglJqiKKmNxbTl1BV4noX2mdiWDaoxDeMi9/gUAv+wPt30+lTtkTQBIUSAFwD/kXPuH7Sb7wohdp1zt1t1f6/dfhO4vPDzS+22peac+xvA3wCI5eX73OEZBdtNC5NOw3itTY3XDqb7TqewaMOFQgim+fF+wZ6WfZYLQnKuFQjEgqDw/zc1DA5LOl3NeGDZv1W25cjPitnFK76fEH7YA31Er/C5zsV7jxSxTsQmI3u3pfaWKClRU+FlLE4JhBRUVUle5HQ6GXVdUbTknzrwgzFOY/LRXT4x/x8UXZTSrPR6rd2twFm09EU3Au1Df4EKkAiqsqQsS4LQawM+1q+ZFDl5PgGHz8irKsq8pChK+kHPh+6c9XSA1iE0KKnbZ+8wtgHnQTlaB0gVYI3AGR81aFpvflVXRGHA8ckx4zwnDEKP7LOCIAg8ZNda6qr0AkQIlBRIGXguQCHamopBixKsGI3HKCHJsgwhvF/COTfTBqy13jRSyvsPmgYpK9AK09RIpWdU6VNKMlvDaDyhrh0R4UOHwXlsV5+mPUp0QAB/C3jTOfd/XfjqHwP/Zvv+3wT+0cL2v9RGCX4OOF0wGz7DNl/5vUNvEfY7Rx0ur5WLIcLpO3fPYed9uvA7Zzg9LBkPDfu3coqxQYrWeSjEDENgl1CLn1Y7eJweeIAm0KqvkegTix2s8Xnu3siBSEkCIfyK1/oHrLVMJmOMMfR7faRUM6oyqTRxmBIlMYfmZQ6a75BEKWnsVego9MSbYRAQSE0cRnQSX4AjL/IWrlz6OH5Z+hoDWlFUvrBHmqSsrKxQ1TWnoyENFhUFBFLg2gpFTVVRFyXW+BReh0UqSWNMuxJ755pSiiiJCaIQpKA2DYdHRygVIFDEaZfaWNI4ppumHuUHWNNgm6Z13PpxJQQgBUIpZCsYhBQMxyOGgyGB1m1Ogee/6KSprzBkLA2Gsqo4GQ05HY98RSbhKKuSsvZCcAYvlr4uYtMYxnmBMRK//j5gDDzIBHhE2MmjmAN/BPjvAb8ohHilff0p4N8H/mUhxLv4QiT/frv/f4kvOPIe8DeB//EjnGOeL8Ai/n/+2S1M8LPq+/3k4HmTZOodP9/BuPj/PNQ35dXIJ4bb10ecHBWLR/TXLjwzsQ4B2V7rYr7DuWe8T1+c+dXDTYf7mxQOgaZHIi4gXIyx8zBnEOiZKruIITCmYTQaoLQmy1Kk9KqtVAJJQCdLUSE0nNLJPDmHtc477cIQrRVRECDxk6o2DcPRiOFoRNOYFvvvnXtaKYoipyhy0jQmTRKKsqSsa6TW0CbgIPDVjUMfLciLgvF47LUh5zH8jW05+vF0ZlXlk36SJEUr5dl8kpQwTOh1VuhmPZRQxEE4E4BTanRfIs3OQpVlq1EUlRdAtg2BlnWNVpoin2CaBim9qm+dxdgGT73mOGrrQqZRjJYSgY88lLV3ApZV1Wqi/nyT8QScRi6ZA49qKn46s/Kh5oBz7re4vzz54+fs74C/8khnP9umvrV2AsmZKPMruBBz8eZw3mk43ad1zC1FVYU3B+RUxZ8hAf1a6Gvo+g62zodipk6y5aP5v9Y6Tg5KDzEQMIUCSm3o9CK6/RilIS8Mw+OKcty0ZsjZhzE3PM5v7p7w8AO6675tykgjCYjlLoHpY8w+wnm6KyEFWktE7UWrcs47SAVUVcF4PKTT8Zlx43HeOtgUWsf0u5LD+oBuL0VrhUD4VGDpEW/OWcq6YVIUPjzpHFiIwxgdBOgoQAWaYpJzdHSIEB6gUxQFRZGDwMfdpaRxDpRABcrz97cqt5SCumqoXO1hudbOwndK0rIYWbI0o258qDLtpBwdnbDS7/PM1WcwjaVynm69sQZhW23OWpramxHT0WOahnE+QUqB0pLxZELtfCSgqmuiMEJKhbOeFMU5izEOJxxlURBKRZLEDAYDOllKmkRMqhrnIBJylt9RliXj8QRBgBCL5sCZ5e4z0jI/VXTgR9bc9M8UhHtmuLupETCdqq3Ua4kvp/6BRYExO54Qs4nP0l87EyT+aD44MxcIcnZti10vJPTWIrYvdUiyACEdprakmWLvZk4+amaT/TygjptveJIeu28TGITTJGwSscHE3G0jAv4+lPD+gdr6wSqmXwgYj8eEYUi326WuDXVdtWm6kiiK6GQZ6+u+6o/FtcU8oGoaVF21bhWvWQghSeKEJE4IoqCtNWgYjccMh0PSJCHLMiZ5TlXVnqAjikmiBGcNKIEQAmMaoji61xPj3Nwss9PipDVlXRGEnog0yzo+FNjJ2N5c58LuBW8yAUrpWYqwVBJXeZt/6lOSUqGURCk/WYtxznA8pqkNQRhicaS9DvHE1yIUQhCGEXVdUdae6TpNU689lCUrKyseg6C8CREEAUprwJGXOePJGIFG3scc+CzNzKcCNjxtZ7MAPdzXzbH+Z9TdKXZ6Wjdg7sw7S0m2DBSaMxIvqOznEZ0uKOazNj1n+5ukp9i+2CHpaZyyWGGQoaO/oVndDtGROPeBzVOcp1fkloyeWbThsSIP88v34VUIRJ+YLawRWNfSVfmFf0bB5U0C2/o3JM4ZhsMBSil6vS5SShrT+Jz5trBGt613qNrIgJAKKTVV3VDW3rmWhBFx0KbKhq1Dz1jKsuTw6IjxZEIUx20ykPQTsRVGSgiiMCQOQ184xpoZPsDaNnKhfHES01YUqlub3nrlg8YYTlqfQ6B9ivPq2ipO+Iw9qRSB1i3S0FJW3rQwzrNSK62oG68t6BbROE34aYzxjkK8YO12M89yXJQzwM94PPZlyJXi5PiYJMkwxpJPcu+onTI4tWbZpMgZTcYIQoQLFsYzjz8WHtCeKiEAnKP+LkwVN3UAuoXp6RYSjKbOOGaTezk1eQ6OmQocWJSqi2JiYeo7ln43bSqAtc2ItCtwzjCl+HbOO7z6ayFpV88UDiFE+2o1gfs4bxzcc42wfA2P8qK9eyM8XiAWWwgbzFZs2uuYys7lIi5+Y93UDIdDkiTxXPjW1zSwLc5gb2+P8WSMDgK/milvx0vtvfXWWKLQp+YGWs2iAs5a6rKarYxS+GrFgunKK3HGYOoaa3zyjhcSAufsDBVoraUo/YQryoKqqgl0SKCjWcjSWkddN2Rpx9+7taRJ4pmElJ8CZVvwtKor77SrKuq6pm4alNIIIQhaQSaEpG4LuVgcxjhCpVDOEShPaOJwVJVnSQ6CgCDQDAYDVlZWSJKkzXgsvQBVatbvQgomec5oPEEQ4pX1H2Yi8VMkBBZRev7zoovOtbb1VL33e8wUd8eM/WbReehan8F8hRcsu/wWjuLc0jFhoajjmQKPzvnqOFEq6a2FbVKNm5slrbAJY023F6K1WL6uM9d//muxb+73Ot/ZuPj99HokIYnYQdHFGDuFBrQ5F1NzZfHHM4ZS8nxMno/o9rpEUeRBO8Y7+O7u7fHRx9dnRBgC51NhlSZNMtJO5gVE6PMCpnavw9veRVlSVxVZmhIEoXcCOu8PmEJp83YfKWgLmVQ01tI0hrz0E7eu63biVh5UZhuMNT6px/lStnEcUOTeqSsF1FWJM7U3jWwLJBNek2kaA20odaquh1FEEIQYLCeDASenQ7QKiKSmk2YoJSmLEof3jdS1p3xPo4jT01NUGNDt9XwYUQp0EBC3HAKNtdR1Q1N7HsjJpEIQ0xb5XljYzs6b80bBp2tPkRA45/JnjsLptBALg3v6qS1X5qZHmQOIpo6xxekxTTJaSkGensctn22xi+erdlsQRULaCwljtSRQ5u8sQljSjiaI5YztyDFX8c/e6tJr6ut8olerdeCdrLHYIXIbNMbOQoUsnmdB+/B9NhUOluFwgHWGfr+P1p5JF+f5Ft776DpHR6eEQegBP60a7CeQ742p0KiqkqqqqGuP6ivKkqpqiKK4hSpXTAuaqEChAs1UVdY6QCBwxhJHkf9tXaF0QFnXXvNwjsFwwMnpMUVRoLSiyPMZm9FoPCZNEo8PMJ7bb0r7NYVVqxaX4GYOQk922pgGIQVFVXAyGFIWFUmc0slSnLOzHAbVUp17rcVxeHjQVrfWvvZA6YuWxlGEarWZuq4pSo+NGI1GXgiIGM+Q/ZB23rP/FO2pEQLntcWJMl3BZym+i3bSdJ0VzPKsZzn8Mz/B/Vd6N/M9zM2Fe1fjBatdeJbhrBvyoFK+DksQC8IIxEIa81zc3X/1f4TeecRt8+9i1knELs748NdUqIG3Zxd5mxabV+Etw+EJWiv6/VU8H4HP9x+MS+7cOaQqm5mDrqwq8qLAWNty8Hkew6nd623lCZPxBK39QD85PW2dca1D2DSkSUwn8xGIpjG4xiIRBFLNuq2ua4QQpHGM1sqr7FK2YUVJPs5R0oOCiqIky3xl5KnC45w3cZoWUVnV1SwjESFojMEYnyFpjKGuagaDAY01JElMEITUxlJMCl+C3Dik876Wj2/eoKgrkjSlaYuoxG29A+t83xQtX6LWCmsNg+GIIjcoEn4UU/QpEwLnqTvTaeOHqGHReTYvseQWJvPSyj8l0pg52uZ+hcUjT8XK9EjGTZ1kZ9mL/O+ktoQxWGfOfLPcPHbAL7dzmTY1GRZfbnYv95aOerC5cF6PTc8xF3gNipSOuII0Hg2I8zaokKL1rLce/iVBNW9VWTKZjOh0Mrrdnqf/MpYoSki7PY5OT2daQJ7nDEcjr+4bD5gZjkaUpU9R9pRmfsJ3u10sfgWvmso76oKAuqmZjEdI4ck5pdKoQHtYcVn4gp9RiMM7JmVrRiBEq4koQhWghKTb8dWOEIKd7W2iUBNHMUppH0IWsvUxtGFB2daocB7/EIehD/m1fAPD8QgL6CBEaIV1XtMoq4q6qambmrt7ex5RGGoaa1BakWUZ3V6XOI68gCoLTGMI2z4RQjAaT6hKUKRe8/mMHYFn29MlBM61e9rP07Cfs/NoAMzV16nHnrkmMLO+Z2r+gqmw5D9YFiLT1f1+lrnDIZVABVMN4X72mHdwKS1nRJUPuvnzHXxnhcX8tVxf7rx93cJfEC6kywvEbFOVlQ/dsWB6LPTp4rOYPxPJeDyiaXL6vR5x7B2FgZLcObjLa2+93mYeNp7iyzSt195QNT5mX1WVxwKUZVsMRdDr9xBC0BjvD5BSEgYBcRhhjfEVf1wbElYKK/0Fxy33XxzHHlMgPOIOfMgvTjw4SuLodBIaUyIl2KbxJgKuTek1OOtaurI2OtHCeYXwWlNjfSr2lEdgPBkjpSRNU4SU5KWv6tw4R2kaRkXOyXBA1ulQ1TV1VRHHPhszjiJPSFLXICBL0xZkpWc8DE0FSkQLKu0Prz0lQmC+Ci7zAix+D3OUzjzS7yf9mVXUm90LIbepQPCYg7kLb27vz9fX9t2s/qH1jkDH4rdIKZBLvTfd32Db11QgIVq4kqOVSMvMxuet88si537/Fs0UdybMeVY78Z8ScYmueBHXRNSVJ66QrrXC2xwLHx6cC6Klu7SO0XBIEGqyrINSAePxmDfefpOPb16nqHKapsa1KA4pPRdf2XrwkRLjfJnyvChmlXpGgwHC4YFHjhmCUWtNty1jXtUllTWtA09grPEpvlJijGHcNOB8ApDSmk43xQkP5gm1Jh+PyVrMQFE3lHWJ0AIZSqSCyWTM6WDQciTmaCWJAp/n0DjQOiJQisloTFVWdLMOa50uwlhsY7BttEUr2Qq6gsp6vIKtfX9oIcGCbbxgUUEIQmKRlFXNYDzmaHAKNkC65FyN7P6LzuO1pwssNHME+sm+KAO9nShoc4v9HovL1xLCbtGXwNJ7iT2zKns1ff5zNz/cmWPODz0PZT3YC+P5/KxrBUNbJn3+n3vI7x/czh0EDzycQxKTyotIm1KbnMhqhJMIJKIVXNPDOme8AGul3fR2i6KgqiqSOKbKMkajIZWpUCKjbho21zZpjKFpWiCMDubY/BaaWzcNUknCMOD05ISmrlhZWZ1BiaeFPpVW1MYTbYSBBuNtboRDSumFQwsPLqqGQCpfz6CufRiy8TUKrTGM8wmbK5s+JGctpm6odQ3a+xWAWQRD4JF7pRCz1d7hQUPjPCcvSvora3SS1Cf90HB6ckqe58RhwGBwSp4XyChgtdsljX2YVOLzKBrbEq84H54sS5/cNMlzTgYDBAFSPCB56DNUEJ4STeC8NldFzzMRvCI/rzGwFOu/5zfLJsUiUGdZA1lee037smfmuq/069o6f/e30R1tFpmZqu8sCbr5VSz6AM7b9lm8/HEFkpBNJB0aA9YKPLBa+TLrC1Ig0gotwJqpdjU3r4bDU4/Lb6vu4jz3/vHxKVmWkaZzgpAoDGexcLtAAdbv9YmiuKU9o/3OE4FMiTajKCbNUk+NLiQ+NcMgWgejTx32qcJxGFBVZWufCybjMcPTgScAqRsa4+j3e2gp0QgPYBIK29j2/P54jbGYxgOFatP6CJxDK49GneQ5dVMTRpowDnHOzEwdIQR5XnD7zh5FWdJUnmqs1+21VYfljFHINA3CGI+vCLx/o2kM49EIIQKEiM4dV591e2qEwD1q5zn+gdn0XAAHLapFfnJb7+U/Y+fPnX/ziAAzh9x84i1nIM7PuziZHK7NVrMLwuF8QWCNo648pt2JpbPfYxRMr5AZIzKf7attmg7KJd44kiClr6Qkp1Dm9vRxoAmkbPH0i/4Hrw241imaZZ57oK4bPvz4OlVREAchSgqSKPH2bpuBNzUNgiDw4cY2jXbqnJjiCKq6pih9NKE2hrwtpipbfoHG+vLqPjLgkX5aQFmVfpIaQ1N5W7yTdbxTUGpWVlbQQYgOQ4yDumlangHf32VVzajfhINOmrWEqJ6W7GRwyt7+HmVVEUURSRxRlAV5nhNFIVr6MOTpYIAUkt1tXzexzAv29vY5bkuYO2cJAo3SGlPXhEojhWA0GnJ6OvQYAeJzx9Rn3Z4aIXC/NkXZ+TZ15C1auefbTMuhQWZ2/1lrGxa1jTPbpy8332eqSRjTULa59lPH273XDlVlqWrrs3Vn1/Xg1o7B+zgKn+xlnUWLEEnscwikRSqQeh4hcM7TZ8VhiPZd16IMF7QoZ///7Z1JbCRnFcd/r9ZePKszMwprMlEuOUEUogghjkByGbjlBAckLiDBgUNQLrmCBAckhAQiEiAEF0BwQWIREieWgCBkUVgjYJSxzYzddnftVY/D+6q77RkTZ5JJteX6S60uf1Wu+ld/Ve973/veQpom5oPgmXW9rGo2NrbY2NggTRKLrstSi/ZTCzWO49g8AsVSnidpOufVes/5vgU3FXnObDqlckuAg3hAEIVI6FO76waBzWgDP7BswACuwq/v29Kj53nzGoKBS0FWBx7q+9QieGHoVgpsRaBwNQkCz6OpKqSx/ABWxMVSmoOrJuSEY16WVC4c+OV//Yswirl8+T7Wz1vxl93p1ARWEBDHMYPB0JKqxnGbdJLpdMpkMmEymSEMkTdptr4SNoF2nLWtGt8NXa0BT1wcoGHfRN221NT21gV24Rc494Jx/7WoBWBKcPuat04x7Ty/tUosVHhVl+wSNWNfA9O9grPrg/nRc0kgi68sycmzch/X/VrDrQqf34bHx5FgV/IYETAmU6HxPDxVAiDwhEI8oGIYBcSBB1FAWdVkDeCJqQ4N4Jkn4Zkz58jSjPFwSJqmbE8Trm5tsn7XeZpSzBtRFHyPRiEMQ9bGY8bDEZPZlGmWWOFOXEyDKGVdUFUDfM9nL5mBKINoyPW8odaaKApIktncg7DKGrQs0cBDAp9YrBzZ9d0dyyngeyRZwunRGkVRkOY5nsAwjq34h0saGscDzohPURQkeUJVlDRVxaxpKLVhbTCkygt2trfNR2A8thwJTUlRVcyyjDzLGAxjTp8+S93UbG/vcPbsGbwwYjgcEvuRFT5p1JZDAx+tauqmJIpDdpMp01mJz9iWB//PdPONwkoIAeDmZ/4mo5zuM8QpiresyMjyS98a3dwplpZZRBbn0wPHyr7/W0QfAm4FYsGpqZW9SUlZNPihgNYo3vzyglJVsLdbURT1/ArtCW4WZftv/o4sDLmTesQEMkZrkEbx1VYuPKd1BZ5YemzxGAxiilrJs9Ky+sw1LGdMUxuRfVeltyhLbtzY4eKFi6RpTl4WDIYDE+9VQxSExGFIGAQk0ynZLJ0Lz7aQqIj5AdRNw9gbkGclTQ1+YBmA06xBaOZ1BkQaJAit2IhYlqBhHDNNZwyiAXWj7M32WD93HpzgCJ2WULmUYLU24HmW2yDPmeztEXg+ozg220Ce4586xe7uLtd3J4SDAePRmKIoqRuzTyCwu7tryUSc49E0mTGIIoaDEYGLVCwL80AMopAsyyzxiu9TlSXbk23StGQoayD+oU/IG4nVEQI3YVkCHjYyLo+8NuLIsi3BCQ0b3BfaxTy0V5ZeTV2M/7Ac699ODfbrIqqQzGp2tkvWL0X7jlL3QOztluxNCupG28TRR3i9W73o9sTA/BfbLweXIAgBPkO0Nu0lEN8q6IqYY47vEfhCWZdIA0Ho4xU1tfttl1OvZ1nmshOXeIFHrQ3XXtmAumH9/DmmSYLvuwSavsX6h35AXhRsbW2RTGfm8NM6KqkZ50Lfwo3zPKeqlOFQCbWhncF6oqZBlDVFXUFRoAJ5nhIHAf5oROzShJeVGWcHw4gwDgmiAK0aRF1BUfeDFWVBUVgKNMHKm9VuWhEFljkorwqysuIdb7vIaDCAuqFKS6hrZtMZN3a2uXDhAoIJ0DDwWRuNLLKyKudBUCJCHMWMRmPLTOT5TPYm3NieUOU+vn8GwUepbtWJbyhWzyZwC4Pgfmu5tgex7Pk3XxXYN+9esvYvlTLTJZOcrezr3ElItTlw7vZMS9WOnattWZVsXZuSZ6ZVtGY/EaHMPK5vZiSz3PZIe+WGhXlyv+vy4noHjYXOZKjNq35aRyHz/LvZ7Ght2HzT5WBUD9SzHy3whNEwwld7OMSTuWvt/Dd2/SMipFk2z7c/iGLqqmZrZ4drm5u85eJF1s+dszk+MBgMCKOYaBiT5hlXr71ia/XOFlHXba0+S7aZpolLDGJBRLMkdyG6FVXdkOelCx+2JJ2RZ2XUq6qkrkrqogaFNM/NeSiKmM2mpEniHJpMCyirkgY1ZyPPNy9CURoXKBVFpspHfkA2SxEJuHTXJUt6Iz4iPuPhiN29PXy3GjIajVgbjVkbjsjLgrSwgiNVbYFNYWgl2IuisKItVc00y7h+Yxshxmd8SzvTncAKawLL1mg3iqsic4chaB9KG+1l39Hzpbj50lxrFWjn9u6gdtmrnce3STU4aOxrk5wurqMN7O4mXLvq8ZZ7TlnAiBMOGxszrm+ZBd14BHNyqo0zhi90i4VXI+6l2G+Nvx0sn/PAnvl1G6y4muVGFOIoJA4juzkRmnpRiATP3+dZ2KjSuIq6gvnzC5DkOc+/+ALvfc9DDAcDxuOR5RcoKoq6pFbY3L7B5o3riO9ZaTAWhtAwDAmC0Dig5HnKcHgaT0KauiApM8ZrY8T3mKUpgR9wZjRmGMekecIgisjTzKIAg5C9WYLgUVYFVe0TBT55WeGLZURSbayAqSpNbf4HcRRQVy4fQGLZkAdxTACcHp/mwvl1tIEky0xQ+CHJbDYfVuM4JkAI8YjPnbFYDbVpViCwtjYyAyRiWYZFSJKEnckET0I8iVkMcHdkcjiH3Gm/5CORENkCZsB/u+byOnAXx5s/HP97OO784c7ewztV9cLBxpUQAgAi8oyqPtQ1j9vFcecPx/8ejjt/6OYeVs8m0KNHjzcVvRDo0eOEY5WEwNe6JvA6cdz5w/G/h+POHzq4h5WxCfTo0aMbrJIm0KNHjw7QuRAQkQ+JyEsi8jcReaJrPkeFiLwsIn92ZdmecW3nReRnIvJX932ua57LEJGnRWRTRJ5barslZ1dL8suuX54VkQe7Yz7neiv+T4nI1QMl8tp9n3P8XxKRD3bDegERebuI/FJEXhCR50Xk06692z64E5FqR/0APvB34DIQAX8CHuiS02vg/jJw14G2LwBPuO0ngM93zfMAv/cDDwLPvRpn4DHgJ5inyiPAb1aU/1PAZ29x7APueYqBe91z5nfM/27gQbd9CviL49lpH3StCTwM/E1V/6GqBfA94ErHnF4PrgDfdNvfBD7cHZWboaq/Am4caD6M8xXgW2r4NXBWrAR9ZziE/2G4AnxPVXNV/SdWIPfhO0buCFDVV1T1D257D3gReCsd90HXQuCtwL+X/v6PazsOUOCnIvJ7EfmEa7ukizLs14BL3VB7TTiM83Hqm085dfnppSnYSvMXkXuAdwO/oeM+6FoIHGe8T1UfBB4FPiki71/eqabPHaull+PIGfgqcB/wLuAV4IudsjkCRGQN+D7wGVXdXd7XRR90LQSuAm9f+vttrm3loapX3fcm8ENM1dxo1TX3vdkdwyPjMM7Hom9UdUNVa7WIq6+zUPlXkr+IhJgA+I6q/sA1d9oHXQuB3wH3i8i9YoXYHwd+3DGnV4WIjEXkVLsNfAB4DuP+MXfYx4AfdcPwNeEwzj8GPuos1I8AkyWVdWVwYI78EawfwPg/LiKxiNwL3A/89s3mtwyxsNFvAC+q6peWdnXbB11aS5csoH/BrLdPds3niJwvY5bnPwHPt7yBdeAXwF+BnwPnu+Z6gPd3MZW5xOaXHz+MM2aR/orrlz8DD60o/287fs+6l+bupeOfdPxfAh5dAf7vw1T9Z4E/us9jXfdB7zHYo8cJR9fTgR49enSMXgj06HHC0QuBHj1OOHoh0KPHCUcvBHr0OOHohUCPHiccvRDo0eOEoxcCPXqccPwPrDRn58AG3BkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def preprocess_img(img_dir):\n",
    "    img = image.load_img(img_dir, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return preprocess_input(img)\n",
    "\n",
    "\n",
    "def grad_cam(img_dir, model, layer_name):\n",
    "    grad_model = Model(inputs=[model.inputs], outputs=[model.get_layer(layer_name).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        img = preprocess_img(img_dir)\n",
    "        layer_output, predictions = grad_model(img)\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    gradients = tape.gradient(loss, layer_output)[0]\n",
    "    casted_layer_output = tf.cast(layer_output > 0, \"float32\")\n",
    "    casted_gradients = tf.cast(gradients > 0, \"float32\")\n",
    "    guided_gradients = casted_layer_output * casted_gradients * gradients\n",
    "\n",
    "    # Remove unnecessary dims\n",
    "    layer_output = layer_output[0]\n",
    "\n",
    "    weights = tf.reduce_mean(guided_gradients, axis=(0,1))\n",
    "    grad_cam = tf.reduce_sum(tf.multiply(weights, layer_output), axis=-1)\n",
    "\n",
    "    width, height = img.shape[2], img.shape[1]\n",
    "    heatmap = cv2.resize(grad_cam.numpy(), (width, height))\n",
    "    counter = heatmap - np.min(heatmap)\n",
    "    denominator = (heatmap.max() - heatmap.min())\n",
    "\n",
    "    scaled_heatmap = counter / denominator\n",
    "    \n",
    "    return scaled_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: block5_conv3. Existing layers are [<keras.engine.functional.Functional object at 0x000001CCDF11BBC8>, <keras.layers.core.flatten.Flatten object at 0x000001CE11C48948>, <keras.layers.core.dense.Dense object at 0x000001CE11D6ED88>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CE11BD30C8>, <keras.layers.core.dropout.Dropout object at 0x000001CE12087E48>, <keras.layers.core.dense.Dense object at 0x000001CE11C359C8>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CE1208E588>, <keras.layers.core.dropout.Dropout object at 0x000001CE1207B448>, <keras.layers.core.dense.Dense object at 0x000001CE12092B88>].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DOMINI~1\\AppData\\Local\\Temp/ipykernel_4264/3054802076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Dominik Hahn/Documents/GitHub/VisualAnalytics/data/images/VICE/xoKwbbnlxi0.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"block5_conv3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\DOMINI~1\\AppData\\Local\\Temp/ipykernel_4264/515050443.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[1;34m(img_dir, model, layer_name)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgrad_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Dominik Hahn\\Anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   2629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2631\u001b[1;33m       raise ValueError(f'No such layer: {name}. Existing layers are '\n\u001b[0m\u001b[0;32m   2632\u001b[0m                        f'{self.layers}.')\n\u001b[0;32m   2633\u001b[0m     raise ValueError('Provide either a layer name or layer index at '\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: block5_conv3. Existing layers are [<keras.engine.functional.Functional object at 0x000001CCDF11BBC8>, <keras.layers.core.flatten.Flatten object at 0x000001CE11C48948>, <keras.layers.core.dense.Dense object at 0x000001CE11D6ED88>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CE11BD30C8>, <keras.layers.core.dropout.Dropout object at 0x000001CE12087E48>, <keras.layers.core.dense.Dense object at 0x000001CE11C359C8>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CE1208E588>, <keras.layers.core.dropout.Dropout object at 0x000001CE1207B448>, <keras.layers.core.dense.Dense object at 0x000001CE12092B88>]."
     ]
    }
   ],
   "source": [
    "plt.imshow(grad_cam(\"C:/Users/Dominik Hahn/Documents/GitHub/VisualAnalytics/data/images/VICE/xoKwbbnlxi0.jpg\", xai_model, \"block5_conv3\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
